\global\long\def\gunderline#1{\mathunderline{greenunder}{#1}}%
\global\long\def\bef{\forwardcompose}%
\global\long\def\bbnum#1{\custombb{#1}}%
\global\long\def\pplus{{\displaystyle }{+\negmedspace+}}%


\chapter{Summary of the book\label{chap:Summary-of-the}}

The book has been written in a tutorial format, motivating and deriving
the results gradually. This makes it easier to learn but harder to
navigate. In this summary chapter, the results are listed without
detailed explanations or proofs, referring to the places of the book
where more detail is found.

\section{Main points and results by chapter}

\setcounter{secnumdepth}{1}%
\begin{comment}
All the following subsections will appear in the TOC but will be unnumbered.
The koma-script package does not have addsubsec. Another solution
could be: 

\% Package 'hyperref' needed for command '\textbackslash nameref'

\textbackslash subsection{*}\{Introduction\} 

\textbackslash label\{subsec:intro\} 

\textbackslash addcontentsline\{toc\}\{subsection\}\{\textbackslash nameref\{subsec:intro\}\}
\end{comment}


\subsection{Chapter~\ref{chap:1-Values,-types,-expressions,}}

Standard mathematical notation such as $\sum_{n=1}^{100}(n^{2}+n)$
implicitly uses nameless functions. Functional programming improves
upon this kind of mathematical notation by using nameless functions
explicitly and consistently. For example, the computation $\sum_{n=1}^{100}(n^{2}+n)$
is implemented in Scala as \lstinline!(1 to 100).map(n => n * n + n).sum!.

The methods \lstinline!sum! and \lstinline!product! are examples
of \textsf{``}aggregations\textsf{''} (functions that convert a collection of data
items to a single value). The method \lstinline!filter! selects some
elements from a sequence; \lstinline!takeWhile! truncates a sequence
once a certain condition is achieved. Those methods are examples of
\textsf{``}transformations\textsf{''} (functions that convert a collection to another
collection).

Functional programming means formulating the solution of a problem
as a mathematical expression and then translating the mathematical
formula into code. Mathematical formulas never use loops or modify
variables. Iteration is expressed using special operators such as
$\sum$. Functional programming encodes transformations and aggregations
via standard library functions such as \lstinline!map!, \lstinline!filter!,
\lstinline!zip!, \lstinline!flatMap!, etc., instead of loops.

\subsection{Chapter~\ref{chap:2-Mathematical-induction}}

Scala\textsf{'}s tuple types represent several values, each with its own fixed
type. Tuples support pattern-matching and are used often in the standard
library when manipulating collections. In particular, the methods
\lstinline!map!, \lstinline!filter!, \lstinline!zip!, \lstinline!flatMap!,
\lstinline!groupBy! use tuples when working with dictionaries (denoted
by \lstinline!Map! in Scala).

Because of strict type checking at each stage, it is safe to work
with collections via chains of those methods.

There are three sorts of tasks for working with collections: aggregation
(converting a sequence to a single value), generation (converting
a single value to a sequence), and transformation (converting a sequence
to another sequence). Aggregation is typically performed with \textsf{``}reduce-like\textsf{''}
functions (\lstinline!foldLeft!, \lstinline!foldRight!, \lstinline!reduce!,
etc.) Generating a new sequence often involves computing each next
element on demand, which can be done with iterators or streams. Transformation
is performed with \lstinline!map!, \lstinline!flatMap!, \lstinline!zip!,
and \lstinline!scan!.

If instead one wants to define a custom recursive function for working
with sequences, one should take care to use tail recursion when appropriate.

\subsection{Chapter~\ref{chap:Disjunctive-types}}

We begin by defining two basic building blocks for constructing new
types: case classes and disjunctive types. Case classes can be viewed
as tuples with names. Disjunctive types can be viewed as the familiar
\lstinline!enum! type enriched with arbitrary typed data for each
alternative. In Scala, disjunctive types (also known as tagged unions,
sum types, and co-product types) are typically implemented via \textsf{``}sealed
traits\textsf{''} and case classes.

Both case classes and disjunctive types support pattern matching and
recursive definitions. In addition to the standard disjunctive types
(\lstinline!Option!, \lstinline!Either!, \lstinline!Try!), the
user may define custom types via arbitrary combinations of case classes
and disjunctive types. This gives rise to a rich type system where
the programmer can define data types flexible enough to describe many
real-world domains, assuring safe treatment of corner cases. Examples
of such types are various list-like and tree-like data types. Functions
for working with those types are often recursive, just as the types
themselves are.

Compiler support for disjunctive types and pattern matching is absent
in most programming languages except for languages designed with functional
programming in mind. Disjunctive types give the programmer an important
degree of flexibility in terms of the \textsf{``}logic of types\textsf{''}. When a
programming language supports both product and co-product types (which
correspond to logical conjunctions and logical disjunctions), the
programmer can directly model problem domains where certain data may
be present, absent, or have a different type depending on circumstances.

\subsection{Chapter~\ref{chap:Higher-order-functions}}

Higher-order functions take function parameters and/or return new
functions. It takes some time to get used to working with higher-order
functions, so we begin with the easier example: curried functions.
The syntax for calling those functions in Scala looks like \lstinline!f(x)(y)!. 

A special sort of functions, called \textsf{``}fully parametric\textsf{''}, will play
an important role throughout this book. We show an example illustrating
what kind of functions can be converted to fully parametric ones. 

To visualize how functions are evaluated, we show several examples
of \textsf{``}symbolic calculation\textsf{''}: simulating program evaluation by hand.
This is an important exercise for understanding and gaining facility
with functional programming. One application of symbolic calculation
is to prove properties of functions. As a first example, we show proofs
for the identity law and the associativity law of function composition. 

A useful skill for a functional programmer is to be able to derive
the type of a function from its code. The Scala compiler has an algorithm
for type inference, which sometimes needs help from the programmer.
It is notable that, for some fully parametric functions, it is also
possible to perform \textsf{``}code inference\textsf{''}, that is, to derive a function\textsf{'}s
code from a given type signature. We show some examples of type inference
and code inference.

\subsection{Chapter~\ref{chap:5-Curry-Howard}}

Curry-Howard correspondence is between types $T$ and logical propositions
(statements) of the form \textsf{``}fully parametric code can compute a value
of type $T$ in a given program scope\textsf{''}. Propositions of that form
are called ${\cal CH}$-propositions.

From the point of view of ${\cal CH}$-propositions, type constructions
correspond to logical operations. Case classes (product types) correspond
to logical conjunctions, disjunctive types (also known as sum types
and co-product types) correspond to logical disjunctions, and function
types correspond to logical implications. This chapter starts developing
special short notation for types and for code that allows us to reason
about type expressions and code expressions more easily.

A proof of a ${\cal CH}$-proposition ${\cal CH}(T)$ corresponds
to some code that computes a value of type $T$. We show how code
can be extracted mechanically (that is, algorithmically) from a logical
proof tree. Then we explain the LJT algorithm for automatic proof
search. The LJT algorithm together with the technique of extracting
code from the proof enables us to derive fully parametric code from
a large class of type signatures.

Logical equivalence is not the same as type equivalence in the sense
that programmers would expect (that is, the situation when two types
carry equivalent information). We show how to recognize equivalent
types in a number of simple cases, and derive some general rules for
type equivalence (see Tables~\ref{tab:Logical-identities-with-disjunction-and-conjunction}\textendash \ref{tab:Logical-identities-with-function-types}
and the examples following).

The Curry-Howard correspondence clarifies the usefulness for specific
type constructions in a programming language and gives guidance for
language design in terms of formal logic. It is notable that the logic
required for the CH correspondence is not the familiar (\textsf{``}classical\textsf{''})
Boolean logic but a slightly different logic, known as \textsf{``}intuitionistic\textsf{''}
or \textsf{``}constructive\textsf{''}. We show some examples to illustrate the difference
between those logics.

\subsection{Chapter~\ref{chap:Functors,-contrafunctors,-and}}

This chapter begins the second part of the book, which is devoted
to a systematic analysis of various type constructions that produce
data structures with different properties. The first kind of data
structure to be analysed is \textsf{``}functors\textsf{''}.

We begin with a motivation for functors as containers or \textsf{``}wrappers\textsf{''}
of data. Those containers should have a \lstinline!map! method that
\textsf{``}lifts\textsf{''} functions of type \lstinline!A => B! into functions of
type \lstinline!F[A] => F[B]!. We examine a programmer\textsf{'}s expectations
for the behavior of the \lstinline!map! method for typical containers.
Those expectations are formulated as mathematical equations (or \textsf{``}laws\textsf{''})
that an implementation of \lstinline!map! must obey. In this way,
we arrive at the functor laws: the identity law and the composition
law.

Scala supports a special \lstinline!for!/\lstinline!yield! syntax
for chains of functor operations. In later chapters, we will see how
this syntax extends to conditionals and nested loops.

Looking at examples of some type constructors that \emph{cannot} have
the map method, we find that in certain cases a \lstinline!contramap!
method can be implemented. This motivates the concept of a contrafunctor
(short for \textsf{``}contravariant functor\textsf{''}). We show examples where we
implement the \lstinline!map! or the \lstinline!contramap! method
for different type constructors.

We introduce a condensed notation for the \lstinline!map! method,
because it is used very often in proofs. In that notation, the functor
laws are written especially concisely, as Eq.~(\ref{eq:functor-laws-in-short-notation})
shows.

Type constructors with two type parameters may be functors (or contrafunctors)
with respect to each type parameter separately. Bifunctors are functors
with respect to both type parameters. We briefly explain their properties.

Then we systematically go through all six standard type constructions:
fixed types, type parameters, product types, co-product types, function
types, and recursive types. In each case, we prove that new functors
(and contrafunctors) can be obtained from previously given ones. 

It follows that in every type expression, each type parameter can
be marked as being in a covariant or in a contravariant position.
This allows us to learn to recognize covariance and contravariance
quickly. The corresponding \lstinline!map! or \lstinline!contramap!
methods may be implemented through a mechanical procedure.

The existence of \lstinline!map! or \lstinline!contramap! methods
has a direct connection to subtyping. We use a simple definition of
subtyping via type conversion functions, and show that covariant and
contravariant functors naturally give rise to subtyping relations.
It is curious that a type conversion function (from a subtype to a
parent type) may be injective, surjective, or neither. If \lstinline!P!
is a subtype of \lstinline!Q!, it does \emph{not} mean that values
of type \lstinline!P! are a subset or a superset of values of type
\lstinline!Q!. We also prove that injective or surjective functions
remain injective or surjective after lifting to a functor. 

\subsection{Chapter~\ref{chap:Reasoning-about-code}}

This book uses certain non-standard notation to write types and code
more concisely. For instance, type parameters are written as superscripts
($F^{A}$ corresponds to the Scala syntax \lstinline!F[A]!). Functions
lifted via \lstinline!fmap! are denoted by arrows such as $f^{\uparrow F}$.
Matrices are used for functions working with co-product types. This
notation has its advantages but requires getting used to.

Chapter~\ref{chap:Reasoning-about-code} begins with a systematic
overview of the code notation, starting with the nine standard code
constructions and then going over the function composition, the pipe
notation, and the lifting notation. 

The main advantage of the code notation is in making proofs shorter
and easier to figure out. To build up intuition and experience with
symbolic derivations, we show how to prove some laws for functions
working with product and co-product types. We also explain some techniques
for proving laws involving arbitrary unknown functions.

\subsection{Chapter~\ref{chap:Typeclasses-and-functions}}

A \textsf{``}typeclass\textsf{''} is a mechanism for constraining type parameters
in generic functions. We show how a typeclass can be implemented by
passing evidence values in extra arguments. We show how to define
functions whose type parameters are constrained to belong to specific
typeclasses. While the function body is able to use the typeclass
methods, the types remain arbitrary and unspecified.

The verbosity of this implementation is reduced if one employs Scala\textsf{'}s
\textsf{``}implicit argument\textsf{''} feature. Another Scala feature is the \textsf{``}extension
method\textsf{''} syntax that allows one to write code as if a new method
can be added to an existing type at any time. We show that, depending
on the method\textsf{'}s type signature, some typeclass methods can be used
as extension methods while others cannot.

In Scala, typeclasses can be declared for type constructors as well
as for ordinary types. We show different ways of implementing such
typeclasses.

We show some examples of simple typeclasses (Table~\ref{tab:Examples-of-simple-typeclasses}).
For each typeclass, we perform structural analysis and determine which
type constructions may create new typeclass members from previous
ones. 

\begin{table}
\begin{centering}
\begin{tabular}{|c|c|c|}
\hline 
\textbf{\small{}Typeclass name} & \textbf{\small{}Evidence type for $T$} & \textbf{\small{}Summary of structural analysis}\tabularnewline
\hline 
\hline 
{\small{}}\lstinline!Extractor! & {\small{}$T\rightarrow Z$} & {\small{}Table~\ref{tab:Type-constructions-for-Extractor}}\tabularnewline
\hline 
{\small{}}\lstinline!Eq! & {\small{}$T\times T\rightarrow\bbnum 2$} & {\small{}Table~\ref{tab:Type-constructions-for-Eq}}\tabularnewline
\hline 
{\small{}}\lstinline!Semigroup! & {\small{}$T\times T\rightarrow T$} & {\small{}Table~\ref{tab:Type-constructions-for-semigroup}}\tabularnewline
\hline 
{\small{}}\lstinline!Monoid! & {\small{}$(T\times T\rightarrow T)\times T$} & {\small{}Table~\ref{tab:Type-constructions-for-monoid}}\tabularnewline
\hline 
{\small{}}\lstinline!Pointed! & {\small{}$\forall A.\,A\rightarrow T^{A}$} & {\small{}Table~\ref{tab:Type-constructions-for-pointed-functor}}\tabularnewline
\hline 
{\small{}}\lstinline!Copointed! & {\small{}$\forall A.\,T^{A}\rightarrow A$} & {\small{}Table~\ref{tab:Type-constructions-for-copointed-functor}}\tabularnewline
\hline 
{\small{}Pointed contrafunctor} & {\small{}$\forall A.\,T^{A}$} & {\small{}Table~\ref{tab:Type-constructions-for-pointed-contrafunctor}}\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:Examples-of-simple-typeclasses}Examples of simple typeclasses
from Section~\ref{sec:Typeclass-derivation-via-structural-analysis}.}
\end{table}

Solved examples and exercises are given to practice defining typeclasses
and various generic functions with typeclass constraints.

To develop a deeper understanding of typeclasses, we discuss various
topics: 
\begin{itemize}
\item How to determine when a recursive type has nontrivial values
\item How to prove associativity of the \lstinline!concat! operation for
sequences
\item What are higher-order type functions, and what are \textsf{``}kinds\textsf{''}
\item How to define and use typeclasses with several type parameters (\textsf{``}type
relations\textsf{''})
\item Inheritance and automatic conversion of typeclasses
\item Why many typeclasses have similar properties as regards typeclass
derivation; the concept of \textsf{``}$P$-typeclasses\textsf{''}
\item How typeclasses unify and generalize both algebraic data types and
object-oriented interfaces
\end{itemize}

\subsection{Chapter~\ref{chap:Filterable-functors}}

Filterable functors have just one more method (\lstinline!filter!)
in addition to ordinary functors having \lstinline!map!. We begin
by looking at practical examples of using the \lstinline!filter!
operation. The standard \lstinline!filter! method for sequences removes
all values that do not satisfy a given condition. However, we can
imagine different definitions of \lstinline!filter! where data items
are removed in other ways. To figure out what qualifies as a filtering
operation, we look at some examples and codify a programmer\textsf{'}s expectations
about how filtering should work. This allows us to derive four laws
that a filter function must satisfy. To aid intution, we also examine
a few examples of functors that \textsf{``}are not filterable\textsf{''} (do not support
a lawful filtering operation).

The four laws of filter are not easy to verify, so the next step is
to simplify those laws. We introduce new functions called \lstinline!deflate!
and \lstinline!liftOpt! and prove rigorously that their logic is
equivalent to the logic of \lstinline!filter!. However, \lstinline!deflate!
has only three laws and \lstinline!liftOpt! only two. 

Here for the first time this book embarks on rigorous proofs of laws,
so the derivations are performed step by step and written out in full
detail. To help the reader get used to the mathematical notation,
some derivations are duplicated in Scala syntax as well.

Armed with a concise formulation of the laws of \lstinline!liftOpt!,
we proceed to a structural analysis for filterable functors. We attempt
to discover all possible type constructions that produce new filterable
functors out of previously given ones.

In particular, we prove that the standard \lstinline!List! functor
admits \emph{two} lawful implementations of \lstinline!liftOpt!:
one corresponding to \lstinline!filter! and one corresponding to
\lstinline!takeWhile!. The \textsf{``}greedy\textsf{''} filtering logic of \lstinline!takeWhile!
can be straightforwardly generalized to many recursive functors.

Structural analysis turns out to require considering filterable \emph{contrafunctors}
as well. Filterable functors remove data items that fail a given predicate;
filterable contrafunctors avoid consuming such input items. We give
some motivation and code examples for the usage of filterable contrafunctors.
The results of structural analysis for filterable functors and contrafunctors
are shown in Tables~\ref{tab:Constructions-of-filterable-functors}\textendash \ref{tab:Constructions-of-filterable-contrafunctors}.

Further discussions explore some of this chapter\textsf{'}s topics in more
depth:
\begin{itemize}
\item We give an explanation for \textsf{``}naturality laws\textsf{''} and a summary of
various recipes for writing them.
\item By examining the laws of \lstinline!liftOpt!, we arrive at the concept
of \textsf{``}Kleisli functions\textsf{''} and a motivation for generalizing filterable
functors to $M$-filterable functors (where $M$ is any monad). 
\item We notice the similarity between the laws of several typeclasses and
the standard functor laws, which invites us to take a first glance
at category theory and its more general definition of functors. We
show that the laws of typeclasses can be derived from the laws of
categories and of categorical functors. This gives us assurance that
the typeclass laws are chosen in a consistent and useful way. We finish
with a summary of issues for which category theory has been either
helpful or not helpful in the context of functional programming.
\end{itemize}
This chapter studies filterable functors by following a pattern that
all further chapters in Part~II will also follow. Beginning with
working Scala code involving some operation, we motivate some mathematical
laws that describe a programmer\textsf{'}s expectation about that operation\textsf{'}s
behavior. Then we simplify those laws by introducing other, equivalent
operations that have simpler laws. We proceed to structural analysis
and discover what type constructions can support the given operation.

\subsection{Chapter~\ref{chap:Semimonads-and-monads}}

{*}{*}{*}

\subsection{Chapter~\ref{chap:8-Applicative-functors,-contrafunctors}}

{*}{*}{*}

\subsection{Chapter~\ref{chap:9-Traversable-functors-and}}

{*}{*}{*}

\subsection{Chapter~\ref{chap:Free-type-constructions}}

{*}{*}{*}

\subsection{Chapter~\ref{chap:monad-transformers}}

{*}{*}{*}

\subsection{Appendix~\ref{app:Proofs-of-naturality-parametricity}}

This appendix studies \textsf{``}parametricity\textsf{''} properties that apply to
all fully parametric code:

A given type constructor may have one fully parametric and lawful
implementation of the \lstinline!Functor! or \lstinline!Contrafunctor!
typeclass instance. (For most other typeclasses, such as \lstinline!Filterable!
or \lstinline!Monad!, type constructors often have several inequivalent
and lawful typeclass instances.) The unique implementations are defined
by the type constructions from Sections~\ref{subsec:f-Functor-constructions}
and~\ref{subsec:f-Contrafunctor-constructions}.

The lifting methods of any fully parametric bifunctor or profunctor
obey the commutativity law such as Eq.~(\ref{eq:f-fmap-fmap-bifunctor-commutativity}). 

Any fully parametric expression $t:\forall A.\,Q^{A}$ satisfies the
relational naturality law~(\ref{eq:relational-naturality-law-1}).
In general, the relational naturality law expresses a property of
\emph{relations} rather than functions and is not equivalent to any
equation satisfied by $t$. The chapter explains how relations are
defined and what operations are available for relations, and shows
the proof of the relational naturality law.

All fully parametric functions of type $P^{A,A}\rightarrow Q^{A,A}$
(where $P$, $Q$ are profunctors) obey the dinaturality law~(\ref{eq:dinaturality-law-for-profunctors}).
The form of the law depends only on the function\textsf{'}s type signature
and applies to all fully parametric implementations of that type signature.

If the type signature of $t$ satisfies the conditions of Statements~\ref{subsec:Statement-post-wedge-entails-strong-dinaturality}
or~\ref{subsec:Statement-functor-post-pre-wedge}, the function $t$
satisfies the \textsf{``}strong dinaturality\textsf{''} law~(\ref{eq:strong-dinaturality-law}).
Strong dinaturality gives more information than the ordinary dinaturality
law and is simpler to use than the general relational naturality law~(\ref{eq:relational-naturality-law-1}).

{*}{*}{*}

\setcounter{secnumdepth}{3}%
\begin{comment}
Restore the normal numbering of subsections and subsubsections
\end{comment}


\section{Topics not covered in this book}

This book focuses on mathematical theory that has proven its broad
relevance to the functional programming practice. This section lists
some topics that were omitted from this edition of the book, and explains
why.

\subsection{Trampolines and stack-safe recursion in functor blocks}

Recursion with applicative and monadic functors (say, a loop with
the free monad) can lead to stack overflows when the nesting of \lstinline!flatMap!
methods becomes too deep. There are certain tricks that can be used
to ensure stack safety. One of those tricks is known as \textsf{``}trampolines\textsf{''}.
Another trick is to use stack-safe implementations of various monads. 

Despite the practical significance of those techniques, this book
does not discuss them in detail. Trampolines are already well described
in the book \textsf{``}Functional programming in Scala\textsf{''}. Stack-safe implementations
of standard monads have better performance but are mathematically
equivalent to the same monads implemented via simple, non-stack-safe
code. There is no new theory to be developed and no new laws to be
proved about code that is specially engineered to be stack-safe.

\subsection{Strictness and laziness}

Scala can define values via one of the three evaluation strategies:
eager (also known as \textsf{``}strict\textsf{''}), lazy (\textsf{``}non-strict\textsf{''}), or on-demand.
Eager values are computed immediately as they are defined; lazy values
are computed only on first use and then stored in memory; on-demand
values are computed every time they are used. 

In the functional programming paradigm, it is rare that an algorithm
or a data structure works correctly only when certain values are defined
as lazy. This book focuses on the properties of functional programs
and their types that do not use strictness or laziness in an essential
way. For instance, the laws of a functor are the same and need to
be verified via the same proof regardless of whether the program code
uses strict or lazy functor values. 

\subsection{Combined typeclasses and their laws}

Sequences and trees are perhaps the most frequently used data structures.
Those data structures have at once the properties of several typeclasses:
\lstinline!Functor!, \lstinline!Filterable!, \lstinline!Monad!,
\lstinline!Applicative!, and \lstinline!Traversable!. It turns out
that the methods of various typeclasses satisfy not only the laws
of their own typeclass but also additional laws that express a kind
of compatibility between different typeclasses. For example, the law~(\ref{eq:compatibility-law-deflate-flatten})
expresses compatibility between \lstinline!Filterable!\textsf{'}s \lstinline!deflate!
and \lstinline!Monad!\textsf{'}s \lstinline!flatten! methods.

This book does not systematically study the possible combinations
between the major typeclasses and the relevant compatibility laws
that could be imposed. There does not seem to be a general way of
motivating and deriving the properties and laws of a typeclass defined
by combining any two given typeclasses.

\subsection{Lenses, prisms, and other \textquotedblleft functional optics\textquotedblright}

Lenses are a type constructor with methods that represent the operations
of reading and updating a part of a large data structure while keeping
all other parts unchanged. The theory and laws of lenses are complicated
and do not seem to have been fully explored (for instance, it appears
that lenses that violate certain laws are nevertheless necessary in
practice). 

Apart from lenses, a large range of other \textsf{``}optics\textsf{''} types (\textsf{``}prisms\textsf{''},
\textsf{``}grates\textsf{''}, etc.) has been discovered. Practical applications of
those \textsf{``}optics\textsf{''} remains to be explored.

\subsection{Comonads and comonad transformers}

A comonad is a functor $F$ with two additional methods called \lstinline!extract!
and \lstinline!duplicate!:
\[
\text{ex}_{F}:\forall A.\,F^{A}\rightarrow A\quad,\quad\quad\text{dupl}_{F}:\forall A.\,F^{A}\rightarrow F^{F^{A}}\quad.
\]
The type signatures of those methods are similar to the type signatures
of the monads\textsf{'} methods \lstinline!pure! and \lstinline!flatten!
except that the function arrows point in the opposite direction:
\[
\text{pu}_{F}:\forall A.\,A\rightarrow F^{A}\quad,\quad\quad\text{ftn}_{F}:\forall A.\,F^{F^{A}}\rightarrow F^{A}\quad.
\]
The comonad\textsf{'}s methods must also satisfy the appropriate laws. Similarly
to monads, two comonads can be combined via \textsf{``}comonad transformers\textsf{''}
into a larger comonad. An example of a comonad is the non-empty list
(\lstinline!NEL!). There is also a \textsf{``}co-free comonad\textsf{''} construction,
analogous to the free monad.

Although the properties of comonads have many similarities to those
of monads, this book does not develop the corresponding theory because
comonads do not appear to have nearly as wide a range of applications
in practical programming as monads do.

\subsection{Dependent types}

Scala has limited support for dependent types\index{dependent type}.
While there are occasional uses for those types in some Scala libraries,
most functional programming practice today is formulated with traditional
types that are fully determined at compile time and do not depend
on run-time values. This book does not develop the theory of dependent
types as that theory is quite complicated and yet limited in practical
applications.

\subsection{Linear types}

Some programming languages include features that go beyond the type
system described in this book. For example, the Rust language has
special features of the type system (the \textsf{``}borrow checker\textsf{''}) that
describe memory allocation ownership and lifetimes. In that way, Rust
programs can manage memory explicitly and verify at compile time that
programs never attempt to deallocate memory at the wrong place or
at the wrong time, or to write data to protected (\textsf{``}borrowed\textsf{''})
memory locations. The Rust type system uses some features of \textbf{linear
types} \index{linear types}\index{types!linear}(describing values
that can be used only once).

Features of that kind are complicated and not widely used in the functional
programming community. A Scala library for linear-type programming
is \lstinline!libretto!.\footnote{See \texttt{\href{https://github.com/TomasMikula/libretto}{https://github.com/TomasMikula/libretto}}}
This book focuses on the type system features that are both widely
used and well-understood.

\subsection{Effect systems}

Algebraic effects are currently an active topic of research and experimentation.
The basic idea of an effect system is to use type signatures that
indicate precisely what side effects a function may execute when it
is evaluated. For instance, there is one effect type for printing
to the console, another effect type for querying a database, yet another
for running code via parallel threads, and so on. The type system
of Scala is flexible enough to accommodate complicated type signatures
that can mix and match effects in an application-specific way.

Libraries such as \lstinline!cats-effect!\footnote{See \texttt{\href{https://github.com/typelevel/cats-effect}{https://github.com/typelevel/cats-effect}}}
and \lstinline!zio!\footnote{See \texttt{\href{https://github.com/zio/zio}{https://github.com/zio/zio}}}
provide some simple ways of managing effects, mostly focusing on concurrent
programming. Several advanced Scala libraries for effect-oriented
programming, such as \lstinline!kyo!\footnote{See \texttt{\href{https://github.com/getkyo/kyo}{https://github.com/getkyo/kyo}}}
and \lstinline!yaes!,\footnote{See \texttt{\href{https://github.com/rcardin/yaes}{https://github.com/rcardin/yaes}}}
have been created recently. It is perhaps too early to say what form
of effect-oriented programming will gain wide use.

\section{Additional exercises and open problems\label{chap:Exercises-in-AFTT}}

The following is a sample set of problems that can be solved using
techniques developed in this book.

\subsection{Exercises\index{exercises}}

\subsubsection{Exercise \label{par:Exercise-additional}\ref{par:Exercise-additional}}

Write a function for finding the smallest integer expressible as a
sum of two cubed integers in more than one way.

\subsubsection{Exercise \label{par:Exercise-additional-1}\ref{par:Exercise-additional-1}}

Implement a function \lstinline!norepeat! that removes consecutive
repetitions from sequences:
\begin{lstlisting}
def norepeat[A]: Seq[A] => Seq[A] = ???

scala> norepeat(Seq(1, 2, 2, 1, 1, 3, 3, 3, 0, 3))
res0: Seq[Int] = Seq(1,2,1,3,0,3)
\end{lstlisting}


\subsubsection{Exercise \label{par:Exercise-additional-2}\ref{par:Exercise-additional-2}}

Read a text file, split it by spaces into words, and print the word
counts in decreasing order.%
\begin{comment}
\begin{enumerate}
\item FPIS exercise 2.2: Check whether a sequence \lstinline!Seq[A]! is
sorted according to a given ordering function of type \lstinline!(A, A) => Boolean!.
\item FPIS exercise 3.24: Implement a function \lstinline!hasSubsequence!
that checks whether a \lstinline!List! contains another \lstinline!List!
as a subsequence. For instance, \lstinline!List(1,2,3,4)! would have
\lstinline!List(1,2)!, \lstinline!List(2,3)!, and \lstinline!List(4)!
as subsequences, among others. (Dynamic programming?)
\end{enumerate}
\end{comment}


\subsubsection{Exercise \label{par:Exercise-additional-3}\ref{par:Exercise-additional-3}\protect\footnote{Exercise 4-1 from Hu Zhenjiang\textsf{'}s course \texttt{\protect\href{http://www.prg.nii.ac.jp/course/2015/msp15/}{http://www.prg.nii.ac.jp/course/2015/msp15/}}.}}

Express the \lstinline!filter! method for sequences via \lstinline!flatMap!:
\begin{lstlisting}
def filter[A](p: A => Boolean)(s: Seq[A]): Seq[A] = s.flatMap { a => ??? }
\end{lstlisting}


\subsubsection{Exercise \label{par:Exercise-additional-5}\ref{par:Exercise-additional-5}}

Define a monoid of partial functions with fixed types $P\rightarrow Q$:
\begin{lstlisting}
final case class PFM[P, Q](pf: PartialFunction[P, Q])
// After defining a monoid instance, the following code must work:
val p1 = PFM[Option[Int], String] { case Some(3) => "three" }
val p2 = PFM[Option[Int], String] {
  case Some(20)   => "twenty"
  case None       => "empty"
}
val p3 = p1 |+| p2 // Must be the same as the concatenation of all `case` clauses.
\end{lstlisting}


\subsubsection{Exercise \label{par:Exercise-additional-6-1-1}\ref{par:Exercise-additional-6-1-1}\protect\footnote{This was posted in \texttt{\protect\href{https://cstheory.stackexchange.com/questions/53294}{https://cstheory.stackexchange.com/questions/53294}}}}

Find a general type signature for the expression $a\rightarrow a(y\rightarrow t\rightarrow t)(z(a))$. 

\subsubsection{Exercise \label{par:Exercise-additional-4-1}\ref{par:Exercise-additional-4-1}}

For any functors $F$ and $G$, show that:

\textbf{(a)} There is a natural transformation of type $F^{A}\times G^{A}\rightarrow F^{A}$.

\textbf{(b)} There is a natural transformation of type $F^{A}\rightarrow F^{A}+G^{A}$.

\subsubsection{Exercise \label{par:Exercise-additional-4}\ref{par:Exercise-additional-4}\protect\footnote{R.~Bird and O.~de Moor, \emph{Algebra of programming} (1996), page
20.}}

Derive the following identity between functions $F^{A}\rightarrow F^{A}$,
for any filterable functor $F$ and any predicate $p^{:A\rightarrow\bbnum 2}$:
\[
\text{filt}_{F}(p)=(\Delta\bef\text{id}\boxtimes p)^{\uparrow F}\bef\text{filt}_{F}(\pi_{2})\bef\pi_{1}^{\uparrow F}\quad.
\]


\subsubsection{Exercise \label{par:Exercise-additional-1-9}\ref{par:Exercise-additional-1-9}}

\textbf{(a)} For any polynomial functor $F$ (not necessarily a monad),
show that there exists a fully parametric function we call \lstinline!leaf!,
of type $F^{F^{\bbnum 0}}\rightarrow F^{\bbnum 0}$, obeying the following
special identity law:
\[
\text{absurd}^{\uparrow F}\bef\text{leaf}=\text{id}\quad.
\]
\[
\xymatrix{\xyScaleY{0.3pc}\xyScaleX{3.5pc} & F^{F^{\bbnum 0}}\ar[rd]\sp(0.5){\ \text{leaf}}\\
F^{\bbnum 0}\ar[ru]\sp(0.5){(\text{absurd}^{:\bbnum 0\rightarrow F^{\bbnum 0}})^{\uparrow F}\ \ }\ar[rr]\sb(0.5){\text{id}\,} &  & F^{\bbnum 0}
}
\]

\textbf{(b)} Show that a function of type $F^{F^{\bbnum 0}}\rightarrow F^{\bbnum 0}$
cannot be implemented fully parametrically for some non-polynomial
functors $F$.

\subsubsection{Exercise \label{par:Exercise-additional-1-10}\ref{par:Exercise-additional-1-10}}

Let $T$ be the Church encoding of the least fixpoint of a given functor
$F$:
\[
T\triangleq\forall A.\,(F^{A}\rightarrow A)\rightarrow A\quad.
\]

\textbf{(a)} Show that there exists a function \lstinline!inT! of
type $F^{\bbnum 0}\rightarrow T$.

\textbf{(b)} When $F$ is a \emph{polynomial} functor, show that \lstinline!inT!
has a left inverse ($\text{outT}:T\rightarrow F^{\bbnum 0}$), which
means that \lstinline!inT! is injective (and \lstinline!outT! is
surjective).

\subsubsection{Exercise \label{par:Exercise-additional-6-1}\ref{par:Exercise-additional-6-1}}

Consider the method \lstinline!sequence: L[F[A]] => F[L[A]]! (denoted
by $\text{seq}_{L}^{F}$) that assumes a traversable functor $L$
and an applicative functor $F$. If we set $F=\text{List}$ and also
$L=\text{List}$ then we obtain the type signature $\text{seq}_{\text{List}}^{\text{List}}:\text{List}^{\text{List}^{A}}\rightarrow\text{List}^{\text{List}^{A}}$.
A data structure of type $\text{List}^{\text{List}^{A}}$ may be used
to represent a rectangular matrix. Show that the function $\text{seq}_{\text{List}}^{\text{List}}$
transposes the rectangular matrix.

\subsubsection{Exercise \label{par:Exercise-additional-7}\ref{par:Exercise-additional-7}}

The non-empty list (\lstinline!NEL!) has a \lstinline!flatten! method
as shown in Exercise~\ref{subsec:Disjunctive-Exercise-non-empty-list-2-1}.
However, we may use the type equivalence:
\[
\text{NEL}^{A}\cong A\times\text{List}^{A}\quad,
\]
which expresses \lstinline!NEL! as a product of two monads (the identity
monad and the \lstinline!List! monad). Show that the monad product
construction (Statement~\ref{subsec:Statement-monad-semimonad-product})
implements a different monad structure for \lstinline!NEL!.

\subsubsection{Exercise \label{par:Exercise-additional-7-2}\ref{par:Exercise-additional-7-2}}

Given a monad $M$ and a fixed type $Z$, consider the functor $F^{A}\triangleq(A\rightarrow M^{Z})\rightarrow Z$.
Show that $F$ is a semimonad but not a full monad. Hint: use the
flipped Kleisli technique.

\subsubsection{Exercise \label{par:Exercise-additional-7-1}\ref{par:Exercise-additional-7-1}\protect\footnote{See \texttt{\protect\href{https://cstheory.stackexchange.com/questions/54227}{https://cstheory.stackexchange.com/questions/54227}}}}

A monad $M$\textsf{'}s \lstinline!flatMap! method obeys the naturality law:
\[
\text{flm}_{M}(g\bef h^{\uparrow M})=\text{flm}_{M}(g)\bef h^{\uparrow M}\quad.
\]
This law holds with an arbitrary function $h:A\rightarrow B$. Show
that one cannot replace $h^{\uparrow M}$ in this law by an arbitrary
function $k:M^{A}\rightarrow M^{B}$. Namely, for some monads $M$
and some functions $g$, $k$ (of appropriate types) we will have
$\text{flm}_{M}(g\bef k)\neq\text{flm}_{M}(g)\bef k$.

\subsubsection{Exercise \label{par:Exercise-additional-18-1}\ref{par:Exercise-additional-18-1}}

Find fully parametric implementations of the type signatures:

\begin{lstlisting}
def a[A, B, C]: ((C => B) => A) => B => A
def b[A, B]: (((A => B) => B) => B) => A => B
def c[A, B]: ((((A => B) => A) => A) => B) => B
def d[A, B, C]: (((A => B) => C) => A => B) => (B => C) => A => B
def e[A, B, C]: ((B => C) => A => B) => ((A => B) => C) => A => B
\end{lstlisting}


\subsubsection{Exercise \label{par:Exercise-additional-18}\ref{par:Exercise-additional-18}}

Show that the following type signatures have \emph{no} fully parametric
implementations:

\begin{lstlisting}
def f[A]: Option[A] => A
def g[A, B]: (A => B) => A
def h[A, B]: (A => B) => B => A
def k[A, B, C]: (A => B) => (B => C) => C => A
def l[A, B]: ((((A => B) => B) => A) => B) => B
\end{lstlisting}

Hint: set some type parameters to the void type (\lstinline!Nothing!).

\subsubsection{Exercise \label{par:Exercise-additional-8}\ref{par:Exercise-additional-8}}

Given two fixed types $P$, $Q$ that are not known to be equivalent,
consider the contrafunctors $F^{A}\triangleq\left(\left(A\rightarrow P\right)\rightarrow P\right)\rightarrow Q$
and $G^{A}\triangleq A\rightarrow Q$. Show that there exist natural
transformations $F\leadsto G$ and $G\leadsto F$. Show that these
transformations are \emph{not} isomorphisms.

\subsubsection{Exercise \label{par:Exercise-additional-9}\ref{par:Exercise-additional-9}}

Given two fixed types $P$, $Q$ that are not known to be equivalent,
show that the functor $L^{A}\triangleq\left(\left(\left(A\rightarrow P\right)\rightarrow Q\right)\rightarrow Q\right)\rightarrow P$
is a semimonad but not a full monad. (When $P\cong Q$, the functor
$L$ is then equivalent to a composition of the continuation monad
with itself; that is also only a semimonad. See Exercise~\ref{subsec:Exercise-monad-composition-mm}.)

\subsubsection{Exercise \label{par:Exercise-additional-9-1}\ref{par:Exercise-additional-9-1}}

For any fully parametric contrafunctor $F$ that does not explicitly
use the void type\index{void type} ($\bbnum 0$) in its type expression,
show that the type of fully parametric functions $\forall A.\,F^{A}\rightarrow A$
is void. Show that the condition of not using the void type is necessary,
as the contrafunctor $F^{A}\triangleq(\bbnum 0\rightarrow A)\rightarrow\bbnum 0$
would be a counterexample:
\[
\forall A.\,F^{A}\rightarrow A=\forall A.\,((\bbnum 0\rightarrow A)\rightarrow\bbnum 0)\rightarrow A\cong((\bbnum 0\rightarrow\bbnum 0)\rightarrow\bbnum 0)\rightarrow\bbnum 0\cong\bbnum 1\quad.
\]
The type equivalence $\forall A.\,F^{A}\rightarrow A\cong\bbnum 0$
means that we cannot extract values of type $A$ from a value of type
$F^{A}$. This agrees with the intuition that value of type $F^{A}$
\textsf{``}do not store\textsf{''} any values of type $A$.

\subsubsection{Exercise \label{par:Exercise-additional-11}\ref{par:Exercise-additional-11}}

If $M$ is any monad then $L^{A}\triangleq M^{A+M^{A}}$ is also a
lawful monad.

\subsubsection{Exercise \label{par:Exercise-additional-10}\ref{par:Exercise-additional-10}}

If $M$ is a semimonad then $M\circ M\circ...\circ M$ (with finitely
many $M$) is also a lawful semimonad.

\subsubsection{Exercise \label{par:Exercise-additional-12}\ref{par:Exercise-additional-12}}

If $M$ is a commutative monad then $M\circ M$ is also a lawful commutative
monad.

\subsubsection{Exercise \label{par:Problem-monads-1}\ref{par:Problem-monads-1}}

\footnote{This was an open problem but it was solved by Hew Wolff.}
Prove that $L^{A}\triangleq\bbnum 1+\underbrace{A\times A\times...\times A}_{n\text{ times}}$
cannot be made into a monad if $n\ge2$.

\subsubsection{Exercise \label{par:Exercise-additional-13-1}\ref{par:Exercise-additional-13-1}}

If $M$ is a commutative monad and $W$ is a commutative monoid then
the monoid $M^{W}$ is commutative.

\subsubsection{Exercise \label{par:Exercise-additional-14}\ref{par:Exercise-additional-14}}

Define a type constructor \lstinline!Triang[A]! representing \textsf{``}triangular
matrices\textsf{''} with elements of type \lstinline!A!. Example values $t_{1}$,
$t_{2}$, $t_{3}$ of type \lstinline!Triang[A]! are:
\[
t_{1}=\left|\begin{array}{c}
a_{1}\end{array}\right|\quad,\quad\quad t_{2}=\left|\begin{array}{cc}
a_{1}\\
a_{2} & a_{3}
\end{array}\right|\quad,\quad\quad t_{3}=\left|\begin{array}{cccc}
a_{1}\\
a_{2} & a_{3}\\
a_{4} & a_{5} & a_{6}\\
a_{7} & a_{8} & a_{9} & a_{10}
\end{array}\right|\quad.
\]
Unlike \lstinline!List[List[A]]!, it should \emph{not} be possible
to have a value of type \lstinline!Triang[A]! that has an unexpected
shape:
\[
t=\left|\begin{array}{cccc}
a_{1}\\
a_{2} & a_{3}\\
a_{7} & a_{8} & a_{9} & a_{10}
\end{array}\right|\quad\text{is not of type }\text{Triang}^{A}\quad.
\]
 Implement \lstinline!Functor!, \lstinline!Applicative!, and \lstinline!Traversable!
instances for \lstinline!Triang!.

\subsubsection{Exercise \label{par:Exercise-additional-15}\ref{par:Exercise-additional-15}}

Simplify the type $\forall A.\,((A\rightarrow A)\rightarrow A)\rightarrow A$,
or in Scala:
\begin{lstlisting}
def f[A]: ((A => A) => A) => A
\end{lstlisting}
into a type expression that contains no quantifiers. Show how to implement
all possible values of this type. \footnote{See \texttt{\href{https://cstheory.stackexchange.com/questions/53855/}{https://cstheory.stackexchange.com/questions/53855/}}}

\subsubsection{Exercise \label{par:Problem-Peirce-law}\ref{par:Problem-Peirce-law}}

Consider the functor $F$ defined by:
\[
F^{R}\triangleq\forall A.\,((A\rightarrow R)\rightarrow A)\rightarrow A\quad,
\]
where all functions of type $F^{R}$ are assumed to be fully parametric.
Show that $F^{R}\cong R$.\footnote{See \texttt{\href{https://cstheory.stackexchange.com/questions/51945/}{https://cstheory.stackexchange.com/questions/51945/}}}

Note that \index{Peirce\textsf{'}s law}Peirce\textsf{'}s law (see Eq.~(\ref{eq:ch-example-3-peirce-law}))
is expressed as the type $\forall R.\,F^{R}$. Peirce\textsf{'}s law does not
hold in the constructive logic. The Curry-Howard correspondence says
that the corresponding type $\forall R.\,F^{R}$ should be void, and
it is: $\forall R.\,F^{R}=\forall R.\,R=\bbnum 0$. 

\subsubsection{Exercise \label{par:Problem-Peirce-law-2}\ref{par:Problem-Peirce-law-2}}

Prove the following type equivalences (assuming a fixed type $P$):

\begin{tabular}{|c|c|}
\hline 
\textbf{\footnotesize{}Quantified type} & \textbf{\footnotesize{}Equivalent type}\tabularnewline
\hline 
\hline 
$\forall A.\,(A\rightarrow A)\rightarrow P$ & $P$\tabularnewline
\hline 
$\forall A.\,(A\rightarrow A)\rightarrow A$ & $\bbnum 0$\tabularnewline
\hline 
$\forall A.\,(A\rightarrow A)\rightarrow A+P$ & $P$\tabularnewline
\hline 
$\forall A.\,((A\rightarrow A)\rightarrow A)\rightarrow P$ & $P$\tabularnewline
\hline 
\end{tabular}

\subsubsection{Exercise \label{par:Exercise-additional-16-2}\ref{par:Exercise-additional-16-2}}

Consider the type constructor $F$ defined by:
\[
F^{R,S}\triangleq\forall A.\,((R\rightarrow A)\rightarrow S)\rightarrow A\quad,
\]
where all functions of type $F^{R,S}$ are assumed to be fully parametric.
Show that $F^{R,S}\cong\bbnum 0$ unless we set $R=S=\bbnum 0$, in
which case $F^{\bbnum 0,\bbnum 0}\cong\bbnum 1$. 

\subsubsection{Exercise \label{par:Exercise-additional-16-2-1}\ref{par:Exercise-additional-16-2-1}}

\textbf{(a)} Prove the type equivalence:
\[
\forall A.\,F^{A}\rightarrow E+A\cong\forall B.\,F^{B}\rightarrow(E\rightarrow B)\rightarrow B\quad,
\]
where $E$ is a fixed type and $F$ is any covariant functor.

\textbf{(b)} Show that this type equivalence does \emph{not} hold
for non-covariant $F$ (e.g., if $F$ is contravariant or if $F^{A}=A\rightarrow A$).

\subsubsection{\label{par:Exercise-additional-16}\ref{par:Exercise-additional-16}}

Define a monad transformer $T_{\text{Cod}_{F}^{L}}^{M,A}$ for the
composed codensity monad (Exercise~\ref{subsec:Exercise-combined-codensity-monad})
with type parameters $F$ (an arbitrary but fixed functor), $L$ (an
arbitrary but fixed monad), $M$ (a foreign monad), and $A$ (the
value type). Find out which laws hold for that transformer.

\subsubsection{Exercise \label{par:Exercise-additional-16-1}\ref{par:Exercise-additional-16-1}}

Consider the (non-covariant) type constructor $G^{A}\triangleq A\rightarrow A$.\footnote{See \texttt{\href{https://stackoverflow.com/questions/72490608/}{https://stackoverflow.com/questions/72490608/}}
for discussion about monads having multiple transformers.}

\textbf{(a)} Show that codensity monad on $G$ ($\text{Cod}^{G,\bullet}$)
is equivalent to \lstinline!List! via monad morphisms.

\textbf{(b)} Show that the corresponding monad transformer: 
\[
T_{\text{Cod}^{G}}^{M,A}\triangleq\forall R.\,(A\rightarrow M^{G^{R}})\rightarrow M^{G^{R}}=\forall R.\,(A\rightarrow M^{R\rightarrow R})\rightarrow M^{R\rightarrow R}
\]
is \emph{not} equivalent to the \lstinline!List! monad\textsf{'}s standard
transformer (\lstinline!ListT!) shown in Section~\ref{subsec:Transformer-for-the-List-monad}.

\textbf{(c)} Show that the type constructor $U$ defined by:
\[
U^{M,A}\triangleq\forall R.\,(A\rightarrow G^{M^{R}})\rightarrow G^{M^{R}}=\forall R.\,(A\rightarrow M^{R}\rightarrow M^{R})\rightarrow M^{R}\rightarrow M^{R}
\]
is also a lawful monad transformer (with the foreign monad $M$) for
the \lstinline!List! monad. Show that the transformer $U$ (known
as the \textsf{``}\lstinline!LogicT! monad transformer\textsf{''}\footnote{See \texttt{\href{https://github.com/Bodigrim/logict}{https://github.com/Bodigrim/logict}}
for an example implementation in Haskell.}) is not equivalent to that defined in \textbf{(b)}. 

\textbf{(d)} Generalize \textbf{(c)} using an arbitrary (covariant)
functor $F$ and two fixed types $P$, $Q$:
\[
V^{F,P,Q,M,A}\triangleq\forall R.\,(A\rightarrow F^{M^{R}}\rightarrow P\times M^{R}+Q)\rightarrow F^{M^{R}}\rightarrow P\times M^{R}+Q\quad.
\]
Show that there exists a monad morphism $M^{A}\rightarrow V^{F,P,Q,M,A}$,
and that the converse function of type $V^{F,P,Q,M,A}\rightarrow M^{A}$
exists when $Q=\bbnum 0$ (but is \emph{not} a monad morphism).

\textbf{(e)} Show that the Church-encoded free monoid on $A$ (see
Section~\ref{subsec:Church-encodings-for-free-P-typeclasses}):
\[
\text{FM}^{A}\triangleq\forall X^{:\text{Monoid}}.\,(A\rightarrow X)\rightarrow X
\]
can be modified to the type constructor denoted by \lstinline!FMT!:
\[
\text{FMT}^{M,A}\triangleq\forall X^{:\text{Monoid}}.\,(A\rightarrow M^{X})\rightarrow M^{X}\quad,
\]
which is a lawful monad transformer (with the foreign monad $M$)
for the \lstinline!List! monad. Show that this transformer is not
equivalent to the transformers defined in \textbf{(b)}, \textbf{(c)}. 

\subsubsection{Exercise \label{par:Exercise-additional-17}\ref{par:Exercise-additional-17}}

\textbf{(a)} For any fixed type $Z$, functor $F$ and lawful monad
$P$, show that $L^{A}\triangleq F^{A\rightarrow P^{Z}}\rightarrow P^{A}$
is a lawful monad.

\textbf{(b)} Show that $L$\textsf{'}s monad transformer is $T_{L}^{M,A}\triangleq F^{A\rightarrow T_{P}^{M,Z}}\rightarrow T_{P}^{M,A}$,
where $T_{P}^{M,A}$ is $P$\textsf{'}s monad transformer.

\subsection{Open problems\index{open problems}}

The author of this book does not know how to answer the following
questions and also could not find any answers in existing books or
papers.

\subsubsection{Problem \label{subsec:Statement-filtering-recursive-type-church}\ref{subsec:Statement-filtering-recursive-type-church}}

If a bifunctor $S$ supports a function called \lstinline!liftE!:
\[
\text{liftE}_{S}^{A,B,R}:(A\rightarrow\bbnum 1+B)\rightarrow S^{A,R}\rightarrow R+S^{B,R}\quad,
\]
such that that suitable laws hold:
\begin{align*}
{\color{greenunder}\text{naturality-identity law}:}\quad & \text{liftE}_{S}^{A,B,R}(f^{:A\rightarrow B}\bef\text{pu}_{\text{Opt}}^{B})=f^{\uparrow S^{\bullet,R}}\bef(s^{:S^{B,R}}\rightarrow\bbnum 0^{:R}+s)\quad,\\
{\color{greenunder}\text{composition law}:}\quad & \text{liftE}_{S}^{A,B,R}(f^{:A\rightarrow\bbnum 1+B})\bef\,???\,\bef\text{liftE}_{S}^{B,C,R}(g^{:B\rightarrow\bbnum 1+C})=\text{liftE}_{S}^{A,C,R}(f\diamond_{_{\text{Opt}}}g)\quad,\\
{\color{greenunder}\text{naturality law in }R:}\quad & (g^{:Q\rightarrow R})^{\uparrow S^{A,\bullet}}\bef\text{liftE}_{S}^{A,B,R}(f)=\text{liftE}_{S}^{A,B,Q}(f)\bef g^{\uparrow U^{B,\bullet}}\quad,
\end{align*}
show that the functor $F^{A}\triangleq S^{A,F^{A}}$ is filterable.
Here, the bifunctor $U$ is defined by:
\[
U^{B,R}\triangleq R+S^{B,R}\quad,
\]
and the composition law for \lstinline!liftE! is to be made more
specific.

\subsubsection{Problem \label{subsec:Exercise-function-type-construction-not-applicative}\ref{subsec:Exercise-function-type-construction-not-applicative}}

Suppose $P$ and $Q$ are fixed but unknown types, and define the
functor $F$ by $F^{A}\triangleq(A\rightarrow P)\rightarrow Q$. Is
the functor $F$ applicative? Is $F$ a monad?

To make these questions non-trivial, assume that $P$ and $Q$ are
not void and not unit types, and not isomorphic to each other. (In
case $P\cong Q$, we find that $F$ is equivalent to a continuation
monad.) Specific examples are the functors $(A\rightarrow\text{Int})\rightarrow\text{Bool}$
and $(A\rightarrow\text{Bool})\rightarrow\text{Int}$. Are either
of these functors applicative or monadic?

Note that $F$ will have a \lstinline!pure! method if we have a value
of type $F^{\bbnum 1}\cong P\rightarrow Q$. What additional data
about $P$ and $Q$ is necessary to make $F$ applicative or monadic
when $P$ and $Q$ are \emph{not} isomorphic as types? Is the isomorphism
$P\cong Q$ required?

Applying the contravariant Yoneda identity to the type signature of
$F$\textsf{'}s \lstinline!flatten!, we find: 
\begin{align*}
 & \forall A.\,F^{F^{A}}\rightarrow F^{A}\\
 & =\forall A.\,\gunderline{((((A\rightarrow P)\rightarrow Q)\rightarrow P)\rightarrow Q)}\rightarrow\gunderline{(A\rightarrow P)}\rightarrow Q\\
{\color{greenunder}\text{flip arguments}:}\quad & \cong\forall A.\,\gunderline{(A\rightarrow P)\rightarrow}((((A\rightarrow P)\rightarrow Q)\rightarrow P)\rightarrow Q)\rightarrow Q\\
{\color{greenunder}\text{Yoneda identity}:}\quad & \cong((((P\rightarrow P)\rightarrow Q)\rightarrow P)\rightarrow Q)\rightarrow Q\quad.
\end{align*}
So, all possible implementations of \lstinline!flatten! are in a
one-to-one correspondence with all possible values of type $((((P\rightarrow P)\rightarrow Q)\rightarrow P)\rightarrow Q)\rightarrow Q$.
All possible implementations of pure are in a one-to-one correspondce
with all possible values of type $P\rightarrow Q$. It remains to
see what implementations (if any) obey the monad laws. Note that the
type $((((P\rightarrow P)\rightarrow Q)\rightarrow P)\rightarrow Q)\rightarrow Q$
is a fifth-order function whose cardinality is astronomically large;
enumerating all possible values of that type is impossible.

Applying the Yoneda identity to the type signature of \lstinline!zip!,
we find:
\begin{align*}
 & \forall A.\,\forall B.\,F^{A}\times F^{B}\rightarrow F^{A\times B}\\
 & \cong\forall A.\,\forall B.\,((A\rightarrow P)\rightarrow Q)\rightarrow((B\rightarrow P)\rightarrow Q)\rightarrow\gunderline{(A\rightarrow B\rightarrow P)}\rightarrow Q\\
 & \cong\forall A.\,\forall B.\,\gunderline{(A\rightarrow B\rightarrow P)\rightarrow}((A\rightarrow P)\rightarrow Q)\rightarrow((B\rightarrow P)\rightarrow Q)\rightarrow Q\\
 & \cong\forall B.\,(((B\rightarrow P)\rightarrow P)\rightarrow Q)\rightarrow((B\rightarrow P)\rightarrow Q)\rightarrow Q\quad.
\end{align*}
All implementations of $F$\textsf{'}s \lstinline!zip! are in a one-to-one
correspondence to values of the last type above. The Yoneda identities
cannot apply to that type. It is not clear how to simplify it any
further.

\subsubsection{Problem \label{subsec:Exercise-function-type-construction-not-applicative-1}\ref{subsec:Exercise-function-type-construction-not-applicative-1}}

Suppose $P$ is a fixed but unknown type. Is the functor $F^{A}\triangleq\left(A\rightarrow P\right)\rightarrow\bbnum 1+A$
applicative or a monad?

To make these questions non-trivial, assume that $P$ is not void,
not unit, and not pointed.

If $P$ is pointed (say, $P\cong\bbnum 1+Q$) then $F$ is a \lstinline!Search!
monad of the form $(A\rightarrow L^{Q})\rightarrow L^{A}$ with $L^{X}\triangleq\bbnum 1+X$.
(See comments about the \lstinline!Search! monad in Statement~\ref{subsec:Statement-generalized-search-monad}.)
Is $F$ not a monad and not applicative when $P$ is not a pointed
type (that is, when an isomorphism $P\cong\bbnum 1+Q$ is not available)?

\subsubsection{Problem \label{par:Problem-monads}\ref{par:Problem-monads}}

Section~\ref{subsec:Constructions-of-polynomial-monads} shows four
constructions that make new monads:
\begin{enumerate}
\item The polynomial monad $F^{A}\triangleq Z+W\times A$, where $W$ is
a monoid and $Z$ is a fixed type.
\item The free pointed monad $L^{A}\triangleq A+F^{A}$, where $F$ is a
monad.
\item The product monad $L^{A}\triangleq F^{A}\times G^{A}$, where $F$
and $G$ are monads.
\item The monad $L^{A}\triangleq F^{Z+W\times A}$, where $F$ is a monad,
$W$ is a monoid, and $Z$ is a fixed type.
\end{enumerate}
If we do not assume any existing monads and just keep applying these
constructions, we will obtain a number of polynomial monads. But are
there any polynomial monads \emph{not} obtained by a chain of these
constructions?

For example, functors of the form $L^{A}\triangleq\bbnum 1+A\times A$,
$L^{A}\triangleq\bbnum 1+A\times A\times A$, etc., cannot be obtained
via these constructions. All those functors are not monads (see Exercise~\ref{par:Problem-monads-1}).

\subsubsection{Problem \label{subsec:Problem-co-pointed-applicative}\ref{subsec:Problem-co-pointed-applicative}}

By Statement~\ref{subsec:Statement-co-pointed-applicative-example},
any co-pointed applicative functor of the form $L^{A}\triangleq A\times G^{A}$
satisfies the compatibility law~(\ref{eq:compatibility-law-of-extract-and-zip}).
Statement~\ref{subsec:Statement-co-pointed-applicative-example-failing-compatibility-law}
shows that $L^{A}\triangleq Z\times\left(Z\rightarrow A\right)$ is
applicative and co-pointed but fails the compatibility law. Does there
exist any co-pointed applicative functor that satisfies the law~(\ref{eq:compatibility-law-of-extract-and-zip})
but is \emph{not} of the form $A\times G^{A}$ with some applicative
functor $G$? 

\subsubsection{Problem \label{par:Problem-monads-2}\ref{par:Problem-monads-2}}

Monad transformers are defined in different ways for different monads.
If someone comes up with a new monad, it is not certain that the new
monad\textsf{'}s transformer will be obtained through one of the known methods.
Can we prove that a monad transformer will exist for every monad whose
\lstinline!pure! and \lstinline!flatMap! methods are implemented
via fully parametric code? Is there an algorithm that derives an implemenation
of a monad transformer from the code of \lstinline!pure! and \lstinline!flatMap!
of an arbitrary given monad?

\subsubsection{Problem \label{par:Problem-monads-5-1}\ref{par:Problem-monads-5-1}}

For certain monads $L$, the monad transformers $T_{L}$ can be defined
using a suitable \lstinline!swap! function. Is this always the case
for any monad stacks built out of such monads? If each of the monads
$L_{1}$, $L_{2}$, ..., $L_{k}$ admits a transformer defined via
a lawful \lstinline!swap! function, will the monad $L_{1}\varangle L_{2}\varangle...\varangle L_{k}$
also admit a transformer with a \lstinline!swap! function? (See Section~\ref{subsec:Does-a-composition-have-swap}
for some partial results.)

\subsubsection{Problem \label{par:Problem-monads-3}\ref{par:Problem-monads-3}}

\textsf{``}Rigid functors\textsf{''} are\index{rigid functors!open questions} defined
in Section~\ref{subsec:Rigid-functors}.

\textbf{(a)} Are there any rigid functors that are not monads? 

\textbf{(b)} Are there any rigid functors that are not applicative?

\textbf{(c)} Is it true that any applicative rigid functor is a monad?

\subsubsection{Problem \label{par:Problem-monads-3-1}\ref{par:Problem-monads-3-1}}

Let $L$ be a fixed monad and $H$ be an $L$-filterable contrafunctor.
Then the functor $F^{A}\triangleq H^{A}\rightarrow L^{A}$ is a lawful
monad (see Section~\ref{subsec:Constructions-of-M-filterables}).
What is a monad transformer for the monad $F$? 

Two nontrivial examples of $L$-filterable contrafunctors are $H^{A}\triangleq A\rightarrow L^{Z}$
and $H^{A}\triangleq L^{A}\rightarrow Z$ (where $Z$ is a fixed type).
For these cases, the monad transformers are defined by:
\begin{align*}
 & \text{monad: }(A\rightarrow L^{Z})\rightarrow L^{A}\quad,\quad\quad\text{transformer: }(A\rightarrow T_{L}^{M,Z})\rightarrow T_{L}^{M,A}\quad,\\
 & \text{monad: }(L^{A}\rightarrow Z)\rightarrow L^{A}\quad,\quad\quad\text{transformer: }(T_{L}^{M,A}\rightarrow Z)\rightarrow T_{L}^{M,A}\quad,
\end{align*}
where $T_{L}^{M}$ is the monad $L$\textsf{'}s transformer applied to the
foreign monad $M$.

The problem is to implement the monad $F$\textsf{'}s transformer for an arbitrary
$L$-filterable contrafunctor $H$ and to prove that the transformer
laws hold.

\subsubsection{Problem \label{par:Problem-monads-5-2}\ref{par:Problem-monads-5-2}}

Assume an arbitrary unknown monad $M$ and define recursively $L^{A}\triangleq\bbnum 1+A\times M^{L^{A}}$.
Can one define a lawful monad instance for the functor $L$? (This
is the \lstinline!List! monad\textsf{'}s transformer without the outer layer
of $M$. See Exercise~\ref{subsec:Exercise-effectful-list-not-monad}.)

\subsubsection{Problem \label{par:Problem-monads-5-2-1}\ref{par:Problem-monads-5-2-1}}

Consider the monad transformer \lstinline!ListT! (here denoted just
by $T$): 
\[
T^{A}\triangleq M^{L^{A}}\quad,\quad\quad L^{A}\triangleq\bbnum 1+A\times M^{L^{A}}\quad,
\]
where $M$ is an arbitrary foreign monad. Normally, we cannot implement
fully parametric base runner $T^{A}\rightarrow M^{A}$ because we
cannot have a fully parametric runner $\text{List}^{A}\rightarrow A$
operating on arbitrary types $A$. However, for a \emph{monoid} type
$R$ with binary operation $\oplus_{R}$ and empty element $e_{R}$,
the type signature $\text{List}^{R}\rightarrow R$ is implemented
by the standard \lstinline!reduce! operation: 
\[
\text{reduce}:\text{List}^{R}\rightarrow R\quad,\quad\quad\text{reduce}\triangleq\,\begin{array}{|c||c|}
 & R\\
\hline \bbnum 1 & 1\rightarrow e_{R}\\
R\times\text{List}^{R} & h\times t\rightarrow h\oplus_{R}\overline{\text{reduce}}\,(t)
\end{array}\quad.
\]
We can similarly implement a special base runner (\lstinline!brunE!)
for the transformer $T_{\text{List}}$ if we restrict its usage to
\emph{monoid} types $R$. The function \lstinline!brunE! with the
type signature $M^{L^{R}}\rightarrow M^{R}$ aggregates all elements
of the effectful list into a single value of type $M^{R}$ (which
is also a monoid type):
\[
\text{brunE}:M^{L^{R}}\rightarrow M^{R}\quad,\quad\quad\text{brunE}\triangleq\text{flm}_{M}\bigg(\,\begin{array}{|c||c|}
 & M^{R}\\
\hline \bbnum 1 & 1\rightarrow\text{pu}_{M}(e_{R})\\
R\times M^{L^{R}} & h\times t\rightarrow\text{pu}_{M}(h)\oplus_{M}\overline{\text{brunE}}\,(t)
\end{array}\,\bigg)\quad.
\]
Here, we use the binary operation $\oplus_{M}$ of the monoid $M^{R}$,
which is defined by:
\[
p^{:M^{R}}\oplus_{M}q^{:M^{R}}\triangleq p\triangleright\text{flm}_{M}\big(u^{:R}\rightarrow q\triangleright(v^{:R}\rightarrow u\oplus_{R}v)^{\uparrow M}\big)\quad.
\]

\textbf{(a)} Is \lstinline!brunE! a monoid morphism $T^{A}\rightarrow A$?
(Note that $T^{A}$ is a monoid since $T$ is a lawful monad.) The
monoid morphism identity law holds for \lstinline!brunE!. Does the
composition law hold?

\textbf{(b)} Do the monad morphism laws of \lstinline!brunE! hold
when restricted to monoid types $A$?
\begin{align*}
{\color{greenunder}\text{for all monoid types }A:}\quad & a^{:A}\triangleright\text{pu}_{T}\bef\text{brunE}=a^{:A}\triangleright\text{pu}_{M}\quad,\\
{\color{greenunder}\text{composition law}:}\quad & p^{:T^{T^{A}}}\triangleright\text{ftn}_{T}\bef\text{brunE }=p^{:T^{T^{A}}}\triangleright\text{brunE}\bef\text{brunE}^{\uparrow M}\bef\text{ftn}_{M}\quad.
\end{align*}
(If so, Exercise~\ref{subsec:Exercise-traversables-10-1} would show
that \lstinline!brunE! is also a \emph{monoid} morphism $M^{L^{A}}\rightarrow M^{A}$.)
\begin{comment}
Failed attempts to verify the composition law:

Write its two sides separately:
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & \text{ftn}_{T}\bef\text{brun}=\text{flm}_{M}(\text{prod})\bef\text{flm}_{M}\bigg(\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{R})\\
r\times t\rightarrow\text{pu}_{M}(r)\oplus_{M}\overline{\text{brun}}\,(t)
\end{array}\,\bigg)\\
{\color{greenunder}\text{associativity of }\text{flm}_{M}:}\quad & \quad=\text{flm}_{M}\bigg(\text{prod}\bef\text{flm}_{M}\bigg(\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{R})\\
r\times t\rightarrow\text{pu}_{M}(r)\oplus_{M}\overline{\text{brun}}\,(t)
\end{array}\,\bigg)\bigg)\quad,\\
{\color{greenunder}\text{right-hand side}:}\quad & \text{brun}^{T^{R}}\bef\text{brun}^{\uparrow M}\bef\text{ftn}_{M}=\text{flm}_{M}\bigg(\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{R})\\
r\times t\rightarrow\text{pu}_{M}(r)\oplus_{M^{T^{R}}}\overline{\text{brun}}{}^{T^{R}}(t)
\end{array}\,\bigg)\bef\text{flm}_{M}(\text{brun})\\
{\color{greenunder}\text{associativity of }\text{flm}_{M}:}\quad & \quad=\text{flm}_{M}\bigg(\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{T^{R}})\\
r\times t\rightarrow\text{pu}_{M}(r)\oplus_{M^{T^{R}}}\overline{\text{brun}}{}^{T^{R}}(t)
\end{array}\,\bef\text{flm}_{M}(\text{brun})\bigg)\quad.
\end{align*}
The remaining difference (under $\text{flm}_{M}$) is an equation
between functions of type $L^{M^{L^{R}}}\rightarrow M^{R}$:
\begin{align*}
 & \text{prod}\bef\text{flm}_{M}\bigg(\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{R})\\
r\times t\rightarrow\text{pu}_{M}(r)\oplus_{M}\overline{\text{brun}}\,(t)
\end{array}\,\bigg)=\text{prod}\bef\text{brun}\\
 & \quad\overset{?}{=}\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{T^{R}})\\
r^{:T^{R}}\times t^{:T^{T^{R}}}\rightarrow\text{pu}_{M}(r)\oplus_{M^{T^{R}}}\overline{\text{brun}}{}^{T^{R}}(t)
\end{array}\,\bef\text{flm}_{M}(\text{brun})\quad.
\end{align*}
It is inconvenient to use matrices at this step because the code of
$\text{flm}_{M}$ is unknown. Instead, we will substitute into both
sides an arbitrary value of type $L^{M^{L^{R}}}$, which can be one
of two possibilities, $\text{Nil}$ or $\bbnum 0+h^{:T^{R}}\times t^{T^{T^{R}}}$.
Substituting $\text{Nil}$, we get:
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & \gunderline{\text{Nil}\triangleright\text{prod}}\bef\text{brun}=\text{Nil}\triangleright\text{pu}_{M}\bef\text{brun}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:listt-brun-derivation1})}:}\quad & \quad=e_{R}\triangleright\text{pu}_{M}\quad.\\
{\color{greenunder}\text{right-hand side}:}\quad & \text{Nil}\triangleright\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{T^{R}})\\
r\times t\rightarrow\text{pu}_{M}(r)\oplus_{M}\overline{\text{brun}}\,(t)
\end{array}\,\bef\text{flm}_{M}(\text{brun})\\
 & \quad=e_{T^{R}}\triangleright\gunderline{\text{pu}_{M}\triangleright\text{flm}_{M}}(\text{brun})=e_{R}\triangleright\gunderline{\text{pu}_{T}\bef\text{brun}}\\
{\color{greenunder}\text{identity law of }\text{brun}:}\quad & \quad=e_{R}\triangleright\text{pu}_{M}\quad.
\end{align*}
The two sides are now equal. It remains to substitute the second possibility:
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & (\bbnum 0+h\times t)\triangleright\text{prod}\bef\text{brun}=\\
 & \quad=(\bbnum 0+h\times t)\triangleright\,\begin{array}{||c|}
1\rightarrow\text{Nil}\triangleright\text{pu}_{M}\\
m\times p\rightarrow\text{comb}\,(m)(p\triangleright\text{flm}_{M}(\overline{\text{prod}})
\end{array}\bef\text{brun}\\
 & \quad=\big(\text{comb}\,(h)(t\triangleright\text{flm}_{M}(\overline{\text{prod}}))\big)\triangleright\text{brun}\\
 & \quad=h\triangleright\text{flm}_{M}\big(t\triangleright\text{flm}_{M}(\overline{\text{prod}})\triangleright\xi\big)\bef\text{flm}_{M}\bigg(\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{R})\\
r\times t\rightarrow\text{pu}_{M}(r)\oplus_{M}\overline{\text{brun}}\,(t)
\end{array}\,\bigg)\\
 & \quad=h\triangleright\text{flm}_{M}\big(t\triangleright\text{flm}_{M}(\overline{\text{prod}})\bef\xi\bef\text{brun}\big)\\
 & \quad=h\triangleright\text{flm}_{M}\big(t\triangleright\text{flm}_{M}(\overline{\text{prod}})\bef\big)\\
{\color{greenunder}\text{right-hand side}:}\quad & (\bbnum 0+h\times t)\triangleright\,\begin{array}{||c|}
1\rightarrow\text{pu}_{M}(e_{T^{R}})\\
h\times t\rightarrow\text{pu}_{M}(h)\oplus_{M}\overline{\text{brun}}\,(t)
\end{array}\,\bef\text{flm}_{M}(\text{brun})\\
 & \quad=(\text{pu}_{M}(h)\oplus_{M}\overline{\text{brun}}\,(t))\triangleright\text{flm}_{M}(\text{brun})\\
 & \quad=t\triangleright\overline{\text{brun}}\triangleright(v\rightarrow h\oplus_{R}v)^{\uparrow M}\triangleright\text{flm}_{M}(\text{brun})
\end{align*}
This is suspicious: we need to show that an expression $h\triangleright\text{flm}_{M}(t\triangleright...)$
is equal to $t\triangleright...$, and it seems impossible to convert
one into another, given that $h$ and $t$ are arbitrary values.

Note that:
\[
\text{pu}_{M}(r^{:R})\oplus_{M}q^{:M^{R}}=r\triangleright\gunderline{\text{pu}_{M}\triangleright\text{flm}_{M}}(u\rightarrow q\triangleright(v\rightarrow u\oplus_{R}v)^{\uparrow M})=q\triangleright(v\rightarrow r\oplus_{R}v)^{\uparrow M}\quad.
\]
In particular,
\[
\text{pu}_{M}(p)\oplus_{M}\text{pu}_{M}(q)=q\triangleright\text{pu}_{M}\triangleright(v\rightarrow p\oplus_{R}v)^{\uparrow M}=q\triangleright(v\rightarrow p\oplus_{R}v)\triangleright\text{pu}_{M}=\text{pu}_{M}(p\oplus_{R}q)\quad.
\]
We also have the property of \lstinline!comb!:
\begin{align*}
 & \big(\text{comb}\,(p)(q)\big)\triangleright\text{flm}_{M}(g)=p\triangleright\text{flm}_{M}(q\triangleright\xi)\bef\text{flm}_{M}(g)=p\triangleright\text{flm}_{M}((q\triangleright\xi)\bef\text{flm}_{M}(g))\\
 & =p\triangleright\text{flm}_{M}\bigg(\begin{array}{||c|}
1\rightarrow q\\
h\times t\rightarrow\text{pu}_{M}\big(\bbnum 0+h\times\overline{\text{comb}}\,(t)(q)
\end{array}\,\bef\text{flm}_{M}(g)\bigg)
\end{align*}
\end{comment}
{} 

\subsubsection{Problem \label{subsec:Problem-monatron-lift-reset-and-shift}\ref{subsec:Problem-monatron-lift-reset-and-shift}}

The continuation monad\textsf{'}s operations \lstinline!reset! and \lstinline!shift!
are defined by:
\begin{align*}
 & \text{reset}:\forall S.\,\text{Cont}^{R,R}\rightarrow\text{Cont}^{S,R}\quad,\quad\quad\text{reset}\triangleq c^{:\left(R\rightarrow R\right)\rightarrow R}\rightarrow k^{:R\rightarrow S}\rightarrow k(c(\text{id}))\quad,\\
 & \text{shift}:\forall A.\,((A\rightarrow R)\rightarrow\text{Cont}^{R,R})\rightarrow\text{Cont}^{R,A}\quad,\quad\quad\text{shift}\triangleq g^{:\left(A\rightarrow R\right)\rightarrow\text{Cont}^{R,R}}\rightarrow k^{:A\rightarrow R}\rightarrow g(k)(\text{id})\quad.
\end{align*}
How to lift these operations to an arbitrary monad stack $P$ that
contains a continuation monad?\footnote{See \texttt{\href{https://github.com/renormalist/pugs/blob/master/src/Pugs/AST/Eval.hs}{https://github.com/renormalist/pugs/blob/master/src/Pugs/AST/Eval.hs}}
for custom code (in Haskell) that lifts \lstinline!reset! and \lstinline!shift!
to the \lstinline!ContT! monad transformer.} What are the appropriate type signatures for the lifted operations?

\subsubsection{Problem \label{subsec:Problem-unique-functor-liftings}\ref{subsec:Problem-unique-functor-liftings}}

For any fully parametric and covariant type constructor $P$, the
lifting of a function $f^{:A\rightarrow B}$ to $P$ is performed
via the \lstinline!fmap! method of $P$, so that \lstinline!fmap(f)!
is a function of type $P^{A}\rightarrow P^{B}$ denoted by $f^{\uparrow F}$
in this book. The standard code of \lstinline!fmap! is defined by
induction on the type structure of $P$ and satisfies the functor
laws, as shown in Chapter~\ref{chap:Functors,-contrafunctors,-and}.
The question is to show that there is no non-standard, alternative
implementation \lstinline!fmap!$^{\prime}$ that still satisfies
the functor laws. If the code of \lstinline!fmap!$^{\prime}$ is
fully parametric, Section~\ref{sec:Uniqueness-of-functor-and-contrafunctor}
shows that \lstinline!fmap!$^{\prime}=$ \lstinline!fmap!. However,
parametricity (or naturality) does not seem to follow from functor
laws alone. Does there exist an implementation of \lstinline!fmap!$^{\prime}$
that satisfies the functor laws but is \emph{not} fully parametric?

\subsubsection{Problem \label{par:Problem-Peirce-law-1}\ref{par:Problem-Peirce-law-1}}

Consider the profunctor $F$ defined by:
\[
F^{P,Q}\triangleq\forall A.\,((A\rightarrow A)\rightarrow P)\rightarrow Q\quad,
\]
where functions of type $F^{P,Q}$ are required to be fully parametric.
Show that $F^{P,Q}\cong P\rightarrow Q$.\footnote{See \texttt{\href{https://cstheory.stackexchange.com/questions/55588/}{https://cstheory.stackexchange.com/questions/55588/}}}

An equivalent (but not actually simpler) question is to prove that:
\[
P\cong\exists A.\,(A\rightarrow A)\rightarrow P\quad.
\]

