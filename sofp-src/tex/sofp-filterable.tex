
\chapter{Computations in functor blocks. I. Filterable functors and contrafunctors\label{chap:Filterable-functors}}

\global\long\def\gunderline#1{\mathunderline{greenunder}{#1}}%
\global\long\def\bef{\forwardcompose}%
\global\long\def\bbnum#1{\custombb{#1}}%

Chapter~\ref{chap:Functors,-contrafunctors,-and} studied the mathematical
properties of \lstinline!map! and derived the concept of \textsf{``}functor\textsf{''}
as a general type constructor that permits a \lstinline!map! method
with useful properties. In this chapter, we will study the \lstinline!filter!
method in a similar way. We will start from practical examples and
then derive the relevant mathematical properties. This will give us
a precise definition of \textsf{``}filterable\textsf{''} type constructors \textemdash{}
those that permit useful implementations of \lstinline!filter!.

\section{Practical uses of filtering\label{sec:Practical-uses-of-filterable-functors}}

The Scala standard library defines the \lstinline!filter! method
on sequences, sets, and other data structures. An example of using
\lstinline!filter! is the following calculation:
\[
\sum_{x\in\mathbb{Z};\,0\leq x\leq100;\,\cos x>0}\sqrt{\cos x}\approx38.71\quad.
\]
\begin{lstlisting}
scala> (0 to 100).map(x => math.cos(x)).filter(_ > 0).map(math.sqrt).sum
res0: Double = 38.71218949848382
\end{lstlisting}
The role of \lstinline!filter! in this computation is to remove all
non-positive values of $\cos x$. It is safe to apply the square root
function to positive values.

The code above is a chain of methods, but the same code can be written
using Scala\textsf{'}s \lstinline!for!/\lstinline!yield! syntax, which is
called a \textbf{functor block}\index{functor block} in this book.
The \lstinline!filter! operation is represented by an \lstinline!if!
keyword embedded in a functor block. Compare each line of the functor
block code with the corresponding line of the code written via method
chains:

\noindent \texttt{\textcolor{blue}{\footnotesize{}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\texttt{\textcolor{blue}{\footnotesize{}}}
\begin{lstlisting}
(for { x <- 0 to 100
    y = math.cos(x)
    if y > 0
  } yield math.sqrt(y)
).sum
\end{lstlisting}
%
\end{minipage}\texttt{\textcolor{blue}{\footnotesize{}\hspace*{\fill}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\texttt{\textcolor{blue}{\footnotesize{}}}
\begin{lstlisting}
(0 to 100).map { x =>
   math.cos(x) }.filter { y => 
   y > 0 }.map { y =>
     math.sqrt(y)
  }.sum
\end{lstlisting}
%
\end{minipage}{\footnotesize\par}

\vspace{0.2\baselineskip}

Functor blocks require the first line to have a left arrow placed
before a \textsf{``}source\index{functor block!source}\textsf{''}, i.e., a value
of a functor type (e.g., a sequence or a \lstinline!Try!). Each line
of a functor block can be viewed as a computation that creates an
intermediate value of the same \textsf{``}source\textsf{''} functor type. The result
value of the entire functor block is again a value of the same functor
type. So, a functor block manipulates data wrapped by a functor without
changing the type of the wrapper.

The name \textsf{``}functor block\textsf{''} is chosen because the code is a single
expression (a \textsf{``}block\textsf{''}) whose type is required to be a functor.
The functor\textsf{'}s type is selected by the source\textsf{'}s type in the first line.

We have seen in Chapter~\ref{chap:Functors,-contrafunctors,-and}
that the functor block syntax becomes available for a type constructor
that has a \lstinline!map! method (i.e., for a functor). To support
the embedded \lstinline!if! keyword, the type constructor must support
a method called \lstinline!withFilter! with the same type signature
as the \lstinline!filter! method. The type signatures of \lstinline!map!
and \lstinline!withFilter! methods for a type constructor \lstinline!F!
can be written as:
\begin{lstlisting}
class F[A] {
  def map[B](f: A => B): F[B] = ...
  def withFilter(p: A => Boolean): F[A] = ...
}
\end{lstlisting}

A type constructor\index{filterable!type constructor} that supports
the filtering operation is called \textbf{filterable}. 

The main focus of this chapter is to explore filterable functors in
detail. Programmers would intuitively expect the filtering operation
to have certain properties. We will now examine the expected properties
and translate them into mathematical laws for the function \lstinline!filter!.

\subsection{Examples and intuitions for the filtering operation}

Examples of often used filterable functors defined in the Scala library
are \lstinline!List! and \lstinline!Option!:
\begin{lstlisting}
scala> List(64, 128).filter(_ > 100).map(_ * 2)
res0: List[Int] = List(256)

scala> Some(128).filter(_ > 100).map(_ * 2)
res1: Option[Int] = Some(256)

scala> Some(64).filter(_ > 100).map(_ * 2)
res2: Option[Int] = None
\end{lstlisting}
In an intuitive view, a functor wraps one or more data values, and
the filtering operation may decrease the number of values wrapped.
E.g., the length of the sequence \lstinline!List(64, 128)! is decreased
from $2$ to $1$ after filtering with the condition \lstinline!_ > 100!.
The \lstinline!Option! functor can wrap at most one value, so filtering
with a predicate returning \lstinline!false! will return an empty
\lstinline!Option! value (i.e., \lstinline!None!). In all cases,
the resulting data structure will not store values that fail the filtering
predicate.

Note that \lstinline!Option[T]! is written in the type notation as
a disjunctive type $\bbnum 1+T$, while \lstinline!List[T]! can be
viewed as an \textsf{``}infinite disjunction\textsf{''}:
\begin{equation}
\text{List}^{T}=1+T+T\times T+T\times T\times T+...\label{eq:list-infinite-disjunction}
\end{equation}
Disjunctive type constructors are able to hold a different number
of values of type $T$ in different parts of the disjunction (e.g.,
$T\times T$ for $2$ values and $T\times T\times T$ for $3$ values
of $T$). 

So, we expect that a filterable functor should contain a disjunctive
type supporting a different number of values of $T$, including \emph{zero}
values. When the filtering operation \lstinline!_.filter(p)! is applied,
some values of type $T$ will fail the predicate \lstinline!p! and
will be removed from the collection. This example:
\begin{lstlisting}
scala> List(64, 128).filter(_ > 100)
res0: List[Int] = List(128)
\end{lstlisting}
corresponds to mapping a disjunctive part of type $T\times T$ to
a part of type $T$ within $\text{List}^{T}$ in Eq.~(\ref{eq:list-infinite-disjunction}).

Consider now a custom data type that implements a given application\textsf{'}s
business requirements:

\subsubsection{Example \label{subsec:Example-filtering-orders-tue-fri}\ref{subsec:Example-filtering-orders-tue-fri}}

On a given week, an order (data type $A$) can be placed on Tuesday
and/or on Friday. An order is approved under certain conditions given
by a predicate \lstinline!p: A => Boolean!. Can we represent the
order approval by a filtering operation on a suitable data type?

The data type describing a week\textsf{'}s orders must describe a possible
order on Tuesday (\lstinline!Option[A]!) and a possible order on
Friday (again \lstinline!Option[A]!). So, we can represent a week\textsf{'}s
orders as a product $F^{A}\triangleq\left(\bbnum 1+A\right)\times\left(\bbnum 1+A\right)$
and implement it as a case class having methods \lstinline!map! and
\lstinline!withFilter!:
\begin{lstlisting}
final case class Orders[A](tue: Option[A], fri: Option[A]) {
  def map[B](f: A => B): Orders[B] = Orders(tue.map(f), fri.map(f))
  def withFilter(p: A => Boolean): Orders[A] = Orders(tue.filter(p), fri.filter(p))
}

scala> Orders(Some(500), Some(2000)).withFilter(_ < 1000) // Approved if the amount is below $1000.
res0: Orders[Int] = Orders(Some(500),None)
\end{lstlisting}
This code applies filtering independently to both parts of the product.
With this definition, we will be able to use \lstinline!Orders! as
a \textsf{``}source\textsf{''} of data in functor blocks:
\begin{lstlisting}
scala> for {
  x <- Orders(Some(500), Some(2000))  // "Source" has type Orders[Int].
  y = x - 200     // Apply discount of $200 to each order.
  if y < 500      // Orders are approved if amount < 500 after discount.
} yield y * 1.10  // Add 10% tax. Result is of type Orders[Double].
res1: Orders[Double] = Orders(Some(330.0), None)
\end{lstlisting}

Suppose we are considering additional business rules, such as:

\textbf{(a)} Both orders must be approved, or else no orders can be
placed that week. 

\textbf{(b)} Both orders can be placed that week if at least one of
them is approved.

We could modify the code of \lstinline!withFilter! to implement one
of the rules \textbf{(a)} or \textbf{(b)}. Will the resulting function
still be a \textsf{``}filtering\textsf{''} operation?

We cannot decide this without knowing the mathematical laws that a
filtering operation must satisfy. Let us now consider what intuitive
expectations we have for the concept of filtering.

\subsection{The laws of filtering: Motivation and derivation\label{subsec:Motivation-for-and-derivation-of-laws-of-filtering}}

Computations in a functor block will \textsf{``}make sense\textsf{''} if we easily
understand what the program does when we look at the code. Consider
this schematic example of a functor block program that uses a filterable
functor \lstinline!List!:\textcolor{darkgray}{\footnotesize{}}
\begin{lstlisting}[numbers=left]
val result = for {  // Some computations in the context of the `List` functor.
  x <- List(...) // For each x in the given list...
  y = f(x)       // ... compute y
  if p1(y)       // ... impose condition p1; continue only if p1(y) == true
  if p2(y)       // ... same for condition p2 
  z = g(x, y)    // ... compute z
  if q(x, y, z)  // ... impose another condition q(x, y, z)
} yield          // For those x for which all the conditions hold,
  k(x, y, z)     // compute the list of values k as the `result`.
\end{lstlisting}
{\footnotesize\par}

There are several properties that one intuitively expects such programs
to have. For example, the code says \lstinline!y = f(x)! in line
$3$. Then we expect that checking a condition for \lstinline!y!,
such as \textsf{``}\lstinline!if p1(y)!\textsf{''} in line $4$, should be the same
as checking the condition \textsf{``}\lstinline!if p1(f(x))!\textsf{''}. Translating
this equivalence into code, we obtain the requirement that the following
two expressions (\lstinline!result1! and \lstinline!result2!) should
be equal:

\vspace{0.3\baselineskip}

\noindent \texttt{\textcolor{blue}{\footnotesize{}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\begin{lstlisting}
val result1 = for {
  x <- xs
  y = f(x)
  if p(y)
} yield y
 // Rewritten via method chains:
val result1 = xs.map(f).filter(p)
\end{lstlisting}
%
\end{minipage}\texttt{\textcolor{blue}{\footnotesize{}\hspace*{\fill}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\begin{lstlisting}
val result2 = for {
  x <- xs
  if p(f(x))
  y = f(x)
} yield y
 // Rewritten via method chains:
val result2 = xs.filter(x => p(f(x))).map(f)
\end{lstlisting}
%
\end{minipage}{\footnotesize\par}

\vspace{0\baselineskip}

Lines 4\textendash 5 of the listing above show two filtering operations,
\textsf{``}\lstinline!if p1(y)!\textsf{''} and \textsf{``}\lstinline!if p2(y)!\textsf{''}, applied
one after another. We expect that the first filtering operation keeps
only values that satisfy the condition \lstinline!p1!, and the second
filtering operation is applied to the results of the first one, additionally
imposing the condition \lstinline!p2!. So, we expect that applying
these two filtering operations is equivalent to filtering by the single
condition \textsf{``}\lstinline!if p1(y) && p2(y)!\textsf{''}.

We translate this expectation into the requirement that the following
values \lstinline!result1! and \lstinline!result2! should be equal:

\vspace{0.3\baselineskip}

\noindent \texttt{\textcolor{blue}{\footnotesize{}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\begin{lstlisting}
val result1 = for {
  x <- xs
  if p1(x)
  if p2(x)
} yield x
 // Rewritten via method chains:
val result1 = xs.filter(p1).filter(p2)
\end{lstlisting}
%
\end{minipage}\texttt{\textcolor{blue}{\footnotesize{}\hspace*{\fill}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\begin{lstlisting}
val result2 = for {
  x <- xs
  if (p1(x) && p2(x))
 } yield x

 // Rewritten via method chains:
val result2 = xs.filter(x => p1(x) && p2(x))
\end{lstlisting}
%
\end{minipage}{\footnotesize\par}

\vspace{0\baselineskip}

When a filter predicate \lstinline!p(x)! returns \lstinline!true!
for all \lstinline!x!, the filtering call \lstinline!xs.filter(p)!
will never discard any values. So, we expect the result to remain
the same if we \emph{delete} the line \textsf{``}\lstinline!if true!\textsf{''} from
a functor block program. The corresponding code equivalence can be
written as:
\begin{lstlisting}
xs.filter(_ => true) == xs
\end{lstlisting}

Now, suppose a predicate \lstinline!p(x)! returns \lstinline!false!
for certain values \lstinline!x!. Then we expect those values \lstinline!x!
to be excluded from any computations performed \emph{after} the line
\textsf{``}\lstinline!if p(x)!\textsf{''}. In particular, we should be able to use
a partial function safely as long as that function is well-defined
for \lstinline!x! such that \lstinline!p(x) == true!. To express
this in code, first define a general \textsf{``}factory\textsf{''} for partial functions:
\begin{lstlisting}
def if_p[A, B](p: A => Boolean)(f: A => B): A => B = x => p(x) match { case true => f(x) }
\end{lstlisting}
This \textsf{``}factory\textsf{''} takes a predicate $p^{:A\rightarrow\bbnum 2}$
and a function $f^{:A\rightarrow B}$, and returns a partial function
with the same signature, $A\rightarrow B$, but defined only for values
$x$ for which $p(x)=\text{true}$. Let us denote that function for
brevity by $f_{|p}$. Since the \lstinline!Boolean! type is equivalent
to a disjunction of two \textsf{``}named unit types\textsf{''}, $\bbnum 2\cong\bbnum 1+\bbnum 1$
(meaning \textsf{``}\lstinline!false!\textsf{''} + \textsf{``}\lstinline!true!\textsf{''}), we can
write the code notation for the function $f_{|p}$ as:
\begin{equation}
(f^{:A\rightarrow B})_{|p}\triangleq x^{:A}\rightarrow p(x)\triangleright\,\begin{array}{|c||c|}
 & B\\
\hline \bbnum 1~(\text{false}) & \bbnum 0\\
\bbnum 1~(\text{true}) & 1\rightarrow f(x)
\end{array}\quad.\label{eq:def-partial-f}
\end{equation}
The top row contains the void type\index{void type!in matrix notation}
$\bbnum 0$, indicating that the partial function $f_{|p}$ will crash
if applied to a value $x$ for which $p(x)=\text{false}$.

Using the partial function $f_{|p}$, we write the last property of
the filtering operation as the equality of the expressions \lstinline!result1!
and \lstinline!result2! defined like this:

\vspace{0.3\baselineskip}

\noindent \texttt{\textcolor{blue}{\footnotesize{}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\begin{lstlisting}
val result1 = for {
  x <- xs
  if p(x)
  y = f(x)
} yield y
 // Rewritten via method chains:
val result1 = xs.filter(p).map(f)
\end{lstlisting}
%
\end{minipage}\texttt{\textcolor{blue}{\footnotesize{}\hspace*{\fill}}}%
\begin{minipage}[c]{0.475\columnwidth}%
\begin{lstlisting}
val result2 = for {
  x <- xs
  if p(x)  // def fp = if_p(p)(f)
  y = fp(x)
 } yield y
 // Rewritten via method chains:
val result2 = xs.filter(p).map(fp)
\end{lstlisting}
%
\end{minipage}{\footnotesize\par}

\vspace{0\baselineskip}

We found four requirements for the \lstinline!filter! function, written
in terms of equal code fragments. These requirements are the four
\textsf{``}laws\textsf{''} (i.e., equations) that any reasonable \lstinline!filter!
must satisfy. In the code notation, \lstinline!filter! is $\text{filt}_{F}$:
\[
\text{filt}_{F}:(A\rightarrow\bbnum 2)\rightarrow F^{A}\rightarrow F^{A}\quad.
\]
The $4$ laws (called the naturality, identity, composition, and partial
function laws) are formulated for arbitrary functions $f^{:A\rightarrow B}$,
$p^{:A\rightarrow\bbnum 2}$, $p_{1}^{:A\rightarrow\bbnum 2}$, $p_{2}^{:A\rightarrow\bbnum 2}$,
and $q^{:B\rightarrow\bbnum 2}$:\index{composition law!of filter@of \texttt{filter}}\index{naturality law!of filter@of \texttt{filter}}\index{identity laws!of filter@of \texttt{filter}}\index{partial function law!of filter@of \texttt{filter}}
\begin{align}
{\color{greenunder}\text{naturality law}:}\quad & f^{\uparrow F}\bef\text{filt}_{F}(q)=\text{filt}_{F}(f\bef q)\bef f^{\uparrow F}\quad.\label{eq:naturality-law-of-filter}\\
{\color{greenunder}\text{identity law}:}\quad & \text{filt}_{F}(\_\rightarrow\text{true})=\text{id}^{:F^{A}\rightarrow F^{A}}\quad.\label{eq:identity-law-of-filter}\\
{\color{greenunder}\text{composition law}:}\quad & \text{filt}_{F}(p_{1})\bef\text{filt}_{F}(p_{2})=\text{filt}_{F}(x\rightarrow p_{1}(x)\wedge p_{2}(x))\quad.\label{eq:composition-law-of-filter}\\
{\color{greenunder}\text{partial function law}:}\quad & \text{filt}_{F}(p)\bef f^{\uparrow F}=\text{filt}_{F}(p)\bef f_{|p}^{\uparrow F}\quad.\label{eq:partial-function-law-of-filter}
\end{align}
The following type diagram illustrates the naturality law of \lstinline!filter!:
\[
\xymatrix{\xyScaleY{1.4pc}\xyScaleX{7.0pc}F^{A}\ar[r]\sp(0.5){\text{filt}_{F}(f^{:A\rightarrow B}\bef q^{:B\rightarrow\bbnum 2})}\ar[d]\sb(0.45){(f^{:A\rightarrow B})^{\uparrow F}} & F^{A}\ar[d]\sp(0.5){(f^{:A\rightarrow B})^{\uparrow F}}\\
F^{B}\ar[r]\sp(0.5){\text{filt}_{F}(q^{:B\rightarrow\bbnum 2})} & F^{B}
}
\]

A functor $F$ is called \textbf{filterable} if there is a function
$\text{filt}_{F}$ satisfying these laws.\index{filterable!functor} 

We may define a typeclass \lstinline!Filterable! with the extension
methods \lstinline!filter! and (for use with functor blocks) \lstinline!withFilter!:
\begin{lstlisting}
trait Filterable[F[_]] { def filt[A](p: A => Boolean)(fa: F[A]): F[A] }
implicit class FilterableSyntax[F[_], A](fa: F[A])(implicit ev: Filterable[F]) {
  def filter(p: A => Boolean): F[A] = ev.filt(p)(fa)
  def withFilter(p: A => Boolean): F[A] = filter(p)   // For functor blocks.
}
\end{lstlisting}

It is intuitively clear why functors such as \lstinline!Option! and
\lstinline!List! obey the filtering laws: those types are  \textsf{``}containers\textsf{''}
holding zero or more items of data, and the \lstinline!filter! operation
removes all data that fails the filtering condition. What about the
custom data type \lstinline!Orders! from Example~\ref{subsec:Example-filtering-orders-tue-fri}?
In principle, we would need to verify all four laws symbolically,
using the code of \lstinline!withFilter! as we implemented it for
\lstinline!Orders!. Later in this chapter we will see that the four
laws can be simplified, reduced to just two laws, and proved more
quickly. For now, we can use the \texttt{scalacheck} library\index{scalacheck library@\texttt{scalacheck} library}\index{verifying laws with scalacheck@verifying laws with \texttt{scalacheck}}
to implement randomized tests for the four filtering laws:
\begin{lstlisting}
def checkFilteringLaws[F[_] : Filterable : Functor, A, B](implicit
    faEv: Arbitrary[F[A]], fbEv: Arbitrary[F[B]], abEv: Arbitrary[A => B],
    aEv: Arbitrary[A => Boolean], bEv: Arbitrary[B => Boolean]): Assertion = {
  forAll { (f: A => B, p: B => Boolean, fa: F[A]) =>         // Naturality law.
      fa.map(f).filter(p) shouldEqual fa.filter(f andThen p).map(f)
  }
  forAll { (p1: B => Boolean, p2: B => Boolean, fa: F[B]) => // Composition law.
      fa.filter(p1).filter(p2) shouldEqual fa.filter(b => p1(b) && p2(b))
  }
  forAll { (fb: F[B]) => fb.filter(_ => true) shouldEqual fb }  // Identity law.

  forAll { (f: A => B, p: A => Boolean, fa: F[A]) =>    // Partial function law.
      fa.filter(p).map(f) shouldEqual fa.filter(p).map[B](x => p(x) match { case true => f(x) })
  }
}
\end{lstlisting}
Creating a \lstinline!Filterable! typeclass instance for \lstinline!Orders!
and running the tests will show no errors:
\begin{lstlisting}
implicit val filterableOrders = new Filterable[Orders] {
  def filt[A](p: A => Boolean)(fa: F[A]): F[A] = fa.filter(p)
}
checkFilteringLaws[Orders, Int, String]          // Need to set type parameters.
\end{lstlisting}


\subsection{Examples of non-filterable functors\label{subsec:Examples-of-non-filterable-functors}}

As usual with Scala typeclasses, the code of the \lstinline!Filterable!
typeclass fixes the type signature of the \lstinline!filter! function
but does not enforce its laws. It is up to the programmer to verify
that the implementation of \lstinline!filter! satisfies the laws.

If we define the filtering operation for the \lstinline!Orders! data
type (see Example~\ref{subsec:Example-filtering-orders-tue-fri})
with the extra business rule \textbf{(a)}, we get:
\begin{lstlisting}
implicit val filterableOrdersRuleA = new Filterable[Orders] {
  def filt[A](p: A => Boolean)(fa: F[A]): F[A] =
    if (fa.tue.forall(p) && fa.fri.forall(p))) fa.filter(p)
    else Orders(None, None)        // Rule (a): No orders are approved unless both are approved.
}
checkFilteringLaws[Orders, Int, String]    // Tests pass.
\end{lstlisting}
However, implementing business rule \textbf{(b)} will violate some
laws:
\begin{lstlisting}
implicit val filterableOrdersRuleB = new Filterable[Orders] {
  def filt[A](p: A => Boolean)(fa: F[A]): F[A] =
    if (fa.tue.exists(p) || fa.fri.exists(p)) fa      // Here, the value `fa` remains unchanged.
    else Orders(None, None)   // Rule (b): Both orders are approved if at least one is approved.
}
checkFilteringLaws[Orders, Boolean, Boolean]()      // Tests will fail! A specific failing case:

scala> Orders(Some(500), Some(2000)).filter(x => x < 1000).filter(x => x > 1000)
res0: Orders[Int] = Orders(Some(500),Some(2000))

scala> Orders(Some(500), Some(2000)).filter(x => x < 1000 && x > 1000) // Composition law fails:
res1: Orders[Int] = Orders(None, None)
\end{lstlisting}
If we implement rule \textbf{(b)}, the filtering operation will not
correspond to an intuitive understanding of computations in functor
blocks:
\begin{lstlisting}
scala> for { x <- Orders(Some(500), Some(2000))
  if x < 1000 // Intuition says that values of x must be below 1000 from now on.
  y = s"Amount: $x"  // So, the value x = 2000 should never appear in this line.
} yield y         // But the final result does not correspond to this intuition:
res2: Orders[String] = Orders(Some("Amount: 500"), Some("Amount: 2000"))
\end{lstlisting}
This computation violates the partial function law: the value \lstinline!x = 2000!
is not excluded from further computations despite filtering with the
predicate \textsf{``}\lstinline!x < 1000!\textsf{''}. This happened because the code
of \lstinline!filter! does not remove the value \lstinline!x = 2000!
from the data structure in case there is another value that passes
the predicate.

The four laws of filtering are a rigorous formulation of our intuitions
about what it means to \textsf{``}filter data\textsf{''}. The type \lstinline!Orders!
with business rule \textbf{(b)} is an example of a filtering operation
that does not correspond to our intuitions and, as a consequence,
violates the filtering laws. This does not mean that business rule
\textbf{(b)} cannot be used in real-world programs; it only means
that order approval according to rule \textbf{(b)} is not a filtering
operation. For instance, applying two order approvals one after another
will not give the intuitively expected results. Nevertheless, this
may be acceptable in applications where one order approval is never
applied after another.

Violations of the filtering laws by business rule \textbf{(b)} also
does not mean that the functor \lstinline!Orders! is not filterable.
The same functor with business rule \textbf{(a)} has a lawful implementation
of \lstinline!filter!. 

What are examples of functors that are not filterable? One way of
implementing the type signature of the \lstinline!filter! function
is to use the identity function:
\begin{lstlisting}
def filt[A](p: A => Boolean)(fa: F[A]): F[A] = fa  // Ignore the predicate `p`; always return `fa`.
\end{lstlisting}
This implementation never removes any data and so will violate the
partial function law if the functor $F^{A}$ wraps a value of type
$A$ that does not pass the filter. However, the identity function
is the \emph{only} possible implementation of \lstinline!filter!
for certain functors $F$, e.g., the identity functor $F^{A}\triangleq A$
or the exponential functor $F^{A}\triangleq Z\rightarrow A$. So,
functors of the form $F^{A}\triangleq Z\rightarrow A$ (where $Z$
is a fixed type) are not filterable.

The functor $F^{A}\triangleq A\times(\bbnum 1+A)$ is not filterable
because the filtering operation $\text{filt}_{F}(p)$ cannot remove
the first value of type $A$ when it does not pass the filter predicate
$p$.

Functors such as $F^{A}\triangleq\bbnum 1+A$ and $F^{A}\triangleq\bbnum 1+A\times A$
are filterable because the function $\text{filt}_{F}$ can be defined
correctly; but incorrect implementations are also possible. For example,
one could imagine defining \lstinline!filter! for an \lstinline!Option!
type as:
\begin{lstlisting}
implicit val wrongFilterableOption = new Filterable[Option] {
  def filt[A](p: A => Boolean)(fa: Option[A]): Option[A] = None // Discard input, always return None.
}
\end{lstlisting}
This code discards information and violates the identity law: the
filtering with an identically \lstinline!true! predicate is \emph{not}
the identity function of type \lstinline!Option[A] => Option[A]!.

Finally, one could violate the naturality law by defining \lstinline!filter!
in a special way when the type parameter $A$ is set to, say, \lstinline!Int!.
To obey the naturality law, the \lstinline!filter! function must
be fully parametric and may not use hard-coded values of specific
types or make decisions based on specific types.

Note that the \lstinline!Boolean! type is equivalent to $\bbnum 2\cong\bbnum 1+\bbnum 1$.
In other words, that type can be expressed via the basic type constructions
(disjunction and the \lstinline!Unit! type) without using any externally
defined values. For this reason, it is allowed to use the \lstinline!Boolean!
type in fully parametric functions.

\subsection{Examples: Programming with filterable functors\index{examples (with code)} }

\subsubsection{Example \label{subsec:filt-solved-example-1}\ref{subsec:filt-solved-example-1}}

A cluster has two servers; each server needs to have valid credentials,
which expire periodically. If credentials expire for one server, it
may copy valid credentials from the other server. If no server has
valid credentials, the cluster is down. Is this setup described by
a filterable functor?

\subparagraph{Solution}

Assuming that credentials have type $A$, we can have two possibilities:
both servers have valid credentials, or the cluster is down. The corresponding
data type is the functor $F^{A}\triangleq\bbnum 1+A\times A$. This
functor is filterable if we can implement a lawful \lstinline!filter!
function. Begin writing code for \lstinline!filter!:
\begin{lstlisting}[numbers=left]
type F[A] = Option[(A, A)]
def filter[A](p: A => Boolean): F[A] => F[A] = {
    case None             => None
    case Some((a1, a2))   => ???
}
\end{lstlisting}
In line~4, we need to compute a value of type \lstinline!F[A]! using
the given values \lstinline!a1! and \lstinline!a2!. We need to check
whether the predicate \lstinline!p! holds for \lstinline!a1! and
\lstinline!a2!. What if \lstinline!p(a1) == false! but \lstinline!p(a2) == true!?
We need to remove \lstinline!a1! from the result, or else the filtering
laws will not hold. But the functor $F^{A}\triangleq\bbnum 1+A\times A$
does not allow us to keep just one of the values of type $A$; it
requires two such values or none. So, we may return \lstinline!Some((a2, a2))!
or \lstinline!None!. 

We may describe the validity of credentials by a predicate \lstinline!p: A => Boolean!.
If \lstinline!p(a1) == false! then the first server\textsf{'}s credentials
expired. In that case, if \lstinline!p(a2) == true!, the first server
will copy the second server\textsf{'}s valid credentials (\lstinline!a2!).
So, we must return \lstinline!Some((a2, a2))!. Other cases are handled
similarly. The full code is:
\begin{lstlisting}
def filter[A](p: A => Boolean): F[A] => F[A] = {
    case None             => None  // No credentials to validate.
    case Some((a1, a2))   => (p(a1), p(a2)) match {
        case (true, true)     => Some((a1, a2))  // Both credentials are still valid.
        case (true, false)    => Some((a1, a1))  // Server 2 copies credentials from server 1.
        case (false, true)    => Some((a2, a2))  // Server 1 copies credentials from server 2.
        case (false, false)   => None        // Both credentials expired, the cluster is down.
    }
}
\end{lstlisting}

It remains to check that the filtering laws hold. The naturality law
requires that the equation $f^{\uparrow F}\bef\text{filt}_{F}(p)=\text{filt}_{F}(f\bef p)\bef f^{\uparrow F}$
must hold for any values $s^{:F^{A}}$, $f^{:A\rightarrow B}$, and
$p^{:B\rightarrow\bbnum 2}$. The code for \lstinline!fmap! is:
\begin{lstlisting}
def fmap[A, B](f: A => B): F[A] => F[B] = {
    case None             => None
    case Some((a1, a2))   => Some((f(a1), f(a2)))
}
\end{lstlisting}
The code for the left-hand side of the law, $f^{\uparrow F}\bef\text{filt}_{F}(p)$,
is written by composing \lstinline!fmap! and \lstinline!filter!:
\begin{lstlisting}
fmap(f) andThen filter(p) == {
    case None            => None
    case Some((a1, a2))  => (p(f(a1)), p(f(a2))) match {
        case (true, true)     => Some((f(a1), f(a2)))
        case (true, false)    => Some((f(a1), f(a1)))
        case (false, true)    => Some((f(a2), f(a2)))
        case (false, false)   => None
    }
}
\end{lstlisting}
The code for the right-hand side of the law, $\text{filt}_{F}(f\bef p)\bef f^{\uparrow F}$,
is:
\begin{lstlisting}
filter(f andThen p) == {
    case None            => None
    case Some((a1, a2))  => (p(f(a1)), p(f(a2))) match {
        case (true, true)     => Some((a1, a2))
        case (true, false)    => Some((a1, a1))
        case (false, true)    => Some((a2, a2))
        case (false, false)   => None
    }
} andThen fmap(f) == {
    case None            => None
    case Some((a1, a2))  => (p(f(a1)), p(f(a2))) match {
        case (true, true)     => Some((f(a1), f(a2)))
        case (true, false)    => Some((f(a1), f(a1)))
        case (false, true)    => Some((f(a2), f(a2)))
        case (false, false)   => None
    }
}
\end{lstlisting}
Since the code is exactly the same, the law holds. 

This computation illustrates why fully parametric functions such as
\lstinline!filter! obey the naturality law. Such functions manipulate
their arguments purely as symbols of unknown types, without referring
to any specific types or values. Applying a lifted function $f^{\uparrow F}$
before \lstinline!filter! is the same as inserting \lstinline!f(...)!
around values of type \lstinline!A! at every place in the code of
\lstinline!filter(p)! where a value of type \lstinline!A! is used.
Applying a lifted function $f^{\uparrow F}$ after \lstinline!filter!
is the same as inserting \lstinline!f(...)! at every place where
a value of type \lstinline!A! is \emph{returned}; but this does not
put \lstinline!f(...)! around values of type \lstinline!A! used
by the predicate \lstinline!p!. To compensate, the right-hand side
of the naturality law replaces the predicate \lstinline!p! by the
new predicate \lstinline!f andThen p!, which inserts \lstinline!f(...)!
into the remaining places in the code.

This turns out to be the rule: fully parametric functions always satisfy
a suitably formulated naturality law. We will see many more examples
of naturality laws in this book, and we will find that the naturality
law of a method $q$ often has the form $f^{\uparrow}\bef q=\text{<modified }q\text{>}\bef f^{\uparrow}$,
i.e., the composition of a lifted function $f^{\uparrow}$ and a method
$q$ can be interchanged, possibly after some modifications.

The identity law holds because the code of \lstinline!filter(p)!
is the identity function when $p=(\_\rightarrow\text{true})$:
\begin{lstlisting}
filter[A](_ => true) == {
    case None             => None
    case Some((a1, a2))   => Some((a1, a2))
} == identity[F[A]]
\end{lstlisting}

It takes a bit more work to show that the composition law holds. We
need to consider two cases: the cluster is down, or both servers have
valid credentials.

In the first case, the value is \lstinline!None! (denoted by $1+\bbnum 0^{:A\times A}$)
and remains \lstinline!None! after any filtering operation. (If the
cluster is down, a check of credentials will not bring it up.) So,
the composition law holds for that case. 

In the second case, we have two credentials $a_{1},a_{2}$ in a value
$s\triangleq\bbnum 0+a_{1}\times a_{2}$. The filtering operation
$s\triangleright\text{filt}_{F}(p_{1})\triangleright\text{filt}_{F}(p_{2})$
will produce different results according to the values of the predicates
$p_{1}$ and $p_{2}$ applied to $a_{1}$ and $a_{2}$. We can summarize
all results in a table, where we denote for brevity the left-hand
side of the composition law by $\text{L.H.S.}\triangleq s\triangleright\text{filt}_{F}(p_{1})\triangleright\text{filt}_{F}(p_{2})$
and the right-hand side by $\text{R.H.S.}\triangleq s\triangleright\text{filt}_{F}(p_{12})$,
where $p_{12}\triangleq x\rightarrow p_{1}(x)\wedge p_{2}(x)$:
\noindent \begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline 
{\footnotesize{}$p_{1}(a_{1})$} & {\footnotesize{}$p_{1}(a_{2})$} & {\footnotesize{}$p_{2}(a_{1})$} & {\footnotesize{}$p_{2}(a_{2})$} & {\footnotesize{}$p_{12}(a_{1})$} & {\footnotesize{}$p_{12}(a_{2})$} & {\footnotesize{}$s\triangleright\text{filt}_{F}(p_{1})$} & {\footnotesize{}$\text{L.H.S.}$} & {\footnotesize{}$\text{R.H.S.}$}\tabularnewline
\hline 
\hline 
{\small{}}\lstinline!true! & {\small{}}\lstinline!true! & {\small{}}\lstinline!true! & {\small{}}\lstinline!false! & {\small{}}\lstinline!true! & {\small{}}\lstinline!false! & {\small{}$\bbnum 0+a_{1}\times a_{2}$} & {\small{}$\bbnum 0+a_{1}\times a_{1}$} & {\small{}$\bbnum 0+a_{1}\times a_{1}$}\tabularnewline
\hline 
{\small{}}\lstinline!true! & {\small{}}\lstinline!false! & {\small{}}\lstinline!true! & {\small{}}\lstinline!true! & {\small{}}\lstinline!true! & {\small{}}\lstinline!false! & {\small{}$\bbnum 0+a_{1}\times a_{1}$} & {\small{}$\bbnum 0+a_{1}\times a_{1}$} & {\small{}$\bbnum 0+a_{1}\times a_{1}$}\tabularnewline
\hline 
{\small{}}\lstinline!???! & {\small{}}\lstinline!???! & {\small{}}\lstinline!false! & {\small{}}\lstinline!false! & {\small{}}\lstinline!false! & {\small{}}\lstinline!false! & {\small{}}\lstinline!???! & {\small{}$1+\bbnum 0^{:A\times A}$} & {\small{}$1+\bbnum 0^{:A\times A}$}\tabularnewline
\hline 
{\small{}}\lstinline!true! & {\small{}}\lstinline!false! & {\small{}}\lstinline!false! & {\small{}}\lstinline!true! & {\small{}}\lstinline!false! & {\small{}}\lstinline!false! & {\small{}$\bbnum 0+a_{1}\times a_{1}$} & {\small{}$1+\bbnum 0^{:A\times A}$} & {\small{}$1+\bbnum 0^{:A\times A}$}\tabularnewline
\hline 
{\small{}}\lstinline!false! & {\small{}}\lstinline!false! & {\small{}}\lstinline!???! & {\small{}}\lstinline!???! & {\small{}}\lstinline!false! & {\small{}}\lstinline!false! & {\small{}$1+\bbnum 0^{:A\times A}$} & {\small{}$1+\bbnum 0^{:A\times A}$} & {\small{}$1+\bbnum 0^{:A\times A}$}\tabularnewline
\hline 
\end{tabular}
\par\end{center}

We see that the last two columns are always equal, which verifies
the composition law. We omitted some rows from the table because the
filtering code is completely symmetric with respect to interchanging
$a_{1}$ and $a_{2}$, and because the composition law is trivial
when $p_{1}=p_{2}$.

The partial function law holds because the code of \lstinline!filter!
will always remove the value \lstinline!a1!, or \lstinline!a2!,
or both of them when the filtering predicate \lstinline!p! returns
\lstinline!false! for any of those values.

So, we have proved that all filtering laws hold for the \lstinline!filter!
function shown above. If the program\textsf{'}s requirements change, the \lstinline!filter!
function will need to be changed. For instance, suppose the first
server becomes the only source of valid credentials. The second server
may copy the first server\textsf{'}s credentials if needed, but the cluster
will go down whenever the first server\textsf{'}s credentials expire. This
corresponds to the code:

\begin{lstlisting}
def filter[A](p: A => Boolean): F[A] => F[A] = {
    case None             => None
    case Some((a1, a2))   => (p(a1), p(a2)) match {
        case (true, true)     => Some((a1, a2))
        case (true, false)    => Some((a1, a1))
        case (false, _)       => None    // The cluster is down if credentials expire for server 1.
    }
}
\end{lstlisting}
Alternatively, we may get a new requirement that credentials \emph{cannot}
be copied between servers:
\begin{lstlisting}
def filter[A](p: A => Boolean): F[A] => F[A] = {
    case None             => None
    case Some((a1, a2))   => (p(a1), p(a2)) match {
        case (true, true)     => Some((a1, a2))   // Both credentials are valid.
        case _                => None    // The cluster is down when any of the credentials expire.
    }
}
\end{lstlisting}
The filtering laws will still hold with these alternative implementations.
We omit the proofs.

\subsubsection{Example \label{subsec:filt-solved-example-2}\ref{subsec:filt-solved-example-2}}

John can have up to $3$ coupons, and Jill up to $2$. All of John\textsf{'}s
coupons must be valid on purchase day, while each of Jill\textsf{'}s coupons
is checked independently. Implement a filterable functor describing
this situation.

\subparagraph{Solution}

We use a type parameter $A$ for the type of \textsf{``}coupons\textsf{''}. A data
structure holding \textsf{``}up to $3$\textsf{''} values of type $A$ is written
as $\bbnum 1+A+A\times A+A\times A\times A$ and can be implemented
in Scala by:
\begin{lstlisting}[mathescape=true]
sealed trait JohnsCoupons[A]  // This represents the type $\color{dkgreen}\bbnum 1+A+A\times A+A\times A\times A$.
final case class John0[A]()                    extends JohnsCoupons[A]
final case class John1[A](c1: A)               extends JohnsCoupons[A]
final case class John2[A](c1: A, c2: A)        extends JohnsCoupons[A]
final case class John3[A](c1: A, c2: A, c3: A) extends JohnsCoupons[A] 
\end{lstlisting}
This code models John\textsf{'}s coupons. Jill\textsf{'}s coupons are implemented similarly:
\begin{lstlisting}[mathescape=true]
sealed trait JillsCoupons[A]    // This represents the type $\color{dkgreen}\bbnum 1+A+A\times A$.
final case class Jill0[A]()             extends JillsCoupons[A]
final case class Jill1[A](c1: A)        extends JillsCoupons[A]
final case class Jill2[A](c1: A, c2: A) extends JillsCoupons[A] 
\end{lstlisting}
The full data type is the product of John\textsf{'}s and Jill\textsf{'}s coupons:
\begin{lstlisting}
final case class Coupons[A](johns: JohnsCoupons[A], jills: JillsCoupons[A])
\end{lstlisting}
It is convenient to define the filtering functions separately for
\lstinline!JohnsCoupons! and for \lstinline!JillsCoupons!:
\begin{lstlisting}[mathescape=true]
def filterJohn[A](p: A => Boolean): JohnsCoupons[A] => JohnsCoupons[A] = {
  case John0()             => John0()  // We return John0() unless ${\color{dkgreen}\text{\emph{all}}}$ coupons are valid:
  case John1(c1)           => if (p(c1)) John1(c1) else John0()
  case John2(c1, c2)       => if (p(c1) && p(c2)) John2(c1, c2) else John0()
  case John3(c1, c2, c3)   => if (p(c1) && p(c2) && p(c3)) John3(c1, c2, c3) else John0()
}
def filterJill[A](p: A => Boolean): JillsCoupons[A] => JillsCoupons[A] = {
  case Jill0() => Jill0()  // We must remove all the invalid coupons.
  case Jill1(c1) => if (p(c1)) Jill1(c1) else Jill0()
  case Jill2(c1, c2) => (p(c1), p(c2)) match {
     case (true, true)     => Jill2(c1, c2)
     case (true, false)    => Jill1(c1)
     case (false, true)    => Jill1(c2)
     case (false, false)   => Jill0()
  }
}
\end{lstlisting}
Now we can define the \lstinline!filter! function for \lstinline!Coupons!:
\begin{lstlisting}
def filter[A](p: A => Boolean)(fa: Coupons[A]): Coupons[A] =
  Coupons(filterJohn(p)(fa.johns), filterJill(p)(fa.jills))
\end{lstlisting}

We will not prove the laws for the \lstinline!filter! function because
its code follows from general constructions derived later in this
chapter. Running the \texttt{scalacheck} tests shows no failures:
\begin{lstlisting}
implicit val filterableCoupons = new Filterable[Coupons] {
  def filt[A](p: A => Boolean)(fa: Coupons[A]): Coupons[A] = filter(p)(coupons)
}
checkFilteringLaws[Coupons, Int, String]        // Tests pass.
\end{lstlisting}


\subsubsection{Example \label{subsec:filt-solved-example-3}\ref{subsec:filt-solved-example-3}}

A server receives a sequence of requests. Each request must be authenticated.
Once a non-authenticated request is found, no further requests are
accepted. Is this situation described by a filterable functor?

\subparagraph{Solution}

We represent the requests by a \lstinline!Seq[A]! wrapped in a \lstinline!Server!
type:
\begin{lstlisting}
final case class Server[A](requests: Seq[A])
\end{lstlisting}
Suppose a predicate \lstinline!p: A => Boolean! checks the authentication.
The filtering operation truncates the sequence when the predicate
\lstinline!p! first returns \lstinline!false!:\index{filterable!defined via takeWhile@defined via \texttt{takeWhile}}
\begin{lstlisting}
def filter[A](p: A => Boolean)(s: Server[A]): Server[A] = Server(s.requests.takeWhile(p))
\end{lstlisting}
We will not prove the laws because this implementation reduces to
general constructions of filterable functors (see page~\pageref{proof-that-takeWhile-is-a-lawful-filter}
below). Intuitively, we expect laws to hold because the \lstinline!filter!
function always removes values that fail the predicate \lstinline!p!.
The filtering function also removes other values that may or may not
fail the predicate, but the filtering laws do not forbid removing
\emph{more} values than strictly necessary.

\subsubsection{Example \label{subsec:filt-solved-example-4}\ref{subsec:filt-solved-example-4}}

If possible, implement a \lstinline!Filterable! typeclass instance
for:

\textbf{(a)} The functor $F$ defined by the Scala code:
\begin{lstlisting}
final case class F[T](x: Option[T], yy: Option[(T, T)])
\end{lstlisting}

\textbf{(b)} $F^{A}\triangleq\text{Int}+\text{Int}\times A+\text{Int}\times A\times A+\text{Int}\times A\times A\times A\quad.$

\textbf{(c)} A non-empty list functor, $F^{A}=\text{NEList}^{A}$,
defined recursively as $F^{A}\triangleq A+A\times F^{A}\quad.$ 

\textbf{(d)} $F^{Z,A}\triangleq Z+\text{Int}\times Z\times A\times A$
(with respect to the type parameter $A$).

\textbf{(e)} $F^{Z,A}\triangleq Z+\text{Int}\times A\times\text{List}^{A}$
(with respect to the type parameter $A$).

\subparagraph{Solution}

\textbf{(a)} The functor $F$ is written in the code notation as $F^{T}\triangleq\left(\bbnum 1+T\right)\times\left(\bbnum 1+T\times T\right)$.
This is a product of \lstinline!Option[T]!, which is filterable,
and the functor $\bbnum 1+T\times T$, which was shown to be filterable
in Example~\ref{subsec:filt-solved-example-1}. We can apply the
corresponding \lstinline!filter! operation to each part of the product:
\begin{lstlisting}
def filter[T](p: T => Boolean): F[T] => F[T] = {
  case F(t, None)             => F(t.filter(p), None)
  case F(t, Some((t1, t2)))   => F(t.filter(p), if (p(t1) && p(t2)) Some((t1, t2)) else None)
}
\end{lstlisting}
Each part of the product type satisfies the filtering laws separately
(see Statement~\ref{subsec:Statement-filterable-functor-product}
below).

\textbf{(b)} The functor $F$ can be written equivalently as:
\[
F^{A}\cong\text{Int}\times\left(\bbnum 1+A+A\times A+A\times A\times A\right)=\text{Int}\times\text{JohnsCoupons}^{A}\quad,
\]
where we used the functor \lstinline!JohnsCoupons! from Example~\ref{subsec:filt-solved-example-2}.
So, we use the same filtering operation for \lstinline!JohnsCoupons!
as in Example~\ref{subsec:filt-solved-example-2}, while keeping
the \lstinline!Int! value unchanged:
\begin{lstlisting}
final case class F[A](n: Int, johns: JohnsCoupons[A])
def filter[A](p: A => Boolean)(fa: F[A]): F[A] = fa.copy(johns = filterJohn(p)(johns))
\end{lstlisting}

An interesting alternative implementation of \lstinline!filter! uses
the integer value \lstinline!n! for tracking the total number of
data items \emph{removed} by filtering:
\begin{lstlisting}
def filter[A](p: A => Boolean)(fa: F[A]): F[A] = {
  val (removed, newJohnsCoupons) = fa.johns match {
    case John0()             => (0, John0())
    case John1(c1)           => if (p(c1)) (0, John1(c1)) else (1, John0())
    case John2(c1, c2)       => if (p(c1) && p(c2)) (0, John2(c1, c2)) else (2, John0())
    case John3(c1, c2, c3)   => if (p(c1) && p(c2) && p(c3)) (0, John3(c1, c2, c3)) else (3, John0())
  }
  F(fa.n + removed, newJohnsCoupons)
}
\end{lstlisting}
The new code still satisfies the filtering laws (we omit the proof).

\textbf{(c)} A type definition of \lstinline!NEList! is:
\begin{lstlisting}
sealed trait NEList[A]
final case class Last[A](x: A)                  extends NEList[A]
final case class More[A](x: A, tail: NEList[A]) extends NEList[A]
\end{lstlisting}
We find that we \emph{cannot} implement the type signature of \lstinline!filter!:
\begin{lstlisting}[numbers=left]
def filter[A](p: A => Boolean): NEList[A] => NEList[A] = {
  case Last(x)       => if (p(x)) ??? else ???    // Need to compute a value of type NEList[A] here.
  case More(x, tail) => ???
}
\end{lstlisting}
The problem is in line~2 above when \lstinline!p(x) == false!: we
need to remove the value \lstinline!x!, making the list empty, but
the type \lstinline!NEList[A]! disallows empty lists. So, line~2
must always return a list containing the value \lstinline!x!, which
violates the partial function law of filtering. We conclude that \lstinline!NEList!
is not filterable.

\textbf{(d)} Looking at the type expression $F^{Z,A}\triangleq Z+\text{Int}\times Z\times A\times A$,
we need to check whether we could remove the values of type $A$ that
do not pass the filter. If none of the two values of type $A$ within
$\text{Int}\times Z\times A\times A$ pass the filter, we will need
to remove both of them and to return a value of type $Z$. Luckily,
we have a value of type $Z$ within $\text{Int}\times Z\times A\times A$.
So, we may implement \lstinline!filter! like this:
\begin{lstlisting}
type F[A] = Either[Z, (Int, Z, A, A)]  // The type `Z` must be already defined.
def filter[A](p: A => Boolean): F[A] => F[A] = {
  case Left(z)                 => Left(z)
  case Right((n, z, a1, a2))   => if (p(a1) && p(a2)) Right((n, z, a1, a2))
                                  else Left(z) // If anything fails the filter condition, use the value `z`.
}
\end{lstlisting}
The filtering laws will hold similarly to Example~\ref{subsec:filt-solved-example-1}.

\textbf{(e)} If $x$ is a value of type $Z+\text{Int}\times A\times\text{List}^{A}$,
we may compute \lstinline!x.filter(_ => false)!. Since \emph{no}
values of type $A$ pass the test, we may not return a data structure
containing any values of type $A$ (or else the partial function law
will fail). The only alternative is to return a value of type $Z$.
But $Z$ is a type parameter, and we cannot create values of type
$Z$ from scratch. We conclude that $F^{Z,A}$ is not filterable with
respect to $A$.
\begin{lstlisting}
type F[A] = Either[Z, (Int, A, List[A])]
def filter[A](p: A => Boolean): F[A] => F[A] = {
  case Left(z)             => Left(z)
  case Right((n, a, as))   =>  // What to compute in case p(a) == false and as.filter(p) == List() ?
                           ??? // In that case, we will have neither values of type A nor of type Z.
}
\end{lstlisting}


\subsection{Exercises: Programming with filterable functors\index{exercises} }

\subsubsection{Exercise \label{subsec:filt-exercise-1}\ref{subsec:filt-exercise-1}}

Confucius\index{Confucius} gave a proverb on each of the 7 days of
a week. Sometimes the wise proverbs were hard to remember. If Confucius
forgets what he said on a given day, he also forgets what he said
on all the \emph{previous} days of the week. Is this situation described
by a filterable functor?

\subsubsection{Exercise \label{subsec:filt-exercise-2}\ref{subsec:filt-exercise-2}}

Define an extension method \lstinline!evenFilter(p)! for \lstinline!IndexedSeq[T]!
such that a value \lstinline!x: T! is kept in the sequence if \lstinline!p(x) == true!
and only if the initial sequence has an \emph{even} total number of
elements \lstinline!y! for which \lstinline!p(y) == false!. Does
\lstinline!evenFilter! define a lawful filterable functor? 

\subsubsection{Exercise \label{subsec:filt-exercise-4-1}\ref{subsec:filt-exercise-4-1}}

Three times each week (on Mondays, Wednesdays, and Fridays) a data
set is collected and a test is run. If a test fails, the corresponding
data set is discarded. Is this situation described by a lawful filterable
functor if we impose one of the following additional requirements:

\textbf{(a)} All data sets for a given week are discarded if at least
\emph{two} of the tests failed that week?

\textbf{(b)} All data sets for a given week are retained if at least
\emph{two} of the tests passed that week?

\subsubsection{Exercise \label{subsec:filt-exercise-3}\ref{subsec:filt-exercise-3}}

If possible, implement the \lstinline!filter! function or a \lstinline!Filterable!
typeclass instance (law checking is optional) for:

\textbf{(a)} The functor $Q^{A,Z}$ with respect to the type parameter
$A$, where $Q$ is defined by this Scala code:\texttt{\textcolor{blue}{\footnotesize{}}}
\begin{lstlisting}
final case class Q[A, Z](id: Long, user1: Option[(A, Z)], user2: Option[(A, Z)])
\end{lstlisting}
{\footnotesize\par}

\textbf{(b)} The functor $R$ defined by the Scala code:
\begin{lstlisting}
final case class R[A](x: Int, y: Int, z: A, data: List[A])
\end{lstlisting}

\textbf{(c)} $F^{P,Q,A}\triangleq(P\rightarrow P)+(Q\rightarrow Q)\times A\times A\times A$
(with respect to the type parameter $A$).

\textbf{(d)} The functor \lstinline!MyTree[A] = Option[Tree2[A]]!,
where \lstinline!Tree2! was defined in Section~\ref{subsec:Binary-trees}.

\textbf{(e)} The functor $\text{Tree22}$ defined recursively as:
\[
\text{Tree22}^{A}\triangleq\bbnum 1+A\times A\times\text{Tree22}^{A}\times\text{Tree22}^{A}\quad.
\]


\subsubsection{Exercise \label{subsec:filt-exercise-4-2}\ref{subsec:filt-exercise-4-2}}

Is the perfect-shaped tree $R$ defined by $R^{A}\triangleq A+R^{A\times A}$
filterable? Implement a \lstinline!filter! function for a perfect-shaped\index{perfect-shaped tree}
tree $R$ defined by:

\textbf{(a)} $R^{A}\triangleq\bbnum 1+A+R^{A\times A}\quad.\quad$
\textbf{(b)} $R^{A}\triangleq A+R^{(\bbnum 1+A)\times(\bbnum 1+A)}\quad.$

\section{Laws and structure}

\subsection{Simplifying the filtering laws: Motivation for \texttt{deflate\label{subsec:Simplifying-the-filtering-laws-deflate}}}

The four laws of \lstinline!filter! (Section~\ref{subsec:Motivation-for-and-derivation-of-laws-of-filtering})
require considerable work to verify directly. Is there a shorter reformulation
of the laws that is easier to understand and to verify?

To motivate that, begin by considering a heuristic picture of a filter
operation ($\text{filt}_{F}(p):F^{A}\rightarrow F^{A}$) that may
remove some values of type $A$ from a wrapper $F^{A}$. For example,
if $F^{A}\triangleq\bbnum 1+A$ then the filtering operation will
sometimes remove the value of type $A$ and return the result $1+\bbnum 0$.
It appears that the filtering operation, at the type level, replaces
the type $A$ by the void type\index{void type} $\bbnum 0$ whenever
a value does not pass the filtering condition. In examples of non-filterable
functors $F$, such as $F^{A}\triangleq A\times\left(\bbnum 1+A\right)$,
the type expression for $F^{A}$ cannot accommodate replacing the
type $A$ by $\bbnum 0$. 

If we had the functor $F^{\bbnum 1+A}$ instead of $F^{A}$, we would
be able to replace $A$ by $\bbnum 0$ whenever necessary:
\begin{lstlisting}
def filter[F[_]: Functor, A](p: A => Boolean): F[Option[A]] => F[Option[A]] =
    _.map(_.filter(p))    // Using the standard .filter method on Option.
\end{lstlisting}
We can always convert a value of type $F^{A}$ back into a value of
type $F^{\bbnum 1+A}$ (as long as $F$ is a functor):
\begin{lstlisting}
def inflate[F[_]: Functor, A]: F[A] => F[Option[A]] = _.map(x => Some(x))
\end{lstlisting}
The code notation for the function \lstinline!inflate! is:
\[
\text{inflate}^{F,A}\triangleq(x^{:A}\rightarrow\bbnum 0^{:\bbnum 1}+x)^{\uparrow F}\quad.
\]
It remains to convert $F^{\bbnum 1+A}$ to $F^{A}$. If we could \emph{somehow}
do that, say, via a function we will call \lstinline!deflate!:
\begin{lstlisting}
def deflate[F[_], A]: F[Option[A]] => F[A] = ???
\end{lstlisting}
or, in the code notation:
\[
\text{deflate}^{F,A}:F^{\bbnum 1+A}\rightarrow F^{A}\quad,
\]
we would then be able to express \lstinline!filter! through \lstinline!map!
and \lstinline!deflate! like this:
\begin{align*}
 & \quad\quad\quad\quad\left(\text{filt}_{F}(p)\right)^{:F^{A}\rightarrow F^{A}}=\text{inflate}\bef\big(\text{filt}_{\text{Opt}}(p)\big)^{\uparrow F}\bef\text{deflate}\quad.\\
 & \xymatrix{\xyScaleX{5pc}\xyScaleY{0.8pc}F^{A}\ar[r]\sp(0.45){\text{inflate}} & F^{\bbnum 1+A}\ar[r]\sp(0.55){\big(\text{filt}_{\text{Opt}}(p)\big)^{\uparrow F}} & F^{\bbnum 1+A}\ar[r]\sp(0.55){\text{deflate}} & F^{A}}
\end{align*}
Here $\text{filt}_{\text{Opt}}$ is the standard \lstinline!filter!
method of \lstinline!Option!. 

We notice that both functions in the composition $\text{inflate}\bef(\text{filt}_{\text{Opt}}(p))^{\uparrow F}$
are lifted to the functor $F$. So, we can simplify that composition
to a single lifted function:
\begin{align*}
 & \gunderline{\text{inflate}}\bef(\text{filt}_{\text{Opt}}(p))^{\uparrow F}\\
{\color{greenunder}\text{definition of }\text{inflate}:}\quad & =(x^{:A}\rightarrow\bbnum 0^{:\bbnum 1}+x)^{\uparrow F}\bef(\text{filt}_{\text{Opt}}(p))^{\uparrow F}\\
{\color{greenunder}\text{functor composition law of }F:}\quad & =\big(x\rightarrow\text{filt}_{\text{Opt}}(p)(\bbnum 0+x)\big)^{\uparrow F}\quad.
\end{align*}
We will need to use this function often, so let us call it $\psi(p)$
or even shorter, $\psi_{p}$, for convenience:
\begin{lstlisting}
def psi[A](p: A => Boolean): A => Option[A] = x => Some(x).filter(p)
\end{lstlisting}
In the code notation:
\begin{align*}
 & \psi^{A}:(A\rightarrow\bbnum 2)\rightarrow A\rightarrow\bbnum 1+A\quad,\\
 & \psi_{p}\triangleq\psi(p^{:A\rightarrow\bbnum 2})\triangleq x^{:A}\rightarrow\text{filt}_{\text{Opt}}(p)(\bbnum 0+x)\quad.
\end{align*}

Using the function $\psi$, we can express the \lstinline!filter!
operation as:
\begin{align}
 & \xymatrix{\xyScaleX{4pc}F^{A}\ar[r]\sp(0.5){\psi_{p}^{\uparrow F}} & F^{\bbnum 1+A}\ar[r]\sp(0.55){\text{deflate}} & F^{A}}
\quad\quad\quad\quad\quad\text{filt}_{F}(p)=\psi_{p}^{\uparrow F}\bef\text{deflate}\quad.\label{eq:def-filter-through-deflate}
\end{align}
\begin{lstlisting}
def filter[A](p: A => Boolean)(fa: F[A]): F[A] = deflate(fa.map(psi(p)))
\end{lstlisting}

We derived the code for \lstinline!filter! assuming that a suitable
function \lstinline!deflate! exists. Can we derive the code for \lstinline!deflate!
for a given filterable functor $F$, e.g., for $F=~$\lstinline!Seq!?
The required type signature is \lstinline!deflate: Seq[Option[T]] => Seq[T]!.
The Scala library has a \lstinline!flatten! method for \lstinline!Seq!
with exactly that type signature; it removes all empty \lstinline!Option!
values from a sequence. This shows how to derive the \lstinline!deflate!
method for any filterable $F$: just use $F$\textsf{'}s \lstinline!filter!
to remove the empty \lstinline!Option! values from $F^{\bbnum 1+A}$.
\begin{lstlisting}[mathescape=true]
def deflate[F[_]: Filterable : Functor, A]: F[Option[A]] => F[A] =
    _.filter(_.nonEmpty).map(_.get)
\end{lstlisting}
\begin{align}
 & \text{deflate}:\xymatrix{\xyScaleX{7.0pc}F^{\bbnum 1+A}\ar[r]\sp(0.5){\text{filt}_{F}(\text{nonEmpty)}} & F^{\bbnum 1+A}\ar[r]\sp(0.5){\text{get}^{\uparrow F}} & F^{A}}
\nonumber \\
 & \text{deflate}^{:F^{\bbnum 1+A}\rightarrow F^{A}}=\text{filt}_{F}(\text{nonEmpty})\bef\text{get}^{\uparrow F}\quad.\label{eq:def-deflate-via-filter}
\end{align}

The method \lstinline!get! is a \index{partial function}partial
function and will fail on empty \lstinline!Option! values (\lstinline!None!).
However, it is safe to use $\text{get}^{\uparrow F}$ here, because
the partial function law of filtering guarantees that \lstinline!.filter(_.nonEmpty)!
will prevent \lstinline!get! from being applied to \lstinline!None!
values. Because of this, \lstinline!deflate! is a \emph{total} function
when defined by Eq.~(\ref{eq:def-deflate-via-filter}), as long as
$F$\textsf{'}s \lstinline!filter! obeys its partial function law.

The ability to express \lstinline!filter! via \lstinline!deflate!
means that a functor\textsf{'}s filtering logic is fully described as long
as we know how to exclude empty \lstinline!Option! values from $F^{\bbnum 1+A}$
and convert the result to $F^{A}$. We can define the \lstinline!Filterable!
typeclass through \lstinline!deflate!, providing \lstinline!filter!
and \lstinline!deflate! as extension methods:
\begin{lstlisting}
abstract class Filterable[F[_]: Functor] {    // Need a `Functor` instance to use `.map`.
  def deflate[A]: F[Option[A]] => F[A]   // Typeclass instances will implement `deflate`.
  def filt[A](p: A => Boolean)(fa: F[A]): F[A] = deflate(fa.map(x => Some(x).filter(p)))
} // Typeclass instances do not have to implement `filt` but may override it for performance reasons.

implicit class FilterableSyntax[F[_]: Filterable, A](fa: F[Option[A]]) {
  def deflate: F[A] = implicitly[Filterable[F]].deflate(fa)
  def withFilter(p: A => Boolean): F[A] = implicitly[Filterable[F]].filt(p)(fa)
}
\end{lstlisting}


\subsubsection{Example \label{subsec:Example-ff-deflate-1-1}\ref{subsec:Example-ff-deflate-1-1}\index{examples (with code)}}

Use \lstinline!deflate! to implement a \lstinline!Filterable! instance
for the functor $F^{A}\triangleq Z\rightarrow\text{List}^{A}$.

\subparagraph{Solution}

The type signature of \lstinline!deflate! is implemented as:
\begin{lstlisting}
type F[A] = Z => List[A]   // The type Z must be defined before.
def deflateF[A](fa: F[Option[A]]): F[A] = { z => fa(z).flatten }
\end{lstlisting}
We used Scala\textsf{'}s library method \lstinline!flatten! with the type
signature \lstinline!Seq[Option[A]] => Seq[A]!. This method is defined
for all sequences, similarly to the \lstinline!flatten! method that
has type \lstinline!Seq[Seq[A]] => Seq[A]!.

Using this function, we implement the typeclass instance as:
\begin{lstlisting}
implicit val filterableF = new Filterable[F] {
  def deflate[A]: F[Option[A]] => F[A] = deflateF
}
\end{lstlisting}


\subsubsection{Example \label{subsec:Example-ff-deflate-1}\ref{subsec:Example-ff-deflate-1}}

Implement \lstinline!deflate! for the functor $F^{A}\triangleq A\times A+(Z\rightarrow Z)$.

\subparagraph{Solution}

The type signature of \lstinline!deflate! is $F^{\bbnum 1+A}\rightarrow F^{A}$
and can be implemented, e.g., as:
\begin{lstlisting}
type F[A] = Either[(A, A), Z => Z]   // The type Z must be defined before.
def deflateF[A]: F[Option[A]] => F[A] = { // Pattern-match on Either[(Option[A], Option[A]), Z => Z].
  case Left((Some(a1), Some(a2)))   => Left((a1, a2))   // Both values pass the filter.
  case Left(_)                      => Right(identity)  // We can use a fixed value of type Z => Z.
  case Right(zz)                    => Right(zz)
}
\end{lstlisting}
This code implements a \textsf{``}greedy\textsf{''} filter that requires both values
in the pair $A\times A$ to satisfy the predicate. Otherwise, the
filter returns the special \textsf{``}empty\textsf{''} value $\bbnum 0^{:A\times A}+\text{id}^{:Z\rightarrow Z}$
of type $F^{A}$. 

\subsubsection{Example \label{subsec:Example-ff-deflate-2}\ref{subsec:Example-ff-deflate-2}}

Use \lstinline!deflate! to verify that the functor $F^{A}\triangleq A+A\times A\times\text{String}$
is not filterable.

\subparagraph{Solution}

We begin by checking whether the type signature of \lstinline!deflate!
can be implemented:
\[
\text{deflate}_{F}:\bbnum 1+A+\left(\bbnum 1+A\right)\times\left(\bbnum 1+A\right)\times\text{String}\rightarrow A+A\times A\times\text{String}\quad.
\]
An immediate problem is that we need to map all disjunctive cases,
including $1+\bbnum 0+\bbnum 0$, into a value of type $F^{A}$, which
contains values of type $A$ in every disjunctive case. So, implementing
\lstinline!deflate! requires us to produce a value of type $A$ from
a unit value, which is impossible in a fully parametric function.
Since \lstinline!deflate! is not implementable, the functor $F$
is not filterable. $\square$

These examples show that \lstinline!deflate! is easier to implement
and to reason about than \lstinline!filter!.

\subsection{Equivalence of \texttt{filter} and \texttt{deflate}\label{subsec:Equivalence-of-filter-and-deflate}}

We have expressed \lstinline!filter! through \lstinline!deflate!
by Eq.~(\ref{eq:def-filter-through-deflate}) and \lstinline!deflate!
through \lstinline!filter! by Eq.~(\ref{eq:def-deflate-via-filter}).
Are the types of \lstinline!deflate! and \lstinline!filter! equivalent?
It turns out that Eqs.~(\ref{eq:def-filter-through-deflate})\textendash (\ref{eq:def-deflate-via-filter})
are inverses of each other only if we assume certain laws.

\subsubsection{Statement \label{subsec:Statement-filter-to-deflate-equivalence}\ref{subsec:Statement-filter-to-deflate-equivalence}}

Begin with a filterable functor $F$\textsf{'}s function \lstinline!filter!,
define \lstinline!deflate! through Eq.~(\ref{eq:def-deflate-via-filter}),
and then define a new function \lstinline!filter!$^{\prime}$ via
Eq.~(\ref{eq:def-filter-through-deflate}):\index{type equivalence!examples}
\[
\text{deflate}=\text{filt}_{F}(\text{nonEmpty})\bef\text{get}^{\uparrow F}\quad,\quad\quad\text{filter}^{\prime}(p)=\psi_{p}^{\uparrow F}\bef\text{deflate}\quad.
\]
Then \lstinline!filter!$^{\prime}$ is equal to \lstinline!filter!,
assuming that the partial function law holds.

\subparagraph{Proof}

We need to show that $\text{filt}_{F}(p)$ is the same as \lstinline!filter!$^{\prime}(p)$
for any predicate $p^{:A\rightarrow\bbnum 2}$:
\begin{align}
{\color{greenunder}\text{expect to equal }\text{filt}_{F}(p):}\quad & \text{filter}^{\prime}(p)=\gunderline{\psi_{p}^{\uparrow F}\bef\text{filt}_{F}}(\text{nonEmpty})\bef\text{get}^{\uparrow F}\nonumber \\
{\color{greenunder}\text{naturality law of }\text{filt}_{F}:}\quad & =\text{filt}_{F}(\psi_{p}\bef\text{nonEmpty})\bef\gunderline{\psi_{p}^{\uparrow F}\bef\text{get}^{\uparrow F}}\nonumber \\
{\color{greenunder}\text{composition law of }F:}\quad & =\text{filt}_{F}(\psi_{p}\bef\text{nonEmpty})\bef\big(\psi_{p}\bef\text{get}\big)^{\uparrow F}\quad.\label{eq:filter-prime-derivation-1}
\end{align}
To proceed with the calculation, we need to simplify the expressions
$\psi_{p}\bef\text{get}$ and $\psi_{p}\bef\text{nonEmpty}$. Begin
by writing the code for the standard methods \lstinline!nonEmpty!
and \lstinline!get!, using the equivalent type \lstinline!Option[Unit]!
(i.e., $\bbnum 1+\bbnum 1$) instead of \lstinline!Boolean! (i.e.,
$\bbnum 2$):
\begin{lstlisting}[mathescape=true]
// Use Option[Unit] instead of Boolean, as Option[Unit] $\color{dkgreen}\cong$ Boolean
def nonEmpty[A]: Option[A] => Option[Unit] = _.map(_ => ())

def get[A]: Option[A] => A = { case Some(a) => a }
\end{lstlisting}
\begin{align}
 & \text{nonEmpty}\triangleq\,\begin{array}{|c||cc|}
 & \bbnum 1\,(\text{false}) & \bbnum 1\,(\text{true})\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & (\_^{:A}\rightarrow1)
\end{array}\,=\,\begin{array}{|c||c|}
 & \bbnum 2\\
\hline \bbnum 1 & \_\rightarrow\text{false}\\
A & \_\rightarrow\text{true}
\end{array}\quad,\label{eq:def-of-nonempty-option}\\
 & \text{get}^{:\bbnum 1+A\rightarrow A}\triangleq\,\begin{array}{|c||c|}
 & A\\
\hline \bbnum 1 & \bbnum 0\\
A & \text{id}
\end{array}\quad.\label{eq:def-of-get-option}
\end{align}
These methods are fully parametric since their code uses only the
eight standard code constructions (see Section~\ref{subsec:Short-notation-for-eight-code-constructions}).
The function $\psi$ is also fully parametric because we can implement
it using the type \lstinline!Option[Unit]!:
\begin{lstlisting}[mathescape=true]
//Use Option[Unit] instead of Boolean, as Option[Unit] $\color{dkgreen}\cong$ Boolean
def psi[A](p: A => Option[Unit]): A => Option[A] = x => p(x).map(_ => x)
\end{lstlisting}
\begin{align*}
{\color{greenunder}\text{view }p^{:A\rightarrow\bbnum 2}(x^{:A})\text{ as having type }\bbnum 1+\bbnum 1:}\quad & x^{:A}\triangleright\psi_{p}\triangleq p(x)\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1\,(\text{false}) & \text{id} & \bbnum 0\\
\bbnum 1\,(\text{true}) & \bbnum 0 & 1\rightarrow x
\end{array}\quad.
\end{align*}
We may write that code equivalently as: 
\[
\text{nonEmpty}\triangleq(\_^{:A}\rightarrow1)^{\uparrow\text{Opt}}\quad,\quad\quad\psi_{p}(x)\triangleq x\triangleright p\bef(1\rightarrow x)^{\uparrow\text{Opt}}\quad.
\]

Now we compute the function compositions we need. First, we show that
$\psi_{p}\bef\text{nonEmpty}=p$:
\begin{align}
{\color{greenunder}\text{expect to equal }x\triangleright p:}\quad & x^{:A}\triangleright\psi_{p}\bef\text{nonEmpty}\nonumber \\
 & =x\triangleright p\bef(1\rightarrow x)^{\uparrow\text{Opt}}\bef(\_^{:A}\rightarrow1)^{\uparrow\text{Opt}}\nonumber \\
{\color{greenunder}\text{composition under }^{\uparrow\text{Opt}}:}\quad & =x\triangleright p\bef(\gunderline{1\rightarrow1})^{\uparrow\text{Opt}}\nonumber \\
{\color{greenunder}\text{identity function of type }\bbnum 1\rightarrow\bbnum 1:}\quad & =x\triangleright p\bef\big(\text{id}^{:\bbnum 1\rightarrow\bbnum 1}\gunderline{\big)^{\uparrow\text{Opt}}}\nonumber \\
{\color{greenunder}\text{identity law of }\text{Opt}:}\quad & =x\triangleright p\bef\text{id}=x\triangleright p\quad.\label{eq:composition-of-psi-p-and-nonEmpty-simplified}
\end{align}
The expression $\psi_{p}\bef\text{get}$ is simplified to the partial
function $\text{id}_{|p}$ by matrix composition:
\begin{align}
{\color{greenunder}\text{definitions of }\psi_{p}\text{ and }\text{get}:}\quad & \gunderline{x^{:A}\triangleright\psi_{p}}\bef\gunderline{\text{get}}\nonumber \\
 & =p(x)\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1\,(\text{false}) & \text{id} & \bbnum 0\\
\bbnum 1\,(\text{true}) & \bbnum 0 & 1\rightarrow x
\end{array}\,\bef\,\begin{array}{|c||c|}
 & A\\
\hline \bbnum 1 & \bbnum 0\\
A & \text{id}
\end{array}\\
{\color{greenunder}\text{matrix composition}:}\quad & =p(x)\triangleright\,\,\begin{array}{|c||c|}
 & A\\
\hline \bbnum 1\,(\text{false}) & \bbnum 0\\
\bbnum 1\,(\text{true}) & 1\rightarrow x
\end{array}\nonumber \\
{\color{greenunder}\text{use Eq.~(\ref{eq:def-partial-f}) as definition of }_{|p}:}\quad & =x\triangleright\text{id}_{|p}\quad.\label{eq:composition-of-psi-p-and-get-simplified}
\end{align}
The same derivation performed in Scala syntax looks like this:
\begin{lstlisting}[mathescape=true]
psi(p)(x).get    // Expand the code for `psi` and `get`:
== p(x) match {
     case false  => None
     case true   => Some(x)
   }) match {
     case Some(x)  => x
   }             // Compute function composition:
         == p(x) match { case true => x }   // Rewrite this code equivalently as 
         == x match { case x if p(x) => x } // $\color{dkgreen}x\triangleright\text{id}_{|p}$
\end{lstlisting}
We can now finish the calculation in Eq.~(\ref{eq:filter-prime-derivation-1}):
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{filt}_{F}(p):}\quad & \text{filter}^{\prime}(p)=\text{filt}_{F}(\gunderline{\psi_{p}\bef\text{nonEmpty}})\bef(\gunderline{\psi_{p}\bef\text{get}})^{\uparrow F}\\
{\color{greenunder}\text{simplify using Eqs.~(\ref{eq:composition-of-psi-p-and-nonEmpty-simplified})--(\ref{eq:composition-of-psi-p-and-get-simplified}) }:}\quad & =\text{filt}_{F}(p)\bef(\gunderline{\text{id}_{|p}})^{\uparrow F}\\
{\color{greenunder}\text{partial function law~(\ref{eq:partial-function-law-of-filter}) of }\text{filt}_{F}:}\quad & =\text{filt}_{F}(p)\bef\gunderline{(\text{id})^{\uparrow F}}\\
{\color{greenunder}\text{identity law of }F:}\quad & =\text{filt}_{F}(p)\,\gunderline{\bef\text{id}}=\text{filt}_{F}(p)\quad.
\end{align*}
So, the new function \lstinline!filter!$^{\prime}$ equals the original
\lstinline!filter! function.

\subsubsection{Statement \label{subsec:Statement-deflate-to-filter-equivalence}\ref{subsec:Statement-deflate-to-filter-equivalence}}

Beginning with a given \lstinline!deflate! function, define the corresponding
\lstinline!filter! function via Eq.~(\ref{eq:def-filter-through-deflate})
and then use Eq.~(\ref{eq:def-deflate-via-filter}) to define a new
function \lstinline!deflate!$^{\prime}$:
\[
\text{filt}_{F}(p)=\psi_{p}^{\uparrow F}\bef\text{deflate}\quad,\quad\quad\text{deflate}^{\prime}=\text{filt}_{F}(\text{nonEmpty})\bef\text{get}^{\uparrow F}\quad.
\]
Then \lstinline!deflate!$^{\prime}$ is equal to \lstinline!deflate!,
assuming that the naturality law~(\ref{eq:naturality-law-of-deflate})
holds.

\subparagraph{Proof}

Try showing that the new function \lstinline!deflate!$^{\prime}$
is equal to \lstinline!deflate!:
\begin{equation}
\text{deflate}^{\prime}=\text{filt}_{F}(\text{nonEmpty})\bef\text{get}^{\uparrow F}=\psi_{\text{nonEmpty}}^{\uparrow F}\bef\text{deflate}\bef\text{get}^{\uparrow F}\overset{?}{=}\text{deflate}\quad.\label{eq:deflate-prime-derivation-2}
\end{equation}
The derivation is stuck here: we cannot prove the last equality unless
we somehow switch the order of function compositions, so that $\psi_{\text{nonEmpty}}^{\uparrow F}$
and $\text{get}^{\uparrow F}$ are placed together and the functor
composition law of $F$ can be applied. To achieve that, we need a
law that switches the order of lifted function compositions around
\lstinline!deflate!. The naturality law~(\ref{eq:naturality-law-of-filter})
of \lstinline!filter! has that form, so we can try deriving a similar
naturality law for \lstinline!deflate!. To switch the order of composition
of \lstinline!deflate! with a lifted function, the law must have
the form:
\[
\text{deflate}\bef f^{\uparrow F}=(\text{???})^{\uparrow F}\bef\text{deflate}\quad,
\]
\[
\xymatrix{\xyScaleY{1.0pc}\xyScaleX{5.0pc}F^{\bbnum 1+A}\ar[r]\sp(0.5){\text{deflate}} & F^{A}\ar[d]\sb(0.45){f^{\uparrow F}}\\
\text{???}\ar[r]\sp(0.5){\text{deflate}} & F^{B}
}
\]
The types will match in the right-hand side only if the argument of
\lstinline!deflate! is of type $F^{\bbnum 1+B}$. So, the law must
have the form: 
\[
\text{deflate}\bef f^{\uparrow F}=(\text{???}^{:\bbnum 1+A\rightarrow\bbnum 1+B})^{\uparrow F}\bef\text{deflate}\quad.
\]
The typed hole $\text{???}^{:\bbnum 1+A\rightarrow\bbnum 1+B}$ must
be filled with a value, say, $g^{:\bbnum 1+A\rightarrow\bbnum 1+B}$,
which is somehow related to $f$. The only way to obtain $g$ is to
lift the function $f$ to the \lstinline!Option! functor, i.e., to
define $g\triangleq f^{\uparrow\text{Opt}}$. So, the \textbf{naturality
law}\index{naturality law!of deflate@of \texttt{deflate}} of \lstinline!deflate!
is:
\begin{equation}
\text{deflate}\bef f^{\uparrow F}=f^{\uparrow\text{Opt}\uparrow F}\bef\text{deflate}\quad,\label{eq:naturality-law-of-deflate}
\end{equation}
\[
\xymatrix{\xyScaleY{1.5pc}\xyScaleX{5.0pc}F^{\bbnum 1+A}\ar[r]\sp(0.5){\text{deflate}}\ar[d]\sp(0.45){(f^{\uparrow\text{Opt}})^{\uparrow F}} & F^{A}\ar[d]\sb(0.45){f^{\uparrow F}}\\
F^{\bbnum 1+B}\ar[r]\sp(0.5){\text{deflate}} & F^{B}
}
\]
where $f^{:A\rightarrow B}$ is an arbitrary function. 

Assuming that the naturality law~(\ref{eq:naturality-law-of-deflate})
holds, we continue the derivation in Eq.~(\ref{eq:deflate-prime-derivation-2})
towards showing that \lstinline!deflate!$^{\prime}=$ \lstinline!deflate!:
\begin{align}
{\color{greenunder}\text{expect to equal }\text{deflate}:}\quad & \text{deflate}^{\prime}=\psi_{\text{nonEmpty}}^{\uparrow F}\bef\gunderline{\text{deflate}\bef\text{get}^{\uparrow F}}\nonumber \\
{\color{greenunder}\text{naturality law~(\ref{eq:naturality-law-of-deflate}) of }\text{deflate}:}\quad & =\gunderline{\psi_{\text{nonEmpty}}^{\uparrow F}\bef\text{get}^{\uparrow\text{Opt}\uparrow F}}\bef\text{deflate}\nonumber \\
{\color{greenunder}\text{composition law of }F:}\quad & =\big(\psi_{\text{nonEmpty}}\bef\text{get}^{\uparrow\text{Opt}}\big)^{\uparrow F}\bef\text{deflate}\quad.\label{eq:deflate-derivation-3}
\end{align}
We now need to perform a separate calculation in order to simplify
the function $\psi_{\text{nonEmpty}}\bef\text{get}^{\uparrow\text{Opt}}$,
which must be a function of type $\bbnum 1+A\rightarrow\bbnum 1+A$
for the types to match. Writing this calculation in Scala syntax,
we obtain (skipping some steps for brevity):
\begin{lstlisting}
psi[Option[A]](nonEmpty)(x).map(get) == (nonEmpty(x) match {
  case false   => None
  case true    => Some(x)
}).map { case Some(y) => y } == // Expand code for `nonEmpty`.
( ( x match {
      case None    => false
      case Some(_) => true
    }) match {
        case false   => None
        case true    => Some(x)  // This will be of the form Some(Some(y)).
}).map { case Some(y) => y } ==  // Compute all function compositions.
  x match {
    case None    => None
    case Some(y) => Some(y)
  } == x  // Identity function applied to `x`.
\end{lstlisting}
To perform the same calculation in the code notation, we first prepare
a formula for the lifting operation $^{\uparrow\text{Opt}}$ of the
\lstinline!Option! functor:
\begin{equation}
(h^{:C\rightarrow D})^{\uparrow\text{Opt}}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & D\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
C & \bbnum 0 & h
\end{array}\quad,\text{ so }\quad\text{get}^{\uparrow\text{Opt}}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1+A & \bbnum 0 & \text{get}
\end{array}\,=\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1 & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \text{id}
\end{array}\quad,\label{eq:def-of-get-lifted-Option}
\end{equation}
where we expanded the matrix to accommodate the disjunctive type $\bbnum 1+A$.
Then we compute:
\begin{align*}
 & x^{:\bbnum 1+A}\triangleright\psi_{\text{nonEmpty}}=\gunderline{\text{nonEmpty}\left(x\right)}\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & \bbnum 1+A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1 & \bbnum 0 & 1\rightarrow x
\end{array}\\
{\color{greenunder}\text{definition~(\ref{eq:def-of-nonempty-option})}:}\quad & =x\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & \bbnum 1\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & \_\rightarrow1
\end{array}\,\bef\,\begin{array}{|c||cc|}
 & \bbnum 1 & \bbnum 1+A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1 & \bbnum 0 & 1\rightarrow x
\end{array}\\
{\color{greenunder}\text{matrix composition}:}\quad & =x\triangleright\,\,\begin{array}{|c||cc|}
 & \bbnum 1 & \bbnum 1+A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & \_\rightarrow x
\end{array}\,=x\triangleright\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}\quad.
\end{align*}
The last matrix was derived using the fact that $x$ matches the bottom
row where the type is $\bbnum 0+A$. Finally:
\begin{align}
 & x^{:\bbnum 1+A}\triangleright\psi_{\text{nonEmpty}}\bef\text{get}^{\uparrow\text{Opt}}=x\triangleright\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}\,\bef\gunderline{\text{get}^{\uparrow\text{Opt}}}\nonumber \\
{\color{greenunder}\text{use Eq.~(\ref{eq:def-of-get-lifted-Option})}:}\quad & =x\triangleright\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}\,\bef\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1 & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \text{id}
\end{array}\,=x\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & \text{id}
\end{array}\nonumber \\
 & =x\triangleright\text{id}=x\quad.\label{eq:simplify-psi-nonEmpty-get-opt}
\end{align}
So, we find $\psi_{\text{nonEmpty}}\bef\text{get}^{\uparrow\text{Opt}}=\text{id}$
and thus Eq.~(\ref{eq:deflate-derivation-3}) gives \lstinline!deflate!$^{\prime}=$
\lstinline!deflate!. $\square$

We conclude that the types of \lstinline!filter! and \lstinline!deflate!
are equivalent as long as the partial function law~(\ref{eq:partial-function-law-of-filter})
holds for \lstinline!filter! and the naturality law~(\ref{eq:naturality-law-of-deflate})
holds for \lstinline!deflate!.

\subsubsection{Statement \label{subsec:Statement-partial-functionlaw-deflate-to-filter}\ref{subsec:Statement-partial-functionlaw-deflate-to-filter}}

The partial function law always holds for a \lstinline!filter! function
defined via \lstinline!deflate!.

\subparagraph{Proof}

Given a \lstinline!deflate! function, define \lstinline!filter!
through Eq.~(\ref{eq:def-filter-through-deflate}). Then the partial
function law~(\ref{eq:partial-function-law-of-filter}) is transformed
into an equation illustrated by the following diagram: 
\[
\xymatrix{\xyScaleY{0.1pc}\xyScaleX{2.8pc} & F^{\bbnum 1+A}\ar[r]\sp(0.5){\text{deflate}} & F^{A}\ar[rd]\sp(0.5){~(f^{:A\rightarrow B})^{\uparrow F}}\\
F^{A}\ar[ru]\sp(0.5){\psi_{p}^{\uparrow F}}\ar[rd]\sb(0.5){\psi_{p}^{\uparrow F}} &  &  & F^{B} & \psi_{p}^{\uparrow F}\bef\text{deflate}\bef f^{\uparrow F}=\psi_{p}^{\uparrow F}\bef\text{deflate}\bef f_{|p}^{\uparrow F}\quad.\\
 & F^{\bbnum 1+A}\ar[r]\sp(0.5){\text{deflate}} & F^{A}\ar[ru]\sb(0.5){(f_{|p}^{:A\rightarrow B})^{\uparrow F}}
}
\]
To show that the law holds, we transform both sides using the naturality
law~(\ref{eq:naturality-law-of-deflate}):
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & \psi_{p}^{\uparrow F}\bef\gunderline{\text{deflate}\bef f^{\uparrow F}}=\gunderline{\psi_{p}^{\uparrow F}\bef f^{\uparrow\text{Opt}\uparrow F}}\bef\text{deflate}=\big(\psi_{p}\bef f^{\uparrow\text{Opt}}\big)^{\uparrow F}\bef\text{deflate}\quad.\\
{\color{greenunder}\text{right-hand side}:}\quad & \psi_{p}^{\uparrow F}\bef\gunderline{\text{deflate}\bef f_{|p}^{\uparrow F}}=\gunderline{\psi_{p}^{\uparrow F}\bef f_{|p}^{\uparrow\text{Opt}\uparrow F}}\bef\text{deflate}=\big(\psi_{p}\bef f_{|p}^{\uparrow\text{Opt}}\big)^{\uparrow F}\bef\text{deflate}\quad.
\end{align*}
It remains to show that $\psi_{p}\bef f_{|p}^{\uparrow\text{Opt}}=\psi_{p}\bef f^{\uparrow\text{Opt}}$.
Apply the function $\psi_{p}\bef f^{\uparrow\text{Opt}}$ to an arbitrary
value $x^{:A}$:

\begin{lstlisting}
psi(p)(x).map(f) == (p(x) match {
  case false   => None
  case true    => Some(x)
}) match {
  case None    => None
  case Some(y) => Some(f(y))
}  == p(x) match {
  case false   => None
  case true    => Some(f(x))
}
\end{lstlisting}
The same calculation in the code notation looks like this:
\begin{align*}
x^{:A}\triangleright\psi_{p}\bef f^{\uparrow\text{Opt}} & =p(x)\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1\,(\text{false}) & \text{id} & \bbnum 0\\
\bbnum 1\,(\text{true}) & \bbnum 0 & 1\rightarrow x
\end{array}\,\bef\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & f
\end{array}\\
{\color{greenunder}\text{matrix composition}:}\quad & =p(x)\triangleright\,\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1\,(\text{false}) & \text{id} & \bbnum 0\\
\bbnum 1\,(\text{true}) & \bbnum 0 & 1\rightarrow f(x)
\end{array}\quad.
\end{align*}
In the last expression, the function $f$ is applied to $x$ only
when $p(x)=\text{true}$. So, the result will be the same if we replace
$f(x)$ by the partial function $f_{|p}(x)$, which was defined by
Eq.~(\ref{eq:def-partial-f}) to be equal to $f(x)$ when $p(x)$
holds. It follows that $\psi_{p}\bef f_{|p}^{\uparrow\text{Opt}}=\psi_{p}\bef f^{\uparrow\text{Opt}}$,
concluding the proof. $\square$

The equivalence between \lstinline!filter! and \lstinline!deflate!
extend to their respective naturality laws. In other words, the naturality
laws for \lstinline!filter! and \lstinline!deflate! hold at the
same time. We only need to check the naturality law for one of these
two functions; the other naturality law will then hold automatically.
The following statement proves this equivalence in one direction:

\subsubsection{Statement \label{subsec:Statement-naturality-law-of-deflate-from-filter}\ref{subsec:Statement-naturality-law-of-deflate-from-filter}}

If the naturality law~(\ref{eq:naturality-law-of-filter}) holds
for \lstinline!filter!, the law~(\ref{eq:naturality-law-of-deflate})
will also hold for \lstinline!deflate! if it is defined through \lstinline!filter!
by Eq.~(\ref{eq:def-deflate-via-filter}).

\subparagraph{Proof}

Compare the two sides of the law~(\ref{eq:naturality-law-of-deflate})
if \lstinline!deflate! is defined by Eq.~(\ref{eq:def-deflate-via-filter}):
\begin{align*}
{\color{greenunder}\text{left-hand side of Eq.~(\ref{eq:naturality-law-of-deflate})}:}\quad & f^{\uparrow\text{Opt}\uparrow F}\bef\gunderline{\text{deflate}}=\gunderline{f^{\uparrow\text{Opt}\uparrow F}\bef\text{filt}_{F}(\text{nonEmpty})}\bef\text{get}^{\uparrow F}\\
{\color{greenunder}\text{naturality law~(\ref{eq:naturality-law-of-filter}) of }\text{filt}_{F}:}\quad & \quad=\text{filt}_{F}(f^{\uparrow\text{Opt}}\bef\text{nonEmpty})\bef f^{\uparrow\text{Opt}\uparrow F}\bef\text{get}^{\uparrow F}\quad.\\
{\color{greenunder}\text{right-hand side of Eq.~(\ref{eq:naturality-law-of-deflate})}:}\quad & \gunderline{\text{deflate}}\bef f^{\uparrow F}=\text{filt}_{F}(\text{nonEmpty})\bef\text{get}^{\uparrow F}\bef f^{\uparrow F}\quad.
\end{align*}
The two sides will be equal if we prove that $f^{\uparrow\text{Opt}}\bef\text{nonEmpty}=\text{nonEmpty}$
and that $f^{\uparrow\text{Opt}}\bef\text{get}=\text{get}\bef f$,
which can be viewed as the naturality laws specific to the functions
\lstinline!nonEmpty! and \lstinline!get!. Use the definitions~(\ref{eq:def-of-nonempty-option})
and~(\ref{eq:def-of-get-option}) of \lstinline!nonEmpty! and \lstinline!get!,
set the type parameters as needed to match the types, and compute:
\begin{align*}
 & f^{\uparrow\text{Opt}}\bef\text{nonEmpty}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & B\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & f
\end{array}\,\bef\,\begin{array}{|c||c|}
 & \bbnum 2\\
\hline \bbnum 1 & \_\rightarrow\text{false}\\
B & \_\rightarrow\text{true}
\end{array}\,=\,\begin{array}{|c||c|}
 & \bbnum 2\\
\hline \bbnum 1 & \_\rightarrow\text{false}\\
A & \_\rightarrow\text{true}
\end{array}\,=\text{nonEmpty}\quad,\\
 & f^{\uparrow\text{Opt}}\bef\text{get}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & B\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & f
\end{array}\,\bef\,\begin{array}{|c||c|}
 & B\\
\hline \bbnum 1 & \bbnum 0\\
B & \text{id}
\end{array}\,=\,\begin{array}{|c||c|}
 & B\\
\hline \bbnum 1 & \bbnum 0\\
A & f
\end{array}\quad,\\
 & \text{get}\bef f=\,\begin{array}{|c||c|}
 & A\\
\hline \bbnum 1 & \bbnum 0\\
A & \text{id}
\end{array}\,\bef\,f^{:A\rightarrow B}=\,\begin{array}{|c||c|}
 & B\\
\hline \bbnum 1 & \bbnum 0\\
A & \text{id}\bef f
\end{array}\,=\,\begin{array}{|c||c|}
 & B\\
\hline \bbnum 1 & \bbnum 0\\
A & f
\end{array}\,=f^{\uparrow\text{Opt}}\bef\text{get}\quad.
\end{align*}
$\square$

We have just shown that the naturality law of \lstinline!filter!
guarantees that the naturality law of \lstinline!deflate! holds.
To show that the naturality laws of \lstinline!filter! and \lstinline!deflate!
are equivalent, it remains to show that the converse statement is
also true:

\subsubsection{Statement \label{subsec:Statement-naturality-for-deflate-entails-naturality-for-filter}\ref{subsec:Statement-naturality-for-deflate-entails-naturality-for-filter}}

If the naturality law~(\ref{eq:naturality-law-of-deflate}) holds
for \lstinline!deflate! and if \lstinline!filter! is defined via
\lstinline!deflate! by Eq.~(\ref{eq:def-filter-through-deflate})
then the naturality law~(\ref{eq:naturality-law-of-filter}) holds
for \lstinline!filter!.

\subparagraph{Proof}

Begin by writing the two sides of the law~(\ref{eq:naturality-law-of-filter}):
\begin{align*}
 & \quad{\color{greenunder}\text{left-hand side of Eq.~(\ref{eq:naturality-law-of-filter})}:}\quad\\
 & f^{\uparrow F}\bef\gunderline{\text{filt}\,(p)}=\gunderline{f^{\uparrow F}\bef\psi_{p}^{\uparrow F}}\bef\text{deflate}=(f\bef\psi_{p})^{\uparrow F}\bef\text{deflate}\quad.\\
 & \quad{\color{greenunder}\text{right-hand side of Eq.~(\ref{eq:naturality-law-of-filter})}:}\quad\\
 & \text{filt}\,(f\bef p)\bef f^{\uparrow F}=\psi_{(f\bef p)}^{\uparrow F}\bef\gunderline{\text{deflate}\bef f^{\uparrow F}}\\
 & \quad{\color{greenunder}\text{naturality law~(\ref{eq:naturality-law-of-deflate}) of }\text{deflate}:}\quad\\
 & \quad=\gunderline{\psi_{(f\bef p)}^{\uparrow F}\bef f^{\uparrow\text{Opt}\uparrow F}}\bef\text{deflate}=(\psi_{(f\bef p)}\bef f^{\uparrow\text{Opt}})^{\uparrow F}\bef\text{deflate}\quad.
\end{align*}
The remaining difference is in the order of composition of $f$ and
$\psi$. The proof will be complete if we show that, for any $f^{:A\rightarrow B}$
and $p^{:B\rightarrow\bbnum 2}$,
\begin{equation}
f\bef\psi_{p}=\psi_{(f\bef p)}\bef f^{\uparrow\text{Opt}}\quad.\label{eq:naturality-law-of-psi}
\end{equation}
This equation can be viewed as a naturality law specific to the function
$\psi$. To prove Eq.~(\ref{eq:naturality-law-of-psi}), it is convenient
to use a definition of $\psi_{p}$ that represents $p$ as a function
of type $A\rightarrow\bbnum 1+\bbnum 1\cong A\rightarrow\text{Opt}^{\bbnum 1}$:
\begin{equation}
x^{:A}\triangleright\psi_{p}\triangleq x^{:A}\triangleright p^{:A\rightarrow\text{Opt}^{\bbnum 1}}\bef(1\rightarrow x)^{\uparrow\text{Opt}}\quad.\label{eq:def-of-psi}
\end{equation}
Using this definition of $\psi_{p}$, we can derive Eq.~(\ref{eq:naturality-law-of-psi})
by applying both sides to an arbitrary value $x^{:A}$:
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & x\triangleright f\bef\psi_{p}=x\triangleright f\triangleright\psi_{p}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:def-of-psi})}:}\quad & \quad=x\triangleright f\triangleright p\bef(1\rightarrow x\triangleright f)^{\uparrow\text{Opt}}\\
{\color{greenunder}\triangleright\text{-notation}:}\quad & \quad=x\triangleright f\bef p\bef(1\rightarrow x\triangleright f)^{\uparrow\text{Opt}}\quad.\\
{\color{greenunder}\text{right-hand side}:}\quad & x\triangleright\psi_{(f\bef p)}\bef f^{\uparrow\text{Opt}}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:def-of-psi})}:}\quad & \quad=x\triangleright f\bef p\bef\gunderline{(1\rightarrow x)^{\uparrow\text{Opt}}\bef f^{\uparrow\text{Opt}}}\\
{\color{greenunder}\text{composition law of }^{\uparrow\text{Opt}}:}\quad & \quad=x\triangleright f\bef p\bef\big(\gunderline{(1\rightarrow x)\bef f}\big)^{\uparrow\text{Opt}}\\
{\color{greenunder}\text{compute composition}:}\quad & \quad=x\triangleright f\bef p\bef(\gunderline{1\rightarrow x\triangleright f})^{\uparrow\text{Opt}}\quad.
\end{align*}


\subsection{Motivation and laws for \texttt{liftOpt}\label{subsec:Motivation-and-laws-for-liftopt-and-equivalence}}

In several derivations we just saw, the function \lstinline!deflate!
was composed with $\psi_{p}^{\uparrow F}$ or another lifted function
that mapped types as $A\rightarrow\bbnum 1+A$. This suggests considering
a more general type signature, $f^{:A\rightarrow\bbnum 1+B}$, and
composing $f^{\uparrow F}$ with \lstinline!deflate! into a function
that maps $F^{A}\rightarrow F^{B}$. It turns out that the resulting
function, which we will call \lstinline!liftOpt! and denote by $\text{liftOpt}_{F}$:
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B]): F[A] => F[B] = _.map(f).deflate
\end{lstlisting}
\begin{equation}
\text{liftOpt}_{F}^{A,B}(f^{:A\rightarrow\bbnum 1+B})\triangleq f^{\uparrow F}\bef\text{deflate}_{F}\quad,\label{eq:def-liftOpt-via-deflate}
\end{equation}
has simpler laws and is helpful for developing the theory of filterable
functors.

The name \lstinline!liftOpt! (\textsf{``}lifting from \lstinline!Option!\textsf{''})
is motivated by the type signature:
\[
\text{liftOpt}_{F}^{A,B}:\left(A\rightarrow\bbnum 1+B\right)\rightarrow F^{A}\rightarrow F^{B}\quad.
\]
This lifts a function of type \lstinline!A => Option[B]! into a function
of type \lstinline!F[A] => F[B]!. Except for using a \textsf{``}twisted\textsf{''}
type $A\rightarrow\bbnum 1+B$ instead of $A\rightarrow B$, this
is similar to lifting via the \lstinline!fmap! function:
\[
\text{fmap}_{F}^{A,B}:\left(A\rightarrow B\right)\rightarrow F^{A}\rightarrow F^{B}\quad.
\]
As this chapter will show, similarities between \lstinline!liftOpt!
and \lstinline!fmap! go well beyond type signatures.

We will now derive some properties of \lstinline!liftOpt!. The definition
of \lstinline!liftOpt! through \lstinline!map! and \lstinline!deflate!
is illustrated by the diagram:
\[
\xymatrix{\xyScaleY{1.4pc}\xyScaleX{4.4pc}F^{A}\ar[r]\sp(0.5){(f^{:A\rightarrow\bbnum 1+B})^{\uparrow F}}\ar[rd]\sb(0.4){\text{liftOpt}\,(f)\triangleq~~} & F^{\bbnum 1+B}\ar[d]\sp(0.4){\text{deflate}}\\
 & F^{B}
}
\]
Since $f$ is arbitrary in Eq.~(\ref{eq:def-liftOpt-via-deflate}),
we may set $f=\text{id}^{:A\rightarrow A}$ and the type parameter
$A=\bbnum 1+B$ to find:
\begin{equation}
\text{liftOpt}^{\bbnum 1+B,B}(\text{id}^{:\bbnum 1+B\rightarrow\bbnum 1+B})=\gunderline{\text{id}^{\uparrow F}}\bef\text{deflate}=\text{deflate}\quad.\label{eq:def-deflate-via-liftOpt}
\end{equation}
This expresses \lstinline!deflate! through \lstinline!liftOpt!.
Are these two functions equivalent?\index{type equivalence!examples}

\subsubsection{Statement \label{subsec:Statement-liftOpt-equivalent-to-deflate}\ref{subsec:Statement-liftOpt-equivalent-to-deflate}}

The types of functions \lstinline!liftOpt! and \lstinline!deflate!
are equivalent via Eqs.~(\ref{eq:def-liftOpt-via-deflate})\textendash (\ref{eq:def-deflate-via-liftOpt}),
assuming that \lstinline!liftOpt! obeys a naturality law (Eq.~(\ref{eq:left-naturality-law-of-liftOpt})
below).

\subparagraph{Proof}

We need to show that the equivalence of \lstinline!liftOpt! and \lstinline!deflate!
holds in both directions:

\textbf{(a)} Given a \lstinline!deflate! function, compute a \lstinline!liftOpt!
function via Eq.~(\ref{eq:def-liftOpt-via-deflate}) and then a new
\lstinline!deflate!$^{\prime}$ function via Eq.~(\ref{eq:def-deflate-via-liftOpt}).
Then the new \lstinline!deflate!$^{\prime}$ will be the same function
as the initial \lstinline!deflate!.

\textbf{(b)} Given a \lstinline!liftOpt! function that obeys Eq.~(\ref{eq:left-naturality-law-of-liftOpt}),
compute a \lstinline!deflate! function via Eq.~(\ref{eq:def-deflate-via-liftOpt})
and then a new \lstinline!liftOpt!$^{\prime}$ function via Eq.~(\ref{eq:def-deflate-via-liftOpt}).
The new \lstinline!liftOpt!$^{\prime}$ will be the same as the initial
\lstinline!liftOpt!.

Proof for \textbf{(a)} directly derives the formula \lstinline!deflate!$^{\prime}\negmedspace=\,$\lstinline!deflate!
by this calculation:
\begin{align*}
{\color{greenunder}\text{use Eq.~(\ref{eq:def-deflate-via-liftOpt}) to define }\text{deflate}^{\prime}:}\quad & \text{deflate}^{\prime}=\text{liftOpt}\,(\text{id})\\
{\color{greenunder}\text{use Eq.~(\ref{eq:def-liftOpt-via-deflate}) to define }\text{liftOpt}:}\quad & =\gunderline{\text{id}^{\uparrow F}}\bef\text{deflate}=\text{deflate}\quad.
\end{align*}

Proof for \textbf{(b)} begins by expressing \lstinline!liftOpt!$^{\prime}$
through the initial \lstinline!liftOpt!:
\begin{equation}
\text{liftOpt}^{\prime}(f)=f^{\uparrow F}\bef\text{deflate}=f^{\uparrow F}\bef\text{liftOpt}\,(\text{id})\quad.\label{eq:liftOpt-equivalent-deflate-derivation-1}
\end{equation}
If nothing is known about \lstinline!liftOpt!, the calculation will
get stuck at this point. To proceed, we need to assume that \lstinline!liftOpt!
obeys a law that switches the order of function compositions around
\lstinline!liftOpt! and allows us to pull $f$ inside of \lstinline!liftOpt!
in the equation above. Laws that switch the order of lifted function
compositions are often naturality laws, as we have already seen. So,
let us derive a suitable naturality law for \lstinline!liftOpt!,
beginning with a \lstinline!liftOpt! function defined via \lstinline!deflate!:
\begin{align*}
 & (h^{:A\rightarrow B})^{\uparrow F}\bef\text{liftOpt}^{B,C}(f^{:B\rightarrow\bbnum 1+C})=\gunderline{h^{\uparrow F}\bef f^{\uparrow F}}\bef\text{deflate}\\
{\color{greenunder}\text{composition under }^{\uparrow F}:}\quad & =(h\bef f)^{\uparrow F}\bef\text{deflate}=\text{liftOpt}^{A,C}(h\bef f)\quad.
\end{align*}
It follows that \emph{if} \lstinline!liftOpt! were defined via \lstinline!deflate!
then \lstinline!liftOpt! would automatically satisfy the naturality
law\index{naturality law!of liftOpt@of \texttt{liftOpt}}:
\[
\xymatrix{\xyScaleY{1.8pc}\xyScaleX{4.5pc}F^{A}\ar[d]\sb(0.5){h^{\uparrow F}}\ar[rd]\sp(0.5){~~\text{ liftOpt}\,(h\bef f)}\\
F^{B}\ar[r]\sp(0.42){\text{liftOpt}\,(f)} & F^{C}
}
\]
\begin{equation}
(h^{:A\rightarrow B})^{\uparrow F}\bef\text{liftOpt}_{F}^{B,C}(f^{:B\rightarrow\bbnum 1+C})=\text{liftOpt}_{F}^{A,C}(h^{:A\rightarrow B}\bef f^{:B\rightarrow\bbnum 1+C})\quad.\label{eq:left-naturality-law-of-liftOpt}
\end{equation}
This motivates \emph{imposing} that law on \lstinline!liftOpt!. We
can then finish the proof, resuming from Eq.~(\ref{eq:liftOpt-equivalent-deflate-derivation-1}):
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{liftOpt}\,(f):}\quad & \text{liftOpt}^{\prime}(f)=\gunderline{f^{\uparrow F}}\bef\text{liftOpt}\,(\gunderline{\text{id}})\\
 & =\text{liftOpt}\,(\gunderline{f\bef\text{id}})=\text{liftOpt}\,(f)\quad.
\end{align*}
$\square$

Since \lstinline!deflate! is equivalent to \lstinline!filter! (Statement~\ref{subsec:Statement-deflate-to-filter-equivalence}),
it follows that \lstinline!filter! is  equivalent to \lstinline!liftOpt!.
The next step is to translate the laws of \lstinline!filter! into
the corresponding laws for \lstinline!liftOpt!. Do the laws become
simpler when formulated for \lstinline!liftOpt!?

We have already seen that the partial function law of \lstinline!filter!
is satisfied automatically when \lstinline!filter! is defined via
\lstinline!deflate! (Statement~\ref{subsec:Statement-partial-functionlaw-deflate-to-filter}).
It appears that \lstinline!deflate! has only $3$ laws while \lstinline!filter!
has $4$. We will now show that \lstinline!liftOpt! has only $2$
laws, and yet they are \emph{equivalent} to the $4$ laws of \lstinline!filter!.

To see that, we first express \lstinline!filter! through \lstinline!deflate!
and then finally through \lstinline!liftOpt!:
\begin{equation}
\text{filt}\,(p^{:A\rightarrow\bbnum 2})=\psi_{p}^{\uparrow F}\bef\text{deflate}=\text{liftOpt}\,(\psi_{p})\quad.\label{eq:filter-via-liftOpt}
\end{equation}
Conversely, \lstinline!liftOpt! is expressed via \lstinline!filter!
like this:
\begin{equation}
\text{liftOpt}^{A,B}(f^{:A\rightarrow\bbnum 1+B})\triangleq f^{\uparrow F}\bef\text{deflate}=f^{\uparrow F}\bef\text{filt}\,(\psi_{\text{nonEmpty}})\quad,\label{eq:def-liftOpt-via-filter}
\end{equation}


\paragraph{Identity law}

Let us now translate \lstinline!filter!\textsf{'}s identity law~(\ref{eq:identity-law-of-filter})
into the corresponding law for \lstinline!liftOpt!. Begin by expressing
$\text{filt}\,(\_\rightarrow\text{true})$ via \lstinline!liftOpt!
using Eq.~(\ref{eq:filter-via-liftOpt}):
\[
\text{filt}\,(\_\rightarrow\text{true})=\text{liftOpt}\,(\psi_{(\_\rightarrow\text{true})})=\text{liftOpt}\,(x^{:A}\rightarrow\bbnum 0+x)\quad.
\]
The function $\psi_{(\_\rightarrow\text{true})}$ is equivalent to
a simpler function $x^{:A}\rightarrow\bbnum 0+x$ (in Scala, this
is \lstinline!x => Some(x)!):
\begin{align}
{\color{greenunder}\text{use Eq.~(\ref{eq:def-of-psi})}:}\quad & x^{:A}\triangleright\psi_{(\_\rightarrow\text{true})}\nonumber \\
 & =x^{:A}\triangleright(\_^{:A}\rightarrow\gunderline{\text{true}^{:\text{Opt}^{\bbnum 1}}})\bef(1\rightarrow x)^{\uparrow\text{Opt}}\\
{\color{greenunder}\text{use equivalence }\bbnum 0+1\cong\text{true}^{:\text{Opt}^{\bbnum 1}}:}\quad & =\gunderline{x^{:A}\triangleright(\_^{:A}\rightarrow\bbnum 0+1)}\bef(1\rightarrow x)^{\uparrow\text{Opt}}\nonumber \\
{\color{greenunder}\text{apply function to }x:}\quad & =(\bbnum 0+1)\triangleright(1\rightarrow x)^{\uparrow\text{Opt}}\nonumber \\
 & =\,\,\begin{array}{||cc|}
\bbnum 0 & 1\end{array}\,\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1 & \bbnum 0 & 1\rightarrow x
\end{array}\\
{\color{greenunder}\text{substitute the row into the matrix}:}\quad & =\,\begin{array}{||cc|}
\bbnum 0 & x\end{array}\,=\bbnum 0+x^{:A}\quad.\label{eq:psi-of-true-equals-Some-derivation}
\end{align}
So, we expect the \textbf{identity law} of\index{identity laws!of liftOpt@of \texttt{liftOpt}}
\lstinline!liftOpt! to be:
\begin{equation}
\text{liftOpt}^{A,A}(x^{:A}\rightarrow\bbnum 0+x)=\text{id}^{:F^{A}\rightarrow F^{A}}\quad.\label{eq:identity-law-of-liftOpt}
\end{equation}


\subsubsection{Statement \label{subsec:Statement-identity-law-of-liftOpt}\ref{subsec:Statement-identity-law-of-liftOpt}}

\textbf{(a)} If \lstinline!filter! obeys its naturality law~(\ref{eq:naturality-law-of-filter})
and identity law~(\ref{eq:identity-law-of-filter}) and \lstinline!liftOpt!
is defined via Eq.~(\ref{eq:def-liftOpt-via-filter}) then \lstinline!liftOpt!
 obeys its identity law~(\ref{eq:identity-law-of-liftOpt}).

\textbf{(b)} If \lstinline!liftOpt! obeys its identity law~(\ref{eq:identity-law-of-liftOpt})
then \lstinline!filter!, defined via Eq.~(\ref{eq:filter-via-liftOpt}),
obeys its law~(\ref{eq:identity-law-of-filter}).

\subparagraph{Proof}

\textbf{(a)} Verify the identity law of \lstinline!liftOpt!:
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{id}^{A}:}\quad & \text{liftOpt}\,(x^{:A}\rightarrow\bbnum 0+x)\\
 & =\gunderline{(x^{:A}\rightarrow\bbnum 0+x)^{\uparrow F}\bef\text{filt}^{\bbnum 1+A}}(\text{nonEmpty})\bef\text{get}^{\uparrow F}\\
{\color{greenunder}\text{naturality law~(\ref{eq:naturality-law-of-filter})}:}\quad & =\text{filt}^{A}\big(\gunderline{(x^{:A}\rightarrow\bbnum 0+x)\bef\text{nonEmpty}}\big)\bef(x^{:A}\rightarrow\bbnum 0+x)^{\uparrow F}\bef\text{get}^{\uparrow F}\\
{\color{greenunder}\text{compute composition}:}\quad & =\gunderline{\text{filt}^{A}(x^{:A}\rightarrow\text{true})}\bef(x^{:A}\rightarrow\bbnum 0+x)^{\uparrow F}\bef\text{get}^{\uparrow F}\\
{\color{greenunder}\text{identity law~(\ref{eq:identity-law-of-filter})}:}\quad & =\text{id}^{A}\bef\gunderline{(x^{:A}\rightarrow\bbnum 0+x)^{\uparrow F}\bef\text{get}^{\uparrow F}}=\big(\gunderline{(x^{:A}\rightarrow\bbnum 0+x)\bef\text{get}}\big)^{\uparrow F}\\
{\color{greenunder}\text{compute composition}:}\quad & =(\text{id}^{A})^{\uparrow F}=\text{id}^{A}\quad.
\end{align*}

\textbf{(b)} Verify the identity law of \lstinline!filter! using
Eq.~(\ref{eq:psi-of-true-equals-Some-derivation}):
\begin{align*}
{\color{greenunder}\text{use Eq.~(\ref{eq:filter-via-liftOpt})}:}\quad & \text{filt}\,(\_\rightarrow\text{true})=\text{liftOpt}\,(\psi_{(\_\rightarrow\text{true})})\\
{\color{greenunder}\text{use Eq.~(\ref{eq:psi-of-true-equals-Some-derivation})}:}\quad & =\text{liftOpt}\,(x\rightarrow\bbnum 0+x)\\
{\color{greenunder}\text{use Eq.~(\ref{eq:identity-law-of-liftOpt})}:}\quad & =\text{id}\quad.
\end{align*}
$\square$

The function $x^{:A}\rightarrow\bbnum 0+x$ plays the role of the
\lstinline!pure! method for the \lstinline!Option! type, if we view
\lstinline!Option! as a pointed functor (see Section~\ref{subsec:Pointed-functors-motivation-equivalence}).
Denote that \lstinline!pure! method for brevity by $\text{pu}_{\text{Opt}}$:
\[
\text{pu}_{\text{Opt}}^{:A\rightarrow\bbnum 1+A}\triangleq x^{:A}\rightarrow\bbnum 0+x\quad.
\]
Then \lstinline!liftOpt!\textsf{'}s \index{identity laws!of liftOpt@of \texttt{liftOpt}}identity
law~(\ref{eq:identity-law-of-liftOpt}) is written more concisely
as:
\begin{equation}
\text{liftOpt}_{F}(\text{pu}_{\text{Opt}})=\text{id}\quad.\label{eq:identity-law-liftOpt-via-pure-puOpt}
\end{equation}
We can combine Eq.~(\ref{eq:identity-law-liftOpt-via-pure-puOpt})
and naturality law~(\ref{eq:left-naturality-law-of-liftOpt}) into
a single law if we compose the identity law with a lifted arbitrary
function $f^{:A\rightarrow B}$:
\[
f^{\uparrow F}\bef\text{liftOpt}_{F}(\text{pu}_{\text{Opt}})=\text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\quad.
\]
So, the \textsf{``}combined\textsf{''} \textbf{naturality-identity law} of\index{naturality law!combined with identity law}
\lstinline!liftOpt! is:
\begin{equation}
\text{liftOpt}_{F}(f^{:A\rightarrow B}\bef\text{pu}_{\text{Opt}}^{B})=f^{\uparrow F}\quad.\label{eq:combined-naturality-identity-law-of-liftOpt}
\end{equation}


\paragraph{Composition law}

Next, we translate Eq.~(\ref{eq:composition-law-of-filter}) into
a corresponding law of \lstinline!liftOpt!. That law needs to combine
two predicates $p_{1}$ and $p_{2}$ into a new predicate $p(x)\triangleq p_{1}(x)\wedge p_{2}(x)$.
As Eq.~(\ref{eq:filter-via-liftOpt}) shows, \lstinline!liftOpt!
uses a predicate $p$ only through the function $\psi_{p}$. So, we
will derive the composition law of \lstinline!liftOpt! if we somehow
express $\psi_{p}$ as a combination of $\psi_{p_{1}}$ and $\psi_{p_{2}}$.
Begin by writing:
\begin{lstlisting}
psi(p) == { x => Some(x).filter(p) } == { x => Some(x).filter(p1).filter(p2) }
\end{lstlisting}
\[
\psi_{p}=x^{:A}\rightarrow(\bbnum 0+x)\triangleright\text{filt}_{\text{Opt}}(p)=x^{:A}\rightarrow(\bbnum 0+x)\triangleright\text{filt}_{\text{Opt}}(p_{1})\triangleright\text{filt}_{\text{Opt}}(p_{2})\quad.
\]
We need to transform this code into some sort of combination of the
functions $\psi_{p_{1}}$ and $\psi_{p_{2}}$:
\begin{lstlisting}
psi(p1) == { x => Some(x).filter(p1) }
psi(p2) == { x => Some(x).filter(p2) }
\end{lstlisting}
Since the value \lstinline!Some(x).filter(p1)! has type \lstinline!Option[A]!,
we may apply \lstinline!.map(psi(p2))! to that value:
\begin{lstlisting}
x => Some(x).filter(p1).map(y => Some(y).filter(p2)) // The type now is Option[Option[A]].
\end{lstlisting}
Except for the type \lstinline!Option[Option[A]]!, the result is
correct: a value \lstinline!x: A! will be present within the \lstinline!Option[Option[A]]!
wrapper only if \emph{both} \lstinline!p1(x)! and \lstinline!p2(x)!
return \lstinline!true!. To convert the result to the required type
\lstinline!Option[A]!, we apply \lstinline!flatten!:
\begin{lstlisting}
psi(p) == x => Some(x).filter(p1).map { y => Some(y).filter(p2) }.flatten
  // Use flatMap instead.
       == x => Some(x).filter(p1).flatMap { y => Some(y).filter(p2) }
       == psi(p1) andThen (_.flatMap(psi(p2)))     // Use the standard methods (flatten and flatMap) for Option.
\end{lstlisting}
Denote this combination of the functions $\psi_{p_{1}}$ and $\psi_{p_{2}}$
by the symbol $\diamond_{_{\text{Opt}}}$:
\[
\psi_{p}=\psi_{p_{1}}\diamond_{_{\text{Opt}}}\psi_{p_{2}}\triangleq x^{:A}\rightarrow x\triangleright\psi_{p_{1}}\triangleright\text{flm}_{\text{Opt}}(\psi_{p_{2}})=\psi_{p_{1}}\bef(y\rightarrow y\triangleright\text{flm}_{\text{Opt}}(\psi_{p_{2}}))\quad.
\]
We use the symbol $\text{flm}_{\text{Opt}}$ for \lstinline!Option!\textsf{'}s
\lstinline!flatMap!. The Scala code \lstinline!x.flatMap(f)! is
denoted by $x\triangleright\text{flm}_{\text{Opt}}(f)$ if we view
$\text{flm}_{\text{Opt}}$ as a curried function with the type signature:
\[
\text{flm}_{\text{Opt}}:(A\rightarrow\text{Opt}^{B})\rightarrow\text{Opt}^{A}\rightarrow\text{Opt}^{B}\quad.
\]
The operation $\diamond_{_{\text{Opt}}}$ is a special kind of composition
called \index{Kleisli composition!for Option@for \texttt{Option}}\textbf{Kleisli}\footnote{The\index{Kleisli!prononciation of the name} Swiss-German name Kleisli
is pronounced \textsf{``}cli-slee\textsf{''} (\textsf{``}cli\textsf{''} as in \textsf{``}climb\textsf{''}).}\textbf{ composition}.\label{kleisli-composition} It applies to functions
such as $\psi_{p}$ that have type $A\rightarrow\bbnum 1+A$; such
functions cannot be composed with the ordinary function composition
($\psi_{p_{1}}\bef\psi_{p_{2}}$ does not type-check). It is straightforward
to extend the operation $\diamond_{_{\text{Opt}}}$ from functions
of type $A\rightarrow\bbnum 1+A$ to functions with more general types,
$A\rightarrow\bbnum 1+B$ and $B\rightarrow\bbnum 1+C$:
\begin{lstlisting}
def kleisliOpt[A, B](f: A => Option[B], g: B => Option[C]): A => Option[C] =
  { x: A => f(x).flatMap(g) }      // Using the standard flatMap for Option.
\end{lstlisting}
\[
f^{:A\rightarrow\bbnum 1+B}\diamond_{_{\text{Opt}}}g^{:B\rightarrow\bbnum 1+C}\triangleq x^{:A}\rightarrow f(x)\triangleright\text{flm}_{\text{Opt}}(g)\quad.
\]
The Kleisli composition $f\diamond_{_{\text{Opt}}}g$ yields a function
of type $A\rightarrow\bbnum 1+C$ and is similar to the ordinary composition
$f\bef g$ except for using \textsf{``}twisted\textsf{''} types, e.g., $A\rightarrow\text{Opt}^{B}$
instead of $A\rightarrow B$. The \textsf{``}twisted\textsf{''} functions cannot be
composed via the ordinary composition operation ($f\bef g$) because
the types would not match.

We can now derive the composition law of \lstinline!liftOpt! starting
from Eq.~(\ref{eq:composition-law-of-filter}):
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & \text{filt}\,(p_{1})\bef\text{filt}\,(p_{2})=\text{liftOpt}\,(\psi_{p_{1}})\bef\text{liftOpt}\,(\psi_{p_{2}})\quad.\\
{\color{greenunder}\text{right-hand side}:}\quad & \text{filt}\,(p)=\text{liftOpt}\,(\psi_{p})=\text{liftOpt}\,(\psi_{p_{1}}\diamond_{_{\text{Opt}}}\psi_{p_{2}})\quad.
\end{align*}
If \lstinline!filter!\textsf{'}s composition law holds, we obtain (without
any additional assumptions) the equation:
\begin{equation}
\text{liftOpt}\,(\psi_{p_{1}})\bef\text{liftOpt}\,(\psi_{p_{2}})=\text{liftOpt}\,(\psi_{p_{1}}\diamond_{_{\text{Opt}}}\psi_{p_{2}})\quad.\label{eq:restricted-composition-law-for-liftOpt}
\end{equation}
This looks like a law typical for a \textsf{``}lifting\textsf{''}: the composition
of lifted functions is equal to the lifted Kleisli composition. So,
it appears useful to formulate the composition law of \lstinline!liftOpt!
in a more general way by allowing arbitrary $f^{:A\rightarrow\bbnum 1+B}$
and $g^{:B\rightarrow\bbnum 1+C}$ instead of specific functions $\psi_{p_{1}}$
and $\psi_{p_{2}}$. The composition law of \lstinline!liftOpt! is
then written as:\index{composition law!of liftOpt@of \texttt{liftOpt}}
\[
\xymatrix{\xyScaleY{1.2pc}\xyScaleX{1.8pc} & F^{B}\ar[rd]\sp(0.55){\ \text{liftOpt}\,(g)}\\
F^{A}\ar[ru]\sp(0.45){\text{liftOpt}\,(f)\ }\ar[rr]\sb(0.5){\text{liftOpt}\,(f\diamond_{_{\text{Opt}}}g)} &  & F^{C}
}
\]
\begin{equation}
\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\bef\text{liftOpt}_{F}(g^{:B\rightarrow\bbnum 1+C})=\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.\label{eq:composition-law-of-liftOpt}
\end{equation}
Because this law holds for $f$ and $g$ involving arbitrary types
$A$, $B$, $C$, it is stronger than \lstinline!filter!\textsf{'}s composition
law. We will now show that \lstinline!deflate!\textsf{'}s naturality law~(\ref{eq:naturality-law-of-deflate})
and hence \lstinline!filter!\textsf{'}s naturality law~(\ref{eq:naturality-law-of-filter})
can be derived from Eqs.~(\ref{eq:combined-naturality-identity-law-of-liftOpt})\textendash (\ref{eq:composition-law-of-liftOpt})
if we choose $f$ and $g$ in a special way, such that one of $f$
or $g$ always returns a non-empty \lstinline!Option! value:

\subsubsection{Statement \label{subsec:Statement-2-laws-of-liftOpt-entail-other-laws}\ref{subsec:Statement-2-laws-of-liftOpt-entail-other-laws}}

Assuming that the laws in Eqs.~(\ref{eq:combined-naturality-identity-law-of-liftOpt}),
(\ref{eq:restricted-composition-law-for-liftOpt}), and (\ref{eq:composition-law-of-liftOpt})
hold:

\textbf{(a)} The naturality law~(\ref{eq:left-naturality-law-of-liftOpt})
of \lstinline!liftOpt! holds.

\textbf{(b)} If \lstinline!deflate! is defined via \lstinline!liftOpt!,
the naturality law~(\ref{eq:naturality-law-of-deflate}) holds.

\subparagraph{Proof}

\textbf{(a)} Choose functions $f^{:A\rightarrow\bbnum 1+B}$ to be
of the form:
\begin{align*}
 & f^{:A\rightarrow\bbnum 1+B}\triangleq h^{:A\rightarrow B}\bef\text{pu}_{\text{Opt}}^{:B\rightarrow\bbnum 1+B}\\
{\color{greenunder}\text{or, written out in more detail}:}\quad & =h^{:A\rightarrow B}\bef(x^{:B}\rightarrow\bbnum 0+x)=x^{:A}\rightarrow\bbnum 0+h(x)\quad,
\end{align*}
where $h^{:A\rightarrow B}$ is an arbitrary function, and use those
$f$ in Eq.~(\ref{eq:composition-law-of-liftOpt}):
\begin{align*}
 & \text{liftOpt}\,(f\diamond_{_{\text{Opt}}}g)=\gunderline{\text{liftOpt}\,(h\bef\text{pu}_{\text{Opt}})}\bef\text{liftOpt}\,(g)\\
{\color{greenunder}\text{use Eq.~(\ref{eq:combined-naturality-identity-law-of-liftOpt})}:}\quad & =h^{\uparrow F}\bef\text{liftOpt}\,(g)\quad.
\end{align*}
To simplify this formula, we need to compute $f\diamond_{_{\text{Opt}}}g$.
The Kleisli composition $\diamond_{_{\text{Opt}}}$ is defined via
the standard \lstinline!flatMap! method of the \lstinline!Option!
type. With the notation $\text{flm}_{\text{Opt}}$ for the curried
\lstinline!flatMap! function, the definition of  $\diamond_{_{\text{Opt}}}$
is simplified to:
\begin{equation}
f^{:A\rightarrow\bbnum 1+B}\diamond_{_{\text{Opt}}}g^{:B\rightarrow\bbnum 1+C}\triangleq f\bef\text{flm}_{\text{Opt}}(g)\quad.\label{eq:def-of-Kleisli-product}
\end{equation}
We use this definition to compute $f\diamond_{_{\text{Opt}}}g$:
\begin{align*}
{\color{greenunder}\text{definition of }f:}\quad & \gunderline f\diamond_{_{\text{Opt}}}g=(h\bef\text{pu}_{\text{Opt}})\,\gunderline{\diamond_{_{\text{Opt}}}}\,g\\
{\color{greenunder}\text{use Eq.~(\ref{eq:def-of-Kleisli-product})}:}\quad & =h\bef\gunderline{\text{pu}_{\text{Opt}}\bef\text{flm}_{\text{Opt}}}(g)\\
{\color{greenunder}\text{compute composition (see below)}:}\quad & =h\bef g\quad.
\end{align*}
The result of composing \lstinline!pure! and \lstinline!flatMap!
for \lstinline!Option! is perhaps not obvious, but it turns out that
$\text{pu}_{\text{Opt}}$ followed by $\text{flm}_{\text{Opt}}(g)$
is equal to just $g$. To verify that, let us first use the syntax
of Scala:
\begin{lstlisting}
pure(x) == Some(x)             // By definition of `pure` for `Option`.
p.flatMap(g) == p match {      // By definition of `flatMap` for `Option`.
  case None      => None
  case Some(x)   => g(x)
}
pure(x).flatMap(g) == Some(x).flatMap(g) == g(x)
\end{lstlisting}

Now we write the same symbolic computation in the code notation:
\begin{align}
\text{pu}_{\text{Opt}}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline A & \bbnum 0 & \text{id}
\end{array}\quad,\quad\quad & \text{flm}_{\text{Opt}}(g^{:A\rightarrow\bbnum 1+B})=\,\begin{array}{|c||c|}
 & \bbnum 1+B\\
\hline \bbnum 1 & 1\rightarrow1+\bbnum 0^{:B}\\
A & g
\end{array}\quad,\label{eq:def-of-puOpt-and-flmOpt}\\
 & \text{pu}_{\text{Opt}}\bef\text{flm}_{\text{Opt}}(g)=\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline A & \bbnum 0 & \text{id}
\end{array}\,\bef\,\begin{array}{|c||c|}
 & \bbnum 1+B\\
\hline \bbnum 1 & 1\rightarrow1+\bbnum 0^{:B}\\
A & g
\end{array}\nonumber \\
{\color{greenunder}\text{matrix composition}:}\quad & \quad=\,\begin{array}{|c||c|}
 & \bbnum 1+B\\
\hline A & \gunderline{\text{id}\bef g}
\end{array}\,=g\quad.\label{eq:simplify-puOpt-flmOpt}
\end{align}
Since we have now shown that $f\diamond_{_{\text{Opt}}}g=h\bef g$,
the naturality law~(\ref{eq:left-naturality-law-of-liftOpt}) follows:
\[
\text{liftOpt}\,(f\diamond_{_{\text{Opt}}}g)=\text{liftOpt}\,(h\bef g)=h^{\uparrow F}\bef\text{liftOpt}\,(g)\quad.
\]

This derivation is possible because the function $f$ always returns
a non-empty \lstinline!Option!, which corresponds to filtering with
a predicate that always returns \lstinline!true!. This reduces filtering
to an identity function, which simplifies the composition law~(\ref{eq:composition-law-of-liftOpt})
by eliminating one of the \lstinline!liftOpt! functions.

\textbf{(b)} We keep $f^{:A\rightarrow\bbnum 1+B}$ arbitrary but
choose $g^{:B\rightarrow\bbnum 1+C}$ to be of the form:
\[
g^{:B\rightarrow\bbnum 1+C}\triangleq h^{:B\rightarrow C}\bef\text{pu}_{\text{Opt}}^{C}\quad,
\]
where $h^{:B\rightarrow C}$ is an arbitrary function, and substitute
into \lstinline!liftOpt!\textsf{'}s composition law~(\ref{eq:composition-law-of-liftOpt}):
\begin{align*}
 & \text{liftOpt}\,(f\diamond_{_{\text{Opt}}}g)=\text{liftOpt}\,(f)\bef\text{liftOpt}\,(h\bef\text{pu}_{\text{Opt}})\\
{\color{greenunder}\text{use Eq.~(\ref{eq:combined-naturality-identity-law-of-liftOpt})}:}\quad & \quad=\text{liftOpt}\,(f)\bef h^{\uparrow F}\quad.
\end{align*}
To proceed, we need to compute the Kleisli composition $f\diamond_{_{\text{Opt}}}g$
for the chosen form of $g$:
\begin{align*}
 & f\diamond_{_{\text{Opt}}}\gunderline g=f\diamond_{_{\text{Opt}}}(h\bef\text{pu}_{\text{Opt}})\\
{\color{greenunder}\text{definition~(\ref{eq:def-of-Kleisli-product}) of }\diamond_{_{\text{Opt}}}:}\quad & =f\bef\text{flm}_{\text{Opt}}(h\bef\gunderline{\text{pu}_{\text{Opt}}})=f\bef\text{flm}_{\text{Opt}}(y\rightarrow\bbnum 0+h(y))\\
{\color{greenunder}\text{definition~(\ref{eq:def-of-puOpt-and-flmOpt}) of }\text{flm}_{\text{Opt}}:}\quad & =f\bef\,\begin{array}{|c||c|}
 & \bbnum 1+C\\
\hline \bbnum 1 & 1\rightarrow1+\bbnum 0^{:C}\\
B & y\rightarrow\bbnum 0+h(y)
\end{array}\\
{\color{greenunder}\text{split matrix into 2 columns}:}\quad & =\,f\bef\,\begin{array}{|c||cc|}
 & \bbnum 1 & C\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
B & \bbnum 0 & h
\end{array}\\
{\color{greenunder}\text{definition of lifting, }^{\uparrow\text{Opt}}:}\quad & =f\bef h^{\uparrow\text{Opt}}\quad.
\end{align*}
This yields the \textbf{right naturality} law\index{naturality law!of liftOpt@of \texttt{liftOpt}}
of \lstinline!liftOpt!:
\[
\xymatrix{\xyScaleY{1.4pc}\xyScaleX{4.5pc}F^{A}\ar[d]\sb(0.5){\text{liftOpt}\,(f)}\ar[rd]\sp(0.5){~~~\text{ liftOpt}\,(f\bef h^{\uparrow\text{Opt}})}\\
F^{B}\ar[r]\sp(0.42){h^{\uparrow F}} & F^{C}
}
\]
\begin{equation}
\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\bef h^{\uparrow F}=\text{liftOpt}_{F}(f\bef h^{\uparrow\text{Opt}})\quad.\label{eq:right-naturality-law-of-liftOpt}
\end{equation}

Assuming that \lstinline!deflate! is defined via \lstinline!liftOpt!
by Eq.~(\ref{eq:def-deflate-via-liftOpt}), we express the two sides
of \lstinline!deflate!\textsf{'}s naturality law~(\ref{eq:naturality-law-of-deflate})
through \lstinline!liftOpt!:
\begin{align*}
{\color{greenunder}\text{left-hand side of Eq.~(\ref{eq:naturality-law-of-deflate})}:}\quad & \text{deflate}\bef f^{\uparrow F}=\text{liftOpt}\left(\text{id}\right)\bef f^{\uparrow F}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:right-naturality-law-of-liftOpt})}:}\quad & \quad=\text{liftOpt}\,(f^{\uparrow\text{Opt}})\quad.\\
{\color{greenunder}\text{right-hand side of Eq.~(\ref{eq:naturality-law-of-deflate})}:}\quad & f^{\uparrow\text{Opt}\uparrow F}\bef\text{deflate}=f^{\uparrow\text{Opt}\uparrow F}\bef\text{liftOpt}\left(\text{id}\right)\\
{\color{greenunder}\text{naturality law~(\ref{eq:left-naturality-law-of-liftOpt})}:}\quad & \quad=\text{liftOpt}\,(\gunderline{f^{\uparrow\text{Opt}}\bef\text{id}})=\text{liftOpt}\,(f^{\uparrow\text{Opt}})\quad.
\end{align*}
We are justified to use the naturality law~(\ref{eq:left-naturality-law-of-liftOpt})
because we proved in part \textbf{(a)} that it holds.

If \lstinline!filter! obeys the naturality law then so does \lstinline!deflate!,
and vice versa (Statements~\ref{subsec:Statement-naturality-law-of-deflate-from-filter}\textendash \ref{subsec:Statement-naturality-for-deflate-entails-naturality-for-filter}). 

To summarize, we have proved that if \lstinline!filter! is defined
via \lstinline!liftOpt! and the two laws~(\ref{eq:combined-naturality-identity-law-of-liftOpt}),
(\ref{eq:composition-law-of-liftOpt}) hold for \lstinline!liftOpt!
then all four laws of \lstinline!filter! will hold.

Conversely, if we define \lstinline!liftOpt! through \lstinline!filter!
by Eq.~(\ref{eq:def-liftOpt-via-filter}), the four laws of \lstinline!filter!
will imply the two laws of \lstinline!liftOpt!. 

\subsubsection{Exercise \label{subsec:Exercise-decompose-Kleisli-opt-function}\ref{subsec:Exercise-decompose-Kleisli-opt-function}
\index{exercises}}

Show that any function $f^{:A\rightarrow\bbnum 1+B}$ can be expressed
as $f=\psi_{p}\bef h_{|p}^{\uparrow\text{Opt}}$ with a suitable choice
of a predicate $p^{:A\rightarrow\bbnum 2}$ and a partial function
$h_{|p}^{:A\rightarrow B}$. Derive explicit formulas for $h$ and
$\psi$ in terms of $f$ and implement them in Scala.

\subsubsection{Exercise \label{subsec:Exercise-derive-composition-law-for-liftOpt-from-filter-laws-1}\ref{subsec:Exercise-derive-composition-law-for-liftOpt-from-filter-laws-1}}

Show that the law~(\ref{eq:composition-law-of-liftOpt}) holds if
\lstinline!liftOpt! is defined via \lstinline!filter! using Eq.~(\ref{eq:def-liftOpt-via-filter}).

Hint: first derive the two naturality laws for \lstinline!liftOpt!;
then use Exercise~\ref{subsec:Exercise-decompose-Kleisli-opt-function}
to extend the restricted composition law~(\ref{eq:restricted-composition-law-for-liftOpt})
to the full law~(\ref{eq:composition-law-of-liftOpt}).

\subsection{Constructions of filterable functors\label{subsec:Constructions-of-filterable-functors}}

How can we recognize a filterable functor $F$ by its type expression,
without having to prove laws? One intuition is that the type $F^{A}$
must be able to accommodate replacing values of $A$ by unit values;
this replacement is performed by the function \lstinline!deflate!.
To make this intuition more precise, it helps to perform structural
analysis that systematically looks for type constructions creating
new filterable functors out of existing ones while preserving the
laws. 

To begin, we note that \lstinline!Option!, \lstinline!Either!, \lstinline!Try!,
\lstinline!Seq!, and \lstinline!Map! are filterable. Let us now
go through all constructions available for exponential-polynomial
types. To check whether a functor is filterable, it is convenient
to use the \lstinline!liftOpt! function and its two laws~(\ref{eq:combined-naturality-identity-law-of-liftOpt}),
(\ref{eq:composition-law-of-liftOpt}).

\paragraph{Type parameters}

There are three constructions that work solely by manipulating type
parameters: the identity functor $\text{Id}^{A}\triangleq A$, the
constant functor $\text{Const}^{Z,A}\triangleq Z$ (where $Z$ is
a fixed type), and the functor composition, $F^{A}\triangleq G^{H^{A}}$
(or $F\triangleq G\circ H$).

The identity functor is \emph{not} filterable because \lstinline!deflate!
of type $\bbnum 1+A\rightarrow A$ cannot be implemented.

The constant functor $\text{Const}^{Z,A}\triangleq Z$ can be viewed
as a \textsf{``}wrapper\textsf{''} that never wraps any values of type $A$. This
functor is filterable because we can define $\text{liftOpt}\,(\_)\triangleq\text{id}^{:Z\rightarrow Z}$
(filtering is a no-op for a \textsf{``}wrapper\textsf{''} that is always empty). All
laws usually hold for an identity function. To verify the laws, note
that the lifting to the $\text{Const}$ functor is also an identity
function: $f^{\uparrow\text{Const}}=\text{id}^{:Z\rightarrow Z}$
for any $f^{:A\rightarrow B}$. We write:
\begin{align*}
{\color{greenunder}\text{verify law~(\ref{eq:combined-naturality-identity-law-of-liftOpt})}:}\quad & \text{liftOpt}_{\text{Const}}(f\bef\text{pu}_{\text{Opt}})=\text{id}=f^{\uparrow\text{Const}}\quad,\\
{\color{greenunder}\text{verify law~(\ref{eq:composition-law-of-liftOpt})}:}\quad & \text{liftOpt}_{\text{Const}}(f)\bef\text{liftOpt}_{\text{Const}}(g)=\text{id}\bef\text{id}=\text{id}\\
 & =\text{liftOpt}_{\text{Const}}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}

The functor composition $F^{A}\triangleq G^{H^{A}}$ requires \emph{only}
$H$ to be a filterable functor:

\subsubsection{Statement \label{subsec:Statement-filterable-composition-functors}\ref{subsec:Statement-filterable-composition-functors}}

The functor $F^{A}\triangleq G^{H^{A}}$ is filterable when $H$ is
filterable and $G$ is \emph{any} functor.

\subparagraph{Proof}

Assuming that $\text{liftOpt}_{H}$ is available and lawful, we define
$\text{liftOpt}_{F}$ as:
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B]): G[H[A]] => G[H[B]] =
  { g: G[H[A]] => g.map(liftOpt_H(f)) }
\end{lstlisting}
\[
\text{liftOpt}_{F}(f)\triangleq\big(\text{liftOpt}_{H}(f)\big)^{\uparrow G}\quad.
\]

To verify the identity-naturality law of \lstinline!liftOpt_F!, note
that $f^{\uparrow F}=f^{\uparrow H\uparrow G}$ by definition of $F$:
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\uparrow F}:}\quad & \text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})=\big(\text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})\big)^{\uparrow G}\\
{\color{greenunder}\text{law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) of }\text{liftOpt}_{H}:}\quad & \quad=\big(f^{\uparrow H}\big)^{\uparrow G}=f^{\uparrow F}\quad.
\end{align*}
To verify the composition law of $\text{liftOpt}_{F}$, compute:
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}f^{\prime}):}\quad & \text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(f^{\prime})\\
 & =\big(\text{liftOpt}_{H}(f)\bef\text{liftOpt}_{H}(f^{\prime})\big)^{\uparrow G}\\
{\color{greenunder}\text{composition law of }\text{liftOpt}_{H}:}\quad & =\big(\text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}f^{\prime})\big)^{\uparrow G}\\
 & =\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}f^{\prime})\quad.
\end{align*}


\paragraph{Products}

To show that the product of two filterable functors is filterable,
we will use a definition of $\text{liftOpt}_{G\times H}$ and a proof
quite similar to what we did for the product of functors (Statement~\ref{subsec:functor-Statement-functor-product}).\index{functor product}

\subsubsection{Statement \label{subsec:Statement-filterable-functor-product}\ref{subsec:Statement-filterable-functor-product}}

The functor $F^{A}\triangleq G^{A}\times H^{A}$ is filterable if
$G$ and $H$ are filterable functors.

\subparagraph{Proof}

To define $\text{liftOpt}_{F}$, we use the pair product operation
$\boxtimes$ similarly to Eq.~(\ref{eq:def-of-functor-product-fmap}):
\[
\text{liftOpt}_{F}(p)\triangleq\text{liftOpt}_{G}(p)\boxtimes\text{liftOpt}_{H}(p)\quad.
\]
The lifting to $F$ is defined by Eq.~(\ref{eq:def-of-functor-product-fmap})
as $f^{\uparrow F}=f^{\uparrow G}\boxtimes f^{\uparrow H}$. To verify
the naturality-identity law:
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\uparrow F}:}\quad & \text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & =\text{liftOpt}_{G}(f\bef\text{pu}_{\text{Opt}})\boxtimes\text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})\\
{\color{greenunder}\text{law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) for }G\text{ and }H:}\quad & =f^{\uparrow G}\boxtimes f^{\uparrow H}=f^{\uparrow F}\quad.
\end{align*}
 To verify the composition law:
\begin{align*}
 & \quad{\color{greenunder}\text{expect to equal }\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g):}\quad\\
 & \text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad\\
 & =\big(\text{liftOpt}_{G}(f)\boxtimes\text{liftOpt}_{H}(f)\big)\bef\big(\text{liftOpt}_{G}(g)\boxtimes\text{liftOpt}_{H}(g)\big)\\
 & \quad{\color{greenunder}\text{composition property~(\ref{eq:function-product-distributive-property-over-composition})}:}\quad\\
 & =\big(\text{liftOpt}_{G}(f)\bef\text{liftOpt}_{G}(g)\big)\boxtimes\big(\text{liftOpt}_{H}(f)\bef\text{liftOpt}_{H}(g)\big)\\
 & \quad{\color{greenunder}\text{composition laws of }G\text{ and }H:}\quad\\
 & =\text{liftOpt}_{G}(f\diamond_{_{\text{Opt}}}g)\boxtimes\text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}g)\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad\\
 & =\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}
In this calculation, we used the distributive property: 
\begin{equation}
(f\boxtimes g)\bef(p\boxtimes q)=(f\bef p)\boxtimes(g\bef q)\quad,\label{eq:function-product-distributive-property-over-composition}
\end{equation}
which follows from the definition of the pair product operation $\boxtimes$:
\begin{align*}
 & (f\boxtimes g)\bef(p\boxtimes q)\\
 & =\big(a\times b\rightarrow f(a)\times g(b)\big)\bef\big(c\times d\rightarrow p(c)\times q(d)\big)\\
{\color{greenunder}\text{compute composition}:}\quad & =\big(a\times b\rightarrow p(f(a))\times q(g(b))\big)\\
{\color{greenunder}\text{definition of }\boxtimes:}\quad & =\big(a\rightarrow p(f(a))\big)\boxtimes\big(b\rightarrow q(g(b))\big)\\
{\color{greenunder}\text{definition of the }\bef\text{ operation}:}\quad & =(f\bef p)\boxtimes(g\bef q)\quad.
\end{align*}


\paragraph{Co-products}

There are two constructions that produce new filterable functors involving
disjunctive types (co-product types). The first construction is the
filterable co-product $F^{A}\triangleq G^{A}+H^{A}$, where $G$ and
$H$ are filterable functors. This is similar to the functor co-product
(Statement~\ref{subsec:functor-Statement-functor-coproduct}). The
second construction is $F^{A}\triangleq\bbnum 1+A\times G^{A}$, where
$G$ is a filterable functor. This cannot be reduced to the first
construction because $A\times G^{A}$ is never filterable.

\subsubsection{Statement \label{subsec:Statement-filterable-coproduct}\ref{subsec:Statement-filterable-coproduct}}

The functor $F^{A}\triangleq G^{A}+H^{A}$ is filterable if $G$ and
$H$ are filterable functors.

\subparagraph{Proof}

Assuming that $\text{liftOpt}_{G}$ and $\text{liftOpt}_{H}$ are
known, we define $\text{liftOpt}_{F}$ as:
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B]): Either[G[A], H[A]] => Either[G[B], H[B]] = {
  case Left(ga)    => liftOpt_G(f)(ga)
  case Right(ha)   => liftOpt_H(f)(ha)
}
\end{lstlisting}
\[
\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\triangleq\begin{array}{|c||cc|}
 & G^{A} & H^{A}\\
\hline G^{A} & \text{liftOpt}_{G}(f) & \bbnum 0\\
H^{A} & \bbnum 0 & \text{liftOpt}_{H}(f)
\end{array}\quad.
\]
Lifting to the functor $F$ is defined as in Statement~\ref{subsec:functor-Statement-functor-coproduct}:
\[
f^{\uparrow F}\triangleq\begin{array}{|c||cc|}
 & G^{A} & H^{A}\\
\hline G^{A} & f^{\uparrow G} & \bbnum 0\\
H^{A} & \bbnum 0 & f^{\uparrow H}
\end{array}\quad.
\]
Our matrix calculations will always have the rows and columns of type
$G^{A}+H^{A}$, so we will omit the type annotations for brevity.
To verify the naturality-identity law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}):
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\uparrow F}:}\quad & \text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & =\,\begin{array}{||cc|}
\text{liftOpt}_{G}(f\bef\text{pu}_{\text{Opt}}) & \bbnum 0\\
\bbnum 0 & \text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})
\end{array}\\
{\color{greenunder}\text{law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) for }G\text{ and }H:}\quad & =\,\,\begin{array}{||cc|}
f^{\uparrow G} & \bbnum 0\\
\bbnum 0 & f^{\uparrow H}
\end{array}\,=f^{\uparrow F}\quad.
\end{align*}
To verify the composition law~(\ref{eq:composition-law-of-liftOpt}):
\begin{align*}
 & \quad{\color{greenunder}\text{expect to equal }\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g):}\quad\\
 & \text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad\\
 & =\,\begin{array}{||cc|}
\text{liftOpt}_{G}(f) & \bbnum 0\\
\bbnum 0 & \text{liftOpt}_{H}(f)
\end{array}\,\bef\,\begin{array}{||cc|}
\text{liftOpt}_{G}(g) & \bbnum 0\\
\bbnum 0 & \text{liftOpt}_{H}(g)
\end{array}\\
 & \quad{\color{greenunder}\text{matrix composition}:}\quad\\
 & =\,\,\begin{array}{||cc|}
\text{liftOpt}_{G}(f)\bef\text{liftOpt}_{G}(g) & \bbnum 0\\
\bbnum 0 & \text{liftOpt}_{H}(f)\bef\text{liftOpt}_{H}(g)
\end{array}\\
 & \quad{\color{greenunder}\text{law~(\ref{eq:composition-law-of-liftOpt}) for }G\text{ and }H:}\quad\\
 & =\,\begin{array}{||cc|}
\text{liftOpt}_{G}(f\diamond_{_{\text{Opt}}}g) & \bbnum 0\\
\bbnum 0 & \text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}g)
\end{array}\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad\\
 & =\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}


\subsubsection{Statement \label{subsec:Statement-filterable-coproduct-1}\ref{subsec:Statement-filterable-coproduct-1}}

If $G$ is a filterable functor then $F^{A}\triangleq\bbnum 1+A\times G^{A}$
is filterable .

\subparagraph{Proof}

Assuming that $\text{liftOpt}_{G}$ is available, we define $\text{liftOpt}_{F}$
as:
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B]): Option[(A, G[A])] => Option[(B, G[B])] = {
  case None            => None         // An empty wrapper remains empty.
  case Some((a, ga))   => f(a) match { // Does `a` satisfy the predicate?
     case None    => None  // No. Drop all data, return an empty wrapper.
     case Some(b) => Some((b, liftOpt_G(f)(ga))) // Yes. Keep `b` and filter `ga` using `liftOpt_G`.
  }
}
\end{lstlisting}
\[
\text{liftOpt}_{F}(f)\triangleq\,\begin{array}{|c||c|}
 & \bbnum 1+B\times G^{B}\\
\hline \bbnum 1 & 1\rightarrow1+\bbnum 0^{:B\times G^{B}}\\
A\times G^{A} & a\times g\rightarrow f(a)\triangleright\,\begin{array}{|c||cc|}
 & \bbnum 1 & B\times G\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
B & \bbnum 0 & b\rightarrow b\times\text{liftOpt}_{G}(f)(g)
\end{array}
\end{array}\quad.
\]
The matrix for $\text{liftOpt}_{F}$ has a non-split output column
(representing the disjunctive type $\bbnum 1+B\times G^{B}$). This
is  because the code must pattern-match on $f(a)$ in order to determine
whether the result is of type $\bbnum 1$ or of type $B\times G^{B}$.
It is inconvenient to use such matrices in calculations: matrix compositions
work best when all parts of a disjunctive type are represented by
separate columns. To proceed with calculations, we need to rewrite
the code in a different way.

Note that the code pattern when destructuring an \lstinline!Option!
value looks like this:
\begin{lstlisting}
def p[A, B, C](q: A => Option[B], r: B => C): Option[A] => Option[C] = {
  case None    => None
  case Some(a) => q(a) match {   // Destructure the result of applying the function `q`.
    case None      => None
    case Some(b)   => Some(r(b)) // Apply a final transformation `r`.
  }
}
\end{lstlisting}
The code of \lstinline!p! can be rewritten using the standard \lstinline!flatMap!
method of the \lstinline!Option! type:
\begin{lstlisting}
def p[A, B, C](q: A => Option[B], r: B => C): Option[A] => Option[C] = _.flatMap { a => q(a).map(r) }
\end{lstlisting}
So, we may write the code of \lstinline!liftOpt_F! as:
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B]): Option[(A, G[A])] => Option[(B, G[B])] = _.flatMap {
     case (a, ga)   => f(a).map { b => (b, liftOpt_G(f)(ga)) }
}
\end{lstlisting}
\begin{equation}
\text{liftOpt}_{F}(f)\triangleq\text{flm}_{\text{Opt}}\big(a^{:A}\times g^{:G^{A}}\rightarrow a\triangleright f\bef(b\rightarrow b\times\text{liftOpt}_{G}(f)(g))^{\uparrow\text{Opt}}\big)\quad.\label{eq:liftOpt-flm-opt-derivation1}
\end{equation}

To verify the laws, we first need to define the lifting to the functor
$F$:
\begin{lstlisting}
def fmap_F[A, B](f: A => B): Option[(A, G[A])] => Option[(B, G[B])] = {
  case None            => None
  case Some((a, ga))   => Some((f(a), ga.map(f)))
}
\end{lstlisting}
Again, it is convenient to rewrite the code using the standard \lstinline!map!
method of the \lstinline!Option! type:
\begin{lstlisting}
def fmap_F[A, B](f: A => B): Option[(A, G[A])] => Option[(B, G[B])] = _.map {
  case (a, ga) => (f(a), ga.map(f))
}
\end{lstlisting}
\[
f^{\uparrow F}=\big(a^{:A}\times g^{:G^{A}}\rightarrow f(a)\times(g\triangleright f^{\uparrow G})\big)^{\uparrow\text{Opt}}=\big(f\boxtimes f^{\uparrow G}\big)^{\uparrow\text{Opt}}\quad.
\]
For brevity, we omit type annotations. The naturality-identity law~(\ref{eq:combined-naturality-identity-law-of-liftOpt})
for $F$ is verified by:
\begin{align*}
 & \quad{\color{greenunder}\text{expect to equal }f^{\uparrow F}:}\quad\\
 & \text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad\\
 & =\text{flm}_{\text{Opt}}\big(a\times g\rightarrow a\triangleright f\bef\text{pu}_{\text{Opt}}\bef\big(b\rightarrow b\times\gunderline{\text{liftOpt}_{G}(f\bef\text{pu}_{\text{Opt}})}(g)\big)^{\uparrow\text{Opt}}\big)\\
 & \quad{\color{greenunder}\text{law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) for }G:}\quad\\
 & =\text{flm}_{\text{Opt}}\big(a\times g\rightarrow a\triangleright f\bef\gunderline{\text{pu}_{\text{Opt}}\bef\big(b\rightarrow b\times f^{\uparrow G}(g)\big)^{\uparrow\text{Opt}}}\big)\\
 & \quad{\color{greenunder}\text{naturality~(\ref{eq:naturality-law-of-pure}) of }\text{pu}_{\text{Opt}}:}\quad\\
 & =\text{flm}_{\text{Opt}}\big(a\times g\rightarrow\gunderline{a\triangleright f\bef\big(b\rightarrow b\times f^{\uparrow G}(g)\big)}\bef\text{pu}_{\text{Opt}}\big)\\
 & \quad{\color{greenunder}\text{function composition}:}\quad\\
 & =\text{flm}_{\text{Opt}}\big(\gunderline{a\times g\rightarrow\big(f(a)\times f^{\uparrow G}(g)\big)\,\triangleright}\,\text{pu}_{\text{Opt}}\big)=\gunderline{\text{flm}_{\text{Opt}}\big(}(f\boxtimes f^{\uparrow G})\bef\gunderline{\text{pu}_{\text{Opt}}}\big)\\
 & \quad{\color{greenunder}\text{use Eq.~(\ref{eq:flatmap-pure-law-for-Option})}:}\quad\\
 & =\big(f\boxtimes f^{\uparrow G}\big)^{\uparrow\text{Opt}}=f^{\uparrow F}\quad.
\end{align*}
Here we used a property that applies to a composition of any $q^{:A\rightarrow B}$
with $\text{pu}_{\text{Opt}}$ under \lstinline!flatMap!:
\begin{equation}
\text{flm}_{\text{Opt}}(q^{:A\rightarrow B}\bef\text{pu}_{\text{Opt}}^{:B\rightarrow\bbnum 1+B})=q^{\uparrow\text{Opt}}\quad.\label{eq:flatmap-pure-law-for-Option}
\end{equation}
This property is derived by applying the code for \lstinline!Option!\textsf{'}s
\lstinline!flatMap! and \lstinline!map! to suitable values:
\begin{lstlisting}
None.flatMap(x => Some(q(x))) == None             None.map(q) == None      
Some(x).flatMap(x => Some(q(x))) == Some(q(x))    Some(x).map(q) == Some(q(x))
\end{lstlisting}

Additional work is necessary to check \lstinline!liftOpt!\textsf{'}s composition
law:
\begin{equation}
\text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)=\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.\label{eq:liftOpt-composition-law-derivation1}
\end{equation}
Since $\text{liftOpt}_{F}(f)$ is equal to $\text{flm}_{\text{Opt}}(...)$,
so we need somehow to transform an expression of the form $\text{flm}_{\text{Opt}}(...)\bef\text{flm}_{\text{Opt}}(...)$
into an expression of the form $\text{flm}_{\text{Opt}}(...)$. To
obtain such a transformation, we use a trick: consider the composition
law for the $\text{liftOpt}_{\text{Opt}}$ operation of the \lstinline!Option!
functor (not the $\text{liftOpt}_{F}$ of the functor $F$). Since
we already know that \lstinline!Option! is filterable, the composition
law must hold for $\text{liftOpt}_{\text{Opt}}$:
\[
\text{liftOpt}_{\text{Opt}}(f^{:A\rightarrow\text{Opt}^{B}})\bef\text{liftOpt}_{\text{Opt}}(g^{:B\rightarrow\text{Opt}^{C}})=\text{liftOpt}_{\text{Opt}}(f\diamond_{_{\text{Opt}}}g)\quad.
\]
To express $\text{liftOpt}_{\text{Opt}}$ through known functions,
recall that \lstinline!Option!\textsf{'}s \lstinline!deflate! function, with
the type signature $\text{Opt}^{\text{Opt}^{A}}\rightarrow\text{Opt}^{A}$,
is equal to the standard method \lstinline!flatten! (denoted by $\text{ftn}_{\text{Opt}}$
for brevity):
\[
\text{liftOpt}_{\text{Opt}}(f)=f^{\uparrow\text{Opt}}\bef\text{deflate}_{\text{Opt}}=f^{\uparrow\text{Opt}}\bef\text{ftn}_{\text{Opt}}=\text{flm}_{\text{Opt}}(f)\quad.
\]
So, \lstinline!Option!\textsf{'}s \lstinline!flatMap! method equals \lstinline!liftOpt!
and obeys a law similar to \lstinline!liftOpt!\textsf{'}s composition law:
\begin{equation}
\text{flm}_{\text{Opt}}(f)\bef\text{flm}_{\text{Opt}}(g)=\text{flm}_{\text{Opt}}(f\diamond_{_{\text{Opt}}}g)=\text{flm}_{\text{Opt}}\big(f\bef\text{flm}_{\text{Opt}}(g)\big)\quad.\label{eq:associativity-law-of-flatMap-for-Option}
\end{equation}
We call Eq.~(\ref{eq:associativity-law-of-flatMap-for-Option}) the
\textbf{associativity law} of \lstinline!flatMap!\index{associativity law!of flatMap for Option@of \texttt{flatMap} for \texttt{Option}}
for reasons explained in Statement~\ref{subsec:Statement-Kleisli-Option-laws}
below.

To make the calculation quicker, denote by $r_{f,g}$ a sub-expression
in Eq.~(\ref{eq:liftOpt-flm-opt-derivation1}), so that we can write:
\begin{equation}
r_{f,g}\triangleq b\rightarrow b\times\text{liftOpt}_{G}(f)(g)\quad,\quad\quad\text{liftOpt}_{F}(f)=\text{flm}_{\text{Opt}}(a\times g\rightarrow a\triangleright f\bef r_{f,g}^{\uparrow\text{Opt}})\quad.\label{eq:liftOpt-short-flatmap-opt-derivation1}
\end{equation}
We can now start with the left-hand side of Eq.~(\ref{eq:liftOpt-composition-law-derivation1}):
\begin{align}
 & \text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(f^{\prime})\nonumber \\
{\color{greenunder}\text{use Eq.~(\ref{eq:liftOpt-short-flatmap-opt-derivation1})}:}\quad & =\text{flm}_{\text{Opt}}\big(a\times g\rightarrow a\triangleright f\bef r_{f,g}^{\uparrow\text{Opt}}\big)\bef\text{flm}_{\text{Opt}}\big(a^{\prime}\times g^{\prime}\rightarrow a^{\prime}\triangleright f^{\prime}\bef r_{f^{\prime},g^{\prime}}^{\uparrow\text{Opt}}\big)\nonumber \\
{\color{greenunder}\text{use Eq.~(\ref{eq:associativity-law-of-flatMap-for-Option})}:}\quad & =\text{flm}_{\text{Opt}}\big(\gunderline{\big(}a\times g\rightarrow a\triangleright f\triangleright r_{f,g}^{\uparrow\text{Opt}}\gunderline{\big)\bef}\,\text{flm}_{\text{Opt}}\big(a^{\prime}\times g^{\prime}\rightarrow a^{\prime}\triangleright f^{\prime}\bef r_{f^{\prime},g^{\prime}}^{\uparrow\text{Opt}}\big)\big)\nonumber \\
{\color{greenunder}\triangleright\text{-notation}:}\quad & =\text{flm}_{\text{Opt}}\big(a\times g\rightarrow a\triangleright f\bef r_{f,g}^{\uparrow\text{Opt}}\bef\text{flm}_{\text{Opt}}\big(a^{\prime}\times g^{\prime}\rightarrow a^{\prime}\triangleright f^{\prime}\bef r_{f^{\prime},g^{\prime}}^{\uparrow\text{Opt}}\big)\big)\quad.\label{eq:composition-lhs-derivation1}
\end{align}
Here we used a convenient \textsf{``}parenthesis-canceling\textsf{''} property of
the $\triangleright$-notation\index{pipe notation}:
\[
\left(x\rightarrow x\triangleright f\right)\bef g=(x\rightarrow\gunderline{g(f(x)})=(x\rightarrow x\triangleright\gunderline{f\triangleright g})=\left(x\rightarrow x\triangleright f\bef g\right)\quad.
\]
It is not immediately clear how to proceed, so let us transform the
right-hand side of Eq.~(\ref{eq:liftOpt-composition-law-derivation1}):
\begin{align}
 & \text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}f^{\prime})\nonumber \\
{\color{greenunder}\text{definition~(\ref{eq:def-of-Kleisli-product}) of }\diamond_{_{\text{Opt}}}:}\quad & =\text{liftOpt}_{F}(f\bef\text{flm}_{\text{Opt}}(f^{\prime}))\nonumber \\
{\color{greenunder}\text{use Eq.~(\ref{eq:liftOpt-short-flatmap-opt-derivation1})}:}\quad & =\text{flm}_{\text{Opt}}\big(a\times g\rightarrow a\triangleright f\bef\text{flm}_{\text{Opt}}(f^{\prime})\bef r_{f\bef\text{flm}_{\text{Opt}}(f^{\prime}),g}^{\uparrow\text{Opt}}\big)\quad.\label{eq:composition-rhs-derivation1}
\end{align}
How can we show that the last expressions in Eqs.~(\ref{eq:composition-lhs-derivation1})\textendash (\ref{eq:composition-rhs-derivation1})
are equal? To find a way forward, let us compare these two equations
and find the sub-expressions that remain different:
\begin{align}
{\color{greenunder}\text{sub-expression from the left-hand side}:}\quad & r_{f,g}^{\uparrow\text{Opt}}\bef\text{flm}_{\text{Opt}}\big(a^{\prime}\times g^{\prime}\rightarrow a^{\prime}\triangleright f^{\prime}\bef r_{f^{\prime},g^{\prime}}^{\uparrow\text{Opt}}\big)\label{eq:composition-law-lhs-remaining-derivation1}\\
{\color{greenunder}\text{we would like that to become equal to}:}\quad & \text{flm}_{\text{Opt}}(f^{\prime})\bef r_{f\bef\text{flm}_{\text{Opt}}(f^{\prime}),g}^{\uparrow\text{Opt}}\quad.\label{eq:composition-law-rhs-remaining-derivation1}
\end{align}
The difference is in the lifted functions to the left and to the right
of $\text{flm}_{\text{Opt}}$. If we somehow bring those functions
inside $\text{flm}_{\text{Opt}}(...)$, we may be able to simplify
them further. So, we look for properties of \lstinline!Option!\textsf{'}s
\lstinline!flatMap! that should have the form:
\begin{align*}
 & (p^{:A\rightarrow B})^{\uparrow\text{Opt}}\bef\text{flm}_{\text{Opt}}(q^{:B\rightarrow\text{Opt}^{C}})=\text{flm}_{\text{Opt}}(\text{???}^{:A\rightarrow\text{Opt}^{C}})\quad,\\
 & \text{flm}_{\text{Opt}}(p^{:A\rightarrow\text{Opt}^{B}})\bef(q^{:B\rightarrow C})^{\uparrow\text{Opt}}=\text{flm}_{\text{Opt}}(\text{???}^{:A\rightarrow\text{Opt}^{C}})\quad.
\end{align*}
The typed holes must be filled using the only available data \textemdash{}
the functions $p$ and $q$:
\begin{align}
 & (p^{:A\rightarrow B})^{\uparrow\text{Opt}}\bef\text{flm}_{\text{Opt}}(q^{:B\rightarrow\text{Opt}^{C}})=\text{flm}_{\text{Opt}}(p\bef q)\quad,\label{eq:left-naturality-flatmap-option}\\
 & \text{flm}_{\text{Opt}}(p^{:A\rightarrow\text{Opt}^{B}})\bef(q^{:B\rightarrow C})^{\uparrow\text{Opt}}=\text{flm}_{\text{Opt}}(p\bef q^{\uparrow\text{Opt}})\quad.\label{eq:right-naturality-flatmap-option}
\end{align}
The last two equations are the \textbf{naturality laws}\index{naturality law!of flatMap for Option@of \texttt{flatMap} for \texttt{Option}}
of \lstinline!flatMap! for \lstinline!Option! (see Exercise~\ref{subsec:Exercise-filterable-laws-2-1}).
Using those laws, we transform Eqs.~(\ref{eq:composition-law-lhs-remaining-derivation1})\textendash (\ref{eq:composition-law-rhs-remaining-derivation1}):
\begin{align*}
 & \gunderline{r_{f,g}^{\uparrow\text{Opt}}\bef}\,\text{flm}_{\text{Opt}}\big(a^{\prime}\times g^{\prime}\rightarrow a^{\prime}\triangleright f^{\prime}\bef r_{f^{\prime},g^{\prime}}^{\uparrow\text{Opt}}\big)\\
{\color{greenunder}\text{use Eq.~(\ref{eq:left-naturality-flatmap-option})}:}\quad & =\text{flm}_{\text{Opt}}\big(\gunderline{r_{f,g}}\bef\big(a^{\prime}\times g^{\prime}\rightarrow a^{\prime}\triangleright f^{\prime}\bef r_{f^{\prime},g^{\prime}}^{\uparrow\text{Opt}}\big)\big)\\
{\color{greenunder}\text{expand }r_{f,g}:}\quad & =\text{flm}_{\text{Opt}}\big((a\rightarrow a\times\text{liftOpt}_{G}(f)(g)\gunderline{)\bef\big(}a^{\prime}\times g^{\prime}\rightarrow a^{\prime}\triangleright f^{\prime}\bef r_{f^{\prime},g^{\prime}}^{\uparrow\text{Opt}}\big)\big)\\
{\color{greenunder}\text{composition}:}\quad & =\text{flm}_{\text{Opt}}\big(a\rightarrow a\triangleright f^{\prime}\bef r_{f^{\prime},\text{liftOpt}_{G}(f)(g)}^{\uparrow\text{Opt}}\big)\quad,
\end{align*}
and:
\begin{align*}
 & \text{flm}_{\text{Opt}}(f^{\prime})\,\gunderline{\bef r_{f\bef\text{flm}_{\text{Opt}}(f^{\prime}),g}^{\uparrow\text{Opt}}}=\text{flm}_{\text{Opt}}\big(\gunderline{f^{\prime}}\bef r_{f\bef\text{flm}_{\text{Opt}}(f^{\prime}),g}^{\uparrow\text{Opt}}\big)\\
{\color{greenunder}\text{expand function }f^{\prime}:}\quad & =\text{flm}_{\text{Opt}}\big(a\rightarrow a\triangleright f^{\prime}\bef r_{f\bef\text{flm}_{\text{Opt}}(f^{\prime}),g}^{\uparrow\text{Opt}}\big)\quad.
\end{align*}
The difference between sub-expressions has become smaller. It remains
to show the following:
\[
r_{f^{\prime},\text{liftOpt}_{G}(f)(g)}\overset{?}{=}r_{f\bef\text{flm}_{\text{Opt}}(f^{\prime}),g}\quad.
\]
Expand the definition of $r_{f,g}$ in both sides:
\[
b\rightarrow b\times\gunderline{\text{liftOpt}_{G}(f^{\prime})\big(\text{liftOpt}_{G}(f)(g)\big)}\overset{?}{=}b\rightarrow b\times\gunderline{\text{liftOpt}_{G}\big(f\bef\text{flm}_{\text{Opt}}(f^{\prime})\big)(g)}\quad.
\]
Omitting the common sub-expressions, we find the remaining difference:
\[
\text{liftOpt}_{G}(f^{\prime})\big(\text{liftOpt}_{G}(f)(g)\big)\overset{?}{=}\text{liftOpt}_{G}\big(f\bef\text{flm}_{\text{Opt}}(f^{\prime})\big)(g)\quad.
\]
This is equivalent to $\text{liftOpt}_{G}$\textsf{'}s composition law  applied
to the function $g$:
\[
g\triangleright\text{liftOpt}_{G}(f)\bef\text{liftOpt}_{G}(f^{\prime})=g\triangleright\text{liftOpt}_{G}(\gunderline{f\diamond_{_{\text{Opt}}}f^{\prime}})=g\triangleright\text{liftOpt}_{G}\big(f\bef\text{flm}_{\text{Opt}}(f^{\prime})\big)\quad.
\]
Since the composition law of $\text{liftOpt}_{G}$ is assumed to hold,
we have finished the proof of Eq.~(\ref{eq:liftOpt-composition-law-derivation1}).

The construction in Statement~\ref{subsec:Statement-filterable-coproduct-1}
implements a special kind of filtering where the value $a^{:A}$ in
the pair of type $A\times G^{A}$ needs to pass the filter for any
data to remain in the functor after filtering. We can use the same
construction repeatedly with $G^{A}\triangleq\bbnum 1$ and obtain
the type:
\[
L_{n}^{A}\triangleq\underbrace{\bbnum 1+A\times\left(\bbnum 1+A\times\left(\bbnum 1+...\times(\bbnum 1+A\times\bbnum 1)\right)\right)}_{\text{parameter }A\text{ is used }n\text{ times}}\quad,
\]
which is equivalent to a list of up to $n$ elements. The construction
defines a filtering operation for $L_{n}$ that will delete any data
beyond the first value of type $A$ that fails the predicate. It is
clear that this filtering operation implements the standard \lstinline!takeWhile!
method defined on sequences.\index{filterable!defined via takeWhile@defined via \texttt{takeWhile}}
\label{proof-that-takeWhile-is-a-lawful-filter}So, \lstinline!takeWhile!
is a lawful filtering operation (see Example~\ref{subsec:filt-solved-example-3}
where it was used).

We can also generalize the construction of Statement~\ref{subsec:Statement-filterable-coproduct-1}
to the functor:
\[
F^{A}\triangleq\bbnum 1+\underbrace{A\times A\times...\times A}_{n\text{ times}}\times\,G^{A}\quad.
\]
We implement the filtering operation with the requirement that \emph{all}
$n$ values of type $A$ in the tuple $A\times A\times...\times A\times G^{A}$
must pass the filtering predicate, or else $F^{A}$ becomes empty.
Example~\ref{subsec:filt-solved-example-2} shows how such filtering
operations may be used in practice.

\paragraph{Function types}

As we have seen in Chapter~\ref{chap:Functors,-contrafunctors,-and}
(Statement~\ref{subsec:functor-Statement-functor-exponential}),
functors involving a function type, such as $F^{A}\triangleq G^{A}\rightarrow H^{A}$,
require $G$ to be a \emph{contrafunctor} rather than a functor. It
turns out that the functor $G^{A}\rightarrow H^{A}$ is filterable
only if the contrafunctor $G$ has certain properties (Eqs.~(\ref{eq:naturality-identity-law-filterable-contrafunctor})\textendash (\ref{eq:composition-law-filterable-contrafunctor})
below) that are quite similar to the properties of filterable functors.
We will call such contrafunctors \textbf{filterable}.\index{filterable!contrafunctor}

To motivate the definition of filterable contrafunctors, consider
the operation \lstinline!liftOpt! for $F$:
\begin{align*}
 & \text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B}):(G^{A}\rightarrow H^{A})\rightarrow G^{B}\rightarrow H^{B}\quad,\\
 & \text{liftOpt}_{F}(f)=p^{:G^{A}\rightarrow H^{A}}\rightarrow g^{:G^{B}}\rightarrow\text{???}^{:H^{B}}\quad.
\end{align*}
Assume that $H$ is filterable, so that we have the function $\text{liftOpt}_{H}(f):H^{A}\rightarrow H^{B}$.
We will fill the typed hole $\text{???}^{:H^{B}}$ if we somehow get
a value of type $H^{A}$. That is only possible if we apply $p^{:G^{A}\rightarrow H^{A}}$
to something of type $G^{A}$:
\[
\text{liftOpt}_{F}(f)=p^{:G^{A}\rightarrow H^{A}}\rightarrow g^{:G^{B}}\rightarrow\text{liftOpt}_{H}(f)(p(\text{???}^{:G^{A}}))\quad.
\]
The only way to proceed is to have a function $G^{B}\rightarrow G^{A}$.
We cannot obtain such a function by lifting $f$ to the contrafunctor
$G$: that gives $f^{\downarrow G}:G^{\bbnum 1+B}\rightarrow G^{A}$.
We need to have a function $\text{liftOpt}_{G}$ with this type signature:
\begin{equation}
\text{liftOpt}_{G}(f^{:A\rightarrow\bbnum 1+B}):G^{B}\rightarrow G^{A}\quad.\label{eq:type-signature-liftOpt-contrafunctors}
\end{equation}
This function is analogous to \lstinline!liftOpt! for functors, except
for the reverse direction of transformation ($G^{B}\rightarrow G^{A}$
instead of $G^{A}\rightarrow G^{B}$). Assuming that $\text{liftOpt}_{G}$
is available, we can now complete the implementation of $\text{liftOpt}_{F}$:
\begin{align}
 & \text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\triangleq p^{:G^{A}\rightarrow H^{A}}\rightarrow g^{:G^{B}}\rightarrow\gunderline{\text{liftOpt}_{H}(f)\big(p(\text{\text{liftOpt}}_{G}(f)(g))\big)}\nonumber \\
 & \quad{\color{greenunder}\text{pipe notation}:}\quad\nonumber \\
 & =p^{:G^{A}\rightarrow H^{A}}\rightarrow\gunderline{g^{:G^{B}}\rightarrow g\,\triangleright}\,\text{\text{liftOpt}}_{G}(f)\triangleright p\triangleright\text{liftOpt}_{H}(f)\nonumber \\
 & \quad{\color{greenunder}\text{omit }(g\rightarrow g\,\triangleright):}\quad\nonumber \\
 & =p\rightarrow\text{\text{liftOpt}}_{G}(f)\bef p\bef\text{liftOpt}_{H}(f)\quad.\label{eq:def-of-liftopt-function-type}
\end{align}
Note that the last line is similar to Eq.~(\ref{eq:f-functor-exponential-def-of-fmap})
but with \lstinline!liftOpt! instead of \lstinline!map!:
\[
(f^{:A\rightarrow B})^{\uparrow F}=p^{:G^{A}\rightarrow H^{A}}\rightarrow f^{\downarrow G}\bef p\bef f^{\uparrow F}=p\rightarrow\text{cmap}_{G}(f)\bef p\bef\text{fmap}_{F}(f)\quad.
\]

The laws for filterable contrafunctors ensure that $F^{A}\triangleq G^{A}\rightarrow H^{A}$
obeys filtering laws when $H$ is a filterable functor and $G$ is
a filterable contrafunctor:

\subsubsection{Statement \label{subsec:Statement-filterable-function-type}\ref{subsec:Statement-filterable-function-type}}

Assume that $H$ is a lawful filterable functor and $G$ is a contrafunctor
with a function $\text{liftOpt}_{G}$ having type signature~(\ref{eq:type-signature-liftOpt-contrafunctors})
and obeying the laws~(\ref{eq:naturality-identity-law-filterable-contrafunctor})\textendash (\ref{eq:composition-law-filterable-contrafunctor})
shown below. Then the functor $F^{A}\triangleq G^{A}\rightarrow H^{A}$
is filterable.

\subparagraph{Proof}

We will find the required laws for $G$ by trying to prove the laws
for $F$.

Because $F$ contains a function type, it is convenient to apply both
sides of the laws to an arbitrary value $p^{:G^{A}\rightarrow H^{A}}$.
Consider the naturality-identity law of $F$:
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\downarrow G}\bef p\bef f^{\uparrow H}:}\quad & p\triangleright\text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
{\color{greenunder}\text{definition~(\ref{eq:def-of-liftopt-function-type}) of }\text{liftOpt}_{F}:}\quad & =\text{\text{liftOpt}}_{G}(f\bef\text{pu}_{\text{Opt}})\bef p\bef\gunderline{\text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})}\\
{\color{greenunder}\text{naturality-identity law of }\text{liftOpt}_{H}:}\quad & =\text{\text{liftOpt}}_{G}(f\bef\text{pu}_{\text{Opt}})\bef p\bef\gunderline{f^{\uparrow H}}\quad.
\end{align*}
The only sub-expression that remains different is $\text{\text{liftOpt}}_{G}(f\bef\text{pu}_{\text{Opt}})$.
The derivation will be finished if we assume the \textbf{naturality-identity
law} of filterable contrafunctors\index{identity laws!of filterable contrafunctors}:
\begin{equation}
\text{\text{liftOpt}}_{G}(f\bef\text{pu}_{\text{Opt}})=f^{\downarrow G}\quad.\label{eq:naturality-identity-law-filterable-contrafunctor}
\end{equation}

The composition law of $F$ applied to a value to a value $p^{:G^{A}\rightarrow H^{A}}$
is:
\begin{align*}
 & \quad{\color{greenunder}\text{left-hand side of Eq.~(\ref{eq:composition-law-of-liftOpt}) for }F:}\quad\\
 & p\triangleright\text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)=\gunderline{p\triangleright\text{liftOpt}_{F}(f)}\triangleright\text{liftOpt}_{F}(g)\\
 & \quad{\color{greenunder}\text{definition~(\ref{eq:def-of-liftopt-function-type}) of }\text{liftOpt}_{F}:}\quad\\
 & =\big(\text{\text{liftOpt}}_{G}(f)\bef p\bef\text{liftOpt}_{H}(f)\big)\,\gunderline{\triangleright\,\text{liftOpt}_{F}(g)}\\
 & \quad{\color{greenunder}\text{again definition~(\ref{eq:def-of-liftopt-function-type})}:}\quad\\
 & =\text{\text{liftOpt}}_{G}(g)\bef\big(\text{\text{liftOpt}}_{G}(f)\bef p\bef\gunderline{\text{liftOpt}_{H}(f)\big)\bef\text{liftOpt}_{H}(g)}\\
 & \quad{\color{greenunder}\text{composition law~(\ref{eq:composition-law-of-liftOpt}) of }\text{liftOpt}_{H}:}\quad\\
 & =\text{\text{liftOpt}}_{G}(g)\bef\text{\text{liftOpt}}_{G}(f)\bef p\bef\text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}
The right-hand side of Eq.~(\ref{eq:composition-law-of-liftOpt})
for $F$ is:
\[
p\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)=\text{liftOpt}_{G}(f\diamond_{_{\text{Opt}}}g)\bef p\bef\text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}g)\quad.
\]
Clearly, we need to assume the \textbf{composition law} of filterable\index{composition law!of filterable contrafunctor}
contrafunctor $G$:
\begin{equation}
\text{\text{liftOpt}}_{G}(g)\bef\text{\text{liftOpt}}_{G}(f)=\text{liftOpt}_{G}(f\diamond_{_{\text{Opt}}}g)\quad.\label{eq:composition-law-filterable-contrafunctor}
\end{equation}
Assuming that $\text{liftOpt}_{G}$ satisfies this law, we obtain
Eq.~(\ref{eq:composition-law-of-liftOpt}) for $F$ and so conclude
the proof.

\paragraph{Recursive types}

How to generalize the filtering operation from sequences to other
recursive types? For motivation, we look at two examples: the filterable
\lstinline!List! functor defined by:
\[
\text{List}^{A}\triangleq\bbnum 1+A\times\text{List}^{A}\quad,
\]
and the recursive construction for ordinary functors (Statement~\ref{subsec:functor-Statement-functor-recursive})
that requires a bifunctor $S$.

\subsubsection{Statement \label{subsec:Statement-filterable-recursive-type}\ref{subsec:Statement-filterable-recursive-type}}

If $G$ is a filterable functor, the recursive functor $F$ defined
by:
\[
F^{A}\triangleq G^{A}+A\times F^{A}
\]
is filterable. When $G^{A}\triangleq\bbnum 1$, this construction
reproduces the standard filtering operation of \lstinline!List!.

\subparagraph{Proof}

We first need to implement the type constructor $F$ and the function
$\text{liftOpt}_{F}$:
\begin{lstlisting}
sealed trait F[A]         // Assume that the functor G was defined previously.
final case class FG[A](g: G[A]) extends F[A]
final case class FAF[A](a: A, rf: F[A]) extends F[A]
                   // Assume that liftOpt_G is available and define liftOpt_F:
def liftOpt_F[A, B](f: A => Option[B]): F[A] => F[B] = {
   case FG(g)       => FG(liftOpt_G(f)(g))
   case FAF(a, rf)  => f(a) match {  // Does `a` pass the filtering predicate?
      case None        => liftOpt_F(f)(rf)             // No. Drop `a` and filter `rf` recursively.
      case Some(b)     => FAF[B](b, liftOpt_F(f)(rf))  // Yes. Keep `b` and filter `rf` recursively.
   }
}
\end{lstlisting}
\begin{align*}
 & \text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\\
 & \triangleq\,\begin{array}{|c||c|}
 & F^{B}\\
\hline G^{A} & g^{:G^{A}}\rightarrow\text{liftOpt}_{G}(f)(g)+\bbnum 0^{:B\times F^{B}}\\
A\times F^{A} & a^{:A}\times r^{:F^{A}}\rightarrow f(a)\triangleright\begin{array}{|c||c|}
 & F^{B}\\
\hline \bbnum 1 & 1\rightarrow\overline{\text{liftOpt}_{F}}(f)(r)\\
B & b^{:B}\rightarrow\bbnum 0^{:G^{B}}+b\times\overline{\text{liftOpt}_{F}}(f)(r)
\end{array}
\end{array}\quad.
\end{align*}
The overline denotes recursive uses of $\text{liftOpt}_{F}$ within
its definition.

With this definition of $\text{liftOpt}_{F}$, it is inconvenient
to use matrix composition because the matrix shown above has a single
column instead of columns split by the disjunctive type $F^{A}=G^{A}+A\times F^{A}$.
We have seen a similar problem in the proof of Statement~\ref{subsec:Statement-filterable-coproduct-1},
where we rewrote the code via $\text{flm}_{\text{Opt}}$ and avoided
using matrices with non-split columns. But it is not clear how to
rewrite the code for $\text{liftOpt}_{F}$ in that way. Instead, we
use a more straightforward approach: apply both sides of the laws
to an arbitrary value of type $F^{A}$.

The disjunctive type $F^{A}$ has two cases, $G^{A}+\bbnum 0^{:A\times F^{A}}$
and $\bbnum 0^{:G^{A}}+A\times F^{A}$. When applied to a value $g^{:G^{A}}+\bbnum 0$,
the function $\text{liftOpt}_{F}$ is exactly the same as $\text{liftOpt}_{G}$,
so both laws are satisfied since $G$ is a lawful filterable functor.
It remains to verify the laws when applied to a value $\bbnum 0^{:G^{A}}+a^{:A}\times r^{:F^{A}}$.

To prepare for the calculations, write the result of applying $\text{liftOpt}_{F}$
to a value $\bbnum 0+a\times r$:
\begin{align}
 & (\bbnum 0^{:G^{A}}+a^{:A}\times r^{:F^{A}})\triangleright\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\nonumber \\
 & =f(a)\triangleright\,\begin{array}{|c||c|}
 & F^{B}\\
\hline \bbnum 1 & 1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f)\\
B & b^{:B}\rightarrow\bbnum 0^{:G^{B}}+\left(b\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f)
\end{array}\quad.\label{eq:expression-liftOpt-derivation2}
\end{align}
To check the naturality-identity law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}),
begin with the left-hand side:
\begin{align*}
 & (\bbnum 0+a\times r)\triangleright\text{liftOpt}_{F}(\gunderline{f\bef\text{pu}_{\text{Opt}}})\\
 & =(\bbnum 0+a\times r)\triangleright\text{liftOpt}_{F}(x\rightarrow\bbnum 0+f(x))\\
{\color{greenunder}\text{use Eq.~(\ref{eq:expression-liftOpt-derivation2})}:}\quad & =\gunderline{a\triangleright(f\bef\text{pu}_{\text{Opt}})}\bef\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})(r)\\
b^{:B}\rightarrow\bbnum 0+\left(b\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})
\end{array}\\
{\color{greenunder}\text{evaluate function of }a:}\quad & =\big(\bbnum 0+f(a)\big)\triangleright\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})\\
b^{:B}\rightarrow\bbnum 0+\left(b\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})
\end{array}\\
{\color{greenunder}\text{substitute into matrix}:}\quad & =\bbnum 0+\left(f(a)\times r\right)\triangleright\gunderline{\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})}\\
{\color{greenunder}\text{inductive assumption}:}\quad & =\bbnum 0+\left(f(a)\times r\right)\triangleright\gunderline{f^{\uparrow F}}\quad.
\end{align*}
 The same expression is found by applying the right-hand side of Eq.~(\ref{eq:combined-naturality-identity-law-of-liftOpt})
to $\bbnum 0+a\times r$:
\[
(\bbnum 0^{:G^{A}}+a^{:A}\times r^{:F^{A}})\triangleright(f^{:A\rightarrow B})^{\uparrow F}=\bbnum 0^{:G^{A}}+f(a)\times f^{\uparrow F}(r)=\bbnum 0+f(a)\times r\triangleright f^{\uparrow F}\quad.
\]

To verify the composition law~(\ref{eq:composition-law-of-liftOpt}),
apply its left-hand side to $\bbnum 0+a\times r$:
\begin{align*}
 & (\bbnum 0+a\times r)\triangleright\text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)\\
{\color{greenunder}\text{use Eq.~(\ref{eq:expression-liftOpt-derivation2})}:}\quad & =f(a)\triangleright\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f)\\
b^{:B}\rightarrow\bbnum 0+\left(b\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f)
\end{array}\,\,\,\gunderline{\triangleright\,\text{liftOpt}_{F}(g)}
\end{align*}
\begin{align}
 & \quad{\color{greenunder}\text{apply }\text{liftOpt}_{F}(g):}\quad\nonumber \\
 & =f(a)\triangleright\,\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f)\,\triangleright\,\text{liftOpt}_{F}(g)\\
b^{:B}\rightarrow\big(\bbnum 0+\left(b\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f)\big)\triangleright\text{liftOpt}_{F}(g)
\end{array}\nonumber \\
 & \quad{\color{greenunder}\text{use Eq.~(\ref{eq:expression-liftOpt-derivation2})}:}\quad\nonumber \\
 & =f(a)\triangleright\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f)\bef\text{liftOpt}_{F}(g)\\
b^{:B}\rightarrow g(b)\triangleright\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f)\bef\overline{\text{liftOpt}_{F}}(g)\\
c^{:C}\rightarrow\bbnum 0+\left(c\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f)\bef\overline{\text{liftOpt}_{F}}(g)
\end{array}
\end{array}\nonumber \\
 & \quad{\color{greenunder}\text{inductive assumption}:}\quad\nonumber \\
 & =a\triangleright f\bef\,\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f\diamond_{_{\text{Opt}}}g)\\
b^{:B}\rightarrow g(b)\triangleright\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f\diamond_{_{\text{Opt}}}g)\\
c^{:C}\rightarrow\bbnum 0+\left(c\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f\diamond_{_{\text{Opt}}}g)
\end{array}
\end{array}\quad.\label{eq:lhs-comp-law-liftOpt-derivation2}
\end{align}
We are justified in using the inductive assumption for $\overline{\text{liftOpt}_{F}}(f)\bef\text{liftOpt}_{F}(g)$
even though the second function call, $\text{liftOpt}_{F}(g)$, is
not marked as a recursive call. This is because the symbol $\overline{\text{liftOpt}_{F}}$
denotes the \emph{same} function as $\text{liftOpt}_{F}$. By the
inductive assumption, the laws already hold for $\overline{\text{liftOpt}_{F}}$.

The right-hand side of Eq.~(\ref{eq:composition-law-of-liftOpt})
applied to $\bbnum 0+a\times r$ gives:
\begin{align*}
 & (\bbnum 0+a\times r)\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\\
{\color{greenunder}\text{use Eq.~(\ref{eq:expression-liftOpt-derivation2})}:}\quad & =a\triangleright(f\diamond_{_{\text{Opt}}}g)\triangleright\,\begin{array}{||c|}
1\rightarrow r\triangleright\overline{\text{liftOpt}_{F}}(f\diamond_{_{\text{Opt}}}g)\\
c^{:C}\rightarrow\bbnum 0+\left(c\times r\right)\triangleright\overline{\text{liftOpt}_{F}}(f\diamond_{_{\text{Opt}}}g)
\end{array}\quad.
\end{align*}
The only remaining difference compared with the last expression in
Eq.~(\ref{eq:lhs-comp-law-liftOpt-derivation2}) is:
\begin{equation}
f\bef\,\begin{array}{||c|}
p\\
b^{:B}\rightarrow g(b)\triangleright\,\begin{array}{||c|}
p\\
q
\end{array}
\end{array}\,\overset{?}{=}(f\diamond_{_{\text{Opt}}}g)\bef\,\begin{array}{||c|}
p\\
q
\end{array}\quad,\label{eq:comp-liftOpt-last-diff-derivation2}
\end{equation}
where $p\triangleq1\rightarrow r\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)$
and $q\triangleq c\rightarrow\bbnum 0+c\times r\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)$
are some fixed functions. We can show that Eq.~(\ref{eq:comp-liftOpt-last-diff-derivation2})
holds for arbitrary functions $p$ and $q$ having suitable types.
Start from the right-hand side:
\begin{align*}
{\color{greenunder}\text{expect the l.h.s.~of Eq.~(\ref{eq:comp-liftOpt-last-diff-derivation2})}:}\quad & (\gunderline{f\diamond_{_{\text{Opt}}}g})\bef\,\begin{array}{||c|}
p\\
q
\end{array}\,=f\bef\gunderline{\text{flm}_{\text{Opt}}(g)}\bef\,\begin{array}{||c|}
p\\
q
\end{array}\\
 & =\,f\bef\,\begin{array}{||c|}
1\rightarrow1+\bbnum 0\\
b\rightarrow g(b)
\end{array}\,\bef\,\begin{array}{||c|}
p\\
q
\end{array}\\
{\color{greenunder}\text{apply }\,\,\begin{array}{||c|}
p\\
q
\end{array}\,:}\quad & =f\bef\,\begin{array}{||c|}
1\rightarrow\gunderline{(1+\bbnum 0)\,\triangleright}\,\begin{array}{||c|}
p\\
q
\end{array}\\
b\rightarrow g(b)\triangleright\,\begin{array}{||c|}
p\\
q
\end{array}
\end{array}\,=f\bef\,\begin{array}{||c|}
1\rightarrow p\\
b\rightarrow g(b)\triangleright\,\begin{array}{||c|}
p\\
q
\end{array}
\end{array}\quad.
\end{align*}
This proves Eq.~(\ref{eq:comp-liftOpt-last-diff-derivation2}) and
concludes the proof of Statement~\ref{subsec:Statement-filterable-recursive-type}.

This implementation preserves all values $x^{:A}$ except those that
fail the filtering predicate (i.e., when $f(x)=1+\bbnum 0$). So,
it has the same filtering logic as the standard \lstinline!filter!
method for sequences. $\square$

The next construction is for a functor defined via a filterable recursion
scheme. Then the filtering logic is different from that used in Statement~\ref{subsec:Statement-filterable-recursive-type}.

\subsubsection{Statement \label{subsec:Statement-filterable-recursive-type-1}\ref{subsec:Statement-filterable-recursive-type-1}}

If $S^{A,R}$ is a bifunctor that is filterable with respect to $A$,
the recursive functor $F$ defined by the type equation $F^{A}\triangleq S^{A,F^{A}}$
is filterable.

\subparagraph{Proof}

We follow the proof of Statement~\ref{subsec:functor-Statement-functor-recursive}.
Define $\text{liftOpt}_{F}$ recursively as:
\begin{align*}
 & \text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\triangleq\text{liftOpt}_{S}(f)\bef\text{bimap}_{S}(\text{id})\big(\overline{\text{liftOpt}_{F}}(f)\big)\\
 & =\text{liftOpt}_{S}(f)\bef\big(\overline{\text{liftOpt}_{F}}(f)\big)^{\uparrow S^{B,\bullet}}\quad,
\end{align*}
where $\text{liftOpt}_{S}$ is assumed to obey the laws. The lifting
to $F$ is implemented (also recursively) by:
\[
(f^{:A\rightarrow B})^{\uparrow F}\triangleq\text{bimap}_{S}(f)(\overline{f^{\uparrow F}})=f^{\uparrow S^{\bullet,R}}\bef\big(\overline{f^{\uparrow F}}\big)^{\uparrow S^{B,\bullet}}\quad.
\]

To verify the naturality-identity law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}),
compute:
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\uparrow F}:}\quad & \text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & =\gunderline{\text{liftOpt}_{S}(f\bef\text{pu}_{\text{Opt}})}\bef\big(\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})\big)^{\uparrow S^{B,\bullet}}\\
{\color{greenunder}\text{law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) of }\text{liftOpt}_{S}:}\quad & =f^{\uparrow S^{\bullet,R}}\bef\big(\gunderline{\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})}\big)^{\uparrow S^{B,\bullet}}\\
{\color{greenunder}\text{inductive assumption}:}\quad & =f^{\uparrow S^{\bullet,R}}\bef\big(\overline{f^{\uparrow F}}\big)^{\uparrow S^{B,\bullet}}=f^{\uparrow F}\quad.
\end{align*}

To verify the composition law~(\ref{eq:composition-law-of-liftOpt}),
compute:
\begin{align*}
 & \text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)\\
 & =\text{liftOpt}_{S}(f)\bef\gunderline{\big(\overline{\text{liftOpt}_{F}}(f)\big)^{\uparrow S^{B,\bullet}}\bef\text{liftOpt}_{S}(g)}\bef\big(\overline{\text{liftOpt}_{F}}(g)\big)^{\uparrow S^{C,\bullet}}\\
 & \quad{\color{greenunder}\text{naturality of }\text{liftOpt}_{S}:}\quad\\
 & =\gunderline{\text{liftOpt}_{S}(f)\bef\text{liftOpt}_{S}(g)}\bef\big(\overline{\text{liftOpt}_{F}}(f)\big)^{\uparrow S^{C,\bullet}}\,\gunderline{\bef}\,\big(\overline{\text{liftOpt}_{F}}(g)\big)^{\uparrow S^{C,\bullet}}\\
 & \quad{\color{greenunder}\text{law~(\ref{eq:composition-law-of-liftOpt}) of }\text{liftOpt}_{S}:}\quad\\
 & =\text{liftOpt}_{S}(f\diamond_{_{\text{Opt}}}g)\bef\big(\gunderline{\overline{\text{liftOpt}_{F}}(f)\bef\overline{\text{liftOpt}_{F}}(g)}\big)^{\uparrow S^{C,\bullet}}\\
 & \quad{\color{greenunder}\text{inductive assumption}:}\quad\\
 & =\text{liftOpt}_{S}(f\diamond_{_{\text{Opt}}}g)\bef\overline{\text{liftOpt}_{F}}(f\diamond_{_{\text{Opt}}}g)=\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}
We have assumed a \textbf{naturality law}\index{naturality law!of liftOpt@of \texttt{liftOpt}}
of $\text{liftOpt}_{S}$ with respect to the type parameter $R$ of
$S^{A,R}$:
\[
\big(p^{:R\rightarrow R^{\prime}}\big)^{\uparrow S^{B,\bullet}}\bef\text{liftOpt}_{S}(g^{:B\rightarrow\bbnum 1+C})=\text{liftOpt}_{S}(g^{:B\rightarrow\bbnum 1+C})\bef\big(p^{:R\rightarrow R^{\prime}}\big)^{\uparrow S^{C,\bullet}}\quad.
\]
\[
\xymatrix{\xyScaleY{2.5pc}\xyScaleX{5.5pc}S^{B,R}\ar[r]\sp(0.5){~\text{liftOpt}_{S}(g^{:B\rightarrow\bbnum 1+C})}\ar[d]\sb(0.4){\big(p^{:R\rightarrow R^{\prime}}\big)^{\uparrow S^{B,\bullet}}} & S^{C,R}\ar[d]\sp(0.4){\big(p^{:R\rightarrow R^{\prime}}\big)^{\uparrow S^{C,\bullet}}}\\
S^{B,R^{\prime}}\ar[r]\sp(0.5){~\text{liftOpt}_{S}(g^{:B\rightarrow\bbnum 1+C})} & S^{C,R^{\prime}}
}
\]
This naturality law will hold automatically for any fully parametric
implementation of $\text{liftOpt}_{S}$ (see Appendix~\ref{app:Proofs-of-naturality-parametricity}).

\subsection{Filterable contrafunctors: motivation and examples}

An intuitive view is that functors are \textsf{``}wrappers\textsf{''} that store data,
while contrafunctors \textsf{``}consume\textsf{''} data. Filterable functors permit
us to exclude certain data from storage; filterable contrafunctors
permit us to exclude certain data from being consumed. Let us now
make this intuition precise.

A simple contrafunctor is $C^{A}\triangleq A\rightarrow Z$, where
$Z$ is a constant type. This is a general form of an \textsf{``}extractor\textsf{''}
\textemdash{} for example, a function that extracts logging information
of type $Z$ from data of various types $A$. It is sometimes necessary
to exclude particular kinds of information (e.g., private personal
data) from logging. We can implement this by providing a predicate
of type \lstinline!A => Boolean! that decides, depending on the given
value $x^{:A}$, whether $x$ should be passed to the extractor. That
predicate will be attached to a given extractor $c^{:C^{A}}$ by the
\lstinline!filter! operation:
\begin{lstlisting}
def filter[A](p: A => Boolean): C[A] => C[A]
val extractor: C[Payload] = ???  // Code that extracts metadata from payloads.
val noPrivateData: Payload => Boolean = ??? // Returns true only if payload has no private data.
val filtered: C[Payload] = filter(noPrivateData)(extractor)     // Will not extract private data.
\end{lstlisting}
How could filtering work when the predicate returns \lstinline!false!?
Even if the data (of type $A$) is excluded from the filtered extractor,
the function of type $A\rightarrow Z$ must still return a value of
type $Z$. A solution is to have a \emph{default value }of type $Z$
that the extractor will return when data is excluded from it.

There are two simple ways of implementing filtering for $C^{A}=A\rightarrow Z$
via a default value of type $Z$: First, by storing that default value
in the type $C^{A}$ and considering the contrafunctor $C^{A}\triangleq Z\times\left(A\rightarrow Z\right)$
instead of $A\rightarrow Z$. Second, by using a type $\bbnum 1+Z$
instead of $Z$, since the type $\bbnum 1+Z$ has a default value
$1+\bbnum 0^{:Z}$. The following two examples show how this works.

\subsubsection{Example \label{subsec:Example-first-filterable-contrafunctor}\ref{subsec:Example-first-filterable-contrafunctor}\index{examples (with code)}}

Implement \lstinline!filter! for the contrafunctor $C^{A}\triangleq A\rightarrow\bbnum 1+Z$,
where $Z$ is a fixed type. 

\subparagraph{Solution}

This contrafunctor \textsf{``}consumes\textsf{''} data of type $A$ and computes values
of type $\bbnum 1+Z$. Given a value $c$ of type $C^{A}$, which
is a function that we might write like this:
\begin{lstlisting}
val c: A => Option[Z] = ???
\end{lstlisting}
we need somehow to ensure that the function $c$ is applied only to
values that pass a given filter predicate $p^{:A\rightarrow\bbnum 2}$.
The result will be a new function $d^{:A\rightarrow\bbnum 1+Z}$ that
will use its argument only if it passes the predicate. The function
$d$ could return \lstinline!None! for all arguments, but that implementation
would lose information. If \lstinline!p(a) == true!, we may compute
\lstinline!c(a)!, getting a value of type $\bbnum 1+Z$ that $d$
should return. If \lstinline!p(a) == false!, the function $d$ must
return \lstinline!None!. So, the code of $d$ must be:
\begin{lstlisting}
val d: A => Option[Z] = { a => if (p(a)) c(a) else None }
\end{lstlisting}
The transformation from \lstinline!c! to \lstinline!d! is a filtering
operation for the contrafunctor $C$, implemented as:
\begin{lstlisting}
def filter[A](p: A => Boolean)(c: A => Option[Z]): A => Option[Z] = { a => 
  if (p(a)) c(a) else None
}     // Equivalent code is { a => Some(a).filter(p).flatMap(c) }
\end{lstlisting}
\[
\text{filt}_{C}(p^{:A\rightarrow\bbnum 2})\triangleq c^{:A\rightarrow\bbnum 1+Z}\rightarrow\text{pu}_{\text{Opt}}\bef\text{filt}_{\text{Opt}}(p)\bef\text{flm}_{\text{Opt}}(c)=c\rightarrow\psi_{p}\bef\text{flm}_{\text{Opt}}(c)\quad.
\]


\subsubsection{Example \label{subsec:Example-first-filterable-contrafunctor-1}\ref{subsec:Example-first-filterable-contrafunctor-1}}

Implement \lstinline!filter! for the contrafunctor $C^{A}\triangleq Z\times\left(A\rightarrow Z\right)$. 

\subparagraph{Solution}

The code for the \lstinline!filter! function is:
\begin{lstlisting}
def filter[A](p: A => Boolean): ((Z, A => Z)) => (Z, A => Z) = {
  case (z, f) => (z, a => if (p(a)) f(a) else z)
}
\end{lstlisting}
\[
\text{filt}_{C}(p^{:A\rightarrow\bbnum 2})\triangleq z^{:Z}\times f^{:A\rightarrow Z}\rightarrow z\times\bigg(a^{:A}\rightarrow p(a)\triangleright\,\begin{array}{|c||c|}
 & Z\\
\hline \bbnum 1\,(\text{false}) & z\\
\bbnum 1\,(\text{true}) & f(a)
\end{array}\,\bigg)\quad.
\]

Note that the type $Z\times\left(A\rightarrow Z\right)$ is equivalent
to $\bbnum 1+A\rightarrow Z$:
\[
Z\times\left(A\rightarrow Z\right)\cong\left(\bbnum 1\rightarrow Z\right)\times\left(A\rightarrow Z\right)\cong\bbnum 1+A\rightarrow Z\quad.
\]
For the contrafunctor $C^{A}\triangleq\bbnum 1+A\rightarrow Z$, the
\lstinline!filter! function is implemented by:
\begin{lstlisting}
def filter[A](p: A => Boolean)(c: Option[A] => Z): Option[A] => Z = {
  case Some(a) if p(a)   => c(Some(a))          // Only apply `c` to `a` if p(a) == true.
  case _                 => c(None)       // Return c(None) if p(a) == false, or for empty Option.
}   // Equivalent code is: filter(p)(c) = _.filter(p).pipe(c)
\end{lstlisting}
\begin{align*}
\text{filt}_{C}(p^{:A\rightarrow\bbnum 2}) & \triangleq c^{:\bbnum 1+A\rightarrow Z}\rightarrow\gunderline{x^{:\bbnum 1+A}\rightarrow x}\triangleright\text{filt}_{\text{Opt}}(p)\triangleright c\\
 & =c^{:\bbnum 1+A\rightarrow Z}\rightarrow\text{filt}_{\text{Opt}}(p)\bef c\quad.
\end{align*}

Another motivation for filterable contrafunctors comes from the construction
$F^{A}\triangleq G^{A}\rightarrow H^{A}$ (Statement~\ref{subsec:Statement-filterable-function-type}):
In order to assure the properties of a filterable functor for $F$,
the contrafunctor $G$ must have the \lstinline!liftOpt! function
as shown in Eq.~(\ref{eq:type-signature-liftOpt-contrafunctors}).
The existence of the \lstinline!liftOpt! function for a contrafunctor
turns out to be equivalent to the existence of the \lstinline!filter!
function, as long as suitable laws hold. To verify that equivalence,
begin by defining the function \lstinline!inflate!, whose role is
similar to that of \lstinline!deflate! for filterable functors. The
type signature of \lstinline!inflate! is:
\[
\text{inflate}_{C}:C^{A}\rightarrow C^{\bbnum 1+A}\quad.
\]
We can relate \lstinline!inflate! to \lstinline!filter! and \lstinline!liftOpt!
by the following equations (to be derived below):
\begin{align}
\text{filt}_{C}(p)=\text{inflate}_{C}\bef(\psi_{p}^{:A\rightarrow\bbnum 1+A})^{\downarrow C}\quad, & \quad\text{inflate}_{C}=\big(\text{get}^{:\bbnum 1+A\rightarrow A}\big)^{\downarrow C}\bef\text{filt}_{C}(\text{nonEmpty})\quad,\label{eq:express-filter-via-inflate-for-contrafunctor}\\
\text{inflate}_{C}=\text{liftOpt}_{C}(\text{id}^{:\bbnum 1+A\rightarrow\bbnum 1+A})\quad, & \quad\text{liftOpt}_{C}(f^{:A\rightarrow\bbnum 1+B})=\text{inflate}_{C}\bef f^{\downarrow C}\quad.\label{eq:express-liftOpt-via-inflate-for-contrafunctors}
\end{align}
\[
\xymatrix{C^{\bbnum 1+A}\ar[rd]\sb(0.4){\text{filt}_{C}^{\bbnum 1+A}(\text{nonEmpty}^{:\bbnum 1+A\rightarrow\bbnum 2})~~~~~~~} & C^{A}\ar[l]\sb(0.4){\text{get}^{\downarrow C}}\ar[d]\sp(0.4){\text{inflate}_{C}}\ar[r]\sp(0.5){\text{filt}_{C}^{A}(p^{:A\rightarrow\bbnum 2})} & C^{A} & C^{B}\ar[r]\sp(0.5){\text{inflate}_{C}}\ar[rd]\sb(0.4){\text{liftOpt}_{C}(f)\triangleq~~~} & C^{\bbnum 1+B}\ar[d]\sp(0.45){(f^{:A\rightarrow\bbnum 1+B})^{\downarrow C}}\\
\xyScaleY{1.8pc}\xyScaleX{4.5pc} & C^{\bbnum 1+A}\ar[ru]\sb(0.6){\psi_{p}^{\downarrow C}} &  &  & C^{A}
}
\]
These functions have different but equivalent laws: $\text{filt}_{C}$
has $4$ laws, $\text{inflate}_{C}$ has $3$, and $\text{liftOpt}_{C}$
has just $2$ laws. So, $\text{liftOpt}_{C}$ is the most convenient
function for proving laws, while $\text{inflate}_{C}$ is the easiest
to implement in code. The laws\index{identity laws!of liftOpt for contrafunctors@of \texttt{liftOpt} for contrafunctors}\index{composition law!of liftOpt for contrafunctors@of \texttt{liftOpt} for contrafunctors}
of $\text{liftOpt}_{C}$ are similar to the laws of \lstinline!liftOpt!
for filterable functors (we omit the derivations):
\begin{align*}
{\color{greenunder}\text{naturality law}:}\quad & \text{liftOpt}_{C}(f^{:A\rightarrow B}\bef g^{:B\rightarrow\bbnum 1+E})=\text{liftOpt}_{C}(g)\bef f^{\downarrow C}\quad,\\
{\color{greenunder}\text{naturality-identity law}:}\quad & \text{liftOpt}_{C}(f^{:A\rightarrow B}\bef\text{pu}_{\text{Opt}}^{:B\rightarrow\bbnum 1+B})=f^{\downarrow C}\quad,\\
{\color{greenunder}\text{composition law}:}\quad & \text{liftOpt}_{C}(g^{:B\rightarrow\bbnum 1+E})\bef\text{liftOpt}_{C}(f^{:A\rightarrow\bbnum 1+B})\\
 & \quad\quad=\text{liftOpt}_{C}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}

As an illustration, let us implement these functions for the contrafunctor
$C$ defined by $C^{A}\triangleq A\rightarrow\bbnum 1+Z$. 

\subsubsection{Example \label{subsec:filt-solved-example-5}\ref{subsec:filt-solved-example-5}}

Implement \lstinline!inflate! and \lstinline!liftOpt! for $C^{A}\triangleq A\rightarrow\bbnum 1+Z$
and verify Eq.~(\ref{eq:express-filter-via-inflate-for-contrafunctor}).

\subparagraph{Solution }

We implement the type signatures of \lstinline!inflate! and \lstinline!liftOpt!,
trying to preserve information as much as possible:
\begin{lstlisting}
def inflate[A](c: A => Option[Z]): Option[A] => Option[Z] = _.flatMap(c)
def liftOpt[A, B](f: A => Option[B])(c: B => Option[Z]): A => Option[Z] =
  { a => f(a).flatMap(c) }
\end{lstlisting}
\begin{align*}
 & \text{inflate}_{C}\triangleq c^{:A\rightarrow\bbnum 1+Z}\rightarrow\text{flm}_{\text{Opt}}(c)\quad,\\
 & \text{liftOpt}_{C}(f^{:A\rightarrow\bbnum 1+B})\triangleq c^{:B\rightarrow\bbnum 1+Z}\rightarrow f\bef\text{flm}_{\text{Opt}}(c)=c\rightarrow f\diamond_{_{\text{Opt}}}c\quad.
\end{align*}
To verify Eq.~(\ref{eq:express-filter-via-inflate-for-contrafunctor}),
we need the code for lifting a function $g^{:A\rightarrow B}$ to
the contrafunctor $C$:
\[
(g^{:A\rightarrow B})^{\downarrow C}=c^{:B\rightarrow\bbnum 1+Z}\rightarrow\gunderline{a^{:A}\rightarrow c(g(a))}=c^{:B\rightarrow\bbnum 1+Z}\rightarrow\gunderline{g\bef c}\quad.
\]
Now we use the code for $\text{filt}_{C}$ from Example~\ref{subsec:Example-first-filterable-contrafunctor}
and compute the function composition $\text{get}^{\downarrow C}\bef\text{filt}_{C}(\text{nonEmpty})$
as:
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{inflate}_{C}:}\quad & \text{get}^{\downarrow C}\bef\text{filt}_{C}(\text{nonEmpty})\\
{\color{greenunder}\text{definitions of }^{\downarrow C}\text{ and }\text{filt}_{C}:}\quad & =(c\rightarrow\text{get}\bef c)\bef(c\rightarrow\psi_{\text{nonEmpty}}\bef\text{flm}_{\text{Opt}}(c))\\
{\color{greenunder}\text{compute composition}:}\quad & =c\rightarrow\psi_{\text{nonEmpty}}\bef\text{flm}_{\text{Opt}}(\text{get}\bef c)\\
{\color{greenunder}\text{use naturality law~(\ref{eq:left-naturality-flatmap-option}) of }\text{flm}_{\text{Opt}}:}\quad & =c\rightarrow\gunderline{\psi_{\text{nonEmpty}}\bef\text{get}^{\uparrow\text{Opt}}}\bef\text{flm}_{\text{Opt}}(c)\\
{\color{greenunder}\text{use Eq.~(\ref{eq:simplify-psi-nonEmpty-get-opt}) to simplify}:}\quad & =c\rightarrow\text{flm}_{\text{Opt}}(c)=\text{inflate}_{C}\quad.
\end{align*}

In the formula~(\ref{eq:express-filter-via-inflate-for-contrafunctor}),
the lifted partial function $\text{get}^{\downarrow C}$ is applied
\emph{before} the filtering operation (rather than after filtering,
as would be the case for filterable functors). The derivation shows
how the partial function \lstinline!get! is moved around due to the
reverse order of composition in contrafunctor-lifted functions, until
we find the expression $\psi_{\text{nonEmpty}}\bef\text{get}^{\uparrow\text{Opt}}$
where the partial function \lstinline!get! is applied \emph{after}
a filter $\psi$ (which is safe due to \lstinline!filter!\textsf{'}s partial
function law). For this reason, it is safe to apply lifted partial
functions before filtering in contrafunctors.\index{partial function law!reverse order in contrafunctors}

\subsubsection{Example \label{subsec:filt-solved-example-5-1}\ref{subsec:filt-solved-example-5-1}}

Verify Eq.~(\ref{eq:express-filter-via-inflate-for-contrafunctor})
for an arbitrary filterable contrafunctor $C$, assuming naturality
laws as needed.

\subparagraph{Solution}

We need to check the two directions of the isomorphism in Eq.~(\ref{eq:express-filter-via-inflate-for-contrafunctor}).

\textbf{(a)} Starting from a given $\text{filt}_{C}$, we compute
$\text{inflate}_{C}$ and then use that to define a new $\text{filt}_{C}^{\prime}$;
we must show that $\text{filt}_{C}=\text{filt}_{C}^{\prime}$.
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{filt}_{C}(p):}\quad & \text{filt}_{C}^{\prime}(p)=\text{inflate}_{C}\bef\psi_{p}^{\downarrow C}=\text{get}^{\downarrow C}\bef\text{filt}_{C}(\text{nonEmpty})\bef\psi_{p}^{\downarrow C}\quad.
\end{align*}
The computation gets stuck here: We would simplify the composition
$\psi_{p}\bef\text{get}$ using Eq.~(\ref{eq:composition-of-psi-p-and-get-simplified}),
if only we could move these functions next to each other. It is clear
that we need a law that exchanges the order of composition of $\text{filt}_{C}$
with lifted functions. Typically, that is done by naturality laws.
By analogy with Eq.~(\ref{eq:naturality-law-of-filter}) and making
sure types match, we obtain a \textbf{naturality law} of\index{naturality law!of filter for contrafunctors@of \texttt{filter} for contrafunctors}
$\text{filt}_{C}$ as:
\begin{equation}
\text{filt}_{C}(p^{:A\rightarrow\bbnum 2})\bef(f^{:B\rightarrow A})^{\downarrow C}=f^{\downarrow C}\bef\text{filt}_{C}(f\bef p)\quad.\label{eq:naturality-for-filter-for-contrafunctors}
\end{equation}
Assuming this law, we find that $\text{filt}_{C}^{\prime}(p)=\text{filt}_{C}(p)$:
\begin{align*}
{\color{greenunder}\text{use naturality law of }\text{filt}_{C}:}\quad & \text{get}^{\downarrow C}\bef\gunderline{\text{filt}_{C}(\text{nonEmpty})\bef\psi_{p}^{\downarrow C}}\\
 & =\gunderline{\text{get}^{\downarrow C}\bef\psi_{p}^{\downarrow C}}\bef\text{filt}_{C}(\gunderline{\psi_{p}\bef\text{nonEmpty}})\\
{\color{greenunder}\text{use Eqs.~(\ref{eq:composition-of-psi-p-and-nonEmpty-simplified})--(\ref{eq:composition-of-psi-p-and-get-simplified})}:}\quad & =(\gunderline{\psi_{p}\bef\text{get}})^{\downarrow C}\bef\text{filt}_{C}(p)=\gunderline{\text{id}_{|p}^{\downarrow C}}\bef\text{filt}_{C}(p)\\
{\color{greenunder}\text{partial function law of }\text{filt}_{C}:}\quad & =\text{id}^{\downarrow C}\bef\text{filt}_{C}(p)=\text{filt}_{C}(p)\quad.
\end{align*}
Here we assumed the partial function law in the form similar to that
for functors:
\[
f_{|p}^{\downarrow C}\bef\text{filt}_{C}(p)=f^{\downarrow C}\bef\text{filt}_{C}(p)\quad.
\]
The lifted partial function $f_{|p}^{\downarrow C}$ is applied \emph{before}
filtering, as appropriate for filterable contrafunctors.

\textbf{(b)} Starting from a given $\text{inflate}_{C}$, we compute
$\text{filt}_{C}$ and then use that to define a new $\text{inflate}_{C}^{\prime}$;
we must show that $\text{inflate}_{C}=\text{inflate}_{C}^{\prime}$.
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{inflate}_{C}:}\quad & \text{inflate}_{C}^{\prime}=\text{get}^{\downarrow C}\bef\text{filt}_{C}(\text{nonEmpty})\\
 & =\text{get}^{\downarrow C}\bef\text{inflate}_{C}\bef\psi_{\text{nonEmpty}}^{\downarrow C}\quad.
\end{align*}
The calculation cannot proceed unless we can exchange lifted functions
around \lstinline!inflate!. By analogy with Eq.~(\ref{eq:naturality-law-of-deflate})
and making changes suitable for contrafunctors, we obtain the \index{naturality law!of inflate for contrafunctors@of \texttt{inflate} for contrafunctors}\textbf{naturality
law} for the function $\text{inflate}_{C}$:
\begin{equation}
(f^{:B\rightarrow A})^{\downarrow C}\bef\text{inflate}_{C}=\text{inflate}_{C}\bef f^{\uparrow\text{Opt}\downarrow C}\quad.\label{eq:naturality-law-of-inflate-for-filterable-contrafunctor}
\end{equation}
\[
\xymatrix{C^{A}\ar[r]\sp(0.5){\text{inflate}_{C}}\ar[d]\sb(0.45){(f^{:B\rightarrow A})^{\downarrow C}} & C^{\bbnum 1+A}\ar[d]\sp(0.45){(f^{:B\rightarrow A})^{\uparrow\text{Opt}\downarrow C}}\\
\xyScaleY{1.8pc}\xyScaleX{4.5pc}C^{B}\ar[r]\sp(0.5){\text{inflate}_{C}} & C^{\bbnum 1+B}
}
\]
With help of this law, we can finish the derivation:
\begin{align*}
{\color{greenunder}\text{use the naturality law}:}\quad & \gunderline{\text{get}^{\downarrow C}\bef\text{inflate}_{C}}\bef\psi_{\text{nonEmpty}}^{\downarrow C}\\
 & =\text{inflate}_{C}\bef\gunderline{\text{get}^{\uparrow\text{Opt}\downarrow C}\bef\psi_{\text{nonEmpty}}^{\downarrow C}}\\
{\color{greenunder}\text{composition lifted to }C:}\quad & =\text{inflate}_{C}\bef\big(\gunderline{\psi_{\text{nonEmpty}}\bef\text{get}^{\uparrow\text{Opt}}}\big)^{\downarrow C}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:simplify-psi-nonEmpty-get-opt})}:}\quad & =\text{inflate}_{C}\,\gunderline{\bef\text{id}^{\downarrow C}}=\text{inflate}_{C}\quad.
\end{align*}


\subsubsection{Exercise \label{subsec:filt-exercise-derive-inflate-liftopt-for-1+a-z}\ref{subsec:filt-exercise-derive-inflate-liftopt-for-1+a-z}\index{exercises}}

Implement \lstinline!inflate! and \lstinline!liftOpt! for the filterable
contrafunctor $C^{A}\triangleq\bbnum 1+A\rightarrow Z$.

\subsubsection{Exercise \label{subsec:filt-exercise-derive-liftOpt-equivalence-1}\ref{subsec:filt-exercise-derive-liftOpt-equivalence-1}}

Proceeding similarly to Example~\ref{subsec:filt-solved-example-5-1},
verify Eq.~(\ref{eq:express-liftOpt-via-inflate-for-contrafunctors})
for an arbitrary filterable contrafunctor $C$, assuming naturality
laws as needed.

\subsection{Constructions of filterable contrafunctors\label{subsec:Constructions-of-filterable-contrafunctors}}

How to build up a filterable contrafunctor from parts? Structural
analysis produces a number of type constructions guaranteed to create
lawful filterable contrafunctors.

The \lstinline!Filterable! typeclass is a $P$-typeclass (see Section~\ref{subsec:P-typeclasses})
if formulated via \lstinline!filter! or via \lstinline!liftOpt!,
because those methods return the type $C^{A}$ itself. So, we expect
that the product, the exponential, and the recursive constructions
will apply to filterable contrafunctors (as they do to filterable
functors).

\paragraph{Type parameters}

Constant contrafunctors $C^{A}\triangleq Z$ are \textsf{``}trivially\textsf{''} filterable:
all methods are identity functions, so all laws hold.

Further constructions that work with type parameters are functor compositions.
The composition $P\circ Q$ defined as $(P\circ Q)^{A}\triangleq P^{Q^{A}}$
is a contrafunctor when $P$ is a functor and $Q$ is a contrafunctor,
or vice versa. It turns out that the contrafunctor $P\circ Q$ is
filterable if $Q$ (whether it is a functor or a contrafunctor) is
filterable:

\subsubsection{Statement \label{subsec:Statement-filterable-contrafunctor-composition}\ref{subsec:Statement-filterable-contrafunctor-composition}}

The type constructor $P\circ Q$ is filterable:

\textbf{(a)} If $P$ is any contrafunctor and $Q$ is a filterable
functor.

\textbf{(b)} If $P$ is any functor and $Q$ is a filterable contrafunctor.

\subparagraph{Proof}

We follow the proof of Statement~\ref{subsec:Statement-filterable-composition-functors},
\emph{mutatis mutandis}. 

\textbf{(a)} Define the \lstinline!liftOpt! operation for $P\circ Q$
as: 
\[
\text{liftOpt}_{P\circ Q}(f^{:A\rightarrow\bbnum 1+B})\triangleq\big(\text{liftOpt}_{Q}(f)\big)^{\downarrow P}\quad.
\]
\begin{lstlisting}
def liftOpt_PQ[A, B](f: A => Option[B]): P[Q[B]] => P[Q[A]] = _.contramap(liftOpt_Q(f))
\end{lstlisting}

To verify the naturality-identity law~(\ref{eq:naturality-identity-law-filterable-contrafunctor}):
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\downarrow(P\circ Q)}:}\quad & \text{liftOpt}_{P\circ Q}(f\bef\text{pu}_{\text{Opt}})=\big(\gunderline{\text{liftOpt}_{Q}(f\bef\text{pu}_{\text{Opt}})}\big)^{\downarrow P}\\
{\color{greenunder}\text{naturality-identity law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) of }Q:}\quad & =f^{\uparrow Q\downarrow P}=f^{\downarrow(P\circ Q)}\quad.
\end{align*}

To verify the composition law~(\ref{eq:composition-law-filterable-contrafunctor}),
we show that its left-hand side equals $\text{liftOpt}_{P\circ Q}(f\diamond_{_{\text{Opt}}}g)$:
\begin{align*}
{\color{greenunder}\text{definition of }\text{liftOpt}_{P\circ Q}:}\quad & \text{liftOpt}_{P\circ Q}(g)\bef\text{liftOpt}_{P\circ Q}(f)\\
 & =\big(\text{liftOpt}_{Q}(g)\big)^{\downarrow P}\bef\big(\text{liftOpt}_{Q}(f)\big)^{\downarrow P}\\
{\color{greenunder}\text{composition law of }P:}\quad & =\big(\text{liftOpt}_{Q}(f)\bef\text{liftOpt}_{Q}(g)\big)^{\downarrow P}\\
{\color{greenunder}\text{composition law~(\ref{eq:composition-law-of-liftOpt}) of }Q:}\quad & =\big(\text{liftOpt}_{Q}(f\diamond_{_{\text{Opt}}}g)\big)^{\downarrow P}=\text{liftOpt}_{P\circ Q}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}

\textbf{(b)} Define the \lstinline!liftOpt! operation for $P\circ Q$
as: 
\[
\text{liftOpt}_{P\circ Q}(f^{:A\rightarrow\bbnum 1+B})\triangleq\big(\text{liftOpt}_{Q}(f)\big)^{\uparrow P}\quad.
\]
\begin{lstlisting}
def liftOpt_PQ[A, B](f: A => Option[B]): P[Q[B]] => P[Q[A]] = _.map(liftOpt_Q(f))
\end{lstlisting}

To verify the naturality-identity law~(\ref{eq:naturality-identity-law-filterable-contrafunctor}):
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\downarrow(P\circ Q)}:}\quad & \text{liftOpt}_{P\circ Q}(f\bef\text{pu}_{\text{Opt}})=\big(\gunderline{\text{liftOpt}_{Q}(f\bef\text{pu}_{\text{Opt}})}\big)^{\uparrow P}\\
{\color{greenunder}\text{naturality-identity law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) of }Q:}\quad & =f^{\downarrow Q\uparrow P}=f^{\downarrow(P\circ Q)}\quad.
\end{align*}

To verify the composition law~(\ref{eq:composition-law-filterable-contrafunctor}),
we show that its left-hand side equals $\text{liftOpt}_{P\circ Q}(f\diamond_{_{\text{Opt}}}g)$:
\begin{align*}
{\color{greenunder}\text{definition of }\text{liftOpt}_{P\circ Q}:}\quad & \text{liftOpt}_{P\circ Q}(g)\bef\text{liftOpt}_{P\circ Q}(f)\\
 & =\big(\text{liftOpt}_{Q}(g)\big)^{\uparrow P}\bef\big(\text{liftOpt}_{Q}(f)\big)^{\uparrow P}\\
{\color{greenunder}\text{composition law of }P:}\quad & =\big(\text{liftOpt}_{Q}(g)\bef\text{liftOpt}_{Q}(f)\big)^{\uparrow P}\\
{\color{greenunder}\text{composition law~(\ref{eq:composition-law-filterable-contrafunctor}) of }Q:}\quad & =\big(\text{liftOpt}_{Q}(f\diamond_{_{\text{Opt}}}g)\big)^{\uparrow P}=\text{liftOpt}_{P\circ Q}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}

Composition of two filterable contrafunctors is a filterable \emph{functor}
(a proof is delegated to Exercise~\ref{subsec:Exercise-filterable-laws}). 

\paragraph{Products and co-products}

If $G$ and $H$ are filterable contrafunctors, the product contrafunctor
$G\times H$ and the co-product contrafunctor $G+H$ will also be
filterable. Proofs are analogous to the case of filterable functors
and are delegated to Exercise~\ref{subsec:Exercise-filterable-laws-6-1}.

\paragraph{Functions}

We have a construction similar to that of Statement~\ref{subsec:Statement-filterable-function-type}:

\subsubsection{Statement \label{subsec:Statement-function-type-exponential-filterable-contrafunctor}\ref{subsec:Statement-function-type-exponential-filterable-contrafunctor}}

The contrafunctor $F^{A}\triangleq G^{A}\rightarrow H^{A}$ is filterable
for any filterable functor $G$ and any filterable contrafunctor $H$.

\subparagraph{Proof}

We define the \lstinline!liftOpt! operation for $F$ by:
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B])(p: G[B] => H[B]): G[A] => H[A] =
  { ga => liftOpt_H(f)(p(liftOpt_G(f)(ga))) }
\end{lstlisting}
To obtain a clearer code formula, rewrite the Scala code using the
$\triangleright$-notation and then simplify:
\begin{align*}
 & \text{liftOpt}_{F}(f)\\
 & \triangleq p^{:G^{B}\rightarrow H^{B}}\rightarrow\gunderline{g^{:G^{A}}\rightarrow g}\triangleright\text{liftOpt}_{G}(f)\triangleright p\triangleright\text{liftOpt}_{H}(f)\\
{\color{greenunder}\text{simplify }(x\rightarrow x\triangleright y)=y:}\quad & =p^{:G^{B}\rightarrow H^{B}}\rightarrow\text{liftOpt}_{G}(f)\bef p\bef\text{liftOpt}_{H}(f)\quad.
\end{align*}

To verify the naturality-identity law~(\ref{eq:naturality-identity-law-filterable-contrafunctor}),
apply both its sides to an arbitrary $p^{:G^{B}\rightarrow H^{B}}$:
\begin{align*}
{\color{greenunder}\text{expect to equal }p\triangleright f^{\downarrow F}:}\quad & p\triangleright\text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & =\text{liftOpt}_{G}(f\bef\text{pu}_{\text{Opt}})\bef p\bef\text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})\\
{\color{greenunder}\text{use laws~(\ref{eq:naturality-identity-law-filterable-contrafunctor}) and~(\ref{eq:combined-naturality-identity-law-of-liftOpt})}:}\quad & =f^{\uparrow G}\bef p\bef f^{\downarrow H}=p\triangleright f^{\downarrow F}\quad.
\end{align*}
To verify the composition law~(\ref{eq:composition-law-filterable-contrafunctor}),
start with its left-hand side and transform it until the result equals
$p\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)$:
\begin{align*}
 & p\triangleright\text{liftOpt}_{F}(g)\,\gunderline{\bef}\,\text{liftOpt}_{F}(f)\\
{\color{greenunder}\triangleright\text{-notation}:}\quad & =\big(p\triangleright\text{liftOpt}_{F}(g)\big)\triangleright\gunderline{\text{liftOpt}_{F}(f)}\\
{\color{greenunder}\text{definition of }\text{liftOpt}_{F}(f):}\quad & =\text{liftOpt}_{G}(f)\bef\big(\gunderline{p\triangleright\text{liftOpt}_{F}(g)}\big)\bef\text{liftOpt}_{H}(f)\\
{\color{greenunder}\text{definition of }\text{liftOpt}_{F}(g):}\quad & =\gunderline{\text{liftOpt}_{G}(f)\bef\text{liftOpt}_{G}(g)}\bef p\bef\gunderline{\text{liftOpt}_{H}(g)\bef\text{liftOpt}_{H}(f)}\\
{\color{greenunder}\text{composition laws}:}\quad & =\text{liftOpt}_{G}(f\diamond_{_{\text{Opt}}}g)\bef p\bef\text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}g)\\
{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad & =p\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}


\subsubsection{Example \label{subsec:Example-search-functor}\ref{subsec:Example-search-functor}
(the search functor)}

An application of Statement~\ref{subsec:Statement-function-type-exponential-filterable-contrafunctor}
is the \textbf{search functor}\index{search functor} $S_{Z}$ defined
by $S_{Z}^{A}\triangleq(A\rightarrow\bbnum 1+Z)\rightarrow\bbnum 1+A$,
where $Z$ is a fixed type. This functor is filterable because it
is a function from the filterable contrafunctor $A\rightarrow\bbnum 1+Z$
to the filterable functor $\bbnum 1+A$. A simple case of the search
functor is found by setting $Z\triangleq\bbnum 1$, which gives the
type constructor:
\[
S_{\bbnum 1}^{A}\triangleq(A\rightarrow\bbnum 2)\rightarrow\bbnum 1+A\quad.
\]
Values of type $S_{\bbnum 1}^{A}$ may be viewed as \textsf{``}searchers\textsf{''}
taking a predicate $q^{:A\rightarrow\bbnum 2}$ and looking for a
value of type $A$ that satisfies the predicate. A searcher will return
either a suitable value of type $\bbnum 0+A$, or an empty value $1+\bbnum 0$
(\textsf{``}not found\textsf{''}). Applying a filter with an a predicate $p^{:A\rightarrow\bbnum 2}$
to a searcher will exclude values of type $A$ from the search unless
they satisfy $p$.

Another function-type construction is a generalization of the filterable
contrafunctor $A\rightarrow\bbnum 1+Z$.

\subsubsection{Statement \label{subsec:Statement-function-a-to-1-+z-filterable-contrafunctor}\ref{subsec:Statement-function-a-to-1-+z-filterable-contrafunctor}}

If a contrafunctor $H$ is filterable then so is the contrafunctor
$F^{A}\triangleq A\rightarrow\bbnum 1+H^{A}$.

\subparagraph{Proof}

We extend the implementation of \lstinline!liftOpt! from Example~\ref{subsec:filt-solved-example-5}:
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B])(c: B => Option[H[B]]): A => Option[H[A]]
  = { a => f(a).flatMap(c).map(liftOpt_H(f)) }
\end{lstlisting}
\begin{align*}
 & \text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\triangleq p^{:B\rightarrow\bbnum 1+H^{B}}\rightarrow\gunderline{a^{:A}\rightarrow a\,\triangleright}f\triangleright\text{flm}_{\text{Opt}}(p)\triangleright\big(\text{liftOpt}_{H}(f)\big)^{\uparrow\text{Opt}}\\
 & =p\rightarrow f\bef\text{flm}_{\text{Opt}}(p)\bef\big(\text{liftOpt}_{H}(f)\big)^{\uparrow\text{Opt}}\quad.
\end{align*}
To verify the naturality-identity law~(\ref{eq:naturality-identity-law-filterable-contrafunctor}),
apply both sides to an arbitrary $p^{:B\rightarrow\bbnum 1+H^{B}}$:
\begin{align*}
{\color{greenunder}\text{expect to equal }p\triangleright f^{\downarrow F}:}\quad & p\triangleright\text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & =f\bef\gunderline{\text{pu}_{\text{Opt}}\bef\text{flm}_{\text{Opt}}(p)}\bef\big(\text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})\big)^{\uparrow\text{Opt}}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:simplify-puOpt-flmOpt})}:}\quad & =f\bef p\bef\big(\gunderline{\text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})}\big)^{\uparrow\text{Opt}}\\
{\color{greenunder}\text{law~(\ref{eq:naturality-identity-law-filterable-contrafunctor}) of }H:}\quad & =f\bef p\bef\big(f^{\downarrow H}\big)^{\uparrow\text{Opt}}=p\triangleright f^{\downarrow F}\quad.
\end{align*}

To verify the composition law~(\ref{eq:composition-law-filterable-contrafunctor}),
we apply its right-hand side to an arbitrary $p^{:C\rightarrow\bbnum 1+H^{C}}$
and transform the result until it is equal to $p\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)$:
\begin{align*}
 & p\triangleright\text{liftOpt}_{F}(g)\,\gunderline{\bef}\,\text{liftOpt}_{F}(f)\\
 & \quad{\color{greenunder}\triangleright\text{-notation}:}\quad\\
 & =\big(p\triangleright\text{liftOpt}_{F}(g)\big)\triangleright\gunderline{\text{liftOpt}_{F}(f)}\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}(f):}\quad\\
 & =f\bef\text{flm}_{\text{Opt}}\big(\gunderline{p\triangleright\text{liftOpt}_{F}(g)}\big)\bef\big(\text{liftOpt}_{H}(f)\big)^{\uparrow\text{Opt}}\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}(g):}\quad\\
 & =f\bef\text{flm}_{\text{Opt}}\gunderline{\big(g\bef\text{flm}_{\text{Opt}}(p)\bef(\text{liftOpt}_{H}(g))^{\uparrow\text{Opt}}\big)}\bef\big(\text{liftOpt}_{H}(f)\big)^{\uparrow\text{Opt}}\\
 & \quad{\color{greenunder}\text{Eqs.~(\ref{eq:associativity-law-of-flatMap-for-Option}) and~(\ref{eq:right-naturality-flatmap-option})}:}\quad\\
 & =\gunderline{f\bef\text{flm}_{\text{Opt}}(g)}\bef\text{flm}_{\text{Opt}}(p)\bef\big(\gunderline{\text{liftOpt}_{H}(g)\bef\text{liftOpt}_{H}(f)}\big)^{\uparrow\text{Opt}}\\
 & \quad{\color{greenunder}\text{definition~(\ref{eq:def-of-Kleisli-product}) of }f\diamond_{_{\text{Opt}}}g:}\quad\\
 & =(f\diamond_{_{\text{Opt}}}g)\bef\text{flm}_{\text{Opt}}(p)\bef\big(\text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}g)\big)^{\uparrow\text{Opt}}\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g):}\quad\\
 & =p\triangleright\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}


\paragraph{Recursive types}

To define a contrafunctor via type recursion, we need to use a recursion
scheme $S^{A,R}$ that is contravariant in $A$ and covariant in $R$.
In other words, the recursion scheme $S^{A,R}$ must be a profunctor\index{profunctor}\index{recursion scheme!using a profunctor}
(see Section~\ref{subsec:f-Profunctors} for the definition of a
profunctor).

\subsubsection{Statement \label{subsec:Statement-recursive-filterable-contrafunctor}\ref{subsec:Statement-recursive-filterable-contrafunctor}}

If $S^{A,R}$ is contravariant in $A$ and covariant in $R$, and
additionally $S^{\bullet,R}$ is filterable (with the type parameter
$R$ fixed), then the recursive contrafunctor $F^{A}\triangleq S^{A,F^{A}}$
is filterable.

\subparagraph{Proof}

The recursive contrafunctor $F$ is implemented by wrapping $S$ in
a case class:
\begin{lstlisting}
type S[A, R] = ...
final case class F[A](s: S[A, F[A]])
\end{lstlisting}
The code of the function \lstinline!liftOpt! for $F$ is recursive
and uses the \lstinline!xmap! method of the profunctor $S$.
\begin{lstlisting}
def liftOpt_F[A, B](f: A => Option[B]): F[B] => F[A] = {
  case F(sbfb)   => F(
    liftOpt_S(f)(sbfb).xmap_S(identity)(liftOpt_F(f))
  )
}
\end{lstlisting}
\[
\xymatrix{S^{B,F^{B}}\ar[r]\sp(0.525){\text{liftOpt}_{S}(f^{:A\rightarrow\bbnum 1+B})}\ar[rd]\sb(0.45){\text{liftOpt}_{F}(f)\triangleq~~~} & S^{A,F^{B}}\ar[d]\sp(0.45){\big(\overline{\text{liftOpt}_{F}}(f)\big)^{\uparrow S^{A,\bullet}}}\\
\xyScaleY{1.8pc}\xyScaleX{6pc} & S^{A,F^{A}}
}
\]
Note that $F^{B}\cong S^{B,F^{B}}$. We use an overline to mark recursive
calls:
\begin{align*}
 & \text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\triangleq\text{liftOpt}_{S}(f)\bef\big(\overline{\text{liftOpt}_{F}}(f)\big)^{\uparrow S^{A,\bullet}}\\
 & =\text{liftOpt}_{S}(f)\bef\text{xmap}_{S}(\text{id})(\overline{\text{liftOpt}_{F}}(f))\quad.
\end{align*}

To verify the laws, we need the code for lifting to the contrafunctor
$F$:
\begin{lstlisting}
def cmap_F[A, B](f: A => B): F[B] => F[A] = { case F(sbfb) =>
  F( sbfb.xmap_S(f)(cmap_F(f)) ) }
\end{lstlisting}
\[
f^{\downarrow F}\triangleq\text{xmap}_{S}(f)(\overline{f^{\downarrow F}})=f^{\downarrow S^{\bullet,F^{B}}}\bef\big(\overline{f^{\downarrow F}}\big)^{\uparrow S^{A,\bullet}}\quad.
\]

The naturality-identity law~(\ref{eq:naturality-identity-law-filterable-contrafunctor})
is verified by:
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\downarrow F}:}\quad & \text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & =\gunderline{\text{liftOpt}_{S}(f\bef\text{pu}_{\text{Opt}})}\bef\big(\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})\big)^{\uparrow S^{A,\bullet}}\\
{\color{greenunder}\text{law~(\ref{eq:naturality-identity-law-filterable-contrafunctor}) for }S^{\bullet,B}:}\quad & =f^{\downarrow S^{\bullet,B}}\bef\gunderline{\big(\overline{\text{liftOpt}_{F}}(f\bef\text{pu}_{\text{Opt}})\big)^{\uparrow S^{A,\bullet}}}\\
{\color{greenunder}\text{inductive assumption}:}\quad & =f^{\downarrow S^{\bullet,B}}\bef\big(\overline{f^{\downarrow F}}\big)^{\uparrow S^{A,\bullet}}=f^{\downarrow F}\quad.
\end{align*}
To verify the composition law~(\ref{eq:composition-law-filterable-contrafunctor}):
\begin{align*}
 & \quad{\color{greenunder}\text{expect }\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g):}\quad\\
 & \text{liftOpt}_{F}(g^{:B\rightarrow\bbnum 1+C})\bef\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad\\
 & =\text{liftOpt}_{S}(g)\bef\big(\overline{\text{liftOpt}_{F}}(g)\big)^{\uparrow S^{B,\bullet}}\bef\text{liftOpt}_{S}(f)\bef\big(\overline{\text{liftOpt}_{F}}(f)\big)^{\uparrow S^{A,\bullet}}\\
 & \quad{\color{greenunder}\text{law~(\ref{eq:binaturality-law-of-filterable-profunctor}) of }\text{liftOpt}_{S}:}\quad\\
 & =\gunderline{\text{liftOpt}_{S}(g)\bef\text{liftOpt}_{S}(f)}\bef\big(\overline{\text{liftOpt}_{F}}(g)\big)^{\uparrow S^{A,\bullet}}\bef\big(\overline{\text{liftOpt}_{F}}(f)\big)^{\uparrow S^{A,\bullet}}\\
 & \quad{\color{greenunder}\text{law~(\ref{eq:composition-law-filterable-contrafunctor}) of }\text{liftOpt}_{S}:}\quad\\
 & =\text{liftOpt}_{S}(f\diamond_{_{\text{Opt}}}g)\bef\big(\gunderline{\overline{\text{liftOpt}_{F}}(g)\bef\overline{\text{liftOpt}_{F}}(f)}\big)^{\uparrow S^{A,\bullet}}\\
 & \quad{\color{greenunder}\text{inductive assumption}:}\quad\\
 & =\text{liftOpt}_{S}(f\diamond_{_{\text{Opt}}}g)\bef\big(\overline{\text{liftOpt}_{F}}(f\diamond_{_{\text{Opt}}}g)\big)^{\uparrow S^{A,\bullet}}=\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}
In this derivation, we have used the naturality law of $\text{liftOpt}_{S}$
with respect to lifting in the type parameter $A$ of $S^{A,R}$.
That law is:
\[
\xymatrix{S^{B,R}\ar[r]\sp(0.5){\text{liftOpt}_{S}(f^{:A\rightarrow\bbnum 1+B})}\ar[d]\sp(0.4){(h^{:R\rightarrow R^{\prime}})^{\uparrow S^{B,\bullet}}} & S^{A,R}\ar[d]\sb(0.4){h^{\uparrow S^{A,\bullet}}}\\
\xyScaleY{1.8pc}\xyScaleX{6.0pc}S^{B,R^{\prime}}\ar[r]\sp(0.45){\text{liftOpt}_{S}(f)} & S^{A,R^{\prime}}
}
\]
\begin{equation}
\text{liftOpt}_{S}(f^{:A\rightarrow\bbnum 1+B})\bef(h^{:R\rightarrow R^{\prime}})^{\uparrow S^{A,\bullet}}=h^{\uparrow S^{B,\bullet}}\bef\text{liftOpt}_{S}(f)\quad.\label{eq:binaturality-law-of-filterable-profunctor}
\end{equation}
We expect this naturality law to hold for fully parametric functions,
as discussed in Section~\ref{subsec:Bifunctors}.

\section{Summary}

What can we do with the techniques of this chapter?
\begin{itemize}
\item Use functor blocks to manipulate data wrapped in filterable functors.
\item Decide whether a given filtering behavior satisfies the laws of \lstinline!filter!.
\item Decide whether a given type constructor (functor or contrafunctor)
is filterable. If so, implement a \lstinline!filter! or \lstinline!liftOpt!
function that satisfies the appropriate laws.
\item Use constructions to derive the code of \lstinline!filter! without
trial and error.
\end{itemize}
What \emph{cannot} be done with these techniques?
\begin{itemize}
\item Given a filterable type constructor, generate the code for \lstinline!filter!
or \lstinline!liftOpt! automatically.
\end{itemize}
This cannot be done because many type constructors have several lawful
but \emph{inequivalent} implementations of \lstinline!filter!. When
we say \textsf{``}a type constructor $F$ is filterable\textsf{''} we mean that there
is at least one lawful implementation. It is not possible to choose
a \textsf{``}preferred\textsf{''} implementation automatically, since different applications
may need different filtering behavior. While in most cases the standard
library provides generally useful implementations of filtering (e.g.,
the \lstinline!filter! or \lstinline!takeWhile! methods on sequences),
in some situations the programmer will need to write a custom implementation
of \lstinline!filter! for a custom data type. The programmer must
examine the given requirements and decide whether those requirements
can be implemented as a lawful \lstinline!filter! function.

\subsection{Examples\index{examples (with code)}}

\subsubsection{Example \label{subsec:Example-filterable-laws-1}\ref{subsec:Example-filterable-laws-1}}

Show that the functor $F^{A}\triangleq G^{A}\rightarrow A$ is not
filterable (for any contrafunctor $G$).

\subparagraph{Solution}

Try to implement \lstinline!deflate!$~:F^{\bbnum 1+A}\rightarrow F^{A}$,
writing out its full type signature:
\[
\text{deflate}_{F}:(G^{\bbnum 1+A}\rightarrow\bbnum 1+A)\rightarrow G^{A}\rightarrow A\quad,\quad\text{deflate}_{F}=p^{:G^{\bbnum 1+A}\rightarrow\bbnum 1+A}\rightarrow g^{:G^{A}}\rightarrow\text{???}^{:A}\quad.
\]
We cannot extract a value of type $A$ from $g^{:G^{A}}$ since the
contrafunctor $G$ does not wrap any values of $A$. So, the only
hope of filling the typed hole $\text{???}^{:A}$ is to apply the
function $p$ to an argument of type $G^{\bbnum 1+A}$. Even if we
are able to map $G^{A}\rightarrow G^{\bbnum 1+A}$ (e.g., if $G$
is filterable), the result of applying $p$ will be a value of type
$\bbnum 1+A$. We cannot compute a value of type $A$ out of that.
So, the type signature of \lstinline!deflate! for $F$ is not implementable.
We conclude that $F$ is not filterable.

\subsubsection{Example \label{subsec:Example-filterable-laws-2}\ref{subsec:Example-filterable-laws-2}}

Use known filterable constructions to show that:
\[
F^{A}\triangleq\text{Int}\times\text{String}\rightarrow\bbnum 1+\text{Int}\times A+A\times\left(\bbnum 1+A\right)+(\text{Int}\rightarrow\bbnum 1+A+A\times A\times\text{String})
\]
is a filterable functor. (Using the constructions avoids the need
for proofs.)

\subparagraph{Solution}

We need to analyze the structure of the functor $F$ to decide which
constructions we may use. Define some auxiliary functors that represents
sub-expressions in $F^{A}$:
\begin{align*}
R_{1}^{A}\triangleq\text{Int}\times\text{String}\rightarrow A\quad, & \quad\quad R_{2}^{A}\triangleq\text{Int}\rightarrow A\quad,\\
G^{A}\triangleq\bbnum 1+\text{Int}\times A+A\times\left(\bbnum 1+A\right)\quad, & \quad\quad H^{A}\triangleq\bbnum 1+A+A\times A\times\text{String}\quad.
\end{align*}
Now we can rewrite the type $F^{A}$ as:
\[
F^{A}=R_{1}^{L^{A}}\quad,\quad\quad L^{A}\triangleq G^{A}+R_{2}^{H^{A}}\quad.
\]
The type of $G$ is a co-product, so we need to check which of the
two co-product constructions (Statements~\ref{subsec:Statement-filterable-coproduct}
or~\ref{subsec:Statement-filterable-coproduct-1}) might apply. The
first of them does not apply because the functors $\text{Int}\times A$
and $A\times\left(\bbnum 1+A\right)$ are not filterable. But the
second construction applies if we write $G^{A}$ in the form $G^{A}=\bbnum 1+A\times K^{A}$
where $K^{A}\triangleq\bbnum 1+\text{Int}+A$. Since $K^{A}$ is the
co-product of the \lstinline!Option! functor and a constant functor
(the fixed type \lstinline!Int!), $K$ is filterable by Statement~\ref{subsec:Statement-filterable-coproduct}.
So, $G$ is filterable.

Similarly, we find that $H$ is filterable by Statement~\ref{subsec:Statement-filterable-coproduct-1}
if we write $H^{A}=\bbnum 1+A\times(\bbnum 1+A\times\text{String})$,
where the functor $\bbnum 1+A\times\text{String}$ is filterable by
the same construction.

The functor $R_{2}\circ H$ is filterable: it is a functor composition
(Statement~\ref{subsec:Statement-filterable-composition-functors})
and $H$ is filterable. The co-product $L^{A}\triangleq G^{A}+R_{2}^{H^{A}}$
is filterable by Statement~\ref{subsec:Statement-filterable-coproduct},
and $R_{1}\circ L$ by Statement~\ref{subsec:Statement-filterable-composition-functors}.

Each construction gives a specific code for the corresponding \lstinline!liftOpt!
function, and so we could derive the code for $\text{liftOpt}_{F}$
that is guaranteed to obey the filter laws. However, keep in mind
that there are several inequivalent ways of implementing a lawful
\lstinline!liftOpt! for this functor. For instance, the filtering
operation for $H$ could be defined similarly to that for \lstinline!JillsCoupons!
in Example~\ref{subsec:filt-solved-example-2} and not through a
co-product construction. The constructions give one possibility out
of many. The programmer needs to choose the implementation according
to the business requirements at hand.

\subsubsection{Example \label{subsec:Example-identity-law-of-deflate}\ref{subsec:Example-identity-law-of-deflate}
(identity law of \texttt{deflate})}

\index{identity laws!of deflate@of \texttt{deflate}}The function
\lstinline!deflate!$~:F^{\bbnum 1+A}\rightarrow F^{A}$ is available
only for filterable functors; but the function with the inverse type
signature, \lstinline!inflate!$~:F^{A}\rightarrow F^{\bbnum 1+A}$
, can be implemented for any functor $F$. (See definition of \lstinline!inflate!
in Section~\ref{subsec:Simplifying-the-filtering-laws-deflate}.)
Assuming that a given functor $F$ is filterable, show that \lstinline!deflate!
is a \textbf{left inverse}\index{left inverse} of \lstinline!inflate!:
\begin{equation}
\text{inflate}_{F}\bef\text{deflate}_{F}=\text{id}\quad.\label{eq:identity-law-of-deflate}
\end{equation}
Also show that it is not a right inverse: $\text{deflate}_{F}\bef\text{inflate}_{F}\ne\text{id}$
for some functors $F$.

\subparagraph{Solution}

We may assume that $F$ satisfies the filtering laws. The function
\lstinline!inflate! can be equivalently written as:
\[
\text{inflate}_{F}=(x^{:A}\rightarrow\bbnum 0+x)^{\uparrow F}=\text{pu}_{\text{Opt}}^{\uparrow F}=\big(\psi_{(\_\rightarrow\text{true})}\big)^{\uparrow F}\quad.
\]
Now we can use the identity law~(\ref{eq:identity-law-of-filter})
to derive:
\[
\text{filt}_{F}(\_\rightarrow\text{true})=\psi_{(\_\rightarrow\text{true})}^{\uparrow F}\bef\text{deflate}_{F}=\text{inflate}_{F}\bef\text{deflate}_{F}\quad.
\]
Since the identity law says $\text{filt}_{F}(\_\rightarrow\text{true})=\text{id}$,
we obtain $\text{inflate}_{F}\bef\text{deflate}_{F}=\text{id}$.

To show that the inverse equation does not always hold, we need an
explicit counterexample, that is, a specific functor $F$ and a value
$x^{:F^{\bbnum 1+A}}$ such that: 
\[
x\triangleright\text{deflate}_{F}\bef\text{inflate}_{F}\neq x\quad.
\]
Looking at the simplest filterable functors, we find that the constant
functor $F^{A}\triangleq Z$ is not suitable because all its methods
are identity functions. The next nontrivial example is the \lstinline!Option!
functor, $F^{A}\triangleq\bbnum 1+A=\text{Opt}^{A}$. With the equivalence
$\text{Opt}^{\text{Opt}^{A}}\cong\bbnum 1+\bbnum 1+A$, we write the
methods \lstinline!inflate! and \lstinline!deflate! as:
\begin{lstlisting}
def inflate[A]: Option[A] => Option[Option[A]] = _.map(x => Some(x))
def deflate[A]: Option[Option[A]] => Option[A] = _.flatten
\end{lstlisting}
\[
\text{inflate}_{\text{Opt}}\triangleq\text{pu}_{\text{Opt}}^{\uparrow\text{Opt}}=\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}\quad,\quad\quad\text{deflate}_{\text{Opt}}\triangleq\text{ftn}_{\text{Opt}}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & \text{id}
\end{array}\quad.
\]
The composition $\text{deflate}_{\text{Opt}}\bef\text{inflate}_{\text{Opt}}$
is computed as:
\begin{align*}
 & \text{deflate}_{\text{Opt}}\bef\text{inflate}_{\text{Opt}}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1 & \text{id} & \bbnum 0\\
A & \bbnum 0 & \text{id}
\end{array}\,\bef\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}\\
{\color{greenunder}\text{matrix composition}:}\quad & =\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
\bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}\,\neq\text{id}=\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
\bbnum 1 & \bbnum 0 & \text{id} & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}\quad.
\end{align*}
The result differs from an identity matrix in the second row. A value
$x^{:\bbnum 1+\bbnum 1+A}\triangleq\bbnum 0^{:\bbnum 1}+1+\bbnum 0^{:A}$
will give a non-void result in the second row of the matrix, showing
the difference:
\[
(\bbnum 0+1+\bbnum 0)\triangleright\,\begin{array}{|c||ccc|}
 & \bbnum 1 & \bbnum 1 & A\\
\hline \bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
\bbnum 1 & \text{id} & \bbnum 0 & \bbnum 0\\
A & \bbnum 0 & \bbnum 0 & \text{id}
\end{array}=\,\begin{array}{|ccc|}
\bbnum 0 & 1 & \bbnum 0\end{array}\,\triangleright\,\begin{array}{||ccc|}
\text{id} & \bbnum 0 & \bbnum 0\\
\text{id} & \bbnum 0 & \bbnum 0\\
\bbnum 0 & \bbnum 0 & \text{id}
\end{array}\,=\,\begin{array}{|ccc|}
1 & \bbnum 0 & \bbnum 0\end{array}\,\neq\,\begin{array}{|ccc|}
\bbnum 0 & 1 & \bbnum 0\end{array}\quad.
\]
In Scala code, this value $x$ is \lstinline!Some(None)!, so the
calculation corresponds to:
\begin{lstlisting}
inflate(deflate(Some(None))) == None  // Would have been Some(None) if the function were an identity.
\end{lstlisting}


\subsubsection{Example \label{subsec:Example-filterable-property-1+K}\ref{subsec:Example-filterable-property-1+K}}

Assume that a given functor $H^{A}\triangleq\bbnum 1+K^{A}$ is filterable
(but $K$ is not necessarily filterable). The functor $H$ is a \textsf{``}data
wrapper\textsf{''} with a fixed empty value, $1+\bbnum 0^{:K^{A}}$. Show
that an empty wrapper must remain empty after any filtering. In other
words, for any $p^{:A\rightarrow\bbnum 2}$ the function $\text{filt}_{H}$
satisfies the equation:
\begin{equation}
(1+\bbnum 0^{:K^{A}})\triangleright\text{filt}_{H}(p)=1+\bbnum 0^{:K^{A}}\quad.\label{eq:empty-filter-remains-empty-via-filt}
\end{equation}


\subparagraph{Solution}

We know nothing about $H$ and $K$ other than the fact that $\text{filt}_{H}$
obeys the filtering laws. Rewrite Eq.~(\ref{eq:empty-filter-remains-empty-via-filt})
via the simpler function \lstinline!deflate!, which is  equivalent
to $\text{filt}_{H}$:
\[
(1+\bbnum 0^{:K^{A}})\triangleright\psi_{p}^{\uparrow H}\bef\text{deflate}_{H}\overset{?}{=}1+\bbnum 0^{:K^{A}}\quad.
\]
Any function lifted to $H$ works separately for the two parts of
the disjunctive type $H^{A}=\bbnum 1+K^{A}$. So:
\[
(1+\bbnum 0^{:K^{A}})\triangleright f^{\uparrow H}=1+\bbnum 0^{:K^{B}}\quad,
\]
regardless of the choice of $f^{:A\rightarrow B}$. Setting $f\triangleq\psi_{p}$,
we obtain:
\begin{equation}
(1+\bbnum 0^{:K^{A}})\triangleright\psi_{p}^{\uparrow H}=1+\bbnum 0^{:K^{\bbnum 1+A}}\quad.\label{eq:emptyable-wrapper-psi-p-filter-derivation1}
\end{equation}
It remains to show that:
\begin{equation}
(1+\bbnum 0^{:K^{\bbnum 1+A}})\triangleright\text{deflate}_{H}\overset{?}{=}1+\bbnum 0^{:K^{A}}\quad.\label{eq:emptyable-wrapper-deflate-derivation1}
\end{equation}
We can proceed only if we use some law of \lstinline!deflate!; Example~\ref{subsec:Example-identity-law-of-deflate}
shows a suitable law. Since Eq.~(\ref{eq:emptyable-wrapper-psi-p-filter-derivation1})
holds for all predicates $p$, we can choose the predicate $p$ to
be identically \lstinline!true! and get:
\begin{equation}
(1+\bbnum 0^{:K^{A}})\triangleright\psi_{(\_\rightarrow\text{true})}^{\uparrow H}=(1+\bbnum 0^{:K^{A}})\triangleright\text{inflate}_{H}=1+\bbnum 0^{:K^{\bbnum 1+A}}\quad.\label{eq:emptyable-wrapper-inflate-derivation1}
\end{equation}
Substituting this into Eq.~(\ref{eq:emptyable-wrapper-deflate-derivation1}),
we find:
\begin{align*}
{\color{greenunder}\text{expect to equal }1+\bbnum 0^{:K^{A}}:}\quad & (\gunderline{1+\bbnum 0^{:K^{\bbnum 1+A}}})\triangleright\text{deflate}_{H}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:emptyable-wrapper-inflate-derivation1})}:}\quad & =(1+\bbnum 0^{:K^{A}})\triangleright\gunderline{\text{inflate}_{H}\bef\text{deflate}_{H}}\\
{\color{greenunder}\text{identity law~(\ref{eq:identity-law-of-deflate}) of }\text{deflate}_{H}:}\quad & =(1+\bbnum 0^{:K^{A}})\triangleright\gunderline{\text{id}}=1+\bbnum 0^{:K^{A}}\quad.
\end{align*}
This completes the proof of Eq.~(\ref{eq:emptyable-wrapper-deflate-derivation1})
and of the property~(\ref{eq:empty-filter-remains-empty-via-filt}).
The same property can be expressed in terms of $\text{liftOpt}_{H}$
as:
\begin{equation}
(1+\bbnum 0^{:K^{B}})\triangleright\text{liftOpt}_{H}(f^{:A\rightarrow\bbnum 1+B})=1+\bbnum 0^{:K^{B}}\quad.\label{eq:empty-filter-remains-empty-via-liftOpt}
\end{equation}


\subsubsection{Example \label{subsec:Example-filterable-laws-3-1}\ref{subsec:Example-filterable-laws-3-1}}

Assuming that $G$ and $H$ are filterable functors and $H$ is of
the form $H^{A}\triangleq\bbnum 1+K^{A}$ (where $K$ is not necessarily
filterable), prove that the functor $F\triangleq G\circ K$ is filterable. 

\subparagraph{Solution}

We need to define $\text{liftOpt}_{F}$ and verify its laws, assuming
that $\text{liftOpt}_{G}$ and $\text{liftOpt}_{H}$ with types:
\[
\text{liftOpt}_{G}(f^{:A\rightarrow\bbnum 1+B}):G^{A}\rightarrow G^{B}\quad,\quad\quad\text{liftOpt}_{H}(f^{:A\rightarrow\bbnum 1+B}):\bbnum 1+K^{A}\rightarrow\bbnum 1+K^{B}\quad,
\]
 are already available and obey the same laws. We need to implement
the type signature:
\[
\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B}):G^{K^{A}}\rightarrow G^{K^{B}}\quad.
\]
We can map $G^{K^{A}}$ to $G^{K^{B}}$ using $\text{liftOpt}_{G}^{K^{A},K^{B}}(k)$
if we supply $k$ of type $K^{A}\rightarrow\bbnum 1+K^{B}$ and use
the type parameters $K^{A}$, $K^{B}$ instead of $A$, $B$. We can
compute the function $k$ as $\text{liftOpt}_{H}(f^{:A\rightarrow\bbnum 1+B})$
if we extend the argument to $\bbnum 1+K^{A}$ instead of $K^{A}$
using the function $\text{pu}_{\text{Opt}}$ with type parameter $K^{A}$:
\[
\text{pu}_{\text{Opt}}^{K^{A}}:K^{A}\rightarrow\bbnum 1+K^{A}\quad,\quad\quad\text{pu}_{\text{Opt}}^{K^{A}}\bef\text{liftOpt}_{H}^{K^{B},K^{B}}(f^{:A\rightarrow\bbnum 1+B}):K^{A}\rightarrow\bbnum 1+K^{B}\quad.
\]
 Now we are ready to write the code for $\text{liftOpt}_{F}$ as:
\[
\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\triangleq\text{liftOpt}_{G}^{K^{A},K^{B}}\big(\text{pu}_{\text{Opt}}^{K^{A}}\bef\text{liftOpt}_{H}(f)\big)\quad.
\]

It remains to verify the laws. The naturality-identity law~(\ref{eq:combined-naturality-identity-law-of-liftOpt})
for $\text{liftOpt}_{F}$:
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\uparrow F}:}\quad & \text{liftOpt}_{F}(f\bef\text{pu}_{\text{Opt}})\\
 & =\text{liftOpt}_{G}^{K^{A},K^{B}}\big(\text{pu}_{\text{Opt}}^{K^{A}}\bef\gunderline{\text{liftOpt}_{H}(f\bef\text{pu}_{\text{Opt}})}\big)\\
{\color{greenunder}\text{law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) of }\text{liftOpt}_{H}:}\quad & =\text{liftOpt}_{G}^{K^{A},K^{B}}\big(\text{pu}_{\text{Opt}}^{K^{A}}\bef\gunderline{f^{\uparrow H}}\big)\\
{\color{greenunder}\text{lifting }^{\uparrow H}\text{ expressed via }^{\uparrow K}:}\quad & =\text{liftOpt}_{G}^{K^{A},K^{B}}\big(\gunderline{\text{pu}_{\text{Opt}}^{K^{A}}\bef f^{\uparrow K\uparrow\text{Opt}}}\big)\\
{\color{greenunder}\text{naturality~(\ref{eq:naturality-law-of-pure}) of }\text{pu}_{\text{Opt}}:}\quad & =\text{liftOpt}_{G}^{K^{A},K^{B}}(f^{\uparrow K}\bef\text{pu}_{\text{Opt}}^{K^{B}})\\
{\color{greenunder}\text{law~(\ref{eq:combined-naturality-identity-law-of-liftOpt}) of }\text{liftOpt}_{G}:}\quad & =\gunderline{(f^{\uparrow K})^{\uparrow G}}=f^{\uparrow F}\quad.
\end{align*}

To verify the composition law~(\ref{eq:composition-law-of-liftOpt})
for $\text{liftOpt}_{F}$:
\begin{align*}
 & \quad{\color{greenunder}\text{expect to equal }\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g):}\quad\\
 & \text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)\\
 & \quad{\color{greenunder}\text{definition of }\text{liftOpt}_{F}:}\quad\\
 & =\gunderline{\text{liftOpt}_{G}\big(}\text{pu}_{\text{Opt}}\bef\text{liftOpt}_{H}(f)\gunderline{\big)\bef\text{liftOpt}_{G}\big(}\text{pu}_{\text{Opt}}\bef\text{liftOpt}_{H}(g)\gunderline{\big)}\\
 & \quad{\color{greenunder}\text{law~(\ref{eq:composition-law-of-liftOpt}) for }\text{liftOpt}_{G}:}\quad\\
 & =\text{liftOpt}_{G}\big((\text{pu}_{\text{Opt}}\bef\text{liftOpt}_{H}(f))\,\gunderline{\diamond_{_{\text{Opt}}}(\text{pu}_{\text{Opt}}\bef\text{liftOpt}_{H}(g))}\big)\\
 & \quad{\color{greenunder}\text{simplify using Eq.~(\ref{eq:simplify-kleisli-opt-right-pure}) below}:}\quad\\
 & =\text{liftOpt}_{G}\big(\text{pu}_{\text{Opt}}\bef\gunderline{\text{liftOpt}_{H}(f)\bef\text{liftOpt}_{H}(g)}\big)\\
 & \quad{\color{greenunder}\text{law~(\ref{eq:composition-law-of-liftOpt}) for }\text{liftOpt}_{H}:}\quad\\
 & =\text{liftOpt}_{G}\big(\text{pu}_{\text{Opt}}\bef\text{liftOpt}_{H}(f\diamond_{_{\text{Opt}}}g)\big)=\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.
\end{align*}
In this derivation, we used a property that simplifies the Kleisli
composition with $\text{pu}_{\text{Opt}}$:
\begin{equation}
f^{:K^{A}\rightarrow\bbnum 1+K^{B}}\diamond_{_{\text{Opt}}}\big(\text{pu}_{\text{Opt}}^{K^{B}}\bef\text{liftOpt}_{H}^{\bbnum 1+K^{B},\bbnum 1+K^{C}}(g^{:B\rightarrow\bbnum 1+C})\big)=f\bef\text{liftOpt}_{H}(g)\quad.\label{eq:simplify-kleisli-opt-right-pure}
\end{equation}
This simplification depends on the property~(\ref{eq:empty-filter-remains-empty-via-liftOpt})
of $\text{liftOpt}_{H}$ shown in Example~\ref{subsec:Example-filterable-property-1+K}
and does \emph{not} work for arbitrary functions $p$, $q$ having
the same type signatures as in Eq.~(\ref{eq:simplify-kleisli-opt-right-pure}):
\[
p^{:A\rightarrow\bbnum 1+B}\diamond_{_{\text{Opt}}}(\text{pu}_{\text{Opt}}^{:B\rightarrow\bbnum 1+B}\bef q^{:\bbnum 1+B\rightarrow\bbnum 1+C})\neq p\bef q\quad.
\]
To prove Eq.~(\ref{eq:simplify-kleisli-opt-right-pure}), use the
code for $\diamond_{_{\text{Opt}}}$ and $\text{pu}_{\text{Opt}}$
from Eq.~(\ref{eq:def-of-puOpt-and-flmOpt}):
\begin{align*}
{\color{greenunder}\text{left-hand side of Eq.~(\ref{eq:simplify-kleisli-opt-right-pure})}:}\quad & f\gunderline{\diamond_{_{\text{Opt}}}}(\text{pu}_{\text{Opt}}^{K^{B}}\bef\text{liftOpt}_{H}(g))\\
{\color{greenunder}\text{definition~(\ref{eq:def-of-Kleisli-product}) of }\diamond_{_{\text{Opt}}}:}\quad & =f\bef\text{flm}_{\text{Opt}}(\gunderline{\text{pu}_{\text{Opt}}}^{K^{B}}\bef\text{liftOpt}_{H}(g))\\
{\color{greenunder}\text{definition of }\text{pu}_{\text{Opt}}:}\quad & =f\bef\gunderline{\text{flm}_{\text{Opt}}}(x^{:K^{B}}\rightarrow(\bbnum 0+x)\triangleright\text{liftOpt}_{H}(g))\\
{\color{greenunder}\text{use Eq.~(\ref{eq:def-of-puOpt-and-flmOpt})}:}\quad & =f^{:K^{A}\rightarrow\bbnum 1+K^{B}}\bef\,\begin{array}{|c||c|}
 & \bbnum 1+K^{C}\\
\hline \bbnum 1 & 1\rightarrow1+\bbnum 0^{:K^{C}}\\
K^{B} & x\rightarrow(\bbnum 0+x)\triangleright\text{liftOpt}_{H}(g)
\end{array}\quad.
\end{align*}
We expect the last expression to equal the right-hand side of Eq.~(\ref{eq:simplify-kleisli-opt-right-pure}),
which is $f\bef\text{liftOpt}_{H}(g)$. To be able to compare these
expressions, we rewrite $\text{liftOpt}_{H}(g)$ equivalently as a
matrix:
\[
\text{liftOpt}_{H}(g^{:B\rightarrow\bbnum 1+C})=\,\begin{array}{|c||c|}
 & \bbnum 1+K^{C}\\
\hline \bbnum 1 & 1\rightarrow(1+\bbnum 0^{:K^{C}})\triangleright\text{liftOpt}_{H}(g)\\
K^{B} & x\rightarrow(\bbnum 0+x)\triangleright\text{liftOpt}_{H}(g)
\end{array}\quad.
\]
Usually, such a rewriting gives no advantages; but here, Eq.~(\ref{eq:empty-filter-remains-empty-via-liftOpt})
simplifies the first row of the matrix to $1\rightarrow1+\bbnum 0^{:K^{C}}$.
This makes both sides of Eq.~(\ref{eq:simplify-kleisli-opt-right-pure})
equal.

\subsubsection{Example \label{subsec:Example-filterable-laws-unrolling-trick}\ref{subsec:Example-filterable-laws-unrolling-trick}}

Prove that the functor $F^{A}\triangleq\bbnum 1+A\times A+A\times\left(\bbnum 1+A\right)\times F^{A}$
(defined recursively) is filterable.

\subparagraph{Solution}

Rather than proving the laws by hand (as we did in a similar case
in Statement~\ref{subsec:Statement-filterable-recursive-type}),
we will use a trick that will make calculations shorter. The trick
is to \textsf{``}unroll\textsf{''} the recursive equation and to reduce $F$ to the
\lstinline!List! functor, which has a standard filtering operation.

The \index{unrolling trick for recursive types}\index{recursive types!unrolling trick}unrolling
trick gives, for any recursive definition of the form $F^{A}\triangleq P^{A}+Q^{A}\times F^{A}$:
\begin{equation}
\text{if}\quad F^{A}\triangleq P^{A}+Q^{A}\times F^{A}\quad\text{then}\quad F^{A}\cong P^{A}\times\text{List}^{Q^{A}}\quad,\label{eq:def-recursive-functor-unrolling}
\end{equation}
where $P$ and $Q$ are arbitrary functors. The functor $F$ given
in this example is of that form with the functors $P^{A}\triangleq\bbnum 1+A\times A$
and $Q^{A}\triangleq A\times\left(\bbnum 1+A\right)$. Comparing with
the definition of the \lstinline!List! functor,
\begin{align*}
\text{List}^{A} & \triangleq\bbnum 1+A\times\text{List}^{A}\cong\bbnum 1+A\times(\bbnum 1+A\times(\bbnum 1+...(\bbnum 1+A\times\text{List}^{A})))\\
 & \cong\bbnum 1+A+A\times A+A\times A\times A+...+\underbrace{A\times...\times A}_{n\text{ times}}\times\,\text{List}^{A}\quad,
\end{align*}
we find that the definition~(\ref{eq:def-recursive-functor-unrolling})
of $F^{A}$ can be \textsf{``}unrolled\textsf{''} $n$ times as:
\begin{align*}
F^{A} & \triangleq P^{A}+Q^{A}\times F^{A}\cong P^{A}+Q^{A}\times(P^{A}+Q^{A}\times(P^{A}+...(P^{A}+Q^{A}\times F^{A})))\\
 & \cong P^{A}+Q^{A}\times P^{A}+Q^{A}\times Q^{A}\times P^{A}+...+\underbrace{Q^{A}\times...\times Q^{A}}_{n\text{ times}}\times\,F^{A}\\
 & \cong P^{A}\times\big(\bbnum 1+Q^{A}+Q^{A}\times Q^{A}+...\underbrace{Q^{A}\times...\times Q^{A}}_{n-1\text{ times}}\big)+\underbrace{Q^{A}\times...\times Q^{A}}_{n\text{ times}}\times\,F^{A}\quad.
\end{align*}
The type equivalence~(\ref{eq:def-recursive-functor-unrolling}),
$F^{A}\cong P^{A}\times\text{List}^{Q^{A}}$, follows by induction
on the number of \textsf{``}unrolled\textsf{''} functors $F$. We can now use the
functor product construction for $F$ if we show that the functor
$\text{List}\circ Q$ is filterable. This does not follow by functor
composition because $Q^{A}\triangleq A\times\left(\bbnum 1+A\right)$
is \emph{not} filterable (we saw that in Section~\ref{subsec:Examples-of-non-filterable-functors}).
However, we can derive from Statement~\ref{subsec:Statement-filterable-coproduct-1},
setting $G^{A}\triangleq\bbnum 1+A$, that:
\[
H^{A}\triangleq\bbnum 1+A\times\left(\bbnum 1+A\right)=\bbnum 1+Q^{A}
\]
is filterable. So, we can use the result of Example~\ref{subsec:Example-filterable-laws-3-1}
and conclude that the functor $\text{List}\circ Q$ is filterable.

\subsubsection{Example \label{subsec:Example-filterable-laws-4}\ref{subsec:Example-filterable-laws-4}}

Show that the contrafunctor $C^{A}\triangleq A\rightarrow Z$ is not
filterable (where the fixed type $Z$ does not have a known default
value).

\subparagraph{Solution}

Try implementing the function $\text{inflate}_{C}:C^{A}\rightarrow C^{\bbnum 1+A}$
and write:
\[
\text{inflate}_{C}:(A\rightarrow Z)\rightarrow\bbnum 1+A\rightarrow Z\quad,\quad\quad\text{inflate}_{C}=c^{:A\rightarrow Z}\rightarrow p^{:\bbnum 1+A}\rightarrow\text{???}^{:Z}\quad.
\]
The only way to fill the type hole $\text{???}^{:Z}$ is to apply
$c$ to an argument of type $A$. However, we do not have values of
type $A$; we only have $p$ of type $\bbnum 1+A$, and $p$ might
be the \textsf{``}empty\textsf{''} value, $1+\bbnum 0$. So, it is impossible to implement
$\text{inflate}_{C}$. We conclude that $C$ is not filterable.

\subsubsection{Example \label{subsec:Example-filterable-laws-4-1}\ref{subsec:Example-filterable-laws-4-1}}

Show that the type $F^{\bbnum 1}\rightarrow F^{\bbnum 0}$ is \emph{not}
void when $F$ is a filterable functor.

\subparagraph{Solution}

A filterable functor must have a \lstinline!deflate! function with
type signature $F^{\bbnum 1+A}\rightarrow F^{A}$. Set the type parameter
$A=\bbnum 0$ in the code of \lstinline!deflate! to obtain the code
for a function of type $F^{\bbnum 1}\rightarrow F^{\bbnum 0}$. 

\subsection{Exercises\index{exercises}}

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws}\ref{subsec:Exercise-filterable-laws}}

Implement a \lstinline!Filterable! instance for the functor \lstinline!F[T] = G[H[T]]!
assuming that the contrafunctor \lstinline!H! already has a \lstinline!Filterable!
instance and \lstinline!G! is an arbitrary contrafunctor. Verify
the laws of filterable functor rigorously (by symbolic derivations,
not tests).

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-1}\ref{subsec:Exercise-filterable-laws-1}}

Implement a \lstinline!Filterable! instance for the functor \lstinline!F[T] = Option[Int => Option[(T, T)]]!.
Show that the laws hold by using known constructions (avoid explicit
proofs or tests).

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-2}\ref{subsec:Exercise-filterable-laws-2}}

Prove rigorously (not via tests) that $\text{flm}_{\text{Opt}}(\text{pu}_{\text{Opt}})=\text{id}^{:\bbnum 1+A\rightarrow\bbnum 1+A}$.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-2-1}\ref{subsec:Exercise-filterable-laws-2-1}}

Prove rigorously (not via tests) that Eqs.~(\ref{eq:left-naturality-flatmap-option})\textendash (\ref{eq:right-naturality-flatmap-option})
hold.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-7}\ref{subsec:Exercise-filterable-laws-7}}

Show that one can define \lstinline!deflate!$~:C^{\bbnum 1+A}\rightarrow C^{A}$
for any contrafunctor $C$ (not necessarily filterable). Prove that
\emph{in case} $C$ is filterable, the \textbf{identity law}\index{identity laws!of inflate@of \texttt{inflate}}
will hold:
\[
\text{inflate}_{C}\bef\text{deflate}_{C}=\text{id}^{:C^{A}\rightarrow C^{A}}\quad.
\]
Show that the inverse equation does not hold in general: $\text{deflate}_{C}\bef\text{inflate}_{C}\neq\text{id}$.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-3}\ref{subsec:Exercise-filterable-laws-3}}

Assuming that $G$ is a filterable functor, prove rigorously that
the recursive functor $F^{A}\triangleq G^{A}+\text{Int}\times A\times A\times A\times F^{A}$
is filterable. Implement a \lstinline!Filterable! instance for $F$.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-6}\ref{subsec:Exercise-filterable-laws-6}}

Show that the functor $F^{A}\triangleq A+\left(\text{Int}\rightarrow A\right)$
is not filterable.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-4}\ref{subsec:Exercise-filterable-laws-4}}

Prove that $F^{A}\triangleq\bbnum 1+A\times G^{A}$ is in general
not filterable if $G$ is an arbitrary (non-filterable) functor; give
an example of a suitable $G$. Since $F^{\bbnum 1}\rightarrow F^{\bbnum 0}\cong\bbnum 1+G^{\bbnum 1}\rightarrow\bbnum 1\cong\bbnum 1$,
this will demonstrate that Example~\ref{subsec:Example-filterable-laws-4-1}
gives a necessary but not a sufficient condition for a functor $F$
to be filterable.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-5}\ref{subsec:Exercise-filterable-laws-5}}

Show that $F^{A}\triangleq\bbnum 1+G^{A}+H^{A}$ is filterable if
$\bbnum 1+G^{A}$ and $\bbnum 1+H^{A}$ are filterable (even when
$G$ and $H$ are not filterable).

\subsubsection{Exercise \label{subsec:filt-exercise-4}\ref{subsec:filt-exercise-4}}

Show that $C^{A}\triangleq A+A\times A\rightarrow\bbnum 1+Z$ is a
filterable contrafunctor (no law checking).

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-6-2}\ref{subsec:Exercise-filterable-laws-6-2}}

Verify Eqs.~(\ref{eq:left-naturality-flatmap-option})\textendash (\ref{eq:right-naturality-flatmap-option})
in Scala syntax and in the code notation.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-6-1}\ref{subsec:Exercise-filterable-laws-6-1}}

If $G$ and $H$ are filterable contrafunctors, prove that the contrafunctors
$P^{A}\triangleq G^{A}\times H^{A}$ and $Q^{A}\triangleq G^{A}+H^{A}$
are also filterable. 

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-8}\ref{subsec:Exercise-filterable-laws-8}}

Show that the contrafunctor $C^{A}\triangleq A\times F^{A}\rightarrow Z$
is \emph{not} filterable for any functor $F$ and any fixed type $Z$
that does not have a known default value.

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-8-1}\ref{subsec:Exercise-filterable-laws-8-1}}

Show that a \emph{necessary} condition for a contrafunctor $C$ to
be filterable is that a function of type $C^{\bbnum 0}\rightarrow C^{\bbnum 1}$
can be implemented (i.e., the type $C^{\bbnum 0}\rightarrow C^{\bbnum 1}$
is not void).

\subsubsection{Exercise \label{subsec:Exercise-filterable-laws-8-2}\ref{subsec:Exercise-filterable-laws-8-2}}

Give an example of a non-filterable polynomial functor $F$ for which
$F^{\bbnum 1}\rightarrow F^{\bbnum 0}\cong\bbnum 0$. Show that a
polynomial functor $F$ is filterable (in some way) if and only if
the type $F^{\bbnum 1}\rightarrow F^{\bbnum 0}$ is not void. 

\section{Further developments}

\subsection{Naturality laws and natural transformations\label{subsec:Naturality-laws-and-natural-transformations}}

While deriving various laws, we often need to interchange the order
of compositions that involve lifted functions. For instance, in the
derivation of Example~\ref{subsec:filt-solved-example-5-1}, we had
an expression:
\[
\text{get}^{\downarrow C}\bef\text{filt}_{C}(\text{nonEmpty})\bef\psi_{p}^{\downarrow C}\quad.
\]
We needed to move $\psi_{p}^{\downarrow C}$ to the left of $\text{filt}_{C}$
in that expression, or else we could make no progress with the derivation.
The required interchange was possible due to the law~(\ref{eq:naturality-for-filter-for-contrafunctors}):
\[
\text{filt}_{C}(p)\bef f^{\downarrow C}=f^{\downarrow C}\bef\text{filt}_{C}(f\bef p)\quad.
\]
In this and previous chapters, we discovered a number of laws of that
form, e.g.:
\begin{align*}
{\color{greenunder}\text{Eq.~(\ref{eq:naturality-law-of-pure})}:}\quad & \text{pu}_{F}\bef f^{\uparrow F}=f\bef\text{pu}_{F} & \text{for } & \text{pu}_{F}:A\rightarrow F^{A}\\
{\color{greenunder}\text{Eq.~(\ref{eq:naturality-law-of-extract})}:}\quad & \text{ex}_{F}\bef f=f^{\uparrow F}\bef\text{ex}_{F} & \text{for } & \text{ex}_{F}:F^{A}\rightarrow A\\
{\color{greenunder}\text{Eq.~(\ref{eq:copointed-bifunctor-naturality-law})}:}\quad & \text{ex}_{S}\bef f=\text{bimap}_{S}(f)(f)\bef\text{ex}_{S} & \text{for } & \text{ex}_{S}:S^{A,A}\rightarrow A\\
{\color{greenunder}\text{Eq.~(\ref{eq:naturality-law-of-filter})}:}\quad & f^{\uparrow F}\bef\text{filt}_{F}(p)=\text{filt}_{F}(f\bef p)\bef f^{\uparrow F} & \text{for } & \text{filt}_{F}:\left(A\rightarrow\bbnum 2\right)\rightarrow F^{A}\rightarrow F^{A}\\
{\color{greenunder}\text{Eq.~(\ref{eq:naturality-law-of-deflate})}:}\quad & \text{deflate}\bef f^{\uparrow F}=f^{\uparrow\text{Opt}\uparrow F}\bef\text{deflate} & \text{for } & \text{deflate}_{F}:F^{\bbnum 1+A}\rightarrow F^{A}\\
{\color{greenunder}\text{Eq.~(\ref{eq:naturality-law-of-psi})}:}\quad & f\bef\psi_{p}=\psi_{f\bef p}\bef f^{\uparrow\text{Opt}} & \text{for } & \psi:\left(A\rightarrow\bbnum 2\right)\rightarrow A\rightarrow\bbnum 1+A\\
{\color{greenunder}\text{Eq.~(\ref{eq:left-naturality-law-of-liftOpt})}:}\quad & h^{\uparrow F}\bef\text{liftOpt}_{F}(f)=\text{liftOpt}_{F}(h\bef f) & \text{and}\\
{\color{greenunder}\text{Eq.~(\ref{eq:right-naturality-law-of-liftOpt})}:}\quad & \text{liftOpt}_{F}(f)\bef h^{\uparrow F}=\text{liftOpt}_{F}(f\bef h^{\uparrow\text{Opt}}) & \text{for } & \text{liftOpt}_{F}:\\
 &  &  & \ \ (A\rightarrow\text{Opt}^{B})\rightarrow F^{A}\rightarrow F^{B}\\
{\color{greenunder}\text{Eq.~(\ref{eq:naturality-for-filter-for-contrafunctors})}:}\quad & \text{filt}_{C}(p)\bef f^{\downarrow C}=f^{\downarrow C}\bef\text{filt}_{C}(f\bef p) & \text{for } & \text{filt}_{C}:\left(A\rightarrow\bbnum 2\right)\rightarrow C^{A}\rightarrow C^{A}\\
{\color{greenunder}\text{Eq.~(\ref{eq:naturality-law-of-inflate-for-filterable-contrafunctor})}:}\quad & f^{\downarrow C}\bef\text{inflate}_{C}=\text{inflate}_{C}\bef f^{\uparrow\text{Opt}\downarrow C} & \text{for } & \text{inflate}_{C}:C^{A}\rightarrow C^{\bbnum 1+A}
\end{align*}
We called all these laws \textsf{``}naturality laws\textsf{''}, although they were
derived from different premises and do not look similar at first sight.
Is there a common pattern for these laws? For a given function, can
we guess the form of its naturality law? 

Looking at the examples shown above, we find that each law follows
one of the four patterns shown in the following table, where we use
arbitrary functors $F$, $G$, $H$ and contrafunctors $C$:
\begin{center}
\begin{tabular}{|c|c|c|}
\hline 
\textbf{\small{}Pattern} & \textbf{\small{}Type signature} & \textbf{\small{}Naturality law}\tabularnewline
\hline 
\hline 
{\small{}2-transformation} & {\small{}$t^{A}:F^{A}\rightarrow G^{A}$} & {\small{}$(f^{:A\rightarrow B})^{\uparrow F}\bef t^{B}=t^{A}\bef f^{\uparrow G}$}\tabularnewline
\hline 
{\small{}3-transformation} & {\small{}$t^{A}:C^{A}\rightarrow F^{A}\rightarrow G^{A}$} & {\small{}$f^{\uparrow F}\bef t^{B}(c)=t(c\triangleright f^{\downarrow C})\bef f^{\uparrow G}$}\tabularnewline
\hline 
{\small{}$A$-lifting} & {\small{}$t^{A,B}:(A\rightarrow G^{B})\rightarrow F^{A}\rightarrow F^{B}$} & {\small{}$(f^{:A\rightarrow B})^{\uparrow F}\bef t^{B,C}(p)=t^{A,C}(f\bef p)$}\tabularnewline
\hline 
{\small{}$B$-lifting} & {\small{}$t^{A,B}:(A\rightarrow G^{B})\rightarrow F^{A}\rightarrow F^{B}$} & {\small{}$t^{A,B}(p)\bef(g^{:B\rightarrow C})^{\uparrow F}=t^{A,C}(p\bef g^{\uparrow G})$}\tabularnewline
\hline 
\end{tabular}
\par\end{center}

Let us now look at each of these patterns in detail.

\paragraph{\textquotedblleft 2-transformation\textquotedblright}

This pattern covers functions with type signatures of the form $F^{A}\rightarrow G^{A}$,
where $F$ and $G$ must be both functors or both contrafunctors.
Functions of that kind, i.e., fully parametric functions with type
signatures of the form $t^{A}:F^{A}\rightarrow G^{A}$, are called
\textbf{natural transformations} between $F$ and $G$.\index{natural transformation}
Heuristically, we may view $t^{A}$ as a function that copies data
of type $A$ from one \textsf{``}wrapper\textsf{''} to another and may rearrange that
data in a way that does not depend on the type $A$. An example is
the \lstinline!headOption! method defined in Scala on various sequence
types such as \lstinline!List!:
\[
\text{headOpt}:\text{List}^{A}\rightarrow\text{Opt}^{A}\quad.
\]
We can write an equivalent Scala code for this function as:

\begin{lstlisting}
def headOption[A]: List[A] => Option[A] = {
  case List()   => None
  case x :: _   => Some(x)
}
\end{lstlisting}
It is clear that this code works in the same way for all types $A$.
This property is formulated mathematically as the requirement that
we may first transform a list with a lifted function $(f^{:A\rightarrow B})^{\uparrow\text{List}}$
and then apply \lstinline!headOption!; or we may first apply \lstinline!headOption!
and then transform the data with a lifted function $f$ (and we will
then need to lift $f$ to the \lstinline!Option! functor rather than
to the \lstinline!List! functor); the results will be equal. We write
this requirement as an equation called the \textbf{naturality law}\index{naturality law!of headOption@of \texttt{headOption}}
of \lstinline!headOption!:
\[
\xymatrix{\text{List}^{A}\ar[r]\sp(0.55){\text{headOpt}^{A}}\ar[d]\sb(0.5){(f^{:A\rightarrow B})^{\uparrow\text{List}}} & \text{Opt}^{A}\ar[d]\sb(0.4){f^{\uparrow\text{Opt}}}\\
\xyScaleY{1.6pc}\xyScaleX{4.5pc}\text{List}^{B}\ar[r]\sp(0.55){\text{headOpt}^{B}} & \text{Opt}^{B}
}
\]
\[
(f^{:A\rightarrow B})^{\uparrow\text{List}}\bef\text{headOpt}^{B}=\text{headOpt}^{A}\bef f^{\uparrow\text{Opt}}\quad.
\]
It is important to keep in mind that this law does not depend on the
fact that \lstinline!headOption! extracts the \emph{first} element
of a list. The same law will hold for any fully parametric function
of type $\text{List}^{A}\rightarrow\text{Opt}^{A}$, e.g., for the
functions \lstinline!_.lastOption! or \lstinline!_.drop(2).headOption!.
The naturality law only expresses the property that the function works
in the same way for all types; the function should not behave differently
for any specific types or for any specific values in the list. This
is true for \lstinline!headOption!, for \lstinline!lastOption!,
and for many other functions.

Further examples of natural transformations are the functions \lstinline!pure!,
\lstinline!deflate!, and \lstinline!inflate!, whose naturality laws
we have already seen. All these naturality laws are captured by the
\textsf{``}natural transformation\textsf{''} pattern, which we can formulate for arbitrary
functors $F$ and $G$ as the following law:
\[
\xymatrix{F^{A}\ar[r]\sp(0.55){t^{A}}\ar[d]\sb(0.5){(f^{:A\rightarrow B})^{\uparrow F}} & G^{A}\ar[d]\sp(0.4){f^{\uparrow G}}\\
\xyScaleY{1.7pc}\xyScaleX{3.5pc}F^{B}\ar[r]\sp(0.55){t^{B}} & G^{B}
}
\]
\begin{equation}
(f^{:A\rightarrow B})^{\uparrow F}\bef t^{:F^{B}\rightarrow G^{B}}=t^{:F^{A}\rightarrow G^{A}}\bef f^{\uparrow G}\quad.\label{eq:law-natural-transformation-of-functors}
\end{equation}
Once we recognize that a given function $t^{A}:F^{A}\rightarrow G^{A}$
has the type signature of a natural transformation, how can we remember
its naturality law? A naturality law always involves an arbitrary
function $f^{:A\rightarrow B}$ with two type parameters. Types will
match only if the function $f$ is lifted to the functor $F$ when
$f$ is applied before $t$, and to the functor $G$ when $f$ is
applied after $t$. So, naturality laws have the form $f^{\uparrow F}\bef t=t\bef f^{\uparrow G}$
with appropriate type parameters.

The naturality law for natural transformations $t^{A}:C^{A}\rightarrow D^{A}$
between \emph{contrafunctors} $C$ and $D$ has exactly the same form,
but the order of type parameters must be swapped:
\[
\xymatrix{C^{A}\ar[r]\sp(0.55){t^{A}}\ar[d]\sb(0.5){(f^{:B\rightarrow A})^{\downarrow C}} & D^{A}\ar[d]\sp(0.4){f^{\downarrow D}}\\
\xyScaleY{1.7pc}\xyScaleX{3.5pc}C^{B}\ar[r]\sp(0.55){t^{B}} & D^{B}
}
\]
\begin{equation}
(f^{:B\rightarrow A})^{\downarrow C}\bef t^{:C^{B}\rightarrow D^{B}}=t^{:C^{A}\rightarrow D^{A}}\bef f^{\downarrow D}\quad.\label{eq:law-natural-transformation-of-contrafunctors}
\end{equation}
Examples of this pattern are the naturality law~(\ref{eq:naturality-law-for-pure-for-contrafunctors})
for $\text{pu}_{D}$ (where we need to set $C^{A}\triangleq\bbnum 1$)
and the naturality law~(\ref{eq:naturality-law-of-inflate-for-filterable-contrafunctor})
for $\text{inflate}_{C}$.

\paragraph{\textquotedblleft 3-transformation\textquotedblright}

The second pattern, which we called \textsf{``}3-transformation\textsf{''}, is a curried
function that takes a first argument of type $C^{A}$ and returns
a natural transformation of type $F^{A}\rightarrow G^{A}$. This pattern
is recognized by a type signature $C^{A}\rightarrow F^{A}\rightarrow G^{A}$
where $C$ is a contrafunctor while $F$ and $G$ are functors (or
vice versa, $C$ is a functor while $F$ and $G$ are contrafunctors).
Examples of such type signatures are the methods \lstinline!filter!,
\lstinline!takeWhile!, and \lstinline!find!, defined in the Scala
library for sequence-like type constructors (e.g., \lstinline!List!,
\lstinline!Vector!, or \lstinline!Array!). 

For functions of this kind, naturality laws must modify the argument
of type $C^{A}$ when changing the order of lifted functions. In order
to formulate the naturality law for $t^{A}:C^{A}\rightarrow F^{A}\rightarrow G^{A}$,
use an arbitrary function $f^{:A\rightarrow B}$ and first transform
the argument of type $F^{A}$ into $F^{B}$ using $f^{\uparrow F}$
before applying $t^{B}(c)$:
\[
f^{\uparrow F}\bef t^{B}(c^{:C^{B}})=\text{???}^{:F^{A}\rightarrow G^{B}}\quad.
\]
It is clear that we must choose an arbitrary value $c$ of type $C^{B}$
(rather than $C^{A}$) for all types to match. It remains to fill
the right-hand side, which must be of the form $t(...)\bef f^{\uparrow G}$.
We write:
\[
f^{\uparrow F}\bef t^{B}(c^{:C^{B}})=t^{A}(\text{???}^{:C^{A}})\bef f^{\uparrow G}\quad.
\]
The value $\text{???}^{:C^{A}}$ is obtained by applying $f^{\downarrow C}$
to $c$. So, the law is:
\begin{equation}
f^{\uparrow F}\bef t(c)=t(c\triangleright f^{\downarrow C})\bef f^{\uparrow G}\quad.\label{eq:naturality-law-general-parameterized-transformation}
\end{equation}
A similar law can be derived for the case when $C$ is a functor and
$F$, $G$ are contrafunctors.

Functions $t:C^{A}\rightarrow F^{A}\rightarrow G^{A}$ are reduced
to natural transformations if we swap the order of curried arguments
to $F^{A}\rightarrow C^{A}\rightarrow G^{A}$ and define the functor
$H^{A}\triangleq C^{A}\rightarrow G^{A}$. Then $F^{A}\rightarrow C^{A}\rightarrow G^{A}=F^{A}\rightarrow H^{A}$,
which is a type signature of a natural transformation. Denoting by
$\tilde{t}^{A}:F^{A}\rightarrow H^{A}$ the function $t$ with its
arguments swapped, we can write the naturality law of $\tilde{t}$
as:
\[
f^{\uparrow F}\bef\tilde{t}=\tilde{t}\bef f^{\uparrow H}\quad,\quad\text{where}\quad\tilde{t}^{A}\triangleq p^{:F^{A}}\rightarrow c^{:C^{A}}\rightarrow p\triangleright t(c)\quad.
\]
To show that this law is equivalent to Eq.~(\ref{eq:naturality-law-general-parameterized-transformation}),
we use the definition of $^{\uparrow H}$,
\[
f^{\uparrow H}\triangleq h^{:H^{A}}\rightarrow c^{:C^{B}}\rightarrow c\triangleright f^{\downarrow C}\bef h\bef f^{\uparrow G}\quad.
\]
Substituting this into the naturality law of $\tilde{t}$, we obtain
the naturality law~(\ref{eq:naturality-law-general-parameterized-transformation}):
\begin{align*}
{\color{greenunder}\text{left-hand side applied to }p^{:F^{A}}:}\quad & p\triangleright f^{\uparrow F}\bef\gunderline{\tilde{t}}=\gunderline{p\triangleright f^{\uparrow F}}\bef\gunderline{\big(p}\rightarrow c\rightarrow\gunderline p\triangleright t(c)\big)\\
{\color{greenunder}\text{apply function to }p\triangleright f^{\uparrow F}:}\quad & \quad=c\rightarrow p\triangleright f^{\uparrow F}\triangleright t(c)=c\rightarrow p\triangleright f^{\uparrow F}\bef t(c)\quad,\\
{\color{greenunder}\text{left-hand side applied to }p^{:F^{A}}:}\quad & \gunderline{p\triangleright\big(p}\rightarrow c\rightarrow p\triangleright t(c)\big)\bef f^{\uparrow H}=\big(c\rightarrow p\triangleright t(c)\big)\triangleright\gunderline{f^{\uparrow H}}\\
{\color{greenunder}\text{definition of }f^{\uparrow H}:}\quad & \quad=c\rightarrow\gunderline{c\triangleright f^{\downarrow C}\bef}\,\big(c\rightarrow p\triangleright t(\gunderline c)\big)\bef f^{\uparrow G}\\
{\color{greenunder}\text{apply function to }c\triangleright f^{\downarrow C}:}\quad & \quad=c\rightarrow p\triangleright t(c\triangleright f^{\downarrow C})\bef f^{\uparrow G}\quad.
\end{align*}
So, we have reduced both sides of $\tilde{t}$\textsf{'}s law to the two sides
of the law~(\ref{eq:naturality-law-general-parameterized-transformation})
applied to an arbitrary $p^{:F^{A}}$and considered as functions of
$c^{:C^{B}}$.

Reduction to natural transformations works similarly when $C$ is
a functor and $F$, $G$ are contrafunctors. A naturality law of $t^{A}:C^{A}\rightarrow F^{A}\rightarrow G^{A}$
can then be derived from $t$\textsf{'}s type signature.

\paragraph{\textquotedblleft Liftings\textquotedblright}

A \textsf{``}lifted\textsf{''} function $f^{\uparrow F}$ is the result of applying
a functor $F$\textsf{'}s \lstinline!map! operation to a function $f$. The
type signatures of \lstinline!flatMap! and \lstinline!liftOpt! are
similar to that of \lstinline!map! except for using the function
type $A\rightarrow\text{Opt}^{B}$ instead of $A\rightarrow B$:
\begin{align*}
 & \text{fmap}_{F}:\left(A\rightarrow B\right)\rightarrow F^{A}\rightarrow F^{B}\quad,\\
 & \text{flm}_{\text{Opt}}:(A\rightarrow\text{Opt}^{B})\rightarrow\text{Opt}^{A}\rightarrow\text{Opt}^{B}\quad,\\
 & \text{liftOpt}_{F}:(A\rightarrow\text{Opt}^{B})\rightarrow F^{A}\rightarrow F^{B}\quad.
\end{align*}
Replacing \textsf{``}$\text{Opt}$\textsf{''} by an arbitrary functor $G$, we obtain
the type signature:
\[
\text{lift}_{G,F}^{A,B}:(A\rightarrow G^{B})\rightarrow F^{A}\rightarrow F^{B}\quad.
\]
We can view this as a generalized \textsf{``}lifting\textsf{''} from functions of
type $A\rightarrow G^{B}$ (called \index{Kleisli!functions}\textbf{Kleisli
functions}) to functions of type $F^{A}\rightarrow F^{B}$. We will
look at properties of generalized liftings in the next subsection.
Here we focus on the naturality laws for generalized liftings.

A generalized lifting has two type parameters and two naturality laws.
Looking at the two naturality laws~(\ref{eq:left-naturality-law-of-liftOpt}),
(\ref{eq:right-naturality-law-of-liftOpt}) for \lstinline!liftOpt!
or at the two laws~(\ref{eq:left-naturality-flatmap-option}), (\ref{eq:right-naturality-flatmap-option})
for $\text{flm}_{\text{Opt}}$, we notice that each naturality law
replaces one of the type parameters but keeps the other type parameter
unchanged. This motivates us to fix one of the type parameters in
the type signature of $\text{lift}_{G,F}^{A,B}$. For fixed $A$,
the function $\text{lift}_{G,F}^{A,B}$ is a natural transformation
between functors $A\rightarrow G^{\bullet}$ and $F^{A}\rightarrow F^{\bullet}$.
With a fixed $B$, the function $\text{lift}_{G,F}^{A,B}$ is a natural
transformation between contrafunctors $\bullet\rightarrow G^{B}$
and $F^{\bullet}\rightarrow F^{B}$. One can show that the corresponding
naturality laws for these two natural transformations are equivalent
to the two naturality laws of a generalized lifting.

We have reduced the four patterns of naturality laws to the laws of
natural transformations, Eq.~(\ref{eq:law-natural-transformation-of-functors})
for functors and Eq.~(\ref{eq:law-natural-transformation-of-contrafunctors})
for contrafunctors, which are easier to understand.

\paragraph{Parametricity theorem}

It turns out that the naturality law of a natural transformation $t^{A}:F^{A}\rightarrow G^{A}$
will \emph{always hold} if the code of the function $t$ is fully
parametric. More precisely, naturality holds if the code of $t$ is
a combination of the eight standard code constructions (shown in Section~\ref{subsec:Short-notation-for-eight-code-constructions})
together with recursion. This is a consequence of the \textsf{``}parametricity
theorem\textsf{''}\index{parametricity theorem}, which is beyond the scope
of this chapter.\footnote{Formulations and proofs sufficient for the scope of this book are
given in Appendix~\ref{app:Proofs-of-naturality-parametricity}.} So, we do \emph{not} need to verify naturality laws for functions
whose code is known to be fully parametric. This saves a significant
amount of work, since every method of every typeclass will have one
naturality law per type parameter. Until now, we have been systematically
deriving and checking all naturality laws; but we will not keep checking
those laws in the rest of the book.

Even if naturality laws hold automatically, it is important to be
able to recognize their form and to use them in derivations where
they are frequently needed. The mnemonic recipe for naturality laws~(\ref{eq:law-natural-transformation-of-functors})\textendash (\ref{eq:law-natural-transformation-of-contrafunctors})
is that an arbitrary function $f$ is lifted to the functor $F$ at
the left side of $t^{A}:F^{A}\rightarrow G^{A}$ and to the functor
$G$ at the right side of $t$, matching the two sides of the type
signature $F^{A}\rightarrow G^{A}$. 

All methods of typeclasses considered in this book are covered by
the natural transformation recipe. However, not all type signatures
of fully parametric functions can be reduced to natural transformations.
For example, $t^{A}:(A\rightarrow A)\rightarrow A$ is not of the
form $F^{A}\rightarrow G^{A}$ where $F,G$ are either functors or
contrafunctors. The parametricity theorem will still produce naturality
laws for such functions; but we will not be able to write those laws
via the natural transformation recipe. (A general procedure that works
for all type signatures is given in Section~\ref{sec:Naturality-laws-for-fully-parametric-functions}.)

\subsection{Generalizing the laws of liftings. Kleisli functions\label{subsec:Generalizing-the-laws-of-liftings-kleisli-functions}}

As we have seen in this chapter, the laws of filtering may be formulated
equivalently via the \lstinline!filter!, \lstinline!deflate!, or
\lstinline!liftOpt! methods. These methods and their laws are equivalent
but play different roles: \lstinline!filter! is the most convenient
to use in program code; \lstinline!deflate! is the easiest type signature
to implement and to reason about, especially in order to detect that
a functor is not filterable; \lstinline!liftOpt! has the fewest laws
and is most convenient for proofs of general type constructions.

If we put the naturality laws aside, \lstinline!liftOpt! has the
laws of identity~(\ref{eq:identity-law-of-liftOpt}) and composition~(\ref{eq:composition-law-of-liftOpt}).
It is notable that those two laws are similar to the functor laws~(\ref{eq:f-identity-law-functor-fmap})\textendash (\ref{eq:f-composition-law-functor-fmap}):
\begin{align*}
\text{liftOpt}_{F}(\text{pu}_{F})=\text{id}\quad, & \quad\text{liftOpt}_{F}(f^{:A\rightarrow\bbnum 1+B})\bef\text{liftOpt}_{F}(g^{:B\rightarrow\bbnum 1+C})=\text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)\quad.\\
\text{fmap}_{F}(\text{id})=\text{id}\quad, & \quad\text{fmap}_{F}(f^{:A\rightarrow B})\bef\text{fmap}_{F}(g^{:B\rightarrow C})=\text{fmap}_{F}(f\bef g)\quad.
\end{align*}
The only difference between those sets of laws is in replacing $\text{id}^{:A\rightarrow A}$
by $\text{pu}_{F}^{:A\rightarrow F^{A}}$ and the function composition
$f\bef g$ by the Kleisli composition $f\diamond_{_{\text{Opt}}}g$.
We will now focus on the analogy between those laws, which goes far
beyond the superficial similarity of form.

Kleisli functions $f^{:A\rightarrow\bbnum 1+B}$ and $g^{:B\rightarrow\bbnum 1+C}$
cannot be composed as $f\bef g$ with the ordinary function composition.
If we instead use the Kleisli composition, $f\diamond_{_{\text{Opt}}}g$,
the properties of Kleisli functions with respect to composition become
completely analogous to the properties of the ordinary functions,
except that the $\text{pu}_{\text{Opt}}:A\rightarrow\bbnum 1+A$ plays
the role of the identity ($\text{id}^{:A\rightarrow A}$). 

\subsubsection{Statement \label{subsec:Statement-Kleisli-Option-laws}\ref{subsec:Statement-Kleisli-Option-laws}}

The Kleisli composition $\diamond_{_{\text{Opt}}}$ obeys the identity
and the associativity laws:
\begin{align*}
{\color{greenunder}\text{identity laws}:}\quad & \text{pu}_{\text{Opt}}^{:A\rightarrow\text{Opt}^{A}}\diamond_{_{\text{Opt}}}g^{:A\rightarrow\text{Opt}^{B}}=g\quad,\quad f^{:A\rightarrow\text{Opt}^{B}}\diamond_{_{\text{Opt}}}\text{pu}_{\text{Opt}}^{:B\rightarrow\text{Opt}^{B}}=f,\\
{\color{greenunder}\text{associativity law}:}\quad & \big(f^{:A\rightarrow\text{Opt}^{B}}\diamond_{_{\text{Opt}}}g^{:B\rightarrow\text{Opt}^{C}}\big)\diamond_{_{\text{Opt}}}h^{:C\rightarrow\text{Opt}^{D}}=f\diamond_{_{\text{Opt}}}\big(g\diamond_{_{\text{Opt}}}h\big)\quad.
\end{align*}


\subparagraph{Proof}

Use the definitions~(\ref{eq:def-of-Kleisli-product}) and Eqs.~(\ref{eq:simplify-puOpt-flmOpt}),
(\ref{eq:simplify-kleisli-opt-right-pure}), (\ref{eq:associativity-law-of-flatMap-for-Option})
derived previously in this chapter:
\begin{align*}
{\color{greenunder}\text{use Eq.~(\ref{eq:simplify-puOpt-flmOpt})}:}\quad & \text{pu}_{\text{Opt}}\diamond_{_{\text{Opt}}}g=\text{pu}_{\text{Opt}}\bef\text{flm}_{\text{Opt}}(g)=g\quad,\\
{\color{greenunder}\text{use Exercise~\ref{subsec:Exercise-filterable-laws-2}}:}\quad & f\diamond_{_{\text{Opt}}}\text{pu}_{\text{Opt}}=f\bef\gunderline{\text{flm}_{\text{Opt}}(\text{pu}_{\text{Opt}})}=f\bef\text{id}=f\quad,\\
{\color{greenunder}\text{expect to equal }f\diamond_{_{\text{Opt}}}\big(g\diamond_{_{\text{Opt}}}h\big):}\quad & \big(f\diamond_{_{\text{Opt}}}g\big)\diamond_{_{\text{Opt}}}h=f\bef\gunderline{\text{flm}_{\text{Opt}}(g)\bef\text{flm}_{\text{Opt}}(h)}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:associativity-law-of-flatMap-for-Option})}:}\quad & \quad=f\bef\text{flm}_{\text{Opt}}(g\diamond_{_{\text{Opt}}}h)=f\diamond_{_{\text{Opt}}}\big(g\diamond_{_{\text{Opt}}}h\big)\quad.
\end{align*}
This calculation motivates the name \textsf{``}associativity law\textsf{''} for Eq.~(\ref{eq:associativity-law-of-flatMap-for-Option}).
$\square$

The function \lstinline!liftOpt! can be viewed as a \textsf{``}generalized
lifting\textsf{''} from Kleisli functions $A\rightarrow\bbnum 1+B$ to functions
$F^{A}\rightarrow F^{B}$, just as \lstinline!fmap! is a lifting
from ordinary functions $A\rightarrow B$ to functions $F^{A}\rightarrow F^{B}$;
the laws of composition and the laws of liftings are analogous. The
close analogy between ordinary functions and Kleisli functions means
that any proofs of properties of ordinary liftings can be mechanically
translated into proofs of the corresponding properties of generalized
liftings. Indeed, replacing \lstinline!fmap! by \lstinline!liftOpt!
and $\text{id}$ by $\text{pu}_{\text{Opt}}$ where appropriate, we
can translate the proof of Statement~\ref{subsec:functor-Statement-functor-product}
(functor product), written using the pair product operation $\boxtimes$,
into the proof of Statement~\ref{subsec:Statement-filterable-functor-product}
(filterable functor product). The same holds for the proofs of functor
co-product and functor composition constructions.

The similarity between those proofs means, in a mathematician\textsf{'}s view,
that we have been proving essentially the same statement twice but
did not use an appropriate level of abstraction to see that. While
programmers may accept the work of writing those proofs twice, a mathematician
would prefer to define a \textsf{``}generalized lifting\textsf{''} that replaces $\text{Opt}$
by a functor $M$:
\begin{align*}
 & \text{lift}_{M,F}:(A\rightarrow M^{B})\rightarrow F^{A}\rightarrow F^{B}\quad,\\
 & \text{pu}_{M}:A\rightarrow M^{A}\quad,\quad\quad\diamond_{_{M}}:(A\rightarrow M^{B})\rightarrow(B\rightarrow M^{C})\rightarrow(A\rightarrow M^{C})\quad,
\end{align*}
and postulating the required properties as the laws of identity, associativity,
and composition:
\begin{align*}
 & \text{lift}_{M,F}(\text{pu}_{M}^{:A\rightarrow M^{A}})=\text{id}^{:F^{A}\rightarrow F^{A}}\quad,\quad\quad\text{lift}_{M,F}(f)\bef\text{lift}_{M,F}(g)=\text{lift}_{M,F}(f\diamond_{_{M}}g)\quad,\\
 & \text{pu}_{M}\diamond_{_{M}}g=g\quad,\quad\quad f\diamond_{_{M}}\text{pu}_{M}=f\quad,\quad\quad\big(f\diamond_{_{M}}g\big)\diamond_{_{M}}h=f\diamond_{_{M}}\big(g\diamond_{_{M}}h\big)\quad.
\end{align*}
Now the two sets of proofs can be replaced by a single set of proofs
formulated for an \textsf{``}$M$\textbf{-filterable}\textsf{''}\index{$M$-filterable functor}
functor $F$, where $M$ could be later set either to the identity
functor or to the \lstinline!Option! functor.

Not all functors $M$ support the Kleisli composition $\diamond_{_{M}}$
with the required laws. We will study such functors $M$, known as
\textbf{monads}\index{monads}, in Chapter~\ref{chap:Semimonads-and-monads}. 

\subsection{Motivation for using category theory\label{subsec:Motivation-for-using-category-theory}}

In this chapter, we have seen four examples of operations that have
the form of a \textsf{``}lifting\textsf{''}:
\begin{align*}
{\color{greenunder}\text{for functors }F:}\quad & \text{fmap}_{F}:(A\rightarrow B)\rightarrow(F^{A}\rightarrow F^{B})\quad,\\
{\color{greenunder}\text{for contrafunctors }C:}\quad & \text{cmap}_{C}:(B\rightarrow A)\rightarrow(C^{A}\rightarrow C^{B})\quad,\\
{\color{greenunder}\text{for }M\text{-filterable functors }F:}\quad & \text{lift}_{M,F}:(A\rightarrow M^{B})\rightarrow(F^{A}\rightarrow F^{B})\quad,\\
{\color{greenunder}\text{for }M\text{-filterable contrafunctors }C:}\quad & \text{lift}_{M,F}:(B\rightarrow M^{A})\rightarrow(C^{A}\rightarrow C^{B})\quad.
\end{align*}
All these operations obey similar laws of naturality, identity, and
composition but differ in the type of functions being lifted: the
ordinary function $A\rightarrow B$, the \textsf{``}reversed\textsf{''} type $B\rightarrow A$,
the Kleisli function $A\rightarrow M^{B}$, and the \textsf{``}reversed\textsf{''}
Kleisli function $B\rightarrow M^{A}$. In turn, all those function
types obey their own versions of the laws of identity and composition.
(For the types to match, composition of reversed functions needs to
be performed in the reverse order.)

In order to avoid writing essentially the same proofs multiple times,
we use a more abstract view of this situation: a new notion of a functor
that can work with modified function types (e.g., $A\rightarrow M^{B}$
or $F^{A}\rightarrow F^{B}$) instead of the ordinary function types
($A\rightarrow B$). This notion of functor is provided by\index{category theory}
\textbf{category theory}, which turns out to be a convenient language
for describing various laws and types of operations in functional
programming.

Category theory generalizes functions of type $A\rightarrow B$ to
\textbf{morphisms} $A\leadsto B$, which\index{morphism}\index{category theory!morphism}
can be in any relation to $A$ and $B$ as long as the identity and
composition laws hold. The morphism types, the \textsf{``}\index{identity morphism}identity
morphism\textsf{''} of type $A\leadsto A$, and the composition operation
must be chosen appropriately. These choices, together with a definition
of the admissible types $A,B,...$, define a \textbf{category}, e.g.:
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline 
\textbf{\small{}Category} & \textbf{\small{}Morphisms} $f:A\leadsto B$ & \textbf{\small{}Identity morphism} & \textbf{\small{}Composition}\tabularnewline
\hline 
\hline 
{\small{}\textsf{``}plain\textsf{''}} & {\small{}$f:A\rightarrow B$} & {\small{}$\text{id}^{:A\rightarrow A}$} & {\small{}$f\bef g$}\tabularnewline
\hline 
{\small{}\textsf{``}reverse\textsf{''}} & {\small{}$f:B\rightarrow A$} & {\small{}$\text{id}^{:A\rightarrow A}$} & {\small{}$g\bef f$}\tabularnewline
\hline 
{\small{}\textsf{``}$M$-Kleisli\textsf{''}} & {\small{}$f:A\rightarrow M^{B}$} & {\small{}$\text{pu}_{M}:A\rightarrow M^{A}$} & {\small{}$f\diamond_{_{M}}g$}\tabularnewline
\hline 
{\small{}\textsf{``}reverse $M$-Kleisli\textsf{''}} & {\small{}$f:B\rightarrow M^{A}$} & {\small{}$\text{pu}_{M}:A\rightarrow M^{A}$} & {\small{}$g\diamond_{_{M}}f$}\tabularnewline
\hline 
{\small{}\textsf{``}$F$-lifted\textsf{''}} & {\small{}$f:F^{A}\rightarrow F^{B}$} & {\small{}$\text{id}^{:F^{A}\rightarrow F^{A}}$} & {\small{}$f\bef g$}\tabularnewline
\hline 
\end{tabular}
\par\end{center}

\subsubsection{Definition \label{subsec:Definition--(category)}\ref{subsec:Definition--(category)}
(category)}

A category\index{category theory!category} $\mathcal{C}$ is a collection
of \index{category theory!object} \textbf{objects}\footnote{The \textsf{``}objects\textsf{''} in category theory are \emph{not} related to \textsf{``}object-oriented
programming\textsf{''}.\index{object-oriented programming}} $\left\{ A,B,...\right\} $ and a collection of morphisms $\left\{ f_{1},f_{2},...\right\} $,
where each morphism is labeled by two objects $A,B$ as $f^{:A\leadsto B}$
(the objects $A$ and $B$ do not need to be different). For any object
$A$, the identity morphism $\text{id}_{\mathcal{C}}^{:A\leadsto A}$
must exist. For any two morphisms $f^{:A\leadsto B}$ and $g^{:B\leadsto C}$,
the composition $f\bef_{_{\mathcal{C}}}g$ must exist as a morphism
labeled $A\leadsto C$. Additionally, the identity and the associativity
laws must hold:
\[
f\bef_{_{\mathcal{C}}}\text{id}_{\mathcal{C}}=f=f\bef_{_{\mathcal{C}}}\text{id}_{\mathcal{C}}\quad,\quad\quad\big(f\bef_{_{\mathcal{C}}}g\big)\bef_{_{\mathcal{C}}}h=f\bef_{_{\mathcal{C}}}\big(g\bef_{_{\mathcal{C}}}h\big)\quad.
\]

The category laws clearly hold for the \textsf{``}plain\textsf{''} category whose
objects are types (\lstinline!String!, \lstinline!Option[Int]!,
etc.) and morphisms are functions available in the programming language.
The $F$-lifted category is a subset of the \textsf{``}plain\textsf{''} category where
we only allow types of the form $F^{A}$, so the category laws also
hold. Most applications of category theory to functional programming
will use categories whose objects are types (or, sometimes, type constructors),
and whose morphisms are functions of specific types, e.g., $A\rightarrow M^{B}$
or $F^{A}\rightarrow F^{B}$ as we have seen. However, the definition
of category is general and does not require that morphisms be functions
or that objects be types.

In functional programming, a \textsf{``}functor\textsf{''} is a type constructor $F$
with a lawful lifting of functions $A\rightarrow B$ to functions
$F^{A}\rightarrow F^{B}$. Category theory\index{category theory!functor|textit}
defines a functor more\index{functor!in category theory|textit} generally
\textemdash{} as a lawful lifting \emph{from one category to another}.
We will use the phrase \textsf{``}\textbf{categorical functor}\textsf{''} to distinguish
the notion of functor in category theory from the programmer\textsf{'}s notion
(a type constructor with \lstinline!map!\footnote{In category theory, programmer\textsf{'}s functors are called \textbf{endofunctors}\index{endofunctor}
\textemdash{} categorical functors from a category $\mathcal{C}$
to itself. The functional programming community says \textsf{``}functor\textsf{''}
instead of \textsf{``}endofunctor\textsf{''} because almost all categorical functors
used in programming are endofunctors.}).

\subsubsection{Definition \label{subsec:Definition--(categorical-functor)}\ref{subsec:Definition--(categorical-functor)}
(categorical functor)}

Given two categories ${\cal C}$ and ${\cal D}$, a functor $\mathcal{F}:{\cal C}\rightarrow{\cal D}$
is a mapping of each type $A$ in ${\cal C}$ to the corresponding
type $\mathcal{F}(A)$ in $\mathcal{D}$, as well as a mapping of
each morphism $f:A\leadsto_{_{\mathcal{C}}}B$ from $\mathcal{C}$
to a corresponding morphism $\mathcal{F}(f):\mathcal{F}(A)\leadsto_{_{\mathcal{D}}}\mathcal{F}(B)$
in \emph{$\mathcal{D}$. }Additionally, the laws of identity and composition
must hold according to the rules of each category. That is, identity
morphisms $\text{id}_{\mathcal{C}}$ from the category $\mathcal{C}$
must be mapped to those of the category $\mathcal{D}$; and the composition
($\bef_{\mathcal{C}}$) of any two morphisms in the category $\mathcal{C}$
must be mapped to the composition ($\bef_{\mathcal{D}}$) of morphisms
in the category $\mathcal{D}$.
\begin{align*}
{\color{greenunder}\text{identity law of categorical functor}:}\quad & \mathcal{F}(\text{id}_{\mathcal{C}}^{:A\leadsto_{_{\mathcal{C}}}A})=\text{id}_{\mathcal{D}}^{:\mathcal{F}(A)\leadsto_{_{\mathcal{D}}}\mathcal{F}(A)}\quad,\\
{\color{greenunder}\text{composition law of categorical functor}:}\quad & \mathcal{F}(f^{:A\leadsto_{_{\mathcal{C}}}B})\bef_{_{\mathcal{D}}}\mathcal{F}(g^{:B\leadsto_{_{\mathcal{C}}}C})=\mathcal{F}(f\bef_{_{\mathcal{C}}}g)\quad.
\end{align*}

To clarify this definition, consider two examples: a contrafunctor
$C$ and a filterable functor $F$.

\subsubsection{Example \label{subsec:Example-category-definition-of-contrafunctor}\ref{subsec:Example-category-definition-of-contrafunctor}}

A contrafunctor $C$ is specified via a lawful function $\text{cmap}:(B\rightarrow A)\rightarrow C^{A}\rightarrow C^{B}$.
To formulate this in category theory, we say that there must exist
a categorical functor from the reversed category to the $C$-lifted
category. To define that functor, we need to specify how types and
morphisms are mapped from the first category to the second. Each type
$A$ of the reversed category is mapped to the corresponding type
$C^{A}$ of the $C$-lifted category. Each $(A\leadsto B)$-morphism
$f^{:B\rightarrow A}$ of the reversed category is mapped to the morphism
$f^{\downarrow C}:C^{A}\rightarrow C^{B}$ of the $C$-lifted category. 

To formulate the laws of identity and composition for the (categorical)
functor, we look up the definitions of the identity morphisms and
the composition operation in each category:
\begin{align*}
{\color{greenunder}\text{for the reversed category}:}\quad & \text{id}^{:A\rightarrow A}\quad\text{and}\quad g\bef f\quad,\\
{\color{greenunder}\text{for the }C\text{-lifted category}:}\quad & \text{id}^{:C^{A}\rightarrow C^{A}}\quad\text{and}\quad f\bef g\quad.
\end{align*}
Now we require that the first category\textsf{'}s identity morphism is mapped
to the second category\textsf{'}s identity morphism, and that a composition
of any two morphisms (as defined in the first category) is mapped
to a composition as defined in the second category:
\begin{align*}
{\color{greenunder}\text{identity law}:}\quad & \big(\text{id}^{:A\rightarrow A}\big)^{\downarrow C}=\text{id}^{:C^{A}\rightarrow C^{A}}\quad,\\
{\color{greenunder}\text{composition law}:}\quad & (g\bef f)^{\downarrow C}=f^{\downarrow C}\bef g^{\downarrow C}\quad.
\end{align*}
We derived these laws previously as the laws of contrafunctors.

\subsubsection{Example \label{subsec:Example-category-definition-of-filterable-functor}\ref{subsec:Example-category-definition-of-filterable-functor}}

A filterable functor $F$ is specified via a lawful function $\text{liftOpt}_{F}:(A\rightarrow\text{Opt}^{B})\rightarrow F^{A}\rightarrow F^{B}$.
To formulate the categorical definition for this situation, we say
that there must exist a functor from the $\text{Opt}$-Kleisli category
to the $F$-lifted category.

To define that (categorical) functor, we need to specify how types
and morphisms are mapped from the first category to the second. Each
type $A$ of the $\text{Opt}$-Kleisli category is mapped to the corresponding
type $F^{A}$ of the $F$-lifted category. Each $(A\leadsto B)$-morphism
$f^{:A\rightarrow\bbnum 1+B}$ of the $\text{Opt}$-Kleisli category
is mapped to the morphism $\text{liftOpt}_{F}(f):F^{A}\rightarrow F^{B}$
of the $F$-lifted category.

Write the laws of identity and composition for that categorical functor
using the definitions of the identity morphisms and the composition
operation in each category:
\begin{align*}
{\color{greenunder}\text{for the Opt-Kleisli category}:}\quad & \text{pu}_{\text{Opt}}^{:A\rightarrow\bbnum 1+A}\quad\text{and}\quad f\diamond_{_{\text{Opt}}}g\quad,\\
{\color{greenunder}\text{for the }F\text{-lifted category}:}\quad & \text{id}^{:F^{A}\rightarrow F^{A}}\quad\text{and}\quad f\bef g\quad.
\end{align*}
The functor laws require that the first category\textsf{'}s identity morphism
is mapped to the second category\textsf{'}s identity morphism, and that a composition
of any two morphisms (as defined in the first category) is mapped
to a composition as defined in the second category:
\begin{align*}
{\color{greenunder}\text{identity law}:}\quad & \text{liftOpt}_{F}\big(\text{pu}_{\text{Opt}}\big)=\text{id}^{:F^{A}\rightarrow F^{A}}\quad,\\
{\color{greenunder}\text{composition law}:}\quad & \text{liftOpt}_{F}(f\diamond_{_{\text{Opt}}}g)=\text{liftOpt}_{F}(f)\bef\text{liftOpt}_{F}(g)\quad.
\end{align*}
We derived these laws previously as the laws of \lstinline!liftOpt!.
$\square$

In both examples, the laws of the suitably defined categorical functors
turned out to be equivalent to the typeclass laws we derived previously.
This gives us assurance that we have correctly guessed the relevant
laws. The choice of typeclass laws is not self-evident. For example,
Section~\ref{subsec:Motivation-for-and-derivation-of-laws-of-filtering}
derived the four laws of the \lstinline!filter! function from heuristic
ideas. The laws of \lstinline!filter! have been formulated differently
by different people, also starting from heuristic considerations.\footnote{See \texttt{\href{https://github.com/fantasyland/fantasy-land\#filterable}{https://github.com/fantasyland/fantasy-land\#filterable}}
where \lstinline!filter! has an additional \textsf{``}empty-value\textsf{''} law.} It is not obvious whether we correctly guessed the relevant laws
of \lstinline!filter! and did not assume more laws than necessary.
In contrast, the two laws of the categorical functor are general and
appear time and again in different areas of mathematics. This gives
us confidence that those laws are correctly chosen and will be useful
in a wide range of contexts. Proving that the four laws of \lstinline!filter!
from Section~\ref{subsec:Motivation-for-and-derivation-of-laws-of-filtering}
are equivalent to the two laws of a categorical functor gives assurance
that our choice of filtering laws is mathematically consistent and
is likely to prove useful in applications.

Having looked at the laws of \lstinline!liftOpt!, we noticed that
we can reduce the number of different proofs if we generalize the
$\text{Opt}$-Kleisli category to an $M$-Kleisli category\index{Kleisli!category}
with a suitable functor $M$. It turns out that one can prove general
theorems about products, co-products, and composition of (categorical)
functors that map between any categories. In this way, we can replace
four theorems (say, for the product of functors, contrafunctors, filterable
functors, and filterable contrafunctors) by a single but more abstract
theorem about the product of (categorical) functors being a functor
between suitably defined categories. We will not look at those proofs
here; Chapters~\ref{chap:Functors,-contrafunctors,-and}\textendash \ref{chap:Filterable-functors}
already worked through a few almost identical proofs that show the
required techniques.

The categorical view also shows us some directions for developing
the theory further, hoping to find useful applications. We have found
a useful operation (Kleisli composition) and the properties it must
satisfy (the identity and the associativity laws). The \lstinline!Option!
functor obeys those properties, and so we may want to look for other
functors $M$ that also have these properties. (Those functors are
called \textsf{``}monads\textsf{''}.) Having found a new monad $M$, we can then look
for \textsf{``}$M$-filterable\textsf{''} functors\index{$M$-filterable functor}
or contrafunctors $F$ that admit an operation $\text{lift}_{M,F}$
similar to $\text{liftOpt}_{F}$ but adapted to the monad $M$ instead
of \lstinline!Option!. We will see some examples of $M$-filterable
contrafunctors\index{$M$-filterable contrafunctor} later in this
book.

\medskip{}

To summarize, using the category theory\textsf{'}s notion of functor brings
the following advantages:
\begin{itemize}
\item We are assured that we have found a correct set of laws of a typeclass.
We can derive the formulation of those laws without guessing, by starting
from the standard laws of categories and functors.
\item We may find some promising directions for obtaining more general type
constructions.
\item Several proofs may be replaced by a single proof for properties of
some (categorical) functors.
\item We may find general constructions (e.g., functor product) that work
in the same way for many different typeclasses.
\end{itemize}
We see that category theory is a useful tool for reasoning about abstract
constructions that work with different typeclasses (functor, contrafunctor,
filterable, etc.). Category theory views many typeclasses in a similar
way and gives a systematic guidance for deriving the typeclass laws.

\medskip{}

What does category theory (CT) \emph{not} do for functional programming\index{category theory!in functional programming}?
\begin{itemize}
\item CT defines many abstract constructions but does not say which of these
constructions will have useful applications in practical programming.
\item For verifying specific laws (e.g., the laws of the \lstinline!Filterable!
typeclass for the \lstinline!takeWhile! function), CT gives neither
proofs nor proof techniques that programmers could use.
\item CT does not help determine whether a given type constructor (say,
\lstinline!type F[A] = Option[(A, A)]!) belongs to a specific typeclass
(e.g., a filterable functor, a pointed functor, or a monad).
\item Even if we know that, say, a lawful \lstinline!Filterable! instance
actually exists for the type constructor \lstinline!F[A] = Option[(A, A)]!,
CT does not help in writing correct code for that typeclass instance.
\item CT does not say whether there exists a natural transformation between
two given type constructors, or how to implement one if it exists
and how to verify the suitable naturality laws.
\end{itemize}
Performing those tasks requires certain symbolic derivation techniques
adapted to \emph{applied} (that is, practically relevant) functional
programming. Developing such techniques and selecting the necessary
theoretical material is one of the main themes of this book.

\begin{comment}
Chapter six of the functional programming tutorial it is about computations
in the filterable factor consider this example this is a mathematical
computation how would we express this computation in functional program
we can write this Scala code now let us look a little bit more carefully
about what this computation is doing for all integer X such that X
is between 0 and 100 we select those that have positive value of cosine
X and then we compute square root of cosine X and sum over all those
so we sum over only those that have cosine X greater than 0 those
eggs and then if cosine X Radian is greater than 0 it is safe to compute
the square root of cosine X so we compute that and we add together
all those values of the square root of cosine X so in the Scala code
this is represented by in this program because we take the sequence
from zero to hundred we map with a cosine function we filter with
the condition that the argument is greater than zero after the filter
only those elements which are already transformed to the cosine values
are left then it is safe to take the square root of those cosine values
and add them up so this would be approximately the result now Scala
has a different syntax for computations like this where you have a
chain of map filter map and so on the syntax uses the key words for
and the yield so it is sometimes called a for yield syntax I prefer
to call it a Thunder block because this does not work unless you have
some functor type around and you're using this only for computations
in the factory type other names for the syntax are for comprehension
now this comes from Python I believe and it does not add to my comprehension
of what this code is doing so I will not call it a for comprehension
I will call it a functor block because it\textsf{'}s a block of code for something
yield something and it has to be handled as a single expression so
if I want to do anything with this expression I have to put it in
parenthesis like this so it\textsf{'}s a block that is except is an expression
it yields a value so how does it work we can compare it side-by-side
with the code of this program written a little bit more verbally where
I wrote out all the arguments with names so here I say for example
cosine of underscore and this is a Scala syntax for a function like
this X goes to cosine of X so Scala allows you to have this function
shorter just say cosine of underscore but let\textsf{'}s write it out with
names of variables and it will be map of X going to math dot cosine
X then filter Y is going to wine greater than zero the map y is going
to square root of y and then some the for yield syntax describes exactly
the same computation and we can come compare line by line how the
syntax is changing the for yield syntax is automatically transformed
by the compiler into the form on the right so this is just syntax
there is no special keyword or function that is called yield there\textsf{'}s
a keyword yield what healed itself is not a function it has syntax
keyword so all of this is removed by the compiler and replaced by
the code on the right the first line is equivalent to saying that
whatever follows will have the value X going from 1 0 to 100 the first
line in the for yield block must be this line with the left pointing
arrow to the right of the left pointing arrow there must be a functor
a functor value so this value is a sequence from zero to hundred and
as we know sequences are factors to the left of the arrow is a variable
or more generally a pattern with pattern variables in these examples
we will only use simple variables to the left of the arrow but it
can be a pattern match so the first line says take X to be any value
in this sequence the second line says compute cosine of this value
call it Y exactly similar to this is that we compute the cosine of
X and in the next whatever comes filter or mat or whatever we call
that why we're free to call that X here in fact aren't we it\textsf{'}s a different
scope it would be confusing however if we wrote X here X equals math
dot cosine of X we can though it will be valid it will be just confusing
so let\textsf{'}s not do it but it would be exactly the same code if we renamed
Y to X in what follows in this block just because it\textsf{'}s translated
into this kind of code and there we are free to call this variable
by any name we want we can call it X Y or whatever the next line here
says if y greater than zero now if is a keyword and this is an expression
that should evaluate two boolean just like here this is an expression
that should evaluate two boolean and this is under filter the last
line is yield and after yield there can be some expression this expression
is what comes here after we do the last map so actually yield is just
as part of a block as as all this stuff it is not different we could
put this computation inside the block for example we could have said
Z equals a little Y and then say yield Z instead of this it will be
exactly the same computation this would be here the last map after
that we do the sum the sum cannot be done inside the filter block
because it takes us out of the factor context as I say some transforms
a functor value or sequence in the same in this case into a single
number so every line in the functor block after the first line will
be repeated for every X that belongs to this sequence however if some
Y in in this computation isn't is non positive we will not compute
the square root of Y so this value will be emitted from this resulting
sequence just like it is here because it\textsf{'}s the same code that\textsf{'}s just
written in a different syntax after we filter only values that pass
the condition are left in the sequence so the same logic is a little
more visual in the functor block syntax that anything after the if
only is executed or is computed when it passes the condition so to
summarize the block as a syntax for manipulating data within a container
where this container in this case this was a sequence of integers
it could be any container which is a functor which is any type constructor
that has a map function such that the function laws hold as a result
of computations in a functor block we manipulate data inside the factor
or the container however the data changes it will still still remain
within the same container so the value of this expression is a sequence
it can be a sequence of double numbers level precision floating point
numbers as a in this example so it changes type the data items inside
the container can change their type of course the container does not
change it is still a sequence we cannot change the type of the container
in the functor block it must be within the same container so in Chapter
four we have started with the container semantics looking at the map
function and generalized from it to obtain the Kansai the concepts
of a functor we will do the same in this tutorial to generalize the
filter we will find what laws the filter must satisfy and what kind
of containers will be such that you can define a filter method now
more precisely in Scala there is a method called with filter if your
functor has a method called with filter then you can use this function
in a functor block with an if keyword otherwise it will fail to compile
so we will call a functor filterable if it has a method called with
filter that satisfies the appropriate laws that we will investigate
later in this tutorial however for convenience many factors also define
the filter method it is shorter to write it might be implemented differently
for performance reasons in this tutorial we will not distinguish between
filter and West filter we will consider them to be the same function
their types are exactly the same and they are isomorphic in the sense
that they yield maybe different implementations but these implementations
are completely equivalent this is the type signature of the function
with filter that needs to be implemented in order for us to be able
to use the if syntax in a functor block with the factory F Scala syntax
will be available no matter how you define this method with filter
it must be that you are able to write F dot with filter it can be
done using an implicit conversion typeclass or just defining a method
West filter on your on your data type that does not matter you can
use it in the functor block after that so the main questions that
remains for this tutorial is what are the required laws that captured
the intuition we have for these computations and once we found those
laws what are the possible data types that are filterable the main
intuition is that the filter call the function filter when you call
it with some non-trivial condition may decrease the number of data
items that a container holds it may not decrease it but it may also
decrease the container therefore must be able to hold fewer or more
data items it must be able to hold in some sense a different number
of data items of course still of the same type t so here\textsf{'}s an example
that we are familiar with which is option the option type is written
in the type in the short type notation as 1 plus T and here are some
computations that we can do with an option using filter if an option
is empty then whatever you filter it or whatever it still returns
empty so that\textsf{'}s not very interesting but you see if this number passes
the condition and the number remains but if it does not pass the condition
the option becomes empty also you can use width filter on an option
that actually returns a different type not option but that type is
isomorphic to option so it still has all the same methods as the option
has it has map it also has filter and with filter and so on so it\textsf{'}s
isomorphic and it can be used if you wish but as I said in this tutorial
it will be not important for us how this is implemented and what types
are behind this operation in the standard library a standard library
makes its choices which may change with time what\textsf{'}s important is that
the results of filtering can can be an empty option if the number
inside the option does not pass the condition a second example familiar
to us is lists so a list type can be visualized as this short notation
so this is a disjunction of unit a single data item of type T two
data items three data items and so on and if you apply filter to the
list then only those elements that pass the condition remain in the
list how does it work so for instance a list 10 20 30 is a disjunction
of three elements which is this part of the disjunction after the
filter only two elements remain twenty and thirty so after the filter
we are in this part of the disjunction in the second example after
the filter we go from this part of the disjunction to this one the
empty list so what do we learn by looking at these examples it looks
like the data type must be a disjunction of some sort or must contain
a disjunction may be somewhere in this disjunction must have a different
number of data items of type T so that when some data items do not
pass the condition we take data from one part of the disjunction and
put it into another part of the disjunction so for example here we
had ten twenty thirty now this one did not pass the condition we still
had these two so we put them into these two data items in this part
of the disjunction so the data goes from one part of the disjunction
to another as necessary according to whether the predicate P returns
which is this this predicate P the function from a to Gulen or from
in this case will be from T to boolean whether this predicate returns
false on some T values of or true on the on the values that you actually
have in your in your function another curious thing here we can notice
is that when some data item does not pass the condition like this
one in this example we we can see what\textsf{'}s happening as if we replace
this T with a unit with one unit type and the result would be 1 times
T times T which is exactly is isomorphic to T times T so 1 times T
times T is this part of the disjunction actually so this is a curious
phenomenon that we noticed at the type level that certain items are
replaced by a unit type and then the resulting type like this for
example would be T times 1 times T it\textsf{'}s equivalent to T times T and
that\textsf{'}s another part of the disjunction so we can accommodate replacing
some items T by unit type that does not break the type it still remains
within the same disjunction we will use this intuition later in second
part of this tutorial and finally we notice that the container can
actually become empty so all of these examples contain a disjunction
part which is unit which represents an empty container now of course
there are names for this in Scala so this is not the unit itself in
this case it\textsf{'}s a case object called none in this case it\textsf{'}s a case
object called nil I believe but that\textsf{'}s just syntax this is a name
for a unit type so Scala can have any number of named unit types the
unit is the standard one but you can define any number of your own
of course so these are these intuitions we we gather from these examples
we would like to generalize this realize we need more examples so
let\textsf{'}s consider a business application where we have the following
logic an order can be placed on Tuesday and or on Friday and under
certain conditions an order is approved so separately on Tuesday and
on Friday the order is considered for approval now this logic of approving
or not approving is a function such as amount less than thousand or
any other requirements we would like to abstract away the logic of
approval from the logic of which orders are approved and that logic
is the one that the filter function represents so therefore we will
also abstract the type of order to a type parameter so we will consider
a class or data type orders with type parameter a and it has two parts
as a conjunction one is an option of a another is also an option away
you're presenting that we can place an order on Tuesday or not and
we can also place an order on Friday or not and then we define a filter
function on this case class by simply calling the filter function
on each option now this filter function option does what we just saw
it does these things so that\textsf{'}s going to represent exactly what we
want when T is given some kind of approval condition we can apply
this condition to the order placed on Tuesday if any order was placed
on Tuesday and also we will apply it to an order placed on Friday
if any the result of this definition is like this so suppose we placed
an order for 500 on Tuesday and for 2,000 on Friday but approval happens
only when it\textsf{'}s less than a thousand so then the Friday order will
not be approved and the Tuesday order will be approved so the result
will be this data so would have we achieved well we separated the
logical which orders will be approved from the order of from the logic
of how orders are approved and also from the specific data type that
represents orders so this code only represents the logic of how orders
will be removed from our container and that\textsf{'}s what filter represents
let\textsf{'}s look at example code so this is this code I have written here
orders 1 because we will have some variations on it shortly and here
are some typical examples so if we filter with this condition then
only this one survives now of course if no order was placed and it\textsf{'}s
still empty on Friday so condition is such that every order passes
then both of the orders remain in the container and finally when now
none of the orders pass the filter then a container becomes empty
so we see that orders one is a container that can can represent empty
or non empty sets of orders and that\textsf{'}s the logic we want now in the
short notation this functors type is written like this it\textsf{'}s just a
product of two option values and option is one plus a so it\textsf{'}s one
plus a times one plus a as in the other examples we see that the a
is replaced by one or by the nun named unit when the value here does
not pass the filter in this case filtering is applied independently
to both parts of the product but we could consider other options for
example both orders must be approved or else no orders can be placed
at all that could be a business requirement another business requirement
that one could come up with is that if at least one of the orders
is approved then both orders can be placed so let\textsf{'}s see how that works
in code if we implement the rule a it means that both orders orders
must be approved for them to be placed now if there\textsf{'}s one order then
this rule does not modify our previous behavior if there is only one
order placed then we still apply a filter to it as as before but if
there are two orders placed and then both of them must be approved
so let\textsf{'}s see how this logic can be implemented so first we find what
will be the ordinary filtering procedure so the Tuesday orders after
filtering is this new to use them and new Friday now the order the
the ordinary filtering procedure would be applicable if both of them
passed the test passed the predicate now this condition expresses
that either the Tuesday is empty and for the empty option for all
is always true well this is a mathematical convention that empty for
all is true if this is not empty then predicate must hold for the
value of the option so this condition therefore will be true either
if both orders are present and pass the test or if one of the orders
are both are empty and if not empty they pass the test so only in
this situation we return something that could be non empty and that
in other cases we return empty container so this expresses the business
rule a so for example if we have 500 and 2000 and the filter is less
than 1000 and one of them passes and the other one does not pass and
then we return empty container so this is the new business requirement
in all other cases we do exactly as before so for example here one
of them passes the other didn't was not placed so that\textsf{'}s fine all
of the orders that were placed pass that\textsf{'}s the business rule and that\textsf{'}s
the result then and finally when both pass then we return both non-empty
so this is the new rule now the second business rule that we could
consider in the business rule B is that both orders are approved if
at least one of them is approved so both orders can be placed if at
least one of them is approved so this is expressed by this condition
exists on an option means that the option is not empty and its contents
pass the test so P is a predicate exists on an option is this means
that other exists a value inside the option and such that P on that
value returns true so if at least one of them exists in other words
is placed on order that was approved then we return this which is
the the value of the container unmodified so we do not actually filter
so even if some of them did not pass the filter so the first one did
not pass the filter here\textsf{'}s an example first one passed the second
one did not pass the children but the result is still that we returned
both orders so both orders can be placed if at least one of them was
approved that\textsf{'}s the new business rule now if one of the orders was
empty still we applied the filter to the other one if both orders
pass we'll return both others if none of the orders passed were returned
empty container so in this way we have implemented these business
requirements but now I would like to ask well I can come up with any
number of other requirements of this kind which of them actually make
sense in terms of filtering and this cannot be answered without some
mathematical principles or laws that allow us to decide whether a
certain function satisfies the laws and therefore it makes sense to
be used as a filter otherwise we're just going to argue opinions and
that is not productive so what are these mathematical laws in order
to arrive at them we need some more intuition and now we can generalize
from examples we have seen the main intuition here is that computations
in the funds our block should be reasonable they should make sense
in other words here is a thunder block program this program should
make sense you should look at it and reason about it in a way that
is intuitively correct mathematically reasonable so let us now think
about it and decide and derive what these mathematical requirements
must be so here\textsf{'}s a kind of schematic example of a functor block program
the first line must be the line with a left arrow which let\textsf{'}s say
has some functor on the right hand side let\textsf{'}s say list so then the
entire block will be computations as we say lifted into the list functor
or computation in the context of the list function which means that
we have some data here when we're going to manipulate this data and
the results are going to stay as a list container now let me go back
a little bit and remind you that this is not modifying the container
in place in any way these are mathematical computations are not modifications
of anything these are values so from the point of view of the program
this was one container and the result of this expression will be another
container while this original container is left unmodified so this
is just a mathematical kind of computation which no way to look at
the mathematical equation like this we don't say oh was this X modified
was this X modified when we did the cosine X was this X replaced by
cosine X and then we know it wasn't mathematically we never talked
we never do this replacing value values our values we cannot replace
y 100 by anything makes no sense and so let\textsf{'}s not replace anything
we just compute values so similarly here we just compute new values
every time now imagine we have some kind of program like this we compute
some functions we filter on some conditions we again compute some
more functions again filter and some more conditions and finally we
get some function of all these depending on all these values we computed
and all these values computed here will be put into the final list
and all the values that did not pass any of these tests will not be
put into the final list so what do we expect to be true intuitively
true about such programs for one thing for example here we have a
condition depending on Y but Y is defined as f of X so if we put this
f of X here instead of why we should be computing the same thing it\textsf{'}s
the same condition x goes over all elements in this list and Y is
computed and then we check some condition we should be able to get
the same result if we check this condition directly on f of X instead
of Y and we should be able to do it first so the order should not
matter them once we so once we write if p1 of f of X on this line
instead of this and we write this on the next line instead of that\textsf{'}s
the way interchange these lines and replace Y by f of X it should
be exactly the same thing because these are values that we computed
and these are conditions we we evaluate if that were not true if somehow
Scala compiled this to a different code it will be highly confusing
you would not be able to simplify your program by substituting values
into other places see it looks like Y is equal to f of X but then
somehow you cannot substitute f of X here that will be highly confusing
or you cannot first compute f of X in the condition and maybe you
don't need Y then maybe the older rest doesn't really need Y you can
simplify your program so you want to be able to do that to reason
about your program like this here is my value let\textsf{'}s substitute it
in here instead maybe the program becomes simpler now it means we
have this requirement for any program that has this kind of code must
be equivalent to any program that that that has this kind of code
notice the semicolons I put them here because Scala also allows you
that syntax you can put this entire functor block on one line if you
wish and separate the lines with semicolons but this might be harder
to read it\textsf{'}s up to up to you how to write the code with one line or
with many lines the next requirement is found if we look at these
two conditions intuitively first we check a 1 and we only pass those
values that satisfy that first condition and we check the second condition
only from those that pass the first condition we additionally take
only those that pass the second condition so that should be equivalent
to check in just one condition that is the conjunction of these two
conditions that gives us the second requirement the third requirement
is somewhat trivial if a predicate always returns true for all values
of X for instance if this p1 were just identically true then we should
remove we should be able to remove this check from the program because
that should not affect at all what\textsf{'}s happening if we remove it all
the values will always pass to the next line and so that\textsf{'}s the same
as if this check wasn't there so that\textsf{'}s our requirement 3 another
final requirement quite important in fact is that remember what we
had in our initial computation that the filter was for positive Y
and then we took the square root of Y now if some Y were negative
we shouldn't be doing square root of it so in other words we rely
on the fact that only values that pass the filter will ever be used
in further calculations after this if line just like we rely on this
here with after the filter we relied on the fact that data that the
node passed the filter will be emitted from any further calculation
and so we formulate that as a requirement that when whenever a filter
predicate P of X returns false for some value of X then that value
of x will not be included in any computations performed after that
line so that is our final condition so these are the four properties
that functor block programs must satisfy let us now formulate these
properties mathematically in fact it is very important that we can
formulate these laws mathematically we it\textsf{'}s not just talking about
the program you know what you could change in the program without
changing its result it\textsf{'}s not just words we can actually write equations
and check them to see that these conditions hold how do we do that
for instance we write the first law like this we say whenever there
is a function f and the filter condition P such as here the function
f and the filter condition P then we look at how this part of the
founder block program will be translated by skeleton pilot into the
map and filter so this will be map F filter P and this will be filtered
P of F map F in other words this will be compositions of the functions
map F here is AF map because that\textsf{'}s the right well type the flip map
its argument is f so map F composed with filter P must be equal to
filter of F composed with P which is this remind you that function
composition works from left to right when you when you write it with
this symbol F composed P but if you want to write specifically as
code you must put the functions in the opposite order P of F because
first YouTube f of X and then he applied P to the result and so that\textsf{'}s
first you took F and then the applied P and Scala there is an operation
called and then on functions which does exactly this in Scala this
code would be F and then P which is a nice and visual way of writing
function composition notice here I did not write it here because this
is actually going to be code but I could have written elsewhere and
I will be writing this in the in the example code I'll be using and
then so in other words the factor block program that has first a map
step and then a filter step is equivalent to the factor block program
that first has a filter step with this different condition as it is
necessary as we were thinking here and then it has the map step now
what does it mean to have one step of a functor block program remember
how the functor block program is translated into maps and filters
each line actually consists is replaced by a step so a function map
or fill map with a function filter with a function and so on so instead
of saying the functor block program remains the same when we do this
and that with the line we say the map with this function would do
the same with the functor value as a map with another function x filter
with another function and so on so we actually say instead of saying
the Thunderer block program remains the same when we change the number
of lines or something we say the functor value itself the value of
the sequence or the value of some other factor the factor value itself
is transformed in the same way by a certain map and filter operation
and that\textsf{'}s what it is so f map f is a function that transforms the
frontier value into another frontier value the filter p is a function
that transforms a function value into another function value and so
this law says that function values are transformed in the same way
any function value whatever you want will be transformed in the same
way by these two functions composed and also by these two functions
composed if this is so then you can replace here this map filter with
that filter map and for any functor value here and this could be actually
a long funter program before that so this could be instead of just
a simple sequence this could be sequence does map that map does filter
those children map all inside this expression regardless of this the
transformation by these two functions will be the same as the transformation
by these two functions so it is in this way that we can stop talking
about just replacing lines in code and start talking about mathematical
functions and their equality that has a great advantage because first
of all functions have types we can check the types are correct we
can reason about functions with types much better second functions
have values that we can check to be equal for all values of the argument
this is what we have done before with the functor laws and we will
do the same now with a filter laws so this was the first law the second
law represents this condition the conjunction law by the way laws
have names for convenience but actually there are just equations so
the first law is called natural ality this comes from category theory
and it\textsf{'}s not important why it is called natural 'ti but basically
whatever law you have that interchanges your interesting function
with f map or map that\textsf{'}s naturally G so typically that means you can
map the contents of your container before your operation or you can
map it after your operation and it\textsf{'}s equivalent in some way so that\textsf{'}s
naturally naturality expresses the idea that you're manipulating data
inside the factor in some way or inside a container and this manipulation
preserves the data items it does not look into their details so when
you map the data items from one type to another then your manipulation
would be equivalent to some similar manipulation followed by the transformation
of the data items so for instance if the manipulation is to omit some
elements and you can omit them before transformation or you can rip
them sorry this is will be after you can read them before the transformation
or you can omit them after the transformation if the condition is
adjusted appropriately the result will be the same or this could be
a transformation that somehow rearranges the order of elements or
does some other such thing that does not actually look into the elements
values themselves but just rearranges something about them it can
emit them which can duplicate them and so on so all these transformations
are called natural and so therefore this law of natural T is called
let\textsf{'}s look at the second law now the second law represents this requirement
that if we have two conditions next to each other then we can replace
them by a single condition that is the conjunction of these two mathematically
we can say that the filter transformation so think about filter P
as a single symbol just like F map F is a single value that transforms
the functor values FA to FB so filter filter P transforms FA 2 FA
so this is a transformation of theta FA composed with another transformation
of FA 2 FA and they must be equivalent to a filter transformation
again FA 2 FA when the predicate is equal to the conjunction of these
two predicates so I have written down the mathematical conjunction
but of course in Scala code there will be just the double ampersand
boolean conjunction so that\textsf{'}s the second law the third law is that
if the condition is identically true it returns true for all X then
the transformation that the filter on the functor is identity does
not change the function value at all and if this is so then whenever
you have a filter with identity function you know that whatever was
before is going to be identically preserved by that kind of filter
so you can just you delete that operation and that would correspond
here to deleting this line if this were an identically true condition
so in this way you see how mathematical laws actually represent a
general way of manipulating code and the fourth law is a little more
complicated to formulate so filter P and followed by some map that\textsf{'}s
we're trying to describe what it means that X will be excluded from
computations performed after this if so we need to put some computation
after this if let\textsf{'}s call it let\textsf{'}s say this is a computation that is
transforming by F it could be a filter right so we have a filter or
F map as possible computations but we already have a law for what
happens when we have a filter followed by a filter so now we have
a law about what happens when we have a filter followed by F map so
this computation F should not see any values X for which PA will return
false how do we express that but F should not see those memories a
good way to express that is to use a partial function instead of F
I denoted it like this so F barque is a partial function that is only
defined for those X for which the condition P holds in Scala this
could be written like this it\textsf{'}s a case expression with the condition
and if the condition is true we just return f of X so we don't change
the function f but now if the condition is not true this partial function
fails it will it will be a runtime exception if we apply this partial
function to value X for which P of X does not hold so the filter guarantees
however that all further computations will never see such X for which
P of X does not hold and so therefore it should be safe for us to
use that partial function here after the filter so the filter transforms
FA to FA look at this type signature again filter P so we put the
first argument and the result is a function from a fatal funny so
filter will transform a fading in such a way that the values that
are left in it will always pass the condition P and so it is safe
to apply a partial function not only it is safe but it will give the
same result because the partial function is made out of the function
f unmodified so therefore we have this law that filter followed by
MANET should be the same as filter followed by a partial function
map and it should be safe and it should give the same result so that
is well because it is safe mathematically we don't know how to express
that we just say it needs to give the same result if it always gives
the same result for any functor values that you put into this transformation
then you are safe so here are the four laws and we can define a typeclass
let\textsf{'}s call it filterable and the typeclass will have a method with
filter which will be a partial type 2 value function and this function
must satisfy these laws together with F map so we cannot really define
filterable without also defining map for this type so this partial
type 2 value function must be defined in such a way that it requires
already the functor typeclass as a constraint so it is only defined
for types 4 for type constructors that are functors and so then for
those we already have F map with the correct laws so those are necessary
for filter so filter is a further property of a functor so we can
say it\textsf{'}s a filterable functor so let us see if the laws hold for the
functor example that we have the orders but with Tuesday and Friday
we will also look at some examples of the filter block program notation
so before we return to the orders example let\textsf{'}s refresh the filter
block notation so here are some examples we take integers from 1 to
10 we perform some calculation with them so there\textsf{'}s this Y will be
I computed for each of these axes then we impose the condition that
y is negative and only for those Y\textsf{'}s we continue so then Z is computed
then we impose another condition of Z and then we can get something
else but actually we don't use this P and that\textsf{'}s fine and then we
return a tuple we don't actually return a tuple we return a sequence
of these tuples the yield is not the final result of this entire factor
block the yield is the result of a single computation for a single
data item inside the factor or if you wish the container of data so
now I'm showing some transformations that you can make so for instance
here instead of saying if Z is less than 100 on line 86 I'm saying
on line 96 if this entire expression is less than 100 and then I compute
Z later and that gives the same result and also instead of doing P
equals Z minus X which I'm not actually using so I could actually
should actually delete this from the code I use P here and that\textsf{'}s
exactly the same so you can put more computations into the yield part
of the block or fewer computations you can put some of them here it\textsf{'}s
entirely equivalent and the only consideration here is readability
how easy it is to read the code and understand what it should do also
I can mathematically express this condition as a condition on Y is
that absolute value of y must be less than the square root of 100
minus six and together gives the same result so I can transform these
conditions in any way I want and the results are the same and finally
I merge these two conditions for y into one condition using the conjunction
law and again the results are the same so this is the test not very
far yet so this isn't this is the way that we expect the program to
behave we expect to be able to simplify the program in certain ways
so that for instance here we notice we compute this expression twice
let\textsf{'}s not do it let\textsf{'}s compute it here first as Z and then use it that\textsf{'}s
a typical transformation of a program that the programmer would do
so we see that the naturality law the first law of filter guarantees
that this program transformation is valid it does not change the result
what a surprise it would be if that were not true a programmer would
look for a button for a very long time and this is because reasoning
about the program has become broken if you break the laws of the filter
so it becomes impossible to reason about the program by looking at
the code we should avoid that at all costs breaking mathematical laws
is something that has real costs that has real consequences makes
our life much harder so now let\textsf{'}s see if these laws hold for the orders
example to do that we define the typeclass instance in the example
code I have defined typeclass called filterable with filter I have
not found a standard filterable typeclass in libraries either in the
cats or in the Scala z library so I defined my own it\textsf{'}s just a few
lines of code to do that {[}Music{]} we'll see how that is defined
it\textsf{'}s using an abstract class with an implicit function value which
means that you cannot create instances of this abstract class without
having a functor instance for your type constructor f so in this way
I enforce that filterable here must be already a factor and then it
has this method which is in the way I implemented the partial type
T value function so I define the partial type to type function and
a partial type to value function the other typeclass is just called
filterable not filter ball with filter and it does not define a function
with filter it defines a function called flatten so this we'll be
talking about in the second part of this tutorial so now we only look
at filter and it\textsf{'}s its properties in order to define typeclass instance
for orders so that we you find a partial type 2 type function extending
it to orders we need to define this and override the function with
filter and also we need to have a functor instance for orders until
we have that this wouldn't compile so we need to have the functor
instance well a functor instance for orders is the straightforward
thing orders is a simple conjunction type option times option so the
cats library has an extension that derives such functor instances
for case classes so I'm just going to use it very convenient very
little typing when it works we'll see cases when it doesn't work so
we first define a functor instance and then a filterable instance
so how do we define the federal instance we just override the function
with filter in the class and this is the exactly exactly the same
code as we had in our first example we filter the first option we
filter in the second option and notice that this is a standard library
function on options so this is not the function I am defining this
is not really recursive in any way this is a standard library function
already defined on option and very easy one to implement so then I
check the laws now I have implemented this law checking helper just
as I did with factors so let\textsf{'}s look at how it\textsf{'}s implemented so it
has a bunch of arbitrary values as at once and then for all these
values I will check the laws so the first law is that map followed
by filter is the same as filter followed by map the only thing is
that the filter needs to have a different function type so this is
a 2 B this is B 2 boolean and this is a to be B to boolean so this
entire thing is a tubulin so then it is filter of a and then a to
B so first you map filter than you filter map and that should have
equal values the conjunction law is that we do a filter not filter
and that\textsf{'}s the same as filter with this function the identity law
is that you do a filter with something that\textsf{'}s identically true and
that should be exactly the same as what you started with so in all
these examples I have an arbitrary value of the function and I check
that for an arbitrary value of the funder these transformations are
equivalent give the same values so for this I need to be able to compare
values of the factors so learn in this extra function compare for
equality of the funder this is very similar to what I did in the factor
that class they finalized the partial function law for which we savings
the filter P and then map F and then we do a filter P and then we
map using this partial function which is f except that it\textsf{'}s only defined
for those X for which P of X is true so here are the four laws naturality
sometimes called permit Rissa t but let\textsf{'}s avoid the mumbo-jumbo and
not reality is not mumbo-jumbo because it\textsf{'}s natural so conjunction
law identity law and partial function law so this test passes so the
laws hold for this order\textsf{'}s functor with this type cons instance now
notice in this test i define the functor instance outside the test
but the filter will instance inside so that i can define different
filterable instances in different tests and that\textsf{'}s what I will do
I will first vary for example 1 which is this straightforward filtering
here\textsf{'}s how it works so we can use it in the filter in the filter block
notation data is this orders of some orders of 500 and 2,000 so X
is compared with 1000 which is our approval criterion and then we
transform to a string and the result is the orders of transformed
and they're printed more nicely and this second order was not approved
so the first order was approved the second example is the orders with
business rule a and orders with business rule a is this more complicated
code that we saw before again we check the laws and notice we define
a different filterable instance and so this checking is with a different
instance and exactly the same function block code returns now empty
orders because for business rule a both orders need to be approved
for any of them to be placed and so exactly the same function block
code now gives a different result because we define the filterable
instance differently and interestingly the example 2 B does not work
that it breaks the function or sorry the filterable law it does not
break the function but still factor it breaks the filter rule law
and so this fails and actually there is specific data that shows it
to fail and also it fails a partial function law and so we will look
at it why why that happens for now let\textsf{'}s look at this well actually
that\textsf{'}s what\textsf{'}s finished with the orders why does the law break it\textsf{'}s
an interesting consideration so if we filter with one filter and then
it was another filter that should be equal to the filtering with a
conjunction now in this example I chose the two conditions so that
their conjunction always returns folks so we should be having an empty
container after this however in the data one of the orders is below
and one is above thousand and so the business rule to be says that
both orders can be placed if if at least one can be approved and so
then after the first filter both orders are still placed and I laughter
the second filter also both holders can be placed however if we filter
with the condition that no orders pass then we get an empty order
so that\textsf{'}s not the same and also breaks the partial function law we
filter with a condition and we use the function that is only defined
when that condition holds and we have an exception at runtime so what
happens here is that it\textsf{'}s counterintuitive we thought we would limit
computations to these eggs but actually we have not limited them to
that to the next mm is still there so reasoning about a program that
uses this filter implementation would break our intuition about what
the filter should do and that\textsf{'}s why this is not a good filterable
implementation so business rule to be is not filterable {[}Music{]}
so now consider the example of this factor it is a disjunction that
has either no data items or two data items so it\textsf{'}s a product or nothing
how can we implement it as a filterable so I call this a collapsible
product for reasons we'll we'll see momentarily well we first derive
a functor for it so the type isn't just an option of tuple a a which
is this type now how do we define filter for it well let\textsf{'}s write this
function so we have F a of type option to pull a a and we have a filter
function so now option to call a a has two cases in the disjunction
first as its non-empty with some values X and one now what can we
do we must apply the filter to both of them because if we don't go
fail some of the laws as we just saw with the business rule to be
example when we don't apply the filter to some of the values then
partial functions will fail and conjunctions may also feel so now
if we apply to X and we also applied to Y what if one of them passes
and the other does not what we can we have to exclude the one that
did not pass but our type has a disjunction that has only two parts
one must have two and the other is empty so if X passes and why does
not pass we cannot retain Y we could retain X if we had any way of
retaining X but we need a we need a two value so we cannot just put
X here we need another value we could put X twice I'm not sure that
would be a good idea though it doesn't feel right it probably will
violate some law if you do that it feels wrong but you duplicate values
it will be I have not checked it so you're welcome to check if the
laws hold with that implementation but the most reasonable implementation
is that if none of them if if only one of them passes we need to remove
both so we get the empty container so that\textsf{'}s how it\textsf{'}s implemented
so only if both x and y passes the test the container is unchanged
I just write FA just to save typing sum of X Y again and it\textsf{'}s faster
otherwise we return empty container so laws hold I checked the laws
with different types just to be sure now as a reminder this function
takes type parameters so that it cannot just check laws with all types
at once it\textsf{'}s impossible you have to give specific types on which you
would check the laws so transform from int to strain to something
that need to be specified so let\textsf{'}s look now at examples of functors
that are not filterable so we have seen that orders with business
you'll be or break laws it actually breaks law for as well now another
example of a function that is not filterable is a function that defines
filter in a special way for certain types for example for into type
it defines the filter function in one way and for all other types
in a different way so that is not natural the filter should not look
at types it should manipulate data without regard of its type so this
type a should be unknown type and should not check that it is integer
or something else so it actually breaks slower so let\textsf{'}s look at how
that works so here is this factor a zero which is just an option and
I'm going to define a filterable instance where I define a filter
not in the way that usual option is defined in the filter I will first
check if the type is integer if the type is integer then I'm going
to check the condition if the condition passes I do whatever what
was before I return the same value if the condition does not pass
then I return zero so this is actually zero so I especially prepared
this so if the type is integer and the filter fails I replace the
integer by zero that\textsf{'}s a special rule that\textsf{'}s only used for integer
for all other types i do the standard thing and filter on an option
in the standard way so this kind of thing is an incorrect implementation
of filter because it is not natural in the type it is using some information
about the type that is not parametric and what happens is that as
long as you don't try to use the integer type then you are in this
second case and it\textsf{'}s all right it\textsf{'}s it\textsf{'}s it\textsf{'}s correct but once you
start using the integer type then naturality law fails and if you
uncomment this test and run it it won't tell you that it failed in
the natural tool and here\textsf{'}s a counter example that breaks naturality
law we say this data is some zero subtract one and check that it is
greater than zero and another way is to check first that X minus 1
is greater than zero which is the same right y is equal to X minus
1 so I could put this X minus 1 in here which I did and put the condition
first and that should be the same it doesn't matter if I first check
the condition and then compute X minus 1 or if I first come to the
X minus 1 and then check the same condition but the results are not
the same so actually the first result is not equal to the second one
the second result is not empty the first result is empty so that is
a clear violation of the naturality law so this is this shows you
that we are trying to reason about the program and we refactored the
program in some way and the results changed this kind of bug would
be very hard to find you refactor your program and results change
example is this factor 1 plus a where the filter is defined so that
it always returns 1 plus 0 now 1 plus 0 is my short notation for this
part of the disjunction so it\textsf{'}s only the unit so 1 plus a is option
of a and 1 plus 0 would mean none so you always return none part of
the disjunction now if you do that here is our implementation so the
filter always returns none that breaks the identity law if filter
with true and it\textsf{'}s not the same because it always returns none so
if you did not have none to begin with you get none and that\textsf{'}s regardless
of what you filter so even if you filter with the true that\textsf{'}s still
none so that breaks like the identity oh yeah there were 3 so these
are so far wrong implementations of filter this is the notion type
as we know it has a good implementation of photo so now the last two
examples are functors that cannot have an implementation of filter
they are not filterable so let\textsf{'}s see how that works the first is the
identity function it\textsf{'}s not filterable identity factor needs to implement
filter but how can we implement filter well we get a value a and we
need to return let me let me just you bring then use two penny for
clarity we get the value of type a and we need to filter now if the
condition does not pass there is nothing for us to do except still
to return the same value so we cannot actually apply the filter there\textsf{'}s
nothing we could do if the filter were to return false there\textsf{'}s nothing
we can do we must return the value of type a and so we return the
identity so basically this is a filter that always returns identity
does not ever filter out anything and that breaks the partial function
law because it does not filter out anything and so we rely on filtering
out certain values and that expectation is broken so here\textsf{'}s an example
we have some data with a negative number we filter by positive we
take square roots and we expect that everything is fine but actually
the result is this not a number because square root of a negative
number is not a number and so our expectation is broken and the second
example is this factor is a product of a and 1 plus a now one plus
a is option a is the identity factor so it\textsf{'}s a product of two factors
one of them is not filter what we just saw the other is filterable
it turns out that the product is still not filterable so why is that
well a very similar reason we have a value of type T and the value
of type option T if this value does not pass the we need to remove
it somehow from the container but we can't the container always must
have a value here it\textsf{'}s a product so it requires both parts and so
it always must have a value of type T here we can not remove it so
let\textsf{'}s suppose this were some value and this were an empty option so
this one none the only way we could filter this is to retain this
value X and that\textsf{'}s the same problem as we had with the identity function
if we do not filter out values that don't pass the test when we violate
the partial function law so this is exactly the same test as before
we violate the partial function law so to summarize this these laws
one to four these are equation laws with in other words these are
equations for functions there are not just some kind of vague descriptions
of what we do with the code these are actually mathematical equations
for functions that can be proved to hold or not to hold and these
equations rigorously specify what it means to filter data in the container
so we have derived these four equations from our intuitions about
what a filter should do now we will only use these equations we will
not need to do any more intuitive reasoning we're now on solid ground
and we will derive there is functors filter ball or not filterable
in these worked examples in the first example john has up to three
coupons and Jill after two coupons all the John\textsf{'}s coupons must be
valid but each of jewels coupons is going to be checked independently
why is this even described by a functor we need to abstract the problem
from details and see how we can represent this as a functor and then
we will see what is the filterable factor first of all to represent
this as a factor we need to have a tight constructor so what is a
type parameter more clearly the type of coupons the factor is going
to be the container with all the coupons the type of the data that
coupons represent is going to be a parameter so we are going to abstract
away a specific type of the coupon data so then we have a container
that has two parts so it\textsf{'}s a conjunction one part is John\textsf{'}s coupons
and other part is juice coupons and the first part will be itself
a disjunction because it can have zero one two or three coupons the
second part zero one or two so once we reformulate the situation in
this way it is clear that it is represented by a factor and then the
conditions of coupon being valid is an arbitrary condition which is
a predicate a function from coupon type to believe and we are going
to filter our container using that condition and the result will be
a container having all valid coupons according to the logic defined
here so the first thing I would do is to write the type in a short
notation then I can have a bird\textsf{'}s-eye view of the data so the type
is a conjunction of two parts Jones coupons is a disjunction of unit
one coupon two coupons three coupons and each group one is represented
by a data item of type a joke just coupons is a disjunction of 0 coupons
one coupon and two coupons so now we can implement this in a standard
way using sealed trades and case closes so for convenience we first
implement the left part of the disjunction and the right part of the
disjunction ah sorry of the conjunction and so at the end we'll have
the functor coupons which is the conjunction of jones coupons and
jones coupons as before we need to define the factory instance so
we use automatic derivation for functor instance now it remains to
implement in a filterable so the logic is that first of all jones
coupons and jost coupons are validated independently so jones are
independent from Jules for John there is one kind of logic and for
Jo there\textsf{'}s another kind of logic so what is it for Jones well if there
is any number of coupons there could be none and then we don't have
to filter anything there is any number of coupons then all of them
must be valid by the filter condition and then we retain them otherwise
we discard them so logic is that if John has no coupons then we return
again in no coupon situation if there\textsf{'}s one coupon and the condition
is valid then the coupon is retained otherwise we return the empty
situation if there are two coupons then both must be valid and then
we retain both of them otherwise we return the empty situation again
similarly for three coupons so that\textsf{'}s the logic for John\textsf{'}s coupons
and for dos 2.0 logic has just examined each coupon separately so
there\textsf{'}s one we keep one if there are two we see which one returns
true so we use this matching on pair so we compute a pair of two boolean
values corresponding to whether the filter results are true or false
for c1 and c2 which are the two coupons of jill\textsf{'}s and then we match
at the same time on both values of the pair so that it makes the code
a little more clear and readable so we have just four situations and
way you turn one coupon or two coupons or zero coupons so finally
having computed the new filtered John\textsf{'}s coupons and filtered jos coupons
we put them into the coupons let\textsf{'}s class into the conjunction and
that\textsf{'}s our result so now here is some test data there are two coupons
each for John and Jill but the condition is that the value must be
above 150 and so for John one of them is below and so none of his
coupons are valid for Jill one of the coupons is valid and then this
Thunder block will transform the coupon value into a string and so
we see that John\textsf{'}s coupons are all gone they're not valid because
one of them is not valid but Jill\textsf{'}s coupons have been filtered differently
so the valid coupon is retained and there is a Jill one disjunction
part so that\textsf{'}s how we can implement the situation and this is indeed
a filterable factor which we can check automatically by a helper function
that checks the laws the second example is that we imagine that there
is the server that receives a sequence of requests and each request
must be authenticated now there\textsf{'}s a special logic that once an own
authenticated request is found the server accepts no further requests
how shall we describe this with a functor and how shall we make that
function filterable if possible so the server is representing a sequence
of requests so let\textsf{'}s first of all generalize the request type to R
so we have done a sequence of our as requests we make the functor
instance for the server and that doesn't seem to work with automatic
generation so we just do the met by hand this is not a lot of code
the server is just a sequence wrapped in a case class so we just need
to call me up on the sequence so how do we implement filterable so
we need to take requests one by one until we find a request that is
not not authenticated so we abstract the condition for being authenticated
as a predicate that goes from a to boolean and then we use the function
take while which is the standard library function defined on sequences
and this will take the initial part of the sequence until while the
predicate is true on the well on elements of the sequence until we
find an element that fails the predicate or until the sequence is
over so we compute that sequence and though so we have the resulting
instance testing this we do using this test data so let\textsf{'}s say the
condition for acceptance would be that the square of the number is
less than 1000 and so then only the first three numbers satisfy now
I could actually put a zero here and it still would just be the first
three because after this the take wire will stop taking illness once
one element was found to fail the condition and so this logic is now
encapsulated by this code you see in this code I do not mention this
logic that the server should take sequence and so on it looks like
I am just processing elements one by one for each X in the container
compute this and check this condition and then compute this so this
code describes what I compute and the logic about how elements are
retained or emitted from the container is encapsulated in the filterable
in instance that we defined over there and as usual we check the laws
of the filterable the other examples already start with a tight data
type in the first two examples I showed how you can stake a real world
situation and convert it into a factor with a filterable instance
so this should help us to learn to recognize such situations in real
life and make code so that the logic of filtering is separate from
the logic of checking data data for conditions well so the filter
by instance helps us separate such situations in three parts first
part is the data type privet which is completely freed data it\textsf{'}s a
type parameter so we can we will separate all knowledge about the
data type into a different part of the code second is the predicates
in which we filter so the specific logic for checking valid coupons
or authenticating requests so that\textsf{'}s a function from this data type
to boolean so again this is implemented in a different part of the
code and the third part into which we split the code is the filtering
logic which is which elements are retained and which elements are
emitted under what condition so the condition is already given but
then for instance for John all coupons must be must be valid for Jill
they're all independent and for the server the initial subsequence
must be all valid and so on so that logic is what the filter will
instance implements so by recognizing these situations and structuring
the code in this way we separate concerns and so in the following
examples we assume that the first two logical steps have been made
and we already have a data type and it only remains to see if that
data type is filterable and if so to implement the filterable instance
the first example is this case class which is written here so the
first step for me would be to write this in a short notation because
then I can see much more clearly how to implement anything with it
so the short notation would be this so there\textsf{'}s an option and conjunction
or product with an optional tuple so now I'm this type that I see
it\textsf{'}s a product so I can filter this because this is an option and
I can filter this because we just had this example this was the collapsing
product example I can filter both of them so most likely I can easily
filter the product by just filtering the two parts so let\textsf{'}s see how
that works by actually declaring separately the filter both instances
for the two parts of the product and then combining them so the first
type would be optionally in a second would be option of two point
a so that\textsf{'}s the first type the first the part of the conjunction and
the second part in the conjunction so they functor value needs a functor
instance needs to be defined so we use a giraffe for that and the
filter will instance needs three defines our we define these functions
in the usual way so that i just wrote out here the code which would
be exactly the same as a filter clean but just for clarity and to
illustrate what exactly is doing this is the code so the option is
standard filter instance for option f is non-empty we need to check
the condition for for the value that\textsf{'}s in it and if the condition
holds then we return the non-empty option as it was so unchanged in
all other cases either it was empty or it is not empty but the predicate
does not hold we return empty option the second factor is the option
of a tuple and here we did what we did before if both conditions are
valid we return unchanged otherwise return none so either we had an
empty option here or we had a non empty option but one of these conditions
failed so then we return empty ocean so now we have defined two filterable
instances for the two parts of the conjunction let\textsf{'}s now define the
total instance for {[}Music{]} the conjunction itself so as of this
class p that is defined here and all we need to do so again we derive
the function automatically all we need to do really is to take the
two parts of the conjunction and filter them separately now just to
note this detail of the syntax of dot filter is available because
of this typeclass so the first is of type F one of a so it\textsf{'}s some
kind of function second a subtype of two away it\textsf{'}s another kind of
function that we defined these factors do not by themselves automatically
get a dot filter method so this method as a syntax appears once you
define the class at the typeclass of filter ball and then in the imports
at the top of this test file you look at the imports I have imports
filterable so the filterable is the object filterable underscore so
the filterable is the object that contains all the syntax for the
factory and sorry for the filter multi class so this is the way that
it is defined which we already saw in the previous tutorial so let
me just go very quickly over it the filter syntax is defined when
we have already with filter then we defined also a filter isn't an
alias to with filter and we also define other functions which I will
talk about later but this is this implicit class that converts your
factor into something that has this syntax this is a pure syntax extension
which does not change the code we could have used the different syntax
we could have said yet the evidence value for this partial function
and the evidence value contains the filter call that so that will
be just less readable using that syntax we have this more readable
style of dot something dot something does something which is easier
to read so now we can check the laws for the P using these definitions
so you see it\textsf{'}s very easy to derive filter instances if from parts
that already have filter instances and we will look at it in more
detail later the next example is this type now if you look at this
type its int + int here and also in so each part of the disjunction
has an int so we could factorize it out like in ordinary algebra with
types and we have int times 1 plus a plus a na plus a a in we could
have done this like that and then we already have a filterable instance
for this cut type because this is John\textsf{'}s coupons in their previous
examples we already have an implementation of this type so we could
just leave the integer unchanged under filter filter this and we're
done now the other implementation is possible and valid there\textsf{'}s another
implementation that\textsf{'}s perhaps more interesting because it keeps information
about what filters what items were filtered out and it gives you no
trivial information in these integer values yet it\textsf{'}s still consistent
with the laws so let\textsf{'}s see what we want to do well so let\textsf{'}s look at
this type what we're given suppose that we are in this part of the
disjunction so we are given a value which is in this part of the disjunction
then we filter something and we have one of the data items not passing
the test so two of them are left well clearly we have an int we have
two data items so we should be in this part of a disjunction so we
will move data over here and in this way we implement that\textsf{'}s how we
did in the Jones example Jones good but we can also add one to the
integer value here to show that we have emitted one data item so more
generally this type allows us to implement a filter in such a way
that whenever we emit some data items we can add the number of these
items to the integer value and in this way we will in some sense keep
track of how much we have lost so how many have been filtered out
this could have been this could be an interesting implementation for
certain cases maybe so let\textsf{'}s see how it works so we implement first
of all this type as a sealed trait with four case classes sorts of
disjunction with four parts so this part will be just the integer
this part has one item two items three items implemented functor instance
now we implement the filtering so how we do this well actually this
is a bit complicated because of all the different cases that can help
so in order to simplify the code I implemented the ad function from
list that converts a list of a into this leader structure and a list
of a should be at most a length three so this function takes an integer
and takes a list away and then it implements it finds out how many
elements are in the list and notice this thing it adds to the integer
the number corresponding to how many elements were not in the list
so now I'm using this function and implement the filter so if I have
zero elements I returns in your elements nothing to filter if I have
one element I check the condition and if it passes I return unchanged
otherwise I return the zero elements but I increment the end showing
that I have emitted one element and similarly for all the other cases
I filter but then I put the new integer into the data items in other
words that\textsf{'}s what I implemented so here\textsf{'}s here\textsf{'}s an example so I have
it initially three elements with integer equal to zero and I have
a condition that the string has length less than for only two elements
sorry only one element passes that test and so this code will give
me a list of one a one with a value Firefox and the integer value
too so that was here so L plus two and plus two in other words I know
that after filtering this is the result of Firefox went to items were
filtered out so in this way I can implement more interesting logic
and and keeping track of how many items were deleted because I have
the integer value in the types so that\textsf{'}s an integer that\textsf{'}s so interesting
presentation of the filter and I can of course check I should check
that laws hold in fact if I changed anything here if I put n plus
three here for example instead of n plus one the laws would not hold
why is that because for example we have a conjunction law or the filter
by one condition and then filter by another condition the result must
be equal to the filtering by and junction of the conditions so the
keeping track of how many elements were deleted must be consistent
it must actually keep track of the number of elements deleted because
only that will satisfy the conjunction law if you first delete one
element then you delete two more elements then it should be the same
as if you deleted three elements and right away and so the integer
must reflect that so if the integer does not reflect that you will
violate one of the laws the next example is the functor which is non
empty list it\textsf{'}s a recursive function defined like this so it\textsf{'}s type
F is defined as a disjunction of a or a times F so it can be a or
it can be a times a or it can be any times a times a and so on so
it\textsf{'}s a list that has always at least one element is just like a list
except it does not have the unit it cannot be empty so actually this
cannot be filtered law the intuitive reason for this is that the empty
container cannot be represented so this disjunction {[}Music{]} as
this form a plus a times a plus a times a times a and so on and all
the parts of the disjunction have at least one item of type a and
so if let\textsf{'}s say the filter condition were identically false we should
have excluded all data items but we cannot because there is no part
of a disjunction that represent in all data items there must be at
least one somewhere so if we had a functor like this you'll find recursively
like this or in some other way with a 1 plus something so if we had
the unit as one part of the disjunction then we would be able to represent
the empty container using that part of the disjunction but now we
we can't so let\textsf{'}s see how that works so we can certainly write down
the factor a functor instance is fine and we can try dividing a filterable
instance but we will fail the laws and the reason is when we do this
case so how do we define the recursive first of all how do we define
recursive filter for instance we use this function with filtering
recursively so there are two cases for the disjunction one case is
the one in this case we just have no choice except to return the same
value because there\textsf{'}s no way to represent anything else we cannot
represent empty now the recursive case with tail we again we don't
do anything with the hell because well we we could actually they wouldn't
help us by we could we couldn't actually filter the hill it\textsf{'}s not
true there\textsf{'}s no way to point a filter at your hand let\textsf{'}s apply it
I'll still fail of course because if this one is wrong we should have
used the filter here as well we can't there\textsf{'}s no way to present absence
the absence of data but let\textsf{'}s try as hard as we can so what do we
do with the head well we need to check whether the predicate is true
on the head if if so then we can return this otherwise what if the
predicate is wrong is false only head well we don't have this a so
we omit it we still have FFA we can filter F of n notice we are returning
this part after filter so we can omit that and we return F of a which
is the tail which is off of the same type non-empty list already and
that\textsf{'}s fine because it\textsf{'}s recursive type so this type is the same as
the entire type it\textsf{'}s recursively the same so we can return a value
of this type of a way taking as a tail so we can return tail organ
return filter detail it will be of the right type so this is the best
we can do to implement filter law but that actually won't help us
if we are we see what happens here well I'm just ingest all the tests
so we could filter on this so how would that work this is an instance
of the non-empty list with two elements both negative and we want
to filter with a positive condition and then we take a square root
so according to the logic of what the filter should do let\textsf{'}s reveal
an empty container because none of that one should pass the test so
we should never can compute any square roots in this calculation but
this is not what happens because the filter is wrong so the first
one is filtered so we were here P hat is false so we're in this case
so we return the filter on recursive so this is a recursive invocation
of the seen function with the filter we returned the recursive invocation
on this then we are in this case where we must return the same thing
since there\textsf{'}s no other way to do anything there\textsf{'}s nothing else that
we can return so as a result the square root will be applied to minus
100 so this would be emitted but this would not be emitted so in other
words this filter fails to filter out some of the data and that\textsf{'}s
why it\textsf{'}s wrong it\textsf{'}s not going to satisfy laws and it\textsf{'}s not filterable
so in fact it is impossible to implement the filter function correctly
it\textsf{'}s not just that we didn't manage it\textsf{'}s actually impossible in this
second part of the tutorial we will see why the next example is this
factor which has two type parameters but we are interested in the
type parameter a so there\textsf{'}s a Z or there is an integer Z a and a so
how do we filter that I certainly it\textsf{'}s a functor its covariant in
a but how do we filter so in order to understand how we will filter
this I look at the type in this notation and I imagine well it would
be if one of these failed the filter well if if no element fails the
filter I know what to do I just return the same continue so the only
question is what happens when some elements fail the filter condition
and so then let\textsf{'}s say this one fails and let\textsf{'}s say this one passes
so I have to exclude this one but and what can I return like I must
return one of these two parts of the disjunction I cannot return this
part well I could I could duplicate this value it\textsf{'}s probably not very
interesting but I might want to do this in some cases I shall return
this perhaps well it\textsf{'}s more logical right you have fewer data items
after filtering if you duplicate then you don't represent the fact
that you have fewer data items and maybe it is better to try to represent
that fact if you can and here we can so we can actually return Z we
had a Z already we can just return it we don't need to change it in
any way we just return it and so in this way we will be representing
a collapsible filter collapsible product so if at least one of them
fails then both will be filtered out and will have this value which
will we will use to represent an empty container now this value is
not going to be just one value like a unit if it\textsf{'}s some type Z and
we don't know what that type is but having that part of the disjunction
will represent an empty container doesn't have any ace in it it has
a Z in it but that\textsf{'}s not what we were filtering we're filtering AIDS
so this is totally fine to represent an empty container and notice
we can only return the Z because we already had a Z in this part of
the disjunction so in this part we already had a Z if we didn't for
instance if we had this type then there\textsf{'}s no way for us to return
a Z when these two fail all the tests we have an int we have an A
but we need to return a Z we can't and so this factor is not filterable
with respect to a so just to show you that it\textsf{'}s important that in
this function there is a Z here and the Z here all right let\textsf{'}s implement
so we will just write it short without we don't need to have sealed
traits here just right on either of Z and this conjunction or the
product or the tuple the same thing so either of Z and tuple these
things is the type now we have a type constructor with two parameters
and we only are interested in a factor with respect to one parameter
so we need to use the type lambda or anonymous type function which
is written like this I'm using that projector plug in the kind projector
plug-in so this syntax means take this type constructor fix Z consider
the second type parameter as unknown and the result is a type constructor
which still waits for a type parameter to be given and that\textsf{'}s our
type constructor so that\textsf{'}s the syntax equivalent syntax is let\textsf{'}s say
we could say lambda X going to f of Z X so the capital lambda introduces
a type function and so the type function is taking the type X and
returning this type so this type function is an anonymous type expression
that is unnamed type expression it represents a type function a functional
type level takes one type argument and returns a type so just like
our anonymous functions are called lambdas anonymous type functions
are called type lambdas what the type lambda represents would be something
like this if we could write it with which we can note for example
Q of x equals F of G of X now if Z were not a type parameter but a
type that is already fixed somewhere we could write this and then
Q would be a type function that we want but in this situation we cannot
write that because Z is not a fixed type C is a type parameter so
we must put Z here which defeats the purpose we want a type constructor
with a single type parameter we want to fix the Z type parameter in
F and we want the result to be type constructor with a single undetermined
type parameter so that\textsf{'}s what type lambda does so this syntax does
not work an alternative faster syntax for this is that so this is
a tentative syntax that works and let me just for reference show what
it would be in ordinary functions so we had an ordinary function let\textsf{'}s
say f of X we want to define a function that fixes the value of Z
and only considers X as an argument so we want a function with one
argument which is f of X but we don't have a Z to do that Z is not
available in this scope so we cannot do that so instead we write an
anonymous function such as X going to f of Z X so in an expression
where Z is which is known this this can be done so we don't need a
name Q for this function it\textsf{'}s an anonymous function so this is exactly
equivalent and the Scala syntax for this can be shorter we might list
and so see the syntax of the kind projector podan was designed to
resemble the ordinary Scala syntax for anonymous functions were lambdas
to give you an honest type functions for type lambdas so this wasn't
aggression just explain what is it going to have a type London so
we need to use the type lambdas unfortunately the cats derive library
does not work with type lambdas and so that doesn't compile our no
matter we implemented by hand so we write a functor instance by hand
then we can use the carry Harvard library to implement the actual
map function and that works here so anyway we can save typing we should
now the filterable instance needs to be implemented and so let\textsf{'}s go
back to our type so we have a disjunction we have two parts of the
disjunction if the if we are in this part there is nothing to filter
because we don't have any age if we end in this part we need to see
if both of them pass the filter and only in that case we return in
the container unchanged otherwise we return to Z which was this one
this is e so let\textsf{'}s implement this logic if we're in the left we just
returned the container and changed if we're in the right we have an
N Z X and y if both of them can pass the test both of the x and y
chat x and y are tied a z is of type Z and n is integer we don't use
the integer we discard it if we're in the case that at least one of
them fails if we're on the kit in the case that both of them passed
and we return FA which is the original value unchanged so actually
we could replace these unused variables you see now unused intellij
underlines them within gray you can replace them with underscores
which is a shorthand for saying that this is a pattern that we don't
need to name it should just match and whatever is there we don't need
that\textsf{'}s usual way of doing this so then we check the filterable laws
with this factor and that works so we can put a type lambda as a type
parameter that works however we need to put specific types in terms
of bullying or integer or string or something otherwise there\textsf{'}s no
way to run any code actually if your types are not specified the next
example is this functor which is a disjunction of several parts and
one of them includes a list so for the list we're just going to use
the standard filter instance so a filter function on the list I'm
not going to reinvent that or implement that in any other way we're
just interested in finding out how we could implement filter on this
kind of thing we're interested in these parts what a list is already
standard we know how to filter list although of course there are more
than one way of filtering lists but that\textsf{'}s not the point of this exercise
so here\textsf{'}s this factor we define it as the sealed trade with three
is Junction cases so empty have Z and have list there\textsf{'}s standard way
in which we implement these junctions in Scala now unfortunately we
cannot implement functor automatically because cats derive doesn't
work with type lambdas and carry Hubbard\textsf{'}s implement does not work
with list being a fun tree doesn't know how to do function list and
cannot derive it either because it\textsf{'}s a recursive type that is not
yet supported by this library so we need to implement for instance
ourselves which is which is not a lot of work if it\textsf{'}s empty then it\textsf{'}s
empty and we just whatever should be mapped whatever part is mapped
is mapped so as we have seen in Chapter four hunters are relatively
straightforward to implement so if you build a functor out of parts
then if you know how to implement functor for the parts then you're
easily implemented for the entire type and that\textsf{'}s what we have here
so how do we implement filterable well we have again got to look at
the type if we're in this disjunction part or in this part there is
nothing to filter no ace and so we just return them unchanged always
a good idea to return unchanged if there\textsf{'}s nothing to filter in this
way and we could always return one of course the unit but then we
would lose information so if we are in this part of the disjunction
we don't want to lose that information when we're filtered so we shouldn't
in return one actually that would violate the identity law if we're
filtering with a predicate that\textsf{'}s identically true we should not change
the value and so if we're in here there\textsf{'}s nothing to filter and that\textsf{'}s
exactly the same as if we're filtering with something that\textsf{'}s identically
true and so we should not change the value so that means in all other
cases except the case of have lists we should just return the unchanged
value now if we are in the have list case which is that we're in this
case then obviously in truth stay unchanged now we need to check if
this a is passing the test and we also need to use filter on this
so we filter this we will get another list that\textsf{'}s fine but what if
this a does not pass well we cannot then return this part of the disjunction
because we don't have an a to put in this part this list could be
empty so this there could be no ace in there in any case we can't
find given a out of there always and so there\textsf{'}s no other choice except
to return one of these two parts of the disjunction but which one
or we can't really return Z because we don't have a value of Z Z is
a type parameter so we don't know where to get such a value but we
can return one the unit well in this case it\textsf{'}s a named unit it has
a named empty but since it\textsf{'}s a unit you can always return it and so
that\textsf{'}s what we do if that condition holds we return {[}Music{]} the
heaviest case with filtered list here otherwise we return empty case
there\textsf{'}s no other choice and that works lost pass so all the tests
here are run and they'd all pass the laws are always checked the last
example is a little advanced because it introduces a new concept filterable
control factor now it seems the what to introduce a new concept in
an example but it\textsf{'}s an easy step right now we'll talk a bit more about
filterable control factors in the second part of this tutorial recall
that the control factor is a tight constructor that has a control
map function that is like map except that the arrow is going in the
other direction if functor represents a container that is something
that holds values a data of some type and contrivance represents something
that consumes values of the type it\textsf{'}s not a container it\textsf{'}s actually
doesn't have any values of that type it consumes them it needs them
so it will consume them we've given given and so a filterable control
factor means a container that can consume less it can filter what
it consumes and if they're consumed items do not pass a test it will
not consume them it can consume fewer items so here\textsf{'}s an example of
a filter Concha functor will not check laws at this point but we will
check them later once once we find more about filterable hunters it
will be quite easy to understand what the filterable contract you
must be so at this point we will not check laws for contractors from
filterable country hunters so here it is I just put co-variants adaptations
for illustrative purposes for no particular use in the code that follows
I'm not using subtyping but just to illustrate and this is a cultural
factor control factors cannot be able to medically derived by in a
cat\textsf{'}s library which is a shame because they're just as easy to generate
as hunters are but they don't exist there so let\textsf{'}s use the Curie Harvard
library to implement the country hunter instance so the country hunter
is a called contravariant in the cats library and it has the country
map function with this signature so so it\textsf{'}s C of A to C or B but the
function is literally not a to b so i just implement automatically
and by the way just to check that cats cannot derive anything with
exponential types anything with function types but cannot derive so
cannot this is a very easy factor but cannot derive so not support
it well just for our information the cat\textsf{'}s derive can do case classes
polynomial types only products and sums but no Exponential\textsf{'}s so the
contra filter is the function {[}Music{]} sorry the the control control
factor instance which I just called control filter now is implemented
as a function with filter it has exactly the same signature as for
filters so it takes the predicate from a to boolean it takes old value
of the function returns a new oh sorry contra funky and it turns a
new value of the control factor so how do we filter the control factor
quite easily in fact you need to return a function so C is a function
from a to option Z so we need to return a function from a to options
if so that\textsf{'}s that is the that is the function return it takes an X
of tightly and it checks whether X passes the test if so it lets our
country function cancion X otherwise it does not let it consume X
and instead it returns none none is the possible value that it can
return so that\textsf{'}s important that in the case that our argument does
not pass the test we have to return something and we're not allowed
to let the country hunter consume that value and that\textsf{'}s similar to
the partial function law if for fun tips if value does not pass the
test we're not allowing the factor to transform this value any further
so any further processing should not happen for that value and so
for the country functor this happens right here contra fighters conceal
values and so the are they should be guaranteed not to need to consume
values that don't pass the filter that\textsf{'}s the main intuition behind
filtering the Contra factors and so here we define a specific type
constructor example eight which is C of L Z with Z equals string we
can do that with specific type without it we the only thing we have
to do is at I clamp the C of question mark Z so so that\textsf{'}s the only
thing we have to do it here we can if we are willing to constrain
the parameter Z to be a fixed type then we can do it and we are doing
this here because we're about to run tests and for tests in any case
we need specific types so just to run the test I need to define the
Equality function that will compare two different values of contra
factor and since they're functions it\textsf{'}s not immediately easy to compare
them we need to do it for all and run the functions on some arguments
and so I also have contra filterable laws implemented but this is
just for later logo we discussed these laws right now so now here
are some exercises for you which they are based on what we just have
covered {[}Music{]} they're very similar to the works examples I just
gave and after you do these exercises we will go on to the second
part of the tutorial where we will discuss the laws of functors in
more detail and in more depth we will discover why the laws are like
this however they can be simplified and how we can reason about filterable
factors in a much simpler
\end{comment}

\begin{comment}
this is part 2 of chapter 6 of the functional programming tutorial
in part 1 we considered filterable functions starting from examples
we considered the syntax of the functor block starting from the intuitive
requirements that the if operation search should satisfy we derived
the filter laws and then we considered what types could be filterable
or not filter belong examples in the second part we will look at the
laws in more in-depth and one motivation is that there are four laws
it\textsf{'}s a lot of laws to remember each of them seems to be describing
a difference side of the filter function in different property but
doesn't seem to be any obvious connection between these laws but actually
there is we will find by looking at what the filtering function does
with a bit of intuition we can actually reduce the number of laws
to two and we can find why these laws must be as they are to begin
consider our intuition from the first part of the tutorial which is
that we considered filterable type like this more like this and we
noticed that when a data item does not pass the filter condition then
the remaining data items are moved into a different part of the disjunction
but algebraically is a similar to replacing this type with one so
whatever data items do not pass the filter condition are going to
be replaced with one with the unit type and if you replace this with
a unit type what is left is a type 1 times T times T which is isomorphic
to this so let us see if we can make this intuition more precise what
does it mean that we replace a data item of type a by a unit type
if we're given a factor such as a freeway how can we replace this
data item by one without breaking the type because the replacing cannot
be just happening blindly that would be changing the type of F of
a and we are not allowed to change it the filter operation should
keep the type unchanged so the first question is how to replace this
data item by one can we make that more precise and second maybe we
replace it by different type so then how do we transform that time
back to halfway so let us try to do this and first of all note that
we could replace data items by unit if instead of the type F of a
we had the type F of one plus a in other words F of option away and
that type means that every time that the function f contains a data
item type of type A instead now it contains disjunction either it
will be a data item of type A or it will be one the unit value if
we had this kind of type then we could easily implement the step one
every time we look at a data item of this type we see whether this
is you know whether this is one or a o if it is one then it remains
one if it is a and it does not pass the filter condition we replace
that by one and this replacement replacement does not break the type
because this disjunction contains both the type a and the unit type
so but how do we get this type out of this one we can use a function
actually very easily called inflate I'll just call this function inflate
it transforms any factor into the factor type of option a and it works
by lifting this function into the function so this function which
is in Scala the son type constructor it takes a value of type a and
returns a value of type option a just takes this value a and puts
it into the right part of the disjunction so this function exists
obviously for any type a and when we lift this function into the filter
using the F map we get a function from f of A to F of 1 plus a so
that\textsf{'}s the function we want that\textsf{'}s inflate so that always exists from
any function and after that we filter so we perform the filtering
operation by taking each element of type 1 plus a and filtering it
and that is just a filtering operation on an option that operation
is defined in the standard library it is obviously easy to define
we have done it in first part of the tutorial we just filter the option
with the given radical P so if the option I was empty it remains empty
if the option was non empty and the predicate holds on that value
X then it remains non-empty on changed otherwise it becomes empty
now so far we have gotten this type but we need FFA how do we get
from a family of FFA from F of 1 plus a 2 F of 8 so that\textsf{'}s step 2
so actually if filter does not so somehow this function must be available
so I call this function deflate somehow for the filterable factor
this function must be available otherwise the filter couldn't work
like this so this intuition tells us that perhaps we should be able
to define the function deflate for the function f if the filter is
in filterable and notice that the standard Scala library already has
a function called flatten which works like this of this type it takes
a sequence of option and we can return the sequence so this is exactly
the same type signature as deflate except for specific functor seek
for the sequence so sequence is filterable as we know so this suggests
that actually being able to define deflate is necessary if a factor
is filterable so let\textsf{'}s look at this diagram again to see how this
works so that we expect that the filter function applied to a predicate
P and a founder of a functor value if a first works by inflating to
f11 plus a then we filter the option inside the function so we lift
the filtering operation on the option to the factor using F map we
get again everyone plus a then we deflate that into FA and so then
we get a function from FA to F if that\textsf{'}s the type signature of filter
of P just to remind you that filter of PE is a function that is taking
a fail and with returning a fee so let\textsf{'}s try to express more formally
filter through different now there is a car composition here in flight
and this F map inflate itself is defined as f map so we have f map
of some composed with f map of filter so that\textsf{'}s f map of the composition
of these two functions by the property of death note now the composition
of these two functions can be simplified with I call this Bob boolean
option boolean to option so we take filter P which is a condition
from a to boolean and we get a function from a to one plus a it from
a to option A so we kind of lift the boolean predicate P into a function
from a to option A and this function works by checking that the predicate
holds if it does we just return some of that X otherwise we return
none so this is defined by this color code now notice here we use
a standard filter on an option which is a very simple function so
we aren't really using this filter on some arbitrary function f we're
using a very specific function which is called filter on an option
we do not have to write the word filter here we could have implemented
this by hand it\textsf{'}s very easy so this function Bob boolean to option
lifting will be very convenient for us in what follows so make sure
you understand what it does and how its defined it transforms a predicate
from a function a to boolean to a function from a to optional so then
we see that this function is basically a composition of this and this
so therefore we can simplify an Express filter through deflate by
saying this composition is equal to composition of the first two is
equal to f map of the Bob and the second one is deflate and so basically
we have a composition of F map Bob and deflate and that\textsf{'}s how we would
have expressed further if we had the function deflate so the flight
is assumed of this type signature from F M a1 plus a2 F F just a short
digression about notation here sometimes I write functions with parentheses
and sometimes without parentheses now this is similar to mathematical
notation like cosine of X where we do not write parentheses when this
expression is very short but we do right parentheses when it\textsf{'}s longer
for clarity for example cosine of a plus B or some larger expression
we would write of course parentheses the parentheses but if the expression
is very short we do not write parentheses so similarly I would use
this notation we would write both p4f map f filter P without parentheses
so to summarize this in the function type diagram filter P is defined
through the flight as a composition of F map Bob which sub Bob is
Bob T so already applies to the filter condition P is a function from
a to one plus a so we lifted to the vomiter we get a function from
get a function from FA to f1 plus a and then we deflate so as another
reminder my notation is that the composition works from left to right
so we apply first the function on the left and then we apply the function
on the right to the result so just so that it is easier to read easier
to reason about and easier to write on the diagram so far we have
expressed a filter through the flight assuming that defy it existed
so actually we can also express the flight through filter and when
we do that it will be interesting to note we assume we will assume
that law for holes so here\textsf{'}s how we can express deflate through a
filter what\textsf{'}s very easy the idea of deflate is that we have a factor
of 1 plus a sum of these 1 plus A\textsf{'}s are empty some of them are non
empty we just want to filter out those that are empty only the non
empty ones need have to be remaining and then we will get a function
get those that are non empty we will extract the value a value type
made out of them and that will give us F of a so how do we do that
well we can write code like this so F of a is a value of type F of
optionally we can first filter on the condition that the option is
non empty and then can map with the gate function on the option now
the get one method is a partial function that takes only the right
part of the disjunction and returns the X but it is undefined on the
left part of the disjunction so the gate is undefined on 1 plus 0
so it\textsf{'}s a partial function but it is safe to use this partial function
after filter that\textsf{'}s our fourth law we have filtered to the condition
that all the option values that pass are non empty and so it is safe
to use the partial function now in Scala code if this were a sequence
I would have used the collect function and written the code like this
the collect function is functionally equivalent to this consequences
but for arbitrary function f not necessarily having the collect method
we can just use the partial function it\textsf{'}s safe because of the filter
property for so if law for holds then we can define the flight through
filter so we have defined filter thread of flight and we have defined
the flight through filter this means they are computationally equivalent
this is a very important idea these two functions are actually doing
the same thing if we have one of them you can have the other and these
are equations these are not just mappings so to speak from one to
another these are actually equations so one function is equal to some
combination of the other function with stuff and the other function
is also equal to some combination with the first function Wisla so
basically it means we have one you have the other and they carry the
same amount of information the same amount of power so if you are
able to define filter for some function for functor you can also define
deflate and vice versa we have seen that some function some factors
are not filterable so you cannot define filter therefore you also
are unable to define deflate for them so we could actually say that
filterable factors are those that have deflate and we could specify
them by implementing deflate and then we could derive the implementation
of filter from the given implementation of the flight by a standard
library function so we could actually define a typeclass of filter
about 3d flights rather than through filter it would be equivalent
as we have shown we can express one through the other provided that
the laws hold of course but they must be formulated for the flight
in that case and then we need to check the de haut so the flight is
actually there useful because its type signature is so simple it\textsf{'}s
a function from functor of option A to function and because its type
signature is so simple we can easily verify that some functors are
certainly not filterable here are some examples consider this factor
if I wanted to check if that this function is filterable then in principle
I could try to implement filter for it and check the laws that would
take me while perhaps so let me see if I can write a deflate function
the deflate function would have mapped F 1 plus a 2 F a what is F
1 plus a it is this type now mapping F of 1 plus a 2 FA means I'm
mapping this type to this type so I have a function from this type
to this type this function cannot be implemented because the argument
contains the unit part of the disjunction if the argument is unit
if I need to produce a value of this type but I don't have any ace
all I have is a unit type if I am if I'm in any of these parts on
the disjunction maybe I can produce value of type a but if I'm in
this part of the disjunction I don't have any values available in
order to define a function from this type to this type I'm required
to define what happens with every element of the disjunction when
it is given as an argument and so I'm not able to map one to a and
I'm also not able to map one to a times a being able to map this is
equivalent to having a selected element of type a but I don't have
that I don't know what the type a is if the type a were pointed then
I would have a selected element and I would have implemented this
function by returning that selected element when I'm given the unit
so it\textsf{'}s an example of a pointed type is option event the point in
value the selected value is not the empty option but in this example
is a type parameter we do not have any more information about a so
we do not know whether it is pointed therefore we cannot implement
this function 1 to a and therefore we cannot implement this function
since we cannot implement the flight we could not possibly implement
filter either because as we know filter is expressed through deflate
like this another example is this functor this functor is not filterable
how do we see that if we wanted to implement deflate then we would
have to map f a 1 plus a 2 FA every one plus a is this so we need
to have a function of this type how can we implement this function
well we have an int and we have this we need an a well we can put
an end here and we can get one plus a but we need to produce a value
of type a and we only have one plus a so this function cannot be implemented
for an arbitrary type a for the same reason what if its argument is
the empty option the the part of the disjunction that is unit then
we would have to produce some value of type a but we don't have one
therefore it is not filterable so the function deflate is easier to
implement than filter and easier to reason about that non filter is
very quick to see that you cannot map this to this and therefore it
is not filterable or it is also easy to see when you can so let us
continue to analyze the the laws of filterable and we noticed that
we were able to define the flight out of filter only by assuming that
law for homes for filter the interesting thing that and that we find
we will find now is that if we define filter from deflate law for
will be satisfied automatically for filter in other words deflate
only has three laws this is a very interesting observation and perhaps
unexpected let me now show how this is derived we will now derive
and mathematically prove that one filter is defined through deflate
law for four filter is satisfied automatically for convenience we
will be using this function a lot so what can denote this with sy
p sy p is a function that already is applied to the condition p and
its type is this so this function already encapsulate the filtering
functionality if this value does not pass the condition and then it
will be replaced by 1 if it does pass the condition it will remain
here we can then write filter like this much shorter let us now write
law for in this notation expressing filter through deflate law for
looks like this it is the partial function law so if we first filter
which is this composition and then we apply a map with some function
it\textsf{'}s the same as wave first filter and uh apply the partial function
map where the partial function is defined as the same function as
f except it\textsf{'}s only legal to pass values that satisfy the condition
P let us use this type diagram the fact that the function type diagram
as I call them to visualize this law in the vertices of this diagram
are types and each edge of the diagram is labeled with the function
that makes the transformation from this type to this type so then
it is easier to read this law this law means that first we take the
type of a notice that here in this law there is no space really to
write the types of everything so this law is convenient like this
if we don't already know the types when we just need to manipulate
things but if we need to first understand the types and this notation
is too short it\textsf{'}s better to use a diagram notation and on the diagram
intention we just write the same things except we put all the types
intermediate and final initial and so on types of everything so we
start with a value of type of a the left-hand side of the equation
transforms in the upper part on the diagram first transfer strobe
side P and then we get F of 1 plus I because side P has this type
signature then we deflate we get FA and then we map with function
f F maps a to be F map F maps FA to FB and the lower part of the diagram
similarly first of psi P we get F 1 + I and we deflate we get F a
then we have map with the partial of F we got FB and the law says
says that if you take a value here you go to the upper way or you
go the lower way you get to the same value here always connects this
equality again a little remark about notation so I'm writing F map
F without parenthesis here the type signature of F map is curried
so it has a first argument F and then there is a second argument which
is FA and so f map applied to F is a function from a fatal FB and
I do not write parentheses here for clarity so think about this notation
is again similar to mathematical function like cosine X or sine X
without parentheses so then think of this is one value one expression
like cosine X all right so we have formulated the law in terms of
deflect how do we show that this law holds now we are supposed to
show this with no further assumptions perhaps about deflate well actually
that is not true we cannot do this unless we know something about
deflate so one thing we know this is that this law is supposed to
tell me that it is safe to map with a partial function it will be
the same as if I mapped with the total function because I have filtered
so I filtered out the possibly illegal values for this partial function
but the filtering happens right here far from Earth map so there\textsf{'}s
this deflate step in the middle I have filtered here than I deflate
and the ninetieth map maybe I will be able to reason about it better
if this F map were close to beside P because this beside P contains
the predicate P this also contains the predicate P so maybe I can
reason about this eclair together site is by the way its itself enough
map of something so if I put this F map next to this side P somehow
if I transform this expression into an expression where I have a composition
of site P and F map of something then perhaps I can easily reason
about it because that will be F map composition with F map and then
I can simplify everything and look at these functions and maybe get
what I want how do we interchange the flight and F map in the two
sides of this equation well remember that we have a law law one which
interchanges f map and filter so filter now is expressed through deflate
so maybe if we put it right here instead of filter but we'll have
a law that interchanges earth map and deflate such a law is called
usually natural reality law so let\textsf{'}s express the old law one the filters
go one through the flight we get this equation which is now more difficult
to understand without the type diagram so I write a function time
diagram here it starts with F a it first maps with a function a to
b 2f b then we apply the filtering function we get we get F 1 plus
B and we deflate that to f b now this deflate is parametrized by big
f and b so it\textsf{'}s a deflate for F 1 plus B 2 F be the right hand side
is the lower part of the diagram which first maps with psy of composition
F in P now P goes from B to Bui so composition F and P goes from A
to B the boolean so from A to B and shy of that goes from a to 1 plus
a I'm sorry from FA to F 1 plus F so first we get this and this already
incorporates filtering then we deflate we get FA and then we map if
FA to FB using the same function f as we used here so here the filtering
worker is first on the Left map here the filtering occurs after of
milk that\textsf{'}s the law that we can interchange filtering and F map now
we would like to transform this so that we can have a law that interchanges
deflate and F map we almost have that except we have this I in the
way so can we simplify this perhaps somehow let\textsf{'}s write it down f
map F composition with psy which is f map of both P is by the ethnic
composition law it is this so can we simplify this expression we can
actually there is a property which the Bob function has which looks
like we can interchange Bob with some functions so it\textsf{'}s like a natural
Adil except it isn't because Bob is not if a function that works with
functors only those functions can have natural tools so it\textsf{'}s kind
of a similar law not interchanges the order of Bob and some functions
here\textsf{'}s the function type diagram for it we start with some type a
we first map F A to B we get a B and we map with Bob we get big on
plus B some Bob maps from Vito and plus B it and takes the boolean
predicate makes it an option kind of predicate option valued predicate
the second way the right hand side is a lower part of the equation
is first we do the book filtering we get one plus a and then we map
the function f so we have to map 1 plus a 2 1 plus B using F F goes
from A to B so obviously we just lift F to the option factor so we
get a function 1 plus a 2 1 plus B so this is denoted like I denote
it like this is f map for the option factor I right opt for gravity
instead of option I need to spend less faint less less space in my
equations so how can we verify that this property holds well I have
code actually I have both symbolic derivation of this and the code
that checks so let\textsf{'}s look at the code so here\textsf{'}s the definition of
filter from the flight and here\textsf{'}s the definition from the flight from
filter and let me see where my book property is Bob yes it\textsf{'}s here
so let me first look at the Bob property perhaps since we're talking
about this so Bob is defined like this and I also defined it as composition
of apply and filter just like we did in the slide it\textsf{'}s a composition
of this and filter so I can write it down if I want explicitly has
a composition we can check that this is the same function actually
I have a helper function that checks function equality which I could
have used here but functional equality means checking that for all
arguments X and for all arguments P it has two arguments so both of
px is equal to BA first composition P X so now the law of natural
T is that this must hold so f is of type let\textsf{'}s site T to a and this
is a to boolean so this composition is of type so this composition
is of type T to boolean and this can this is composition is of type
T - 1 plus a and that should be equal to that function from T to 1
plus a so therefore we take T to string just to check it a is int
and so then we write that F composition with hope of P so I'm just
writing it straightforwardly here composition and Scala is and then
so F is applied and then this is applied so book of P is a function
so book is already applied to P and the result is again a function
which is of this type that should equal book of composition F and
P like this and then so composition with map of F on the option then
I applied both of these functions to some X so that I can check that
the results are the same and also I can check this law symbolically
now of course the test passes but it checks the law for certain values
maybe 400 randomly chosen this is perhaps if enough of any assurance
but this is correct but it is nice to be able to have rigorous derivation
not just a numerical test so how do we have a sim how do we find a
symbolic rigorous derivation we transform the Scala code so the easy
way of doing this is to first replace these mathematical notations
with specific Scala code that corresponds to them for instance F composition
F and then both P means first we apply F to some X and then we apply
both painter the result when we put in a definition of both P which
is some dot filter of people then we expand what filter means filter
means if P of f of X then some f of X is known so that is the left-hand
side let\textsf{'}s call this expression 1 and the right-hand side is that
this applies to some X in Scala that would be dot map of F and then
we do the same thing so we expand the book into its definition we
expand the definition of filter which is nice for option then we put
the map inside so if this condition is true then this dot map else
this dot map then we simplify this because we can obviously see this
as a non-empty option so mapping it over F means we just put F inside
so that is the result of the right-hand side of the law and this is
expression 2 obviously expression 1 and 2 are identical so in this
way we have proved this property both using a test numerically so
to speak and mathematically rigorous them using this property we can
now rewrite law one which was this by interchanging this F and book
into so f composition book F and then what is pop and then as map
f so we put that in note here that we have now F map of Bob and then
F map of F map depth of of F now this F map is with respect to the
option factor and this F map is with respect to the F factor that\textsf{'}s
why I use this sub sub superscript opt to make sure we don't get lost
different types so this is a lifting of F into the option factor so
this is of type option a to option B and then we F map that over to
function to functor F and then we get this part of the diagram F of
option A to F of option D through F map of F map F so now we rewrite
this left hand side like this and we write the right-hand side of
that already contained the F map of this book of composition which
was here F map because I is f map of Bob so this is f map of both
composition this is this so now the left hand side and the right hand
side contains common prefix and we can remove it because our goal
is to show that they're equal we do not assume that they are equal
we need to show them they're equal so if we show that they're equal
without this prefix then they will be equal with this so we can remove
this prefix now we need to show this codes and that exactly looks
like a law for a deflate that we want this is low one for deflate
now we will also want to show that this law is {[}Music{]} equivalent
to the law one for filtering then we would have to show it in the
other direction and then we have to reason about why we can remove
this prefix but let\textsf{'}s just keep it aside this prefix by the way is
the only one that contains the filter condition P and so this prefix
should it contains the arbitrary filter condition P and so that\textsf{'}s
how it would prove equivalence and the laws but at this point we're
not so interested in the equivalence of the laws for the flight because
deflate actually will not be so important in terms of checking its
laws for us but we could give derive the laws for the flight there
will be two three laws from the first three laws the filter would
follow the three laws of the flight and so at this point we have derived
in natural G law for the flight which was ours so on the diagram it
looks like this we first map F 1 plus I 2 F 1 plus B then we deflate
with respect to B or we first deflate with respective a and then we
map a to b and that should be the same that\textsf{'}s the natural reality
law and having the naturality law for a function between factors means
that it\textsf{'}s a natural transformation that\textsf{'}s basically the definition
of natural transformation it is a transformation of one factor into
another such that the natural T law holds that you can f map before
the transformation or you can F map after the transformation and that\textsf{'}s
the same so here\textsf{'}s an example of implementing deflate so suppose we
take this factor then we look at the type of f of 1 plus a which will
be this just substituting 1 plus a here when we expand brackets just
like in school algebra we expand brackets and we are allowed to do
this because of isomorphisms in the polynomial types so then we have
this type this disjunction and then we say well we need to map with
deflate this into this so let\textsf{'}s see which parts of the disjunction
we could map into which parts obviously this well the unit we can
happen to unit and into nothing else this we should probably map into
this and these things could be mapped into unit all of them so all
of these could be mapped into unit and that\textsf{'}s fine that\textsf{'}s natural
transformation and that would have defined the collapsing filter that
we considered in the first part on this tutorial the filter that retains
the two values only when both of them passed the filter when even
one of them doesn't pass the filter both of them are removed and we
get the empty the empty container so this would be an example of implementing
deflate for this factor so it is quite easy the function has a very
simple type signature and this illustrates what natural transformations
do so in general natural transformation would map some container GA
into some container age and what it does it rearranges the data it
is not allowed to modify the values unless we know something about
these types but generally we don't and so this is an arbitrary type
were not allowed to change its value were allowed to rearrange the
order of values or the disjunction part in which these values are
held and well of course able to remove values or duplicate them also
very loud but we're not allowed to inspect the type and do something
type specific or and so on so same considerations as for a good implementation
of functor that we just look at the type and try to see how we can
produce a new type with no changes to the values exactly the same
considerations apply here a natural transformation will not modify
any values it will just rearrange data in a container so if you have
a natural transformation between two containers which you don't always
have but if you do have it it means that data in this container can
be somehow naturally rearranged with no changes to the data just some
erasing maybe some duplicating in some order changing it can be rearranged
and you get this type is this container so if these two containers
are in some sense sufficiently similar that this can be done this
rearrangement of data then you have a natural transformation between
these two factors so we have found the law for deflate which is this
which interchanges F map and deflate now let\textsf{'}s use this to show that
law for poles what is love for expressed while deflated is this I'm
repeating the type diagram from the slide before now we can use a
natural T law which is this to interchange the flatten map in both
sides of this equation so when we do this we get this equation so
we just interchanged and now this F is next to the sign in both parts
of the equation so we can now admit this common suffix the common
part of the two equations because we're interested in showing that
this is true so we show that this is true without the composition
will deflate then it will also be true with that composition and so
then we expand the PSI back into its definition which was here it\textsf{'}s
just the definition for brevity and we get F map of this equal to
f map of this now this is quite simple to check that this is true
let\textsf{'}s write out the Scala code for the left hand side on the right
hand side we see these two pieces of Scala code I've corrected the
Scala code here so this function is partial function will be always
safe because we are applying it after filtering on the condition P
and so any values X that this partial function will receive will be
guaranteed to satisfy the condition P this is because this is the
law for for the option functor and we need to verify that it holds
for the optional function when we define this filter according to
the usual the usual way of defining the filter going to the way we
we have assumed that we define it so let me show the code and that
demonstrates this unit so easily but this law holds so let me just
write it down so why does it hold for option or we have son of X filter
P f map map is X P of X goes to X or half of X so what is some X filter
P it is if P of X some X else none so how do we map this well if it
is none then it is not so we put them F map we put a map in here so
this is equal to that so this this code is evaluated like this to
this expression so now how do we do a map on the Sun well we have
a non empty option here so we just put this X in there now clearly
this P of X holds so the sum will be evaluated only if P of X holds
so then we don't need this condition this condition will be satisfied
by by the way that if is compiled so then we don't need to to do all
this we just do f of X and that is precisely sum of F of f of X filtered
P of X so if you'll repeat so this is lawful for option that we can
map with function if so this is some of X P so therefore some of X
filter PMF so therefore these two are equivalent and so what do we
find we find that law for holds this was the last equation that we
needed to show and we showed that this is the same code that is evaluated
in the same way for all arguments therefore this holds therefore law
for holds so we find that the law for for filter hold automatically
if we define filter through deflate so let me show you an example
code that was there before where I defined filters through deflate
and deflate through a filter so I actually used functions to define
that so I define a function which is called filter from the flight
which is paralyzed on a factor and this function takes an argument
which is a deflate function which is a function of this type and it
returns so this this takes the deflate as an argument and returns
filter as an argument as a value so it returns as a value a function
with the type necessary for filter so you see this is the this is
part of the power of functional program we can transform code one
function into another by writing a function it transforms code what
we don't actually transform source code we transform expressions algebraically
or using other functions but the point is that we define a function
that performs this work so that can be done with no restrictions so
this could be any type signature pretty much {[}Music{]} as long as
all the type parameters are defined up front in here one limitation
is that we cannot have further type parameters inside of this argument
so this limitation is sometimes quite serious but often not so so
this is our definition of filter from the flight is the F map of Bop
and then deflate since exactly how we defined filter from the flight
I've mapped Bob and then deflate and we also define a function that
takes a filter and returns a deflate now instead of taking a filter
function I just wanted to save myself some typing and I assume that
the founder F was from the filter with filter typeclass so that has
a filter function and then I do so how do these functions work well
they I'm supposed to return this function so I take P which is this
and then I'm supposed to return this function so this is the F map
book and then deflate all I need to do is to prepare this map properly
I need to do F map on an option so I use the implicit evidence value
foot which is this implicitly funder F it has a map function which
has this type signature but has the first argument which is function
f of a and the second argument which is function f but I need these
arguments in the opposite order I need first F F because I want F
map I want a flipped map functions I want to interchange these two
arguments so for this I use the flip function which is defined in
my common code like this it takes a function from A to B to C returns
a function from B to A to C in its code I leave for automatic instrumentation
so this is this flip function and then I get the F map for the types
that I need then I just write more or less than mathematical notation
and here also I prepare an implicit function instance sorry implicit
function evidence and then once I get that evidence into the implicit
scope I can use the syntax F way dot filter dot map if I don't have
this then dot map would not compile on an F for because F Way is a
filter but with filter all we know about it is that it\textsf{'}s filterable
with filter but that actually includes functor and that\textsf{'}s not automatic
as it includes filter and so we need to prepare this evidence other
than that this is the definition we had in the slides we deflate is
first we filter non empty options and then we get the values from
the option so this is a partial function but it is safe here because
it\textsf{'}s after the filter and as an example we do the orders example from
the first part of the tutorial and then we just deflate from filter
actually takes no arguments and filter from the flight takes arguments
so then I first obtain the flight from the filter then I obtain filter
from that D flight and then I check that that filter is the same as
the previous one so that\textsf{'}s what is checked here so that the filter
is the same function as the filter obtained from the flight that was
obtained from Philips alone it\textsf{'}s showing me that it\textsf{'}s really equivalent
functions all right well that is so good but still we have a bit of
complication because the flight seems to have a lot of laws three
laws and notice we always have this deflate composed with psi with
this F map of something always deflate is with F map of something
in front of it so maybe this F map of something or this I and then
deflate maybe this composition is actually easier to handle let\textsf{'}s
look at the type signature of this composition the type signature
is actually interesting it is going from F a then we get this F map
si which is going from some a to some 1 plus B so let\textsf{'}s say this is
a function we get f1 plus B and we deflate that we get FB so actually
the composition of F map and deflate is a function from FA to FB that
consumes this function f from 8 to 1 plus B so let\textsf{'}s call this F map
option or F map opt for short now the type signature of Asmat opt
is that it takes an argument of type from a to one plus B and note
this argument already expresses filtering and mapping at the same
time so this function from a to one plus B expresses first that we
check some condition on a and for some edge rate return every option
and for some is very turned on empty and then we also map a to some
be in some way so so this F combines combines filtering and mapping
and the result is a map from FA to FB so deflation is already incorporated
so F may up F composed with deflate that is the definition of F may
opt here\textsf{'}s the type diagram for it so from FA 12 be either directly
through F map opt and this is how we define it it\textsf{'}s a composition
of F map F and deflate now it\textsf{'}s important to note that F map opt and
deflate are equivalent functions because we can also define the flight
through F map opt to do that it\textsf{'}s very easy we just make this arrow
identity we said let this a be actually the same as 1 plus B so let\textsf{'}s
say this is actually 1 plus a and this is also 1 plus a we can do
this because a and B are arbitrary so we can set a equals 1 plus B
if we want to then this will be identity so this is an identity function
and then obviously deflate is equal to f map opt applied to that identity
function because these two will then become equal so since we can
express one function through another and the second really first they
are equivalent these are equalities so these are not some kind of
mappings so these functions are actually equal on all values so now
it\textsf{'}s interesting to express the laws in terms of F map opt now law
4 is already taken care of so it\textsf{'}s already automatically satisfied
we can express filter through F map opt this is actually quite short
because we have incorporated this F map and deflate into one function
so I'm writing out all the type arguments here for clarity so this
F map opt has actually three type arguments to F and the types a and
B so no filter is this kind of thing so now how do we show that the
laws hold well we will show it now actually well we cannot show that
the law school we need to derive what the laws are for F map opt we
need to serve its press filter through F map opt and substitute into
the laws so for example let\textsf{'}s look at the at this law well in this
law it\textsf{'}s probably easy we just have some morality this law looks interesting
so there is some boolean conjunction here so how are we how will we
deal with it or we need a book of this to be able to do so we need
to know what happens when Bob is applied to the conjunction of two
predicates how is that expressed through a both of the two predicates
alone through Bob of p1 and whoop of p2 well it so happens that for
the option this is the code so we need to take Bob p1 applied it to
X to X and then to do a flat map on the resulting option with Bob
p2 so that is maybe unexpected let\textsf{'}s look at the code that shows yeah
so here\textsf{'}s by the way deflate from map option and map option from the
flight and again the check in that they are equivalent when we will
take one from the other so let me explain this a little later but
let\textsf{'}s look at the boolean some property of Bob the conjunction property
so we can check this property by a numerical test or we can check
it symbolically so numerical test is that for any X a bob of this
applied to X is the same as that formula drop of P 1 of X flat map
book Peter why is that well so we can write out the code the Bob is
defined as some dot filter so we have this code some dot filter means
that since this is already non-empty option if P 1 of X and P 2 of
X then it\textsf{'}s sum of X else is known so that is the left-hand side let\textsf{'}s
call this expression 1 the right-hand side of the law is that we have
what P 1 of X flat mat book Peter now book T 1 X is this which is
this expression so now we need to flat map this with something how
do we flat map well if the option is none then the result is none
now if it\textsf{'}s not known when we need to check if P 2 applies and then
we still have a son otherwise we have known so we have this code if
P 1 then if B 2 then some else none else now so obviously with only
return sum of X when both conditions hold so that is equivalent to
this which is expression 2 and expression 1 and expression 2 are identical
so we see that flat map actually expresses the boolean conjunction
in some strange way so this was the property that we needed and actually
this is very important we will be using this a lot in this this formula
so let\textsf{'}s have a notation for it so this is kind of a composition of
Bob Irwin and Bob - Bob p1 and don't be - let\textsf{'}s go let\textsf{'}s call them
Q so Q actually is a function from a to 1 plus B and Q 2 is a function
from B to 1 plus C and we can write this formula like this q one of
X will be option of B we can flatmap this with q2 and get an option
of C and so the result is a function from a to option C so this is
a kind of composition but the types of the functions are kind of twisted
so the usual composition would be if the types were a to B B to C
and the result is of type A to C but here instead of a to B we have
into one plus B so option B here we have B to one plus C and here
we have a to 1 plus C so every time the type of the function is twisted
there is something added to it on the right hand side but it\textsf{'}s the
same thing that\textsf{'}s added every time so it\textsf{'}s that it\textsf{'}s some functor
that is put on top of that so this is called nicely composition in
the general case of the closely composition is for some functor m
where you have a function from M to M a - M B from B to MC and you
can post these two functions and you get a function from A to M C
so you twist the type on the right hand side of the function by applying
some function m in our case the function M is the option factor so
we just applied 1 + 8 so we twist with 1 plus a at the right hand
side so in this tutorial we'll only be using this closely composition
with this function or as I said twisting the notation for that will
be closely opt and I would use a diamond opt diamond with subscript
opt to remind ourselves that we are only using this specific case
we're not going to be you in the general case in this tutorial but
the general case is extremely useful nevertheless so that\textsf{'}s why I
wanted to mention it so this is called the Kleiss lis composition
so we're using the Chrysler composition for the specific case of option
so this is the closely opted composition and interestingly this composition
has an identity element which is a function of this type that returns
the non empty option this function is an identity for this composition
so if you take this function and compose it with this operation with
any other function you get that function and so we will show now that
the classic composition operation is associative and respects the
closely identity just as a normal compositional would so this is very
interesting because it is a full analog of a normal composition of
functions with identity function and associativity of composition
however the types are twisted so how can we can even do that so the
reason is that are twisted in this way so this is a special kind of
twisting that allows you to to work the option is a very special factor
and that\textsf{'}s why it works and let us now look at the code that shows
how this all works so we define a closely opt composition which is
a function from a to option B from beta option C into a two options
the code of this function is left for automatic implementation we
also define an implicit class for syntax so that we can say this we
can use this symbol to compose using the class Li opt composition
law so we just refer to that function we define the identity which
is a function from a to option a again this is left for automatic
implementation but this is basically some dot apply so X goes to some
of X just so that we know what it is but that\textsf{'}s what it is I'm going
to be implemented and then we check the laws so we say well I have
this now func function equation utility and it checks that functions
are equal just for from brevity so this is exactly like the associativity
of composition except I replace the composition symbol in the little
circle with this strange symbol but that\textsf{'}s the only difference so
this is the closely composition and that is associative and also the
identity so identity on the Left composed with F is equal to F and
identity on the right composed with F is also equal to F and I check
that with various types but also I can derive the symbolically deriving
and symbolically is again a matter of writing out Scala code and transforming
it as if you are evaluating so I will leave this for you to look at
I will just go through the first few steps that are necessary the
important thing to make it easier that you can just do it brute force
you can just write out this code and check everything but it\textsf{'}s much
easier and more visual if you decompose the function of this type
into a pair of functions one is the filter function and the other
is the transformation function so remember that this function represents
at once filtering and transformation but it is easier to reason about
it if you decompose them into filtering separately than transformation
separately so let me do that here is how I can define F is if I have
P and Q here\textsf{'}s a how I define P and Q is if I have F so they are equivalent
so I can define one through the other and the others would have the
first one so then I note that the composition the closely opt composition
expresses boolean conjunction we have seen as before but now I'd like
to see this more explicitly in fact so what is the class the composition
of the two functions and while I transform the code in the same way
I did before I expand then there\textsf{'}s an if when I put the flat map inside
the F and so on and I find that the P and Q component of the composition
is expressed like this so T composition the filter is the boolean
conjunction of the two filters except that the second filter has to
be applied to the transformed value of x because it could be a different
type and the queue functions are simply composed the transformations
that are inside here are actually composed in the usual way but the
filter is composed using the boolean conjunction and so this is why
the walls hold obviously a laws will hold for Q because the ordinary
composition is associative and respects the identity and by the way
the identity function is mapped into a filter that is identically
true and a transformation that is identity and so obviously then the
filter will be identity element for this because this will be identically
true and something that will be equal to that something whether it\textsf{'}s
only right-hand side or in the left hand side and identity and in
these logical so it is for this reason that the laws hold you're welcome
to check in more detail all these calculations and I would like to
wrap up the previous topic the transformation from one function to
another and just illustrate a Scala trick here so I want to define
a deflate function from this map option and I want to deflate to define
map option from the flight however I have a little trouble here during
this and the trouble is I want to define a function deflate from map
option which takes an argument that is map option characterized by
a and parameterize by D but a and B must be special you'll be chosen
so remember how I define it here the flight is defined through map
option when I set one of the parameters to one plus a another to a
well I could I could write B here instead of a so it will be B baby
baby so I could say I say I sat in the D flight I'm sorry uncertain
the F map opt I said a to be equal to one plus B so a must be optional
D but how do i express this in a function map option is a function
with this signature but I need to set somehow the type a equal to
the type option B so that this is actually the same type and I can
put identity in there how do I do that so I use produce the cats library
which contains a useful utility called is so this is is a type constructor
which is parameterize by two types the Scala syntax allows me to write
is in between a and option B but you can see that is is defined just
as a type constructor with two type parameters and is a the class
that holds evidence that this type is equal to that type what does
it mean to hold that evidence it means you could in using this value
you could transform this type to this type or backward with no computation
we just map identically so this evidence would not compile because
you don't have the implicit value if these types are not equal when
you actually call this function so when you define the code of this
function you don't know what a and B are and you say they must be
equal so you have evidence that they are equal but what when you actually
call this function which will do the you needs to write the types
correctly so that actually they are equal and then it will compile
these implicit evidence will be found so once you have this implicit
evidence so then you return this you have a for example an X of type
a but a is option B so how do you get an option B out of it well you
use the squares function which takes an a returns not should be in
this case this function is automatically defined but only because
you have the evidence that a is option B and here\textsf{'}s the substitute
function that will transform F of option B into F of a now a is the
same as option B so this transformation actually doesn't do anything
it doesn't perform computations very convenient and flip means that
you you do it in the other direction so substitute will do FA from
F function B to F a but without flip it will go from F a to F optionally
so with this evidence you can easily coerce one type into another
or the second at first and also with any functions you have functor
and we do have a functor here so we need actually to check the types
and make sure that we are given we're given fo B which is a type F
of option B but we actually need F of a to call the function and that\textsf{'}s
what we do here so we substitute which is a function defined for his
in the cat\textsf{'}s library that\textsf{'}s very convenient it\textsf{'}s a bit of writing
to get all these types correct and actually all this performs no computation
at all because this is just identical equality of types of X is just
of this type or that type it can pile time at the run time is actually
the same value because when you call this function you must use the
same types so there\textsf{'}s no or very little overhead and calling these
functions they don't actually perform computation so if you have a
big data structure here and this is immediate this is very quick to
do that there\textsf{'}s no computation so how do we call that so here\textsf{'}s how
we call that we specify the types option B and B and then this is
a type a right so this is a type parameter a in that function and
we specified directly as option B and that\textsf{'}s why here as well yeah
we directly specify that and that\textsf{'}s why it compiles so that\textsf{'}s how
we implement what\textsf{'}s in the slide here we call F map opt with option
B \& B as type parameters here is option a and a or Justin and we
check that the deflate obtained by direct definition was equal to
deflate that obtained through the map option which itself was obtained
from the flight and just rename this for consistency so these computations
illustrate the equivalence between F map option D flight and the properties
of the class like composition so let us look at the type signature
of F my opt once again it takes a function from a to one plus B and
it returns a function from FA to LV in other words we can imagine
that we have this set of Kleiss Li functions which are functions with
this type which is kind of twisted so these are the nicely opted functions
or in the language of category theory this is a function that belongs
to the class like category with opt functor now for us this is not
particularly helpful right now we are actually coming from another
direction we found that these functions were helpful and we are studying
their properties and we discovered that they have this product the
composition of functions of this type which is very similar to the
usual function composition and this function f map opt is very similar
to a usual F map because it lifts the function of this type into the
functor except for this twist so it lifts a function from a to one
plus B into a function f A to F be not f1 plus B but F B so this is
a twisted kind of lift but it\textsf{'}s very similar to a usual F map it lifts
a function from A to B into a function from F A to F be in other words
it lifts a computation into a functor context it makes those computations
occur on values that are held within a functor so this is a very similar
kind of lifting although it\textsf{'}s with a twist as twist is of course highly
non-trivial we have a lot of work to do to deal with this but once
we have done this work with C and that this formulation is actually
very intriguing it\textsf{'}s very similar to just lifting a function into
a functor context so in fact {[}Music{]} only two laws are necessary
for this F map opt namely this law that if you take identity function
then the lifting of that into the functor context gives you identity
function on the functor in the container and second law is the composition
law which is that if you take the composition of two lifted functions
that\textsf{'}s the same as the lifting of the closely composition of these
two functions so let\textsf{'}s look at the type diagram for the composition
we have F a FB and FC so let\textsf{'}s say F goes from 801 plus B G goes from
B to 1 plus C then the closely composition of F and G goes from a
to 1 plus C and F map opt would lift each of them but this lifting
is consistent so this way gives you the same value as this way and
that\textsf{'}s the left-hand side gives you the same value as the right-hand
side so the two laws for F mapped are very similar to the two function
laws if two functor laws were that lifting an identity gives you identity
and lifting a function and composing it with a rather lifted function
is the same as lifting of the composition so they're very similar
here except that the types are more complicated they're twisted and
as I said and the composition here isn't nicely composition so this
is a kind some kind of twisted composition and your more complicated
types then the the functor laws but conceptually they're simpler actually
they're also more complicated than the filter laws conceptually they're
simpler they're fewer and easier to understand this is just some kind
of twisted lifting from from one kind of set of functions to another
and {[}Music{]} from functions of this type to functions on the container
and the lifting of course must respect the usual laws it must lift
identity to identity must live composition to composition so that\textsf{'}s
kind of natural and there are no more laws so there are only the natural
laws for for the factor just twist it so let us show that this is
indeed so mean I just claimed so fine didn't really show yet and that\textsf{'}s
only two loans are actually necessary let me see how that is proved
so let\textsf{'}s start with the law 3 which is the filter with a identically
true function now that function after you pop it it gives you this
and so this composition is the F map opt of the clearly identity because
actually the book of this filter function is exactly the function
that is the closely identity business this function doesn't let me
highlight correctly this function so therefore if the filter law is
true then this is an identity and so then the F map opt of identity
must be identity and if this is true and the filter must be identity
so old law 3 is actually equivalent to the identity law both of them
imply each other because of this equal votes are equal science everywhere
so that\textsf{'}s very strong identity done isomorphism now we need to derive
the laws 1 \& 2 obviously we have only one law the composition law
left and somehow this one law should cover two old laws at once how
can that be so let\textsf{'}s see we know that the conjunction responds to
the classical position let\textsf{'}s so the way that we can take one law and
get two out of it is to use different type parameters in this law
you see this law has three type parameters a B and C we can choose
them to whatever we want and you choosing them in different ways can
give us different perhaps specific laws and that\textsf{'}s what we shall do
now so let\textsf{'}s consider nicely functions only of types it goes to one
plus a no other types so we're choosing the type parameter in the
class Lee in this way and then actually we can see that the filter
composition is equal to this so Q I'm just defining for gravity that
Q is Bob of P so all Q\textsf{'}s are of this type and then the filter is equal
to f map opt of Bob right so in other words F map opt of dope of p1
which is Q 1 in position with F map opt Q 2 that\textsf{'}s the composition
of two filters now by the composition law we have this and then we
know that the composition of the class ly responds to the Bob of the
boolean conjunction we have already derived that so this derives the
law to law one is a little longer to derive because it\textsf{'}s a natural
to know it has more stuff in it it says that F map can be interchanged
with F map opt so notice that here we have specialized two functions
of this type of the class Lee functions of this type here will always
also specify a specialized namely specialized two functions that are
filled that are ordinary functions transformed into a closely opt
kind of function which we will denote by K F so K F is a function
of a twisted type that corresponds to some function f of an ordinary
type by always returning the non empty option so we just take a we'll
apply F to it and always return a non empty option never return empty
option so that is basically a composition of F with the identity in
the class Lee and because of this we have the property that F map
opt of K F is is by definition is this we can then decompose the F
map because K F is the composition so we can decompose that into F
map lesson F map of it and F map edan on the flight is identity because
you can you can check that and so yeah let\textsf{'}s let me think why I did
not say anything here about why this is identity so if you F map the
identity in the closely means you map F of a into F of one plus a
but in that F of one plus a there are not there no empty options because
the identity never produces an empty option so then when you deflate
that there aren't any empty options and so that it returns you the
original container but in principle this actually oh that isn't actually
easier by definition this is f map opt of it opt because this is F
map and then the flight is the same as f map opt by definition and
so by the identity law this is equal to identity so therefore this
is equal to F map F so f map opt of this transformed function is actually
the same as I've met Beth therefore we can just rewrite this law using
F map opt of K F instead of F map F when we do that we can use the
fly sleep composition and so then for example we will get this using
the closely composition of K F and Bob P which we can then simplify
because we know that the KF times what P we can just you can just
expand we know that that Bob P has this has this law sorry it has
the law that we derived before this one we know that both P has this
law and so therefore we can transform this into that the only thing
we need to do is to see that if we if you do a closely composition
like this and actually this is an ordinary composition with F so all
of this hinges on the fact that K was defined from an ordinary function
f so K is not an arbitrary clastic function it\textsf{'}s a class a function
that never returns empty option and so it\textsf{'}s much simpler to compose
anything with it you just compose normally like this and then finally
you substitute that in there and you find that this is equal to that
they are under F map oops and so therefore the one holds I encourage
you to go through this may be slower but all the steps are written
here we start with this when we write we define an arbitrary function
f then we define K out of that F and we show that we need we can rewrite
star as this equation then we show that what is under F map opt is
the same by transforming the left hand side into F and then book P
the right hand side into Bob FP and them F may opt so we just used
set of Q here and we use this instead of Q here we use this and we
obtain this property which we already showed previously so let me
summarize what we have found filterable functors can be defined in
different ways we can define them using a filter function using a
deflate function or using F mapped all these three methods are equivalent
expressed identically through and so if you have one of them you can
define to others but these methods have different roles for us in
the program code in the funster blocks we use the if operation the
easiest reason about in the code is that operation which corresponds
to a filter or with filter a type signature that is the simplest is
that of deflate that is the easiest goes to implement and to reason
about conceptually however the F map opt has the simplest laws it
has a just two laws which are functor laws with a twist now let me
talk a little about category theory so the to function laws with a
twist are accommodated by category theory as just some kind of generalized
functor laws or other words in other words as ordinary functor laws
for some kind of a twisted functor and the twisted functor has twisted
function types and so if we for example look at type signatures of
f map contrived map and f may poped compare them you see this is an
ordinary of map type signature this is the contra of map type signature
and this is the F myope type signature so they all look like some
kind of lifting of functions from here into a functor context or container
on a Content context but this lifting is ordinary and this lifting
is from reversed functions and this lifting is from these twisted
closely opt functions otherwise it\textsf{'}s very similar the laws are the
same identity law and composition law now here of course we have contract
on position so composition here goes in the into the other direction
that\textsf{'}s natural because we have twisted the composition because we
have twist the type here the composition has a class like composition
we have to twist it so cutting category theory says let\textsf{'}s consider
all of them as actually functors but on the left hand side you have
something twisted so you have a twisted founder here that\textsf{'}s how category
theory generalizes all of this into lifting so it\textsf{'}s always lifting
from one kind of arrow to another kind of function arrow to another
kind of functional arrow with twisted types now category theory gives
us intuitions about how better laws could be derived and two of these
intuitions we have seen is one is that it\textsf{'}s probably helpful and useful
if we look for type signatures that look like lifting if we find a
function like f map opt whose type signature looks like lifting then
it\textsf{'}s probably very useful because then you can expect that you just
need to twist the composition here somehow of these strange twisted
functions other than that you have standard functor laws just the
two laws and they're standard very easy to understand identity and
composition so at the price of twisting the type here and here and
using a different composition because the types are twisted second
hint is look for natural transformations and use a natural T law to
interchange F map and whatever you need so you can do that and that
allows you to reason about the laws and derive one law from another
so that\textsf{'}s kind of intuition that natural transformations are useful
because they have this natural reality where you can flip F map across
them and that is useful for deriving the laws so notice how we have
arrived at this point we have started with filter we derived a large
number of laws of four okay twice as many as now a number of laws
for filter and then we were looking for a better type signature basically
a smaller more kind of reasonable type signature deflate had a great
type signature but F map opt has fantastic excuse me fantastic type
signature because it\textsf{'}s it\textsf{'}s a lifting and it\textsf{'}s laws are very easy
however category theory does not directly provide any derivations
from these laws so I don't think you will find these laws from any
category theory look filter and deflate are not usually found there
or the laws from them category tier is too abstract for that it gives
hints about what you could do but it doesn't give you laws or equations
for these functions or specific types doesn't also doesn't tell you
that this should have been the type that is at the root of being able
to filter not actually somehow you need to look for class Li and use
the option to twist the class Li category theory doesn't tell you
that you start with filter and you think you're doing something very
down-to-earth filtering values out of sequences and actually at the
root of this there is this twisted Kleiss Li opt category of functions
but category Theory doesn't tell you that you have to derive it yourself
it does not also it doesn't help you derive that either just gives
you hints about how you might be able to do it in particular look
for a lifting like type signature but we were lucky to find it there\textsf{'}s
no easy way of deriving this so what are the further directions that
category Theory hints about I can give you two examples so now that
we have seen this pattern let\textsf{'}s investigate other kinds of liftings
for example well if here I have some and a 1 plus a 2 B or something
instead of this what if I here here have F of a to be instead of A
to B well if I have 8 a 2 F of B with the same F as this will I have
something else would have I can try to investigate different kinds
of liftings and see if they're interesting or useful but this actually
so this is one kind of abstract direction we could go now I'm not
going to go into that direction I'll explain why um another thing
you can do is to replace the option in this construction by another
function so not F but let\textsf{'}s say some m and then let\textsf{'}s see what happen
is then we'll have some different twisted thing and let\textsf{'}s try to interpret
it so why I don't want to go into this direction is because first
of all there\textsf{'}s no end to different functions or types that you can
write down there\textsf{'}s no end to twisting and generalizing and putting
more functors here you know F of F of B of F of something there is
no obvious limit or obvious direction where to go so infinitely many
possibilities are open and you can spend a very long time studying
all of those possibilities with not much of a practical use it takes
a very long time to discover which are practical things that you can
use and which are just theoretical things that don't necessarily give
you a lot of practical value so one approach is that I start with
examples we start with practical value that we obviously see in code
and then I generalize so I generalize a certain to a certain extent
to a certain degree and then stop so certainly where to stop is a
judgment call there\textsf{'}s no obvious decision to make and you need to
understand have some intuition about how much generalization is useful
and how much is just I don't play you could you could go very far
here in generalizing and category theory especially encourages you
to generalize with very little regard for practical use and I don't
think that\textsf{'}s the direction I want to go so having said all this let
us look at the practical question what are the filterable factors
if I give you some type how do you know that this is a filterable
factor so let\textsf{'}s eat to answer that question let\textsf{'}s use intuition from
our deflate type signature so we reshuffle data in a container by
replacing some values of type a by unit and reshuffling means we just
reuse a different part of disjunction usually not always so therefore
we can try to reason about it and say look at the type and try to
substitute one plus a instead of a in the type and see if you can
reshuffle the results to get what to get FA again if you cannot it
means you cannot in and deflate I showed you examples of that some
simple ones and then it\textsf{'}s not filterable but if you can then you can
look further how you want to make it filterable and especially for
your particular requirements of your application and to get some intuition
about this let us consider how we can build up filterable factors
from parts this is very similar to what we did with ordinary factors
so we will now list some constructions certainly not all possible
constructions but some sufficiently large number of constructions
and give you new filterable functors given old ones and let\textsf{'}s see
how that works so first of all a constant function meaning that for
all types aids it\textsf{'}s a constant the same fixed type Z and for that
functor we define F map opt as identity so whatever type you have
here you can transform it from A to B but Z stays the same just identity
so filtering does nothing and filter is identical constant I'm sorry
add an identical transformation and Z is some fixed type so that is
filter book note that this is not floatable the identity function
for the reason that you cannot transform one plus a into a unless
a is a pointed type but this needs to be for all types so it is not
filterable the typical constructions that we have for functors are
that you have a product of two functions and that\textsf{'}s a function same
for filterable sum of two functions is a function same for filterable
composition of any factor and the filterable factor is filterable
now this is not necessarily Tolcher well this has to be so if you
compose them then it\textsf{'}s filterable this is a construction that\textsf{'}s specific
to fill troubles and this is a functor that needs to be filter ball
already and then you can do this and you again get a filterable factor
so notice we can replace this one with a pointed type so we can do
this a pointed type is basically something that\textsf{'}s that has an element
that\textsf{'}s selected somehow so we could imagine that this is isomorphic
to a disjunction of either you have that selected element which is
represented by this part of the disjunction or you do not or your
value is not that selected value and then your in this part of the
disjunction so all the values that are not selected are in this type
Z somehow defined and the selected value is represented by this unit
so this is an isomorphism that you could imagine not necessarily very
useful as a morphism but you can imagine that this is one plus Z and
then this is one plus something so one plus something as a as a rule
is filterable similarly you could do mini-mini so how do you how do
you filter this if a passes then you filter this and you are still
in the same part of the disjunction if it does not pass your return
unit you ignore that you just drop from those now so a recursive filter
will functor we had an example where this was I believe a unit or
something but if G is filterable then you can add this and this is
a recursive function that looks like a list a little bit except that
the empty list is not empty but this G and then you have a and then
again a and then again a and and some G so this is a list like functor
and it is filterable in the same way that lists are and the final
construction is that you take some country factor which has to be
filterable as well and that function gives you a filterable factor
here\textsf{'}s an example of something that\textsf{'}s not filterable again if you
have them even if this is filter rule this is not filterable and so
this entire thing is not filtered back so let us look at some of these
constructions in detail and see how the laws can be satisfied so take
the construction of product if the laws hold for the two factors so
they are both vulnerable then let\textsf{'}s do F map opt how do we define
F map opt for the product factor so we have F map opt for the F and
F map opt for the G we have them and now we need to define a map opt
for F G so we define that by taking the product of the two values
one was type F a another of type Q and G a and we do F map opt on
both of them separately obviously that\textsf{'}s an easy way of doing it the
identity law calls because it holds for the two as my box F and G
and therefore we have a product of identity of P and identity of key
as being composition law holds because the composition acts separately
on P and Q and so we have composition of 2f map opts F and tulip earth
map opens G separately so these are we are not mixing up P and Q so
let me pop F only X on P and F map up G only X and Q so when you're
mixing it up and so the composition act separately on the two parts
of the conjunction on the product and therefore the lowest hold now
we can transform each composition using its own law this must be again
diamond opt I forgot the subscript here and finally we get what the
law for the product function notice this is exactly the same proof
as for the functor property if you look at the chapter four we we
have the same construction for product of two factors being a factor
and the proof for the two laws of factor is exactly the same except
for the diamonds and these other notation F map opt instead of F map
otherwise it\textsf{'}s exactly the same computation one-to-one why is this
it\textsf{'}s because in category theory F map opt response to this generalized
functor between a twisted class three category nicely opt category
which is kind of twisted and the functions on the container and so
because it is a fun treat has exactly the same properties of any factor
once we define it that way all the proofs remain literally the same
except for notation new proofs therefore are necessary only when using
non filterable functors when we cannot represent all the factors in
our construction as filterable which is constructions four to six
in constructions four to six son functor is not filterable like this
one and this one and in this construction France and they're both
filterable and so in the category Theory formulation that would be
just functor so that would be exactly the same proof as that this
is a functor if this is a country furniture and this as a function
so we don't really want to repeat the same proofs and just putting
in some new diamonds and so on we want to look at proofs for new interesting
properties here\textsf{'}s the property that lost hold for this type if they
hold for GF so how do we define the map opt F map opt act on this
disjunction if the argument is in the right part of the disjunction
of this form then we return the right part and or if there are if
not only if the argument is in the right part in the disjunction but
also if the function f acting on a is in the right part of its disjunction
so this is there are these two conditions if these two conditions
hold then we'll return the right part of the disjunction which is
we return this B that was transformed from a and we transform the
Q in using its own F map opt otherwise we return the left part of
the disjunction so that is how we define the F map opt I remind you
F map opt takes a function that transforms and filters at the same
so this function could give you a left the left part of the disjunction
the empty option or it could give you a newbie new value so if it
gives you a new value then on only then will return the right part
of the junction with this new value because we're it\textsf{'}s supposed to
return FB so we need to return one plus B times G B and so we return
b times the f map opt and the g filter will factor now we check that
identity law holds is straightforward we take F in this definition
to be the identity in the closely I hoped category so then I'm saying
category just to get familiar with that terminology all I mean here
is that this is a function of type a to one plus a and mean nothing
else and we know that functions of type a to 1 plus B have the property
of this twisted composition and they have this twisted identity and
that\textsf{'}s what we that\textsf{'}s all we know but that\textsf{'}s what it means when I
say it\textsf{'}s class like adding or it\textsf{'}s these functions of these funny
types that have this funny composition so taking F here to be the
flyest identity we find that F of a is f of a is by definition 0 plus
a by definition of this and so f map of the graph is identity by the
identity law in the G not supposed to hold and if we put it in then
1 goes to 1 and a times Q goes into a times Q so that gives you identity
composition law we only need to check that if the argument is of this
type and only when all the functions return the right hand side because
if if even one of the arguments in the composition returns less inside
anywhere then the entire thing was going to return left-hand side
and then all laws will hold because there will be none it was none
in all laws so the only non-trivial case that needs to be checked
is that everything is in the right side of the disjunctions in that
case the conjunction also is in the right side and then we need to
check what happens with this thing and of course that\textsf{'}s that\textsf{'}s really
easy because everything is just working on this right-hand side F
map opt of this is by definition that and we again apply F math opt
and we again have some C which we assume this everything then we'll
the right hand side then we have composition of F math opts in the
GE filter we'll factor that has its own law so we transform it like
this and finally we get the F map opt for F from the composition of
the functions on the right side of the disjunction so the interpretation
of this filter is that it\textsf{'}s kind of greedy if if a does not pass the
test and all the data here is deleted even if they all pass the test
the a is kind of very very special and if that only if the a passes
the test and we filter this and see if any of those pass the test
but if a it does not pass we return one so this is kind of a Brady
filter so now I've shown that its laws hold let me actually look at
some code see if I have oh yeah it\textsf{'}s nicely up category and we have
seen this and {[}Music{]} yeah this is in implementing filterable
typeclass using the flatten instead of instead of a filter and this
is just the check letitia\textsf{'}s satisfying the wall so let me go to my
worked examples for this chapter so these examples show you that sums
and products and all filter balls are filterable so here I have an
implicit def that produces an evidence for functor given the two factors
F and G so that is done using a type lambda here and then I'll just
do the laps on the factors in the usual way the Sun is the either
and I say that if I have F and G functors and I have a functor instance
for either FG so that\textsf{'}s trivial the fermentation here and I do very
similar very trivial implementation using deflate very easy to do
because of its type signature and I show that if F and G are filterable
and if there are factors at the same time says syntax in Scala is
like this : filter book : function and I have both evidence values
then I produce a filterable for this type constructor which is a type
lambda which is a product of F and G and I do the same with yourself
so the implementation of deflate is particularly easy I'm given a
tuple of F option AG option a I'm supposed to return a tuple of f
AG and that\textsf{'}s easy I just deflate both of them separately similarly
with the either and given to an either of a function AG option a I'm
supposed to return either of FNG a and I just match and deflate separately
and I can wear this red did I change maybe maybe I need to refresh
this because the tests tests passed I check the laws I have some data
and I use the borders now the orders to is the tuple of two orders
and orders easy either of two orders so I use the orders and then
the filterable instance for orders is already defined and then I have
already filterable for orders to in order Z and here is the code for
the construction of functor construction v where I have a functor
Jeep which is filterable so first I say that the function f that I
define like this so F of a equals one was a G okay first of all I
need to show this has a functor instance given that G has one so that
is straightforward I need to do this option map and so on and I do
the same with deflate so if G has a filterable and functor instance
then I produce a new evidence for filterable instance for the type
lambda which is this and the code is simple kind because of the signature
of that option of optional a G of option a and I'm supposed to return
an option of a G of a so I just met on the option and flattened and
I'm sorry deflate cannot swallow here I have to deflate as deflate
is an arbitrary function G and then I use flat map on the option because
this is an option type so I use the standard flat map on it so that\textsf{'}s
basically it and see what was was changed not sure what was changed
now let\textsf{'}s check it after this recording just to make sure everything
compiles if I find anything I'll make a patch and upload it the next
example is the recursive construction where you define a new factor
with Perceval using an already existing filterable factor G and you're
adding a new data item and again an instance of recursive function
so this is like a list except in the list this would be a unit and
now here we put a unit is filterable trivially now we put an arbitrary
filterable here so an interesting thing about deriving this law is
that the proof must be inductive because the type is recursive so
given a function f from a to it 1 plus B we have the F map opt for
the filterable function G so we have that and also we have F map opt
for F which is the inductive assumption so I use it I use the prime
here to show that this F map opt is not the one we are going to define
but it\textsf{'}s the one that we already assumed to exist and to satisfy the
laws in the previous inductive step so this is the inductive assumption
that\textsf{'}s how we're going to derive the laws we're going to say if this
F map opt is already satisfying the laws and we will only use it when
we call the recursive F map opt in the definition of this function
filterable functor and so when we use the recursive code we're allowed
to use this recursive definition which already is assumed to satisfy
all laws but then we prove that the definition of the next step satisfies
the laws so here\textsf{'}s the definition we define f map opt by first of
all looking at f of a so first of all if we're in the queue then we
just return if we're in the left side of this disjunction we just
return the F map of G applied to this so there\textsf{'}s not much to do if
we are in this part of the disjunction then we need to check whether
F of a is in the left or in the right if it\textsf{'}s in the left then actually
we do an interesting thing so if this does not pass the filter then
we we can't return this because we don't have a value of Q of type
G we return this filtered so so we descend into the recursive instance
we discard this a this a with this card and we return this filtered
this P filtered using the recursive instance of F map opt so we call
ourselves we call this function that will derive defining now on this
P and we return the result why is this valid it\textsf{'}s because the type
is recursive so when we return that that will be of type FB and that\textsf{'}s
exactly what we are supposed to return because this type is the same
as this entire type this entire disjunction is the same as this so
we are allowed to return it in there in the core otherwise we so if
F of a is some be in the right side then we return this B times again
the recursive filter result of this so we can return the right-hand
side of this disjunction which is fine we can return the left-hand
side of this disjunction if we have a Q or we can return only this
piece after filtering because the type of this piece is the same as
the entire type by the recursive definition so this is a definition
of F nap opt of F let me show you the code to perhaps make it more
clear how the recursive thing works so here is a definition of this
construction using the type constructor c6 it\textsf{'}s paralyzed by filterable
function G and type a so then you have this disjunction so this is
this disjunction the left side has a G a on the right side has a product
of a and FA which is itself of the same type c6 so this defines this
construction so now we have a convenient place to put all the implicit
for this type and Scala allows you to have a object with the same
name as a type constructor and if you put implicit into that object
then whenever you use the type constructor these implicit are visible
you don't have to include them yourself or import them yourself that\textsf{'}s
very convenient but saves you typing and looking for where these employees
must be and so here we put a functor instance assuming that G is a
factor and the filterable instance assuming that G is both filterable
and fund although the filterable typeclass requires function so we
could have just gotten the functor evidence out of filterable evidence
but it\textsf{'}s just for convenience to have both and now let\textsf{'}s look at the
code the both the functor instance and the filterable instance must
be recursive because it\textsf{'}s at a corrosive type so the map function
takes a c6 of GA so a function from A to B and returns a c6 of GB
so there are two cases the base case you just map a GA which should
be fun to play assumption and note that this dot map syntax is available
because cats library allows you to do this with simple input which
I believe is just import cats syntax functor dot underscore so I can
just use this syntax easily anything that\textsf{'}s declared as a factor and
the step I have two values X and s x fa the recursive value of c6
so I apply F to X and I map which is the same map here and map recursively
and the function f over this thing same thing I have to do with the
flight I have to probably have a base I can do flight that if there
is a step that means I have two values here both of them are type
option and I need to deflate the first of all and the second so the
first if the first is not empty it means that in this type this a
passed the test so note that in the slide I had F map opt define but
here I have flat undefined because it\textsf{'}s easier but it\textsf{'}s the same thing
I need to decide what to do when this passes the test or doesn't if
it passes the test I return that thing deflated and I deflate the
other part this part recursively so this is the recursive call of
this to the same function and if the pay is not passing the test if
this option is empty then I need to deflate this recursive value and
return its it deflated alone so that has the same type as the entire
functor and that\textsf{'}s why I - return the 20s so just to make a correspondence
between what I have in the slides and what I have here in the code
it is easier to implement flatten sorry deflate it\textsf{'}s easier to implement
deflate then it is to implement F map opt or map option or anything
like that but it is equivalent so all the decisions we make when we
implement f na opt are made here exactly the same way we need to flatten
sorry to deflate G of option A plus option a times F of option and
so every option needs to give us a decision how to flat deflate it
into a non option type so in our FF definition we had exactly the
same exactly the same question how to define the result of F map opt
when this is given or when this is given and the result of F is in
the left and some one so then we check identity law and the composition
law so identity law it\textsf{'}s easy to check because the identity function
never returns an empty option so we're never in this case and therefore
either we are here and we return the flattened queue the deflated
queue which is just the same for identity or we on the right and then
we have a times P and then we just return the same because a recursive
instance of if map opt already satisfies the identity law and so when
we when we apply that to P we get P identity so in this way we use
induction plane mathematical induction to show that laws hold the
composition law holds in the same way so we need to show this holds
now if the arguments are in the left then it\textsf{'}s just about a loss for
DNA which are holding by assumption if the arguments are in the right
in here then we need to look at what\textsf{'}s happening so we have F 1 and
F 2 and there are four cases so well either if both of them returned
in all empty then the previous proof will go through this one it\textsf{'}s
exactly the same so we need to consider the cases when one of them
returns non-empty if the first one returns empty then we are returning
the recursive instance so there is nothing more to show the second
one will never be cold so we need we need actually two more cases
only the first returns empty and the first returns non empty but the
second returns empty so just remember to remind you decomposition
alloys assuming two arbitrary nicely functions so a - 1 + B beta 1
plus C and we need to show that F map opt gives you the composition
so if the first function returns an empty option then this also returns
an empty option because the class decomposition is the boolean conjunction
of the two filters so if one of them returns emptied in both conjunction
also returns empty so then it which it remains to show so we collapse
this equation because this is now 1 + 0 so we can use that face fruit
for the right-hand side we need to show this and that is just the
inductive assumption for left my post prime so if we are always in
during inductive case we don't want to prove any further it remains
to show this case again the composition is empty so it remains to
show that the F map opt applied to this and is equal to F map opt
prime because we are in the case of + 1 + 0 so there is nothing else
to do and we rewrite this and we again get just the inductive assumption
so this being equal to list so this filter is really lists like if
this is empty we we go into the nested data structure so if you expand
this recursive type it looks like GA plus 8 times open parenthesis
GA plus 8 times opening other parenthesis and so on so it\textsf{'}s it\textsf{'}s then
expanded into GA plus 8 times J plus a times a times G a and so on
so if 1a is empty you can always delete it and you are still in the
disjunction it just recurse into the nested fa and they were still
in in the disjunction so this is exactly like filter on the list the
final marked example is is this one this is a bit interesting so here\textsf{'}s
what we have we have a big type expression how can we show that this
is filter or order that is not it looks a lot of like lot of work
you have to write a lot of code and then check laws and what if you
implement it and then laws don't hold where did you make a mistake
oh that is a lot of work so instead of trying to do that we will analyze
the structure of this data type and use these constructions constructions
that are listed here and try to see if we can decompose this type
expression into these constructions so let\textsf{'}s look at it first of all
we have this int time string going to this big thing okay let\textsf{'}s denote
in time string going to able to denote this by r1 a and also we have
this int going to big expression so let\textsf{'}s call this R to a inte going
to a then we have one plus int of a instance a plus int times 1 plus
6 there\textsf{'}s this big piece and after that big piece is this function
type so the function type contains that so now we can rewrite it like
that so it\textsf{'}s r1 applied to the type GA plus r2 applied to AJ so that\textsf{'}s
great ga is filterable by so what is Jia is this it is filterable
because it has type 1 plus a times something right we can make this
a we can put it outside brackets and then you have 1 plus a times
int plus 1 plus a so n plus 1 plus a is let\textsf{'}s call it K and that is
filterable because it\textsf{'}s of the form 1 plus a plus constant and that
gives us filter rule by constructions 1 and 3 is a constant is construction
1 and the construction of 3 is the sum of 2 filter balls so constant
is filterable and 1 plus a is option filterable of course so therefore
K is filter mo therefore this is federal H is filter ball by the same
construction v again because 1 plus a time string is filterable by
constructions 5 and 1 so we can see this is constant so it\textsf{'}s filterable
then it\textsf{'}s 1 plus a times filter which is construction v this is again
construction v so H is filterable DS filterable and then we have so
r2 of H a is a composition of two functions with the compositional
factor r2 which is this and filterable so that\textsf{'}s filterable then we
have a sum of filterable and filter book therefore this is filterable
and then we have a composition of a factor doesn't have to be full
turbo in that construction and the filter wall so that\textsf{'}s that\textsf{'}s all
we just looked at the types and we use this see in this construction
the factor does not have to be filterable outside so this doesn't
have to be filtered this doesn't have to be filterable these functions
are just whatever functions we want this is filter ball and this is
filterable and we're done so we have shown and also of course each
construction comes with specific code that you can use to implement
the filter walls and so you don't have to worry about it anymore you
can just follow these these constructions you can write general library
that will implement all of these constructions as implicit and you
just call the functions from this line but you want something you
get it and implicit will be found automatically so one important comment
at this point is that first of all these constructions are not the
only ones available and second there are more than one ways there\textsf{'}s
more than one way of implementing the filterable certainly this is
one a valid way but there are alternatives and certain applications
might require different alternatives so if you remember the examples
from the previous the part 1 of this tutorial there are different
business requirements that might lead you to different in implementations
of the filterable and so you can probably add more rules more constructions
to this list but in in any case it shows you a large number of possible
factors that can have filter ball behavior and a large number of different
filterable behaviors such as greedy or collapsible or list like filter
behavior so you can combine them in any way you want using these constructions
here are some exercises for you to follow what we did and we worked
examples and finally some bonus about filterable control factors so
until now we were dealing only with filterable functions but actually
filterable control factors also are interesting and could be useful
and let me just conclude this tutorial with a discussion of filterable
control factors and the discussion will be again modeled after the
way we did we dealt with filterable factors first of all what are
the definitions and laws how do you define filterable control factors
so the filter functions have the same signature for country functions
and for fun clips the there is instead of deflator than there is inflate
which goes the opposite way and instead of F map upstairs contra F
map opt which also goes in the opposite way so again this is a kind
of a twisted function type it has first of all it it has reversed
direction so B to a and here\textsf{'}s a to b as appropriate for a control
factor but also it has this twist with the klystron opt category just
like the content ma opt all these functions are computation like we
want you can express each of them through any other so for example
filter through inflate contra F map is standard for contra factor
so if you have country factor you can express filter through inflate
inflate through filter control app opted to inflate inflate through
contrast map opt in very much the same way as we expressed and for
all four factors they have different laws for laws for filter 3los
translate to laws for contract map opt and as before contract map
opt is just kind of a twisted lifting what are examples of filterable
country factors so here some from a 2 1 plus Z where Z is a fixed
constant type from 1 plus a 2 Z or again C is any constant type what
is a non filterable country function for example this where F is whatever
you cannot implement inflate for it because what to implement inflate
you have to transform this into a sea of 1 plus a which means the
function that consumes UCC a is a function that consumes a and other
stuff C 1 plus a is a function that consumes 1 plus a and other stuff
to construct that function it means that you should be able to consume
1 that is a unit and go on and other stuff and go on but you don't
have that you only have a function that consumes a and other stuff
so you're required to consume a we cannot implement inflate so this
gives us some intuition about what filterable country functors do
first of all let\textsf{'}s recall the main visual image of what frontiers
and country functions do factors hold data a fonder F away in some
sense it holds data of type a and allows you to manipulate that data
a contra functor CA in some sense it consumes data of type a it does
not actually have any data of type a inside it consumes it like these
examples it is a function that consumes data of type a or some other
type related to a so a contra functor wants you to give it one or
more items of type a and then it will consume them and give you something
else which is not a a filterable country functor is able to consume
fewer data items of type a if you filter a country functor by a condition
it means you prevent it from consuming some data that does not pass
a test in other words let\textsf{'}s say it\textsf{'}s such a consumer that it is able
to consume less it is able to refrain from consuming certain items
a function of this type let\textsf{'}s take a simpler example a twosie with
this arbitrary factor being just unit a to Z is a function that requires
you to give it an A it cannot refrain from consuming an a there\textsf{'}s
no way for it to not consume an A this function on the other hand
can do it if you don't give it an A there is this part of the disjunction
and the function can take that and produce a Z so this contra factor
is able to refrain from consuming certain values and still give you
the result but this functor is not able to do that and so it this
contra factor is not filterable for this reason so this is the interpretation
that it can consume fewer data items if necessary by filtering them
out and the easiest function again is inflate so consider that function
and try to implement it here are some constructions some analogous
to filter both under constructions first of all a constant control
factor with identity filter then the functor constructions which are
exactly analogous to functor you don't need to check any laws therefore
really if g and h AR filter will control factors then the product
is filterable control factor their sum and the composition like this
is a filterable control enter and here you have different combinations
you can have a functor of a control function you could have a contra
functor of a function or you could have control factor of contra factor
the result will be a factor again filterable you can do this of course
if they're both filterable this is a factor this is a control function
and contravariance is here on the left sorry covariance is on the
left of the arrow so it becomes contravariant and so this is a contra
factor if they're both filter button this is also filterable that
is quite easy to show all of this it\textsf{'}s just analogous because the
laws are the functor laws it\textsf{'}s just a twist and the twist is irrelevant
for these constructions the twist just remains the same in all computations
so whatever twist you have on the type the proofs remain the same
for the factor construction now there are special constructions where
you have to deal with the twisted type I will not go through the proofs
of these but just to mention two of them so if you have this type
then you can filter because you can refrain from consuming this a
because you have the unit you can consume unit and here you cannot
refrain from consuming any but if there are no a is given you can
return one you can always return one how do you filter a control function
well you just give it before you give it the data you filter it out
so you give it less data and the Contra factors should be able to
handle that if it is filterable it should be able to consume less
data so that\textsf{'}s the intuition behind it and I'm not going to go a lot
into detail for but for country functions because so far haven't seen
a lot of obvious applications for them but certainly there might be
some this concludes chapter 6 or the functional programming tutorial 
\end{comment}

