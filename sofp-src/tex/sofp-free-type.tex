\global\long\def\gunderline#1{\mathunderline{greenunder}{#1}}%
\global\long\def\bef{\forwardcompose}%
\global\long\def\bbnum#1{\custombb{#1}}%
\global\long\def\pplus{{\displaystyle }{+\negmedspace+}}%


\chapter{Free typeclass constructions\label{chap:Free-type-constructions}}

Free typeclass constructions (free monoids, free functors, free monads,
free applicative functors, and so on) are used to implement the DSL
(domain-specific language\index{domain-specific language (DSL)})
design pattern. As a first motivation, we will look at how the free
monad\index{free monad} emerges from elaborating a certain kind of
DSL in the functional programming paradigm.

\section{Motivation for the free monad: create a DSL in five stages}

The main point of using a DSL is to separate the description of computations
from the process of their evaluation. One creates a \textbf{DSL program}\index{DSL program}
as a data structure that fully describes what computations and side
effects need to be run but does not actually perform any of those
computations or side-effects. Helper functions are implemented for
creating the DSL program values, for combining several DSL programs
into larger ones, and for interpreting (or \textsf{``}running\textsf{''}) DSL programs.

This design pattern is known as an \textbf{embedded} \textbf{DSL}\index{embedded DSL},
meaning that it is implemented not as a separate new language but
as a library in an existing programming language (e.g., Scala). This
chapter only considers embedded DSLs and calls them just \textsf{``}DSL'\textsf{'}s
for brevity.

We will look at two examples: a DSL for file operations and a DSL
for complex numbers. Refining and refactoring these DSLs to make them
more powerful and safer to use, we will obtain a construction known
as the \textsf{``}free monad\textsf{''}.

\subsection{Stage 1: unevaluated expression trees}

The first example is a DSL for reading and writing files at given
file paths. Direct Scala code for such operations may look like this:
\begin{lstlisting}
import java.nio.file.{Files, Paths}
val p = Paths.get("config_location.txt")
val configLocation = Paths.get(new String(Files.readAllBytes(p)))
val config = new String(Files.readAllBytes(configLocation))
\end{lstlisting}
The DSL will represent these operations by the case classes \lstinline!Val!,
\lstinline!Path!, and \lstinline!Read!:
\begin{lstlisting}
sealed trait PrgFile
final case class Val(s: String)   extends PrgFile
final case class Path(p: PrgFile) extends PrgFile
final case class Read(p: PrgFile) extends PrgFile
\end{lstlisting}
A DSL program of type \lstinline!PrgFile! is a value consisting of
many nested case classes:
\begin{lstlisting}
val prgFile: PrgFile = Read(Path(Read(Path(Val("config_location.txt")))))
\end{lstlisting}
Such values represent an \emph{unevaluated} expression tree corresponding
to the operations that need to be performed. To actually perform those
operations and extract the final \lstinline!String! value, we use
a \textsf{``}runner\textsf{''} function:\index{runner!for free monads}
\begin{lstlisting}
def runFile: PrgFile => String = {
  case Val(s)          => s
  case Path(p)         => "path=" + runFile(p)                // For debugging.
  case Read(Path(p))   => new String(Files.readAllBytes(Paths.get(runFile(p))))
  case x               => throw new Exception(s"Illegal PrgFile operation: $x")
}
\end{lstlisting}
To test this code, we prepare a file \lstinline!config.txt! containing
the text \lstinline!version = 1! and a file \lstinline!config_location.txt!
containing the text \lstinline!config.txt!. Then we can run the DSL
program and get the result:
\begin{lstlisting}
scala> runFile(prgFile)
res2: String = "version = 1"
\end{lstlisting}

The second example is a DSL for calculations with complex numbers.
Begin by implementing a data structure (\lstinline!case class Complex!)
with some operations: 
\begin{lstlisting}[mathescape=true]
final case class Complex(x: Double, y: Double) {
  def +(other: Complex): Complex = Complex(x + other.x, y + other.y)
  def *(other: Complex): Complex = Complex(x * other.x - y * other.y, x * other.y + y * other.x)
  def conj: Complex = Complex(x, -y)
  def phase: Double = math.atan2(y, x)         // Obtain the phase of a complex number.
  def rotate(alpha: Double): Complex = this * Complex(math.cos(alpha), math.sin(alpha))
}

val a = Complex(1, 2)          // $\color{dkgreen}a = 1 + 2 i$
val b = a * Complex(3, -4)     // $\color{dkgreen}b = (1 + 2 i)(3 - 4 i) = 11 + 2 i$
val c = b.conj                 // $\color{dkgreen}c = 11 - 2 i$

scala> c
res0: Complex = Complex(11.0, -2.0)

scala> c.rotate(Complex(0, 1).phase) // Multiply by $\color{dkgreen}i$
res1: Complex = Complex(2.000000000000001, 11.0)
\end{lstlisting}

Instead of running a complex-number program directly, the DSL pattern
first creates a data structure that contains an unevaluated expression
tree describing what needs to be computed. Separate case classes are
used for different operations as well as for inserting a literal \lstinline!Complex!
value (\lstinline!Val!):
\begin{lstlisting}
sealed trait PrgComplex
final case class Val(c: Complex)                      extends PrgComplex
final case class Add(p1: PrgComplex, p2: PrgComplex)  extends PrgComplex
final case class Mul(p1: PrgComplex, p2: PrgComplex)  extends PrgComplex
final case class Conj(p: PrgComplex)                  extends PrgComplex
final case class Phase(p: PrgComplex)                 extends PrgComplex
final case class Rotate(p: PrgComplex, a: PrgComplex) extends PrgComplex
\end{lstlisting}

Complex-number calculations are now represented by nested case classes:
\begin{lstlisting}
val prgComplex1: PrgComplex = Conj(Mul(Val(Complex(1, 2)), Val(Complex(3, -4))))
val prgComplex2: PrgComplex = Rotate(prgComplex1, Phase(Val(Complex(0, 1))))
\end{lstlisting}
A simple runner for the DSL programs of type \lstinline!PrgComplex!
can be written like this:
\begin{lstlisting}
def runComplex: PrgComplex => Complex = {
  case Val(c)             => c
  case Add(p1, p2)        => runComplex(p1) + runComplex(p2)
  case Mul(p1, p2)        => runComplex(p1) * runComplex(p2)
  case Conj(p)            => runComplex(p).conj
  case Phase(p)           => Complex(runComplex(p).phase, 0) // Pretend the phase is a Complex value.
  case Rotate(p, alpha)   => runComplex(p).rotate(runComplex(alpha).x) // Here alpha must be a phase.
}
\end{lstlisting}
We can now apply \lstinline!runComplex! to some DSL programs and
get the results as \lstinline!Complex! values:
\begin{lstlisting}
scala> runComplex(prgComplex1)
res2: Complex = Complex(11.0, -2.0)

scala> runComplex(prgComplex2)
res3: Complex = Complex(2.000000000000001, 11.0)
\end{lstlisting}

Although the DSLs are simple, we already get several benefits. By
representing file operations as values of type \lstinline!PrgFile!
and complex-number calculations as values of type \lstinline!PrgComplex!,
we can compose, verify, or optimize our DSL programs \emph{before}
running them. We may also implement different runners that execute
the same DSL program on a remote computer, on a distributed file system,
on GPUs instead of CPUs, or in a test-only sandbox environment, with
logging or benchmarking.

\subsection{Stage 2: implementing type safety in the DSLs}

The two DSLs defined in the previous section are not fully type-checked\index{type checking}
at compile time. This becomes clear by looking at the DSL program
\lstinline!prgFile! shown in the previous section. The code of \lstinline!runFile!
assumes that the \lstinline!Read! operation is always applied to
a \lstinline!Path!. However, this assumption is not enforced by the
DSL. When composing a larger DSL program from separately defined parts,
one could by mistake create an invalid DSL program such as \lstinline!Read(Read(Val("file")))!
where the \lstinline!Read! operation is used incorrectly. Running
this program causes a run-time error:
\begin{lstlisting}
scala> runFile(Read(Read(Val("file"))))
java.lang.Exception: Illegal PrgFile operation: Read(Read(Val(file)))
\end{lstlisting}
All DSL program values are of the same type (\lstinline!PrgFile!)
regardless of their intended meaning. So, the Scala compiler cannot
verify that we are using the DSL correctly. It would be better if
the DSL program \lstinline!Read(Read(Val("file")))! failed to compile.
To achieve that, we need to use different Scala types for DSL programs
returning a \lstinline!String! and a \lstinline!Path!. So, let us
replace the type \lstinline!PrgFile! by a type constructor \lstinline!PrgFile[A]!,
representing a DSL program that will return a value of type \lstinline!A!
when we run it:
\begin{lstlisting}
import java.nio.file.{Path => JPath}
import java.nio.file.{Files, Paths}
sealed trait PrgFile[A]
final case class Val(s: String)           extends PrgFile[String]
final case class Path(p: PrgFile[String]) extends PrgFile[JPath]
final case class Read(p: PrgFile[JPath])  extends PrgFile[String]

def runFile[A]: PrgFile[A] => A = {
  case Val(s)   => s
  case Path(p)  => Paths.get(runFile(p))
  case Read(p)  => new String(Files.readAllBytes(runFile(p)))
}
\end{lstlisting}
Our example DSL is now fully type-safe.\index{type safety} Invalid
programs are rejected at compile time:
\begin{lstlisting}
val prgFile: PrgFile[String] = Read(Path(Read(Path(Val("config_location.txt")))))

scala> runFile(prgFile)
res3: String = "version = 1"

scala> runFile(Read(Read(Val("file"))))
type mismatch;
 found   : Val
 required: PrgFile[java.nio.file.Path]
res4 = runFile(Read(Read(Val("file"))))
                                ^
Compilation Failed 
\end{lstlisting}

A similar problem exists in our DSL for complex numbers. The code
of \lstinline!runComplex! assumes that the \lstinline!Rotate! operation
is always applied to a \lstinline!Phase!, but the DSL does not enforce
that assumption. Both arguments of the \lstinline!Rotate! operation
are values of type \lstinline!PrgComplex!, and so the Scala compiler
is unable to verify that the DSL is being used correctly. If the programmer
uses a plain complex number (\lstinline!Val!) instead of a \lstinline!Phase!
value, the program will return an incorrect result \emph{without}
any indication of error:
\begin{lstlisting}
val prgComplex3: PrgComplex = Rotate(prgComplex1, Val(Complex(0, 1)))     // Forgot Phase()!

scala> runComplex(prgComplex3)    // The result is incorrect, but there is no error message!
res5: Complex = Complex(11.0, -2.0)
\end{lstlisting}

To achieve type safety, we add a type parameter to \lstinline!PrgComplex!.
A DSL program of type \lstinline!PrgComplex[A]! will return a value
of type \lstinline!A! when run. (So, the new DSL programs will be
able to compute values of any type, not only of type \lstinline!Complex!.)
The new definitions of the case classes are:
\begin{lstlisting}
sealed trait PrgComplex[A]
final case class Val(c: Complex)                                       extends PrgComplex[Complex]
final case class Add(p1: PrgComplex[Complex], p2: PrgComplex[Complex]) extends PrgComplex[Complex]
final case class Mul(p1: PrgComplex[Complex], p2: PrgComplex[Complex]) extends PrgComplex[Complex]
final case class Conj(p: PrgComplex[Complex])                          extends PrgComplex[Complex]
final case class Phase(p: PrgComplex[Complex])                         extends PrgComplex[Double]
final case class Rotate(p: PrgComplex[Complex], a: Phase)              extends PrgComplex[Complex]
\end{lstlisting}
The revised code of \lstinline!runComplex! is clearer because phases
are no longer wrapped in a \lstinline!Complex! type:
\begin{lstlisting}
def runComplex[A]: PrgComplex[A] => A = {
  case Val(c)             => c
  case Add(p1, p2)        => runComplex(p1) + runComplex(p2)
  case Mul(p1, p2)        => runComplex(p1) * runComplex(p2)
  case Conj(p)            => runComplex(p).conj
  case Phase(p)           => runComplex(p).phase
  case Rotate(p, alpha)   => runComplex(p).rotate(runComplex(alpha))
}
\end{lstlisting}
The example programs, \lstinline!prgComplex1! and \lstinline!prgComplex2!,
do not change except for their type:
\begin{lstlisting}
val prgComplex1: PrgComplex[Complex] = Conj(Mul(Val(Complex(1, 2)), Val(Complex(3, -4))))

val prgComplex2: PrgComplex[Complex] = Rotate(prgComplex1, Phase(Val(Complex(0, 1))))

scala> runComplex(prgComplex1)
res6: Complex = Complex(x = 11.0, y = -2.0)

scala> runComplex(prgComplex2)
res7: Complex = Complex(x = 2.000000000000001, y = 11.0)
\end{lstlisting}
Since \lstinline!Rotate! now requires a \lstinline!PrgComplex[Double]!,
forgetting to use \lstinline!Phase! will cause a type error:
\begin{lstlisting}
scala> val prgComplex3 = Rotate(prgComplex1, Val(Complex(0, 1)))
<console>:1: type mismatch;
 found   : Val
 required: PrgComplex[Double]                                                              
  case Phase(p)           => runComplex(p)
                                       ^ 
Compilation Failed
\end{lstlisting}


\subsection{Stage 3: implementing bound variables}

Another limitation of our DSLs is that we cannot define and use new
variables within a DSL program. We also cannot use any non-DSL code,
such as a library for file manipulation, a numerical algorithms library
for complex numbers, or any other Scala code. 

Both of these limitations would be removed if the DSL could define
\emph{new Scala variables} and set them to values computed within
the DSL. We would then be able to add arbitrary Scala code for working
with those variables. Let us see how this feature may be implemented.

As an example, consider the task of reading a file only if it exists
and reporting an error otherwise. A direct (non-DSL) code for this
computation looks like this:
\begin{lstlisting}
val p = Paths.get("config_location.txt")
val result = if (Files.exists(p)) new String(Files.readAllBytes(p)) else "No file."
\end{lstlisting}
Trying to translate the above code to the \lstinline!PrgFile! DSL,
we find that we need to set the Scala variable \lstinline!p! to the
path computed by a previous operation. Here is a first attempt:
\begin{lstlisting}
val p: JPath = runFile(Path(Val("config_location.txt")))
val prg: PrgFile[String] = if (Files.exists(p)) Read(p) else Val("No file.")
\end{lstlisting}
There are two problems with this code. The first problem is that \lstinline!Read(p)!
does not compile because the argument of \lstinline!Read! should
be a \lstinline!PrgFile[JPath]! rather than just a \lstinline!JPath!.
To solve this problem, we generalize the \lstinline!Val! class to
hold values of arbitrary type:
\begin{lstlisting}
final case class Val[A](a: A) extends PrgFile[A]
\end{lstlisting}
We then replace \lstinline!Read(p)! by \lstinline!Read(Val(p))!
in the code above. The code of \lstinline!run! remains unchanged.

The second problem is that we are using \lstinline!runFile! in the
middle of a DSL program. This breaks the assumption that a DSL program
merely describes the computations without executing them. The use
of a specific runner inside a DSL program will also prevent us from
being able to apply a different runner to the entire DSL program later.

To solve this problem, we introduce a new DSL operation that binds
Scala variables to values returned by other DSL operations. A standard
way of creating \index{bound variable}bound variables is by using
those variables as arguments of nameless functions. So, let us consider
the nameless function:
\begin{lstlisting}
{ p => if (Files.exists(p)) Read(Val(p)) else Val("No file.") }
\end{lstlisting}
This function creates a local variable \lstinline!p! and uses it
directly in an expression of type \lstinline!PrgFile[String]!. We
can call this function at the time when the entire DSL program is
run. So, we replace the code \lstinline!val p = runFile(...)! by
a new DSL operation that we will call \lstinline!Bind!. The above
code that computes \lstinline!p! and \lstinline!prg! is replaced
by:
\begin{lstlisting}
val prg2: PrgFile[JPath] = Path(Val("config.txt"))
val prg: PrgFile[String] = Bind(prg2){ p => if (Files.exists(p)) Read(Val(p)) else Val("No file.") }
\end{lstlisting}
Here, the case class \lstinline!Bind! has two curried arguments:
a value of type \lstinline!PrgFile[JPath]! and a function of type
\lstinline!JPath => PrgFile[String]!. That function will be called
by \lstinline!runFile! when we run the DSL program. At that time,
the argument \lstinline!p! will be set to the value obtained by running
\lstinline!prg2!. We will implement this logic in the new code for
\lstinline!runFile! (shown below).

In a different DSL program, we may need to use different types instead
of \lstinline!String! and \lstinline!JPath!. So, let us replace
those types by type parameters \lstinline!A! and \lstinline!B!.
The declaration of the class \lstinline!Bind! becomes:
\begin{lstlisting}
final case class Bind[A, B](pa: PrgFile[B])(f: B => PrgFile[A]) extends PrgFile[A]
\end{lstlisting}

After adding the \lstinline!Bind!-handling code to the runner, the
implementation of the DSL is:
\begin{lstlisting}
sealed trait PrgFile[A]
final case class Val[A](a: A)                                       extends PrgFile[A]
final case class Bind[A, B](pa: PrgFile[B])(val f: B => PrgFile[A]) extends PrgFile[A]
final case class Path(p: PrgFile[String])                           extends PrgFile[JPath]
final case class Read(p: PrgFile[JPath])                            extends PrgFile[String]

def runFile[A]: PrgFile[A] => A = {
  case Val(a)          => a
  case bind@Bind(pa)   => runFile(bind.f(runFile(pa)))
  case Path(p)         => Paths.get(runFile(p))
  case Read(p)         => new String(Files.readAllBytes(runFile(p)))
}
\end{lstlisting}

Let us explain certain features of Scala used in this DSL. Since the
arguments of the constructor \lstinline!Bind[A, B]! are curried,
the first curried argument (of type \lstinline!PrgFile[B]!) will
allow the Scala compiler to determine the type parameter \lstinline!B!
automatically. At the same time, \lstinline!Bind!\textsf{'}s second curried
argument may be written as a nameless function in a separate set of
braces:
\begin{lstlisting}
val prg: PrgFile[String] = Bind(prg2){ p => if (Files.exists(p)) Read(Val(p)) else Val("No file.") }
\end{lstlisting}
Because the type parameter \lstinline!B! is already fixed, the argument
\lstinline!p! may be written without a type annotation (in this case,
it would have been \lstinline!p:JPath!). This makes the DSL easier
to use. However, the underlying implementation becomes more complicated.
Scala\textsf{'}s pattern matching syntax is limited to the first curried argument.
So, the second curried argument of \lstinline!Bind! needs a \lstinline!val!
declaration and is accessed using another pattern variable (here called
\lstinline!bind!). Finally, the type parameters \lstinline!A! and
\lstinline!B! are defined such that \lstinline!Bind[A, B]! is a
subtype of \lstinline!PrgFile[A]! and not of \lstinline!PrgFile[B]!.
This allows Scala\textsf{'}s type checking to handle correctly the unknown
type \lstinline!B! in the pattern \lstinline!Bind(pa)!.

The new \lstinline!Bind! operation allows one part of a DSL program
to use values computed by other parts. Since a \lstinline!Bind! value
contains a \emph{Scala function} (of type \lstinline!B => PrgFile[A]!),
that function may run arbitrary Scala code, not limited to DSL operations,
in order to compute a result of type \lstinline!PrgFile[A]!. All
non-DSL code is enclosed inside a \lstinline!Bind! and will be evaluated
only when the DSL program is run:
\begin{lstlisting}
scala> runFile(prg)
res8: String = "version = 1"
\end{lstlisting}
 As before, a value of type \lstinline!PrgFile[A]! describes a computation
but does not execute it.

\subsection{Stage 4: refactoring to a monadic DSL}

The next observation is that \lstinline!Bind! and \lstinline!Val!
have the same type signatures as the standard \lstinline!flatMap!
and \lstinline!pure! methods of a monad. For convenience, let us
define those methods on the \lstinline!PrgFile! class:
\begin{lstlisting}
sealed trait PrgFile[A] {
  def flatMap[B](f: A => PrgFile[B]): PrgFile[B] = Bind(this)(f)
  def map[B](f: A => B): PrgFile[B] = flatMap(f andThen PrgFile.pure)
}
final case class Val[A](a: A)                                       extends PrgFile[A]
final case class Bind[A, B](pa: PrgFile[B])(val f: B => PrgFile[A]) extends PrgFile[A]
final case class Path(p: PrgFile[String])                           extends PrgFile[JPath]
final case class Read(p: PrgFile[JPath])                            extends PrgFile[String]

object PrgFile {
  def pure[A](a: A): PrgFile[A] = Val(a) 
}
\end{lstlisting}
Here we defined \lstinline!map! via \lstinline!flatMap! by using
a monad\textsf{'}s right identity law, as shown in Eq.~(\ref{eq:express-map-through-flatMap}).

Like other DSL operations, the methods \lstinline!map!, \lstinline!flatMap!,
and \lstinline!pure! do not run or evaluate any parts of a DSL program.
They only create some nested data structures containing not-yet-called
functions. The necessary logic will be executed when the \lstinline!run!
method is invoked. At that time, the entire DSL program will be converted
into a result value.

Because \lstinline!map! and \lstinline!flatMap! are defined, DSL
programs can now be written as functor blocks:
\begin{lstlisting}
val prg: PrgFile[String] = for {
  p <- Path(Val("config.txt"))
  r <- if (Files.exists(p)) Read(Val(p)) else Val("No file.")
} yield r
\end{lstlisting}
Longer DSL programs may be composed from shorter ones:
\begin{lstlisting}
def readFileContents(filename: String): PrgFile[String] = for {
  path <- Path(Val(filename))
  text <- if (Files.exists(path)) Read(Val(path)) else Val("No file.")
} yield text

val prg2: PrgFile[String] = for {
  str <- readFileContents("config.txt")
  result <- if (str.nonEmpty) readFileContents(str) else Val("No filename.")
} yield result

scala> runFile(prg2)
res9 : String = "version = 1"
\end{lstlisting}

Another benefit of the monadic refactoring is that \lstinline!flatMap!
provides a general way of applying a file operation to a value wrapped
under \lstinline!PrgFile!. So, we may simplify the case classes \lstinline!Path!
and \lstinline!Read! by removing the \lstinline!PrgFile! wrapping:
\begin{lstlisting}
final case class Path(p: String) extends PrgFile[JPath]
final case class Read(p: JPath)  extends PrgFile[String]
\end{lstlisting}
This simplifies the usage of the DSL since we may write, e.g., just
\lstinline!Read(path)! instead of \lstinline!Read(Val(path))!. The
code of \lstinline!runFile! is also shortened:
\begin{lstlisting}
def runFile[A]: PrgFile[A] => A = {
  case Val(a)          => a
  case bind@Bind(pa)   => runFile(bind.f(runFile(pa)))
  case Path(p)         => Paths.get(p)
  case Read(p)         => new String(Files.readAllBytes(p))
}
\end{lstlisting}


\subsection{Stage 5: refactoring to reuse common code\label{subsec:Stage-5:-refactoring-monadDSL}}

Let us rewrite our second example (a DSL for complex numbers) in the
same way:
\begin{lstlisting}
sealed trait PrgComplex[A] {
  def flatMap[B](f: A => PrgComplex[B]): PrgComplex[B] = Bind(this)(f)
  def map[B](f: A => B): PrgComplex[B] = flatMap(f andThen PrgComplex.pure)
}
object PrgComplex {
  def pure[A](a: A): PrgComplex[A] = Val(a)
}

final case class Val[A](a: A)                                             extends PrgComplex[A]
final case class Bind[A, B](pa: PrgComplex[B])(val f: B => PrgComplex[A]) extends PrgComplex[A]
final case class Add(x: Complex, y: Complex)                              extends PrgComplex[Complex]
final case class Mul(x: Complex, y: Complex)                              extends PrgComplex[Complex]
final case class Conj(x: Complex)                                         extends PrgComplex[Complex]
final case class Phase(p: Complex)                                        extends PrgComplex[Double]
final case class Rotate(p: Complex, p: Phase)                             extends PrgComplex[Complex]

def runComplex[A]: PrgComplex[A] => A = {
  case Val(a)                => a
  case bind@Bind(pa)         => runComplex(bind.f(runComplex(pa)))
  case Add(p1, p2)           => p1 + p2
  case Mul(p1, p2)           => p1 * p2
  case Conj(p)               => p.conj
  case Phase(p)              => p.phase
  case Rotate(p, Phase(a))   => p.rotate(a.phase)
}
\end{lstlisting}

Comparing the code of \lstinline!runFile! and \lstinline!runComplex!,
we notice that the \lstinline!Val! and \lstinline!Bind! operations
are implemented in the same way. The differences are in the code for
operations specific to file handling or to complex numbers. So, let
us refactor these data structures, separating the domain-specific
operations and reusing the common code. We can gather all the domain-specific
operations in a new type constructor that we call an \index{effect constructor}\textbf{effect
constructor}. The common code will then use the effect constructor
as a type parameter. Let us now refactor the two example DSLs in this
manner.

The effect constructor for the \lstinline!PrgFile! DSL should contain
the operations \lstinline!Path! and \lstinline!Read!. Let us copy
the existing case classes for these operations but rename their parent
type to \lstinline!PrgFileC!. We will also move the relevant parts
of \lstinline!runFile! into a new function (\lstinline!runFileC!)
that we call an \textbf{effect runner}\index{effect runner}:
\begin{lstlisting}
sealed trait PrgFileC[A]
final case class Path(p: String) extends PrgFileC[JPath]
final case class Read(p: JPath)  extends PrgFileC[String]
  
def runFileC[A]: PrgFileC[A] => A = {
  case Path(p)   => Paths.get(p)
  case Read(p)   => new String(Files.readAllBytes(p))
}
\end{lstlisting}
The code of \lstinline!PrgFile! becomes shorter since we moved some
code out of it:
\begin{lstlisting}
// The same code for sealed trait PrgFile[A] and object PrgFile.
// The case classes are changed to:
final case class Val[A](a: A) extends PrgFile[A]
final case class Bind[A, B](pa: PrgFile[B])(val f: B => PrgFile[A]) extends PrgFile[A]
final case class Op[A](op: PrgFileC[A]) extends PrgFile[A]  // Wrap custom operations.

def runFile[A]: PrgFile[A] => A = {
  case Val(a)          => a
  case bind@Bind(pa)   => runFile(bind.f(runFile(pa)))
  case Op(op)          => runFileC(op) // Run the custom operation and get the result.
}
\end{lstlisting}

The code of \lstinline!PrgComplex! is refactored in a similar way:
\begin{lstlisting}
// The same code for `sealed trait PrgComplex[A]` and `object PrgComplex`.
// The case classes are changed to:
final case class Val[A](a: A) extends PrgComplex[A]
final case class Bind[A, B](pa: PrgComplex[B])(val f: B => PrgComplex[A]) extends PrgComplex[A]
final case class Op[A](op: PrgComplexC[A]) extends PrgComplex[A]     // Wrap custom operations.

def runComplex[A]: PrgComplex[A] => A = {
  case Val(a)             => a
  case bind@Bind(pa)      => runComplex(bind.f(runComplex(pa)))
  case Op(op)             => runComplexC(op)    // Run the custom operation and get the result.

sealed trait PrgComplexC[A]
final case class Add(x: Complex, y: Complex)      extends PrgComplexC[Complex]
final case class Mul(x: Complex, y: Complex)      extends PrgComplexC[Complex]
final case class Conj(x: Complex)                 extends PrgComplexC[Complex]
final case class Phase(p: Complex)                extends PrgComplexC[Double]
final case class Rotate(p: Complex, alpha: Phase) extends PrgComplexC[Complex]
 
def runComplexC[A]: PrgComplexC[A] => A = {
  case Add(p1, p2)           => p1 + p2
  case Mul(p1, p2)           => p1 * p2
  case Conj(p)               => p.conj
  case Phase(p)              => p.phase
  case Rotate(p, Phase(a))   => p.rotate(a.phase)
}
\end{lstlisting}

The code of \lstinline!PrgComplex! is now the same as the code of
\lstinline!PrgFile! except for using a different effect constructor
(\lstinline!PrgComplexC! instead of \lstinline!PrgFileC!) and the
corresponding runner (\lstinline!runComplexC! instead of \lstinline!runFileC!).
The effect constructor and its runner encapsulate the entire domain-specific
logic. The code in the classes \lstinline!PrgComplex! and \lstinline!PrgFile!
is only concerned with providing the monadic functionality to the
DSL. We can replace those two classes by a single class (called, say,
\lstinline!MonadDSL!) that takes the effect constructor as a \emph{type
parameter} \lstinline!F!. Since the type parameter \lstinline!F!
is itself a type constructor, we must declare it via the Scala syntax
\lstinline!F[_]!. The code is:
\begin{lstlisting}
sealed trait MonadDSL[F[_], A] {
  def flatMap[B](f: A => MonadDSL[F, B]): MonadDSL[F, B] = Bind(this)(f)
  def map[B](f: A => B): MonadDSL[F, B] = flatMap(f andThen MonadDSL.pure)
}
object MonadDSL {
  def pure[F[_], A](a: A): MonadDSL[F, A] = Val(a)
}
final case class Val[F[_], A](a: A) extends MonadDSL[F, A]
final case class Bind[F[_], A, B](pa: MonadDSL[F, B])(val f: B => MonadDSL[F, A]) extends MonadDSL[F, A]
final case class Op[F[_], A](op: F[A]) extends MonadDSL[F, A] // Wrap all domain-specific operations.
\end{lstlisting}

The runner for \lstinline!MonadDSL! needs to run the effects described
by the effect constructor \lstinline!F!. For convenience, we will
implement the runner as a \lstinline!run! method in the \lstinline!MonadDSL!
object. We try passing \lstinline!F!\textsf{'}s runner as an additional curried
argument to \lstinline!MonadDSL!\textsf{'}s runner:
\begin{lstlisting}
object MonadDSL {
  def pure[F[_], A](a: A): MonadDSL[F, A] = Val(a)
  def run[F[_], A](runner: F[A] => A): MonadDSL[F, A] => A = { // This code does not compile.
    case Val(a)          => a
    case bind@Bind(pa)   => run(runner)(bind.f(run(runner)(pa)))
    case Op(op)          => runner(op)
  }
}
\end{lstlisting}
However, this code gives a type error. The type of \lstinline!bind.f!
is \lstinline!B => MonadDSL[F, A]!, so the argument of \lstinline!bind.f!
must have type \lstinline!B!. A value of type \lstinline!B! will
be produced by \lstinline!run(runner)(pa)! only if we set type parameters
as \lstinline!run[F, B]!, and only if \lstinline!runner! has type
\lstinline!F[B] => B!. But the given argument \lstinline!runner!
has a fixed type \lstinline!F[A] => A! and cannot be used with type
\lstinline!B!.

The function \lstinline!run(runner)! will work with arbitrary types
only if \lstinline!runner! has type \lstinline!F[X] => X! where
\lstinline!X! remains free and is \emph{not} known in advance. The
type signatures of the effect runners \lstinline!runComplexC! and
\lstinline!runFileC! already have that form:
\begin{lstlisting}
def runComplexC[X]: PrgComplexC[X] => X    // PrgComplexC[X] => X with arbitrary types X
def runFileC[X]: PrgFileC[X] => X          // PrgFileC[X] => X with arbitrary types X
\end{lstlisting}
We need to pass those functions as the \lstinline!runner! arguments
to \lstinline!run(runner)! while not losing the freedom provided
by the type parameter \lstinline!X!. 

To achieve that, we define a new type \lstinline!Runner! as a Scala
trait encapsulating the type signature of an effect runner. The two
effect runners can then be declared as values of type \lstinline!Runner!:
\begin{lstlisting}
trait Runner[F[_]] { def apply[X]: F[X] => X }
val runnerComplex = new Runner[PrgComplexC] { def apply[X]: PrgComplexC[X] => X = runComplexC[X] }
val runnerFile = new Runner[PrgFileC] { def apply[X]: PrgFileC[X] => X = runFileC[X] } 
\end{lstlisting}

Function values that encapsulate a type parameter are called \textbf{polymorphic
functions}\index{polymorphic function}. The type notation for the
type \lstinline!Runner! is:
\[
\text{Runner}^{F}\triangleq\forall X.\,F^{X}\rightarrow X\quad.
\]
The universal quantifier ($\forall X$) indicates that a value of
type \lstinline!Runner[F]! still has the freedom of using any type
\lstinline!X! when the method \lstinline!run! is called.

In Scala 3, the type of an effect runner is written in a shorter syntax:
\begin{lstlisting}
type Runner[F[_]] = [X] => F[X] => X
\end{lstlisting}
This corresponds to the type notation $\forall X.\,F^{X}\rightarrow X$.
The programmer does not need to declare a trait \lstinline!Runner!
in Scala 3 because the compiler does that automatically for polymorphic
functions.

Using the \lstinline!Runner! type, we rewrite the code for \lstinline!run!
as:
\begin{lstlisting}
def run[F[_], A](runner: Runner[F]): MonadDSL[F, A] => A = {
  case Val(a)          => a
  case bind@Bind(pa)   => run(runner)(bind.f(run(runner)(pa)))
  case Op(op)          => runner.apply(op)
}
\end{lstlisting}
We can now define \lstinline!PrgComplex! through \lstinline!MonadDSL!
and test the new code:
\begin{lstlisting}
type PrgComplex[A] = MonadDSL[PrgComplexC, A]
val prgComplex: PrgComplex[Complex] = for {
  x <- Op(Add(Complex(1, 1), Complex(0, 1)))
  y <- Op(Mul(x, Complex(3, -4)))
  z <- Op(Conj(y))
  r <- Op(Rotate(x, Phase(Complex(0, 1))))
} yield r

scala> runComplex(runnerComplex)(prgComplex2)
res0: Complex = Complex(x = 2.000000000000001, y = 11.0)
\end{lstlisting}


\subsection{A first recipe for monadic DSLs\label{subsec:A-first-recipe-monadic-dsl}}

The previous section gave motivation for defining the type constructor
\lstinline!MonadDSL[F[_], A]!. That type constructor is called the
\textsf{``}free monad on \lstinline!F!\textsf{''}, for reasons explained later in
this chapter. Note that \lstinline!MonadDSL[F[_], A]! supports the
monad\textsf{'}s methods \lstinline!map!, \lstinline!flatMap!, and \lstinline!pure!,
which \lstinline!F! does not necessarily have. So, we may view \lstinline!MonadDSL[F[_], A]!
as a special wrapper that adds the monadic variable-binding functionality
to any given DSL whose operations are described by an effect constructor
\lstinline!F!.

Below we will show that monadic DSL programs will satisfy the monad
laws \emph{after} the effects are run (but not necessarily before
that!). Let us now summarize a recipe for using \lstinline!MonadDSL!
in practice.

Begin by writing down the types of the available operations in the
DSL. The operations may be functions between fixed known types, such
as $\text{Int}\rightarrow\text{Int}\rightarrow\text{String}$ or $\text{String}\rightarrow\bbnum 1$.
Operations may be also functions with type parameters, for example,
$A\times\text{Int}\rightarrow\text{String}$ where $A$ is a type
parameter. In every case, we need to write down the types in the form
of a simple (non-curried) function, such as $P\rightarrow Q$, where
$P$ and $Q$ are type expressions possibly depending on some type
parameters.

The next step is to define a new type constructor \lstinline!F[_]!
that will serve as the DSL\textsf{'}s effect constructor\index{effect constructor}:
\begin{lstlisting}
sealed trait F[_]
\end{lstlisting}
 The effect constructor \lstinline!F! will be a disjunctive type
whose parts correspond to each of the domain-specific operations.
For an operation with type $P\rightarrow Q$, define the corresponding
case class as:
\begin{lstlisting}
final case class ReadPWriteQ(x: P) extends F[Q]
\end{lstlisting}
The names of case classes (such as \lstinline!ReadPWriteQ!) may be
chosen for clarity.

It is an important part of the recipe that the result type (\lstinline!Q!)
is wrapped in the effect constructor \lstinline!F! while the argument
type (\lstinline!P!) is \emph{not}. For example, the \lstinline!PrgFile!
DSL described in the previous section has two operations with types
\lstinline!String => JPath! and \lstinline!JPath => String!. The
corresponding effect constructor (\lstinline!PrgFileC!) is defined
by:
\begin{lstlisting}
sealed trait PrgFileC[_]
final case class Path(p: String) extends PrgFileC[JPath]
final case class Read(p: JPath)  extends PrgFileC[String]
\end{lstlisting}

Typically, a type constructor \lstinline!F! defined in this way will
be a GADT\index{GADT}. In the example shown above, \lstinline!PrgFileC!
cannot be a functor because it is impossible to create values of type
\lstinline!PrgFileC[A]! with an arbitrary type \lstinline!A! (the
type \lstinline!A! must be either \lstinline!JPath! or \lstinline!String!).
However, in some cases the effect constructor \lstinline!F! could
be itself a lawful functor.

Next, we implement an \textsf{``}effect runner\textsf{''} \index{effect runner}for
\lstinline!F!. An \textbf{effect runner} for an effect constructor
\lstinline!F! is a polymorphic function\index{polymorphic function}
with the type signature $\forall X.\,F^{X}\rightarrow X$:
\begin{lstlisting}
val runF: Runner[F] = new Runner[F] { def run[X]: F[X] => X = ??? }
\end{lstlisting}
If the definition of \lstinline!F! allows only certain types \lstinline!A!
in values of type \lstinline!F[A]! then the runner only needs to
work for those types. In the \lstinline!PrgFile! DSL, the runner
only needs to work with arguments of types \lstinline!PrgFileC[JPath]!
and \lstinline!PrgFileC[String]! because those are the only allowed
types of values that can be wrapped by  \lstinline!PrgFileC!. The
runner will never be given an argument of type \lstinline!PrgFile[X]!
with an arbitrary unknown \lstinline!X!. However, different effect
constructors may have different allowed types, and \lstinline!MonadDSL!
needs to be able to work with any effect constructor. So, the runner\textsf{'}s
type signature still needs a general type parameter \lstinline!X!:
\begin{lstlisting}
val runnerFile = new Runner[PrgFileC] { def run[X]: (PrgFileC[X] => X) = runFileC[X] }
\end{lstlisting}

We now define the monadic DSL type (\lstinline!MyDSL!) and its runner
function (\lstinline!runMyDSL!) as:
\begin{lstlisting}
type MyDSL[A] = MonadDSL[F, A]
def runMyDSL[A]: MyDSL[A] => A = MonadDSL.run(runF)
\end{lstlisting}
DSL programs may be written using functor blocks:
\begin{lstlisting}
type FileDSL[A] = MonadDSL[PrgFileC, A]
def runFileDSL[A]: FileDSL[A] => A = MonadDSL.run(runnerFile)
val prgFile1: FileDSL[String] = for {
  x <- Op(Path("config.txt"))
  y <- Op(Read(x))
} yield y

scala> runFileDSL(prgFile1)
res0: String = "version = 1"
\end{lstlisting}

Note that each DSL operation needs to be wrapped in an \lstinline!Op!
case class. To make the code shorter, we may define an implicit conversion
from \lstinline!PrgFileC[A]! to \lstinline!Op[A]!:
\begin{lstlisting}
implicit def toOp[A](p: PrgFileC[A]): Op[A] = Op(p) // *** check if this code actually works
val prgFile2: FileDSL[String] = for { // Does it help if we begin the functor block with a Pure()?
  x <- Path("config.txt")
  y <- Read(x)
} yield y

scala> runFileDSL(prgFile1)
res1: String = "version = 1"
\end{lstlisting}

Does\index{free monad!monad laws} the type constructor \lstinline!MonadDSL[F, A]!
satisfy the laws of the monad? We can quickly find out that it does
\emph{not}. The left identity law of \lstinline!flatMap! fails:
\begin{lstlisting}
MonadDSL.pure(a).flatMap(f) == Bind(Val(a))(f) // This should equal f(a) by the left identity law.
\end{lstlisting}
However, the law will hold \emph{after} we apply a runner function
to both sides. For brevity, let us denote \lstinline!MonadDSL!\textsf{'}s
runner function by \lstinline!r(x)! instead of \lstinline!run(runner)(x)!.
The code of \lstinline!run! shows that \lstinline!r(Bind(p)(f)) == r(f(r(p)))!
and \lstinline!r(Val(a)) == a!. Then we find that both sides of the
law give \lstinline!r(f(a))! when run:
\begin{lstlisting}
r(MonadDSL.pure(a).flatMap(f)) == r(Bind(Val(a))(f)) == r(f(a))
\end{lstlisting}

The associativity law~(\ref{eq:associativity-law-flatMap}) of \lstinline!flatMap!
also does not hold directly for \lstinline!MonadDSL! values but will
hold after a \lstinline!MonadDSL! program has been run. To see that,
first compare the two sides of the law~(\ref{eq:associativity-law-flatMap}):
\begin{lstlisting}
/* left-hand side:  */   p.flatMap(x => f(x).flatMap(g)) == Bind(p)(x => Bind(f(x))(g))
/* right-hand side: */   p.flatMap(f).flatMap(g) == Bind(Bind(p)(f))(g)
\end{lstlisting}
The law fails since the two data structures are not the same. When
we apply a runner \lstinline!r! to both sides, we get:
\begin{lstlisting}
/* left-hand side:  */   r(Bind(p)(x => Bind(f(x))(g))) == r(Bind(f(r(p)))(g)) == r(g(r(f(r(p)))))  
/* right-hand side: */   r(Bind(Bind(p)(f))(g)) == r(g(r(Bind(p)(f)))) == r(g(r(f(r(p)))))
\end{lstlisting}

We may say that failures of the monad laws are \textsf{``}not observable\textsf{''}
since the laws will hold after running the DSL programs.

Could we implement \lstinline!MonadDSL!\textsf{'}s \lstinline!flatMap! method
differently so that the monad laws already hold before applying a
runner? To satisfy the left identity law, we need to avoid creating
a nested structure of the form \lstinline!Bind(Val(a))! when applying
\lstinline!flatMap! to a value of the form \lstinline!Val(a)!. Instead,
\lstinline!Val(a).flatMap(f)! should return \lstinline!f(a)! as
required by the left identity law. To satisfy the associativity law,
we need to avoid creating a nested structure of the form \lstinline!Bind(Bind(...))!
when applying \lstinline!flatMap! to a \lstinline!Bind! value. Instead,
applying \lstinline!flatMap! to \lstinline!Bind! should directly
return the value required by the associativity law. The new code of
\lstinline!flatMap! is:
\begin{lstlisting}
sealed trait MonadDSL[F[_], A] { *** check that this code works
  def flatMap[B](f: A => MonadDSL[F, B]): MonadDSL[F, B] = this match {
    case Val(a)          => f(a)
    case bind@Bind(pa)   => Bind(pa)(x => Bind(bind.f(x))(f))
    case _               => Bind(this)(f)
  }
  ... // Other code remains unchanged.
}
\end{lstlisting}
The resulting code creates fewer nested case classes in memory.

Unlike other laws, the right identity law already holds for any value
\lstinline!p! of type \lstinline!MonadDSL[F, A]!:
\begin{lstlisting}
p.flatMap(f andThen MonadDSL.pure) == p.map(f)
\end{lstlisting}
The reason is that our current code implements \lstinline!MonadDSL!\textsf{'}s
\lstinline!map! method via \lstinline!flatMap! in exactly this way. 

\subsection{Running a DSL program into another monad}

In the code from the previous section, one may use different effect
runners with \emph{the same} function \lstinline!MonadDSL.run!. We
may apply \lstinline!MonadDSL.run! to any effect runner of type $\forall X.\,F^{X}\rightarrow X$
and obtain a monad runner of type \lstinline!MonadDSL[F, A] => A!.

More generally, we may need to run the $F$-effects into \emph{another
monad}. Given an effect runner of type $\forall X.\,F^{X}\rightarrow M^{X}$,
where $M$ is some monad, we hope to obtain a runner with type signature
$\forall A.\,\text{MonadDSL}^{F,A}\rightarrow M^{A}$.

To see an example of using such general runners in practice, assume
that the execution of $F$-effects may produce errors.\footnote{\index{jokes}\textsf{``}\emph{A function that launches real-world missiles
can run out of missiles.}\textsf{''} (A quote attributed to \index{Simon Peyton Jones}Simon
Peyton Jones, see \texttt{\href{https://stackoverflow.com/questions/2773004}{https://stackoverflow.com/questions/2773004}}
for discussion.)} For instance, the code of \lstinline!runFileC! (the runner for the
\lstinline!PrgFile! DSL) will throw exceptions when files are not
found or not readable. We may catch those exceptions with Scala\textsf{'}s
standard \lstinline!Try! class. We will then need to replace a runner
of type \lstinline!PrgFileC[X] => X! by a polymorphic function of
type \lstinline!PrgFileC[X] => Try[X]!. The new code looks like this:
\begin{lstlisting}
trait RunnerTry[F[_]] { def run[X]: F[X] => Try[X] }
val runnerFileTry = new RunnerTry[PrgFileC] { def run[X]: PrgFileC[X] => Try[X] = p => Try(runFileC(p)) }
\end{lstlisting}
 The code of the \lstinline!MonadDSL!\textsf{'}s runner needs to be modified
to accommodate the new type. Since a \lstinline!Val(a)! cannot generate
errors (only $F$-effects can), we transform a \lstinline!Val(a)!
into \lstinline!Success(a)!. A \lstinline!Bind! value can only result
from using \lstinline!MonadDSL!\textsf{'}s \lstinline!flatMap!, and so it
is reasonable to transform \lstinline!Bind! into a call to \lstinline!Try!\textsf{'}s
\lstinline!flatMap! method. The new runner\textsf{'}s code becomes:
\begin{lstlisting}
def runTry[F[_], A](runnerTry: RunnerTry[F]): MonadDSL[F, A] => Try[A] = {
  case Val(a)          => Success(a)
  case bind@Bind(pa)   => runTry(runner)(pa).flatMap(bind.f andThen runTry(runner)) // Use flatMap from Try.
  case Op(op)          => runner.apply(op)
} *** check that this code works
\end{lstlisting}

Let us generalize the code of \lstinline!runTry! to an arbitrary
monad $M$ instead of \lstinline!Try!. We note that \lstinline!runTry!
uses only two values specific to \lstinline!Try!: the \lstinline!flatMap!
method of the \lstinline!Try! monad and the \lstinline!Success!
case class, which corresponds to the \lstinline!Try! monad\textsf{'}s \lstinline!pure!
method. To adapt the code to another monad $M$ instead of \lstinline!Try!,
we need to use $M$\textsf{'}s \lstinline!flatMap! and to replace \lstinline!Success!
by $M$\textsf{'}s \lstinline!pure!. The result is a \textsf{``}universal runner\textsf{''}\index{free monad!universal runner}
for the free monad:
\begin{lstlisting}
trait RunnerM[F[_], M[_]] { def run[X]: F[X] => M[X] }
def runM[F[_], M[_]: Monad, A](runnerM: RunnerM[F, M]): MonadDSL[F, A] => M[A] = {
  case Val(a)          => Monad[M].pure(a)
  case bind@Bind(pa)   => runM(runnerM)(pa).flatMap(bind.f andThen runM(runnerM)) // Use flatMap from M.
  case Op(op)          => runnerM.run(op)
} *** check that this code works
\end{lstlisting}

We have implemented the universal runner by mapping \lstinline!MonadDSL!\textsf{'}s
monadic methods (\lstinline!pure! and \lstinline!flatMap!) into
the corresponding \lstinline!pure! and \lstinline!flatMap! methods
of the monad $M$. More precisely, if we fix an effect runner \lstinline!runnerM!
then the corresponding runner \lstinline!run = runM(runnerM)! satisfies:
\begin{lstlisting}
run(MonadDSL.pure(a)) == run(Val(a))  == Monad[M].pure(a)
run(p.flatMap(f)) == run(Bind(p)(f)) == run(p.flatMap(f andThen run))
\end{lstlisting}
These equations also show that there is \emph{only one} implementation
of a runner function of type \lstinline!run[A]: MonadDSL[A] => M[A]!
that preserves the \lstinline!pure! and \lstinline!flatMap! operations.
The \lstinline!Op(op)! values must be transformed into \lstinline!runnerM.run(op)!
as there is no other way of converting a value of type \lstinline!F[A]!
into a value of type \lstinline!M[A]! with an arbitrary monad \lstinline!M!. 

The use of universal runners (with an arbitrary monad $M$) allows
the programmer to better separate the business logic of an application
from its execution environment. For instance, $M$ may itself be a
monadic DSL with a different set of operations and its own effect
runner that works more efficiently or supports a different run-time
environment.

\section{Different encodings of the free monad}

\subsection{Motivation\label{subsec:Motivation-free-monad-different-encodings}}

The type \lstinline!MonadDSL[F, A]! is called a \textbf{free monad}
on\index{free monad} the type constructor \lstinline!F!. The word
\textsf{``}free\textsf{''} indicates that \lstinline!MonadDSL! is free of any domain-specific
code. We may view \lstinline!MonadDSL[F, A]! as a wrapper that adds
the monad\textsf{'}s functionality to any type constructor \lstinline!F! and
creates a new monadic DSL based on \lstinline!F!\textsf{'}s operations. The
construction uses \lstinline!F! as a type parameter, and so it works
equally well with every \lstinline!F!.

A monad must support the methods \lstinline!pure!, \lstinline!flatMap!,
and \lstinline!map!. The effect constructor \lstinline!F! often
does not have these methods. The \lstinline!MonadDSL! constructor
is able to convert an arbitrary \lstinline!F! into a monad because
\lstinline!MonadDSL! defines the methods \lstinline!pure!, \lstinline!flatMap!,
and \lstinline!map! in a special way. Those methods create some data
structures (nested case classes) in memory but do not perform any
domain-specific effects or actions. The effects will be performed
at a later time by an effect runner (\lstinline!runF! of type \lstinline!F[A] => A!)
when we apply \lstinline!MonadDSL.run! to a DSL program. Effect runners
are not part of the code of \lstinline!MonadDSL! and will need to
be supplied separately. So, we may run the same \lstinline!MonadDSL!
program using different runners.

The code of \lstinline!MonadDSL! satisfies our goal of producing
a type-safe DSL out of a given set of domain-specific operations.
But it turns out that \lstinline!MonadDSL! is not the only way of
turning a given type constructor \lstinline!F! into a monad. Various
presentations and blog posts about the free monad have used different
implementations that are not obviously equivalent to each other. Here
are three examples that we will call \lstinline!Free1!, \lstinline!Free2!,
and \lstinline!Free3!. 

In a 2012 blog post,\footnote{See \texttt{\href{http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html}{http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html}}}
\index{Gabriella Gonzalez}G.~Gonzalez showed a free monad corresponding
to this Scala code:
\begin{lstlisting}
abstract class Free1[F[_]: Functor, T] {
  def flatMap[A](f: T => Free1[F, A]): Free1[F, A] = this match {
    case Pure(t)      => f(a)
    case Flatten(p)   => Flatten(p.map(g => g.flatMap(f))) // Use F\textsf{'}s Functor instance.
  }
}
final case class Pure[F[_], T](t: T)                 extends Free1[F, T]
final case class Flatten[F[_], T](p: F[Free1[F, T]]) extends Free1[F, T] 
\end{lstlisting}

In 2014,\footnote{See \texttt{\href{http://functionaltalks.org/2014/11/23/runar-oli-bjarnason-free-monad/}{http://functionaltalks.org/2014/11/23/runar-oli-bjarnason-free-monad/}}}
R.~Bjarnason\index{Runar@R\'unar Bjarnason} presented the following
implementation of a free monad:
\begin{lstlisting}
sealed trait Free2[F[_], T] {
  def flatMap[A](f: T => Free2[F, A]): Free2[F, A] = this match {
    case Return(t)    => f(t)
    case Bind(p, g)   => Bind(p, (b => g(b) flatMap f))
  }
}
final case class Return[F[_], T](t: T)                          extends Free2[F, T]
final case class Bind[F[_], T, A](p: F[A], g: A => Free2[F, T]) extends Free2[F, T]
\end{lstlisting}

In 2016, K.~Robinson\index{Kelley Robinson} gave a talk\footnote{See \texttt{\href{https://www.slideshare.net/KelleyRobinson1/why-the-free-monad-isnt-free-61836547}{https://www.slideshare.net/KelleyRobinson1/why-the-free-monad-isnt-free-61836547}}}
where the code for the free monad looked like this:
\begin{lstlisting}
sealed trait Free3[F[_], T] {
  def flatMap[A](f: T => Free3[F, A]): Free3[F, A] = FlatMap(this, f) 
}
final case class Pure[F[_], T](t: T)                                      extends Free3[F, T]
final case class Suspend[F[_], T](f: F[T])                                extends Free3[F, T]
final case class FlatMap[F[_], T, A](p: Free3[F, A], g: A => Free3[F, T]) extends Free3[F, T]
\end{lstlisting}

The main differences between \lstinline!Free1!, \lstinline!Free2!,
and \lstinline!Free3! are in the definitions of the case classes
and of the \lstinline!flatMap! functions, so we omitted all other
code. The type of \lstinline!Free3! is the same as \lstinline!MonadDSL!
except for renaming \lstinline!Pure! to \lstinline!Val!, \lstinline!Suspend!
to \lstinline!Op!, and \lstinline!FlatMap(f, g)! to \lstinline!Bind(f)(g)!.
However, \lstinline!Free1! and \lstinline!Free2! have different
data in their case classes and are not obviously equivalent to each
other (or to \lstinline!Free3!). We call these implementations \textbf{encodings}\index{free monad!encodings}
of the free monad. The different codes implement the same idea (turning
a type constructor \lstinline!F! into a monad) in different ways.

To figure out how to use those codes in practice, a programmer might
ask the following questions: Are the three encodings equivalent? What
laws does their code need to satisfy in order to be considered \textsf{``}correct\textsf{''}?
The \lstinline!Free2! type has 2 case classes and \lstinline!Free3!
has 3; are there any other encodings of the free monad? Is there a
systematic way of finding constructions that convert any type into
a \textsf{``}free functor\textsf{''}, a \textsf{``}free monoid\textsf{''}, or into another \textsf{``}free\textsf{''}
typeclass? The rest of this chapter will develop the required theory
and show the derivations needed to answer these questions. 

\subsection{The raw tree encoding}

To understand the relationships between the encodings of the free
monad, let us first examine how the code of \lstinline!MonadDSL!
(or equivalently \lstinline!Free3!) implements the \lstinline!map!
method. In \lstinline!MonadDSL!, we implemented \lstinline!map!
through \lstinline!flatMap!. As a result, our code for the \lstinline!map!
method is not similar to the code of the two other monadic methods
(\lstinline!pure! and \lstinline!flatMap!) that merely create new
values of the case classes \lstinline!Val! and \lstinline!Bind!
without performing any computations.

We could implement \lstinline!map! in a similar way if we added a
new case class, say \lstinline!FMap!, to \lstinline!MonadDSL!. The
result is a new encoding of the free monad that we will call \lstinline!Free4!
(since it uses $4$ case classes):
\begin{lstlisting}
sealed trait Free4[F[_], A] {
  def flatMap[B](f: A => Free4[F, B]): Free4[F, B] = Bind(this)(f)
  def map[B](f: A => B): Free4[F, B] = FMap(this)(f)
}
object Free4 {
  def pure[F[_], A](a: A): Free4[F, A] = Val(a)
}
final case class Val[F[_], A](a: A)                                            extends Free4[F, A]
final case class Bind[F[_], A, B](pa: Free4[F, B])(val f: B => Free4[F, A])    extends Free4[F, A]
final case class FMap[F[_], A, B](pa: Free4[F, B])(val f: B => A)              extends Free4[F, A]
final case class Op[F[_], A](op: F[A]) extends Free4[F, A] // Wrap all domain-specific operations.
\end{lstlisting}
The code of the runner needs to be revised accordingly:
\begin{lstlisting}
def run[F[_], A](runner: Runner[F]): Free4[F, A] => A = {
  case Val(a)            => a
  case bind @ Bind(pa)   => run(runner)(bind.f(run(runner)(pa)))
  case fmap @ FMap(pa)   => fmap.f(run(runner)(pa))
  case Op(op)            => runner.apply(op)
} *** check that this code works
\end{lstlisting}

The code of \lstinline!Free4!\textsf{'}s methods \lstinline!map!, \lstinline!flatMap!,
and \lstinline!pure! merely wraps the arguments of each method into
a case class without performing any computations with those arguments.
We call this implementation of the free monad the \textbf{raw tree
encoding}\index{free monad!raw tree encoding}. The name means that
a DSL program is a fully unevaluated (or \textsf{``}raw\textsf{''}) expression tree
that creates a new nested case class for each step of the required
computations.

\subsection{Deriving reduced encodings of the free monad}

In the raw tree encoding (\lstinline!Free4!), \emph{none} of the
monad laws hold. This is not a problem in practice because the monad
laws will hold after running a DSL program. However, we notice that
the \lstinline!Free3! encoding (which is the same as \lstinline!MonadDSL!
from Section~\ref{subsec:Stage-5:-refactoring-monadDSL}) satisfies
the monad\textsf{'}s right identity law by design. A byproduct of that design
is that \lstinline!Free3! has fewer case classes than \lstinline!Free4!.
We also notice that the code of \lstinline!Free2! uses just $2$
case classes and satisfies all monad laws.

These observations suggest that we might find an encoding with fewer
case classes (which we call a \textbf{reduced encoding}) if we use
the monad laws when designing the free monad\textsf{'}s type constructor. To
see how this works, we will first reduce \lstinline!Free4! to \lstinline!Free3!
and then \lstinline!Free3! to \lstinline!Free2! by imposing certain
monad laws directly on the DSL program values. These derivations will
also show that \lstinline!Free2!, \lstinline!Free3!, and \lstinline!Free4!
are equivalent to each other in their expressive power.\footnote{The \lstinline!Free1! encoding cannot be derived from the others
because \lstinline!Free1! \emph{requires} that the effect constructor
\lstinline!F! be a functor with a \lstinline!map! method, while
the other encodings work for any \lstinline!F!. Later in this chapter,
we will prove that \lstinline!Free1! is equivalent to \lstinline!Free2!
when \lstinline!F! is a functor. We will also show more examples
of free typeclass constructions that require another typeclass.}

To derive \lstinline!Free3! from \lstinline!Free4!, we use the right
identity law of \lstinline!flatMap! to express \lstinline!map! through
\lstinline!flatMap!:
\begin{lstlisting}
p.map(f) == p.flatMap (f andThen pure)
\end{lstlisting}
As we have already seen, this definition makes the right identity
law hold for \lstinline!Free3!. Following the form of that law, we
write a function for transforming a \lstinline!Free4! program into
a \lstinline!Free3! program:
\begin{lstlisting}
def free4toFree3[F[_], A]: Free4[F, A] => Free3[F, A] = {
  case fmap @ FMap(p)   => Bind(free4toFree3(p))(fmap.f andThen Free3.pure) // Replace FMap by Bind.
  case Val(a)           => Val(a)                                  // All other cases are unchanged.
  case bind@Bind(p)     => Bind(free4toFree3(p))(bind.f)
  case Op(op)           => Op(op)
}
\end{lstlisting}
An inverse transformation (from \lstinline!Free3! to \lstinline!Free4!)
is implemented by translating all case classes identically:
\begin{lstlisting}
def free3toFree4[F[_], A]: Free3[F, A] => Free4[F, A] = {
  case Val(a)           => Val(a)
  case bind@Bind(p)     => Bind(free3toFree4(p))(bind.f)
  case Op(op)           => Op(op)
}
\end{lstlisting}
The composition \lstinline!free3toFree4 andThen free4toFree3! is
an identity transformation because each case class is simply copied
over to the other type. However, the composition in the other order,
\lstinline!free4toFree3 andThen free3toFree4!, is not an identity
since \lstinline!free3toFree4! never creates \lstinline!Free4! values
of type \lstinline!FMap!. It is impossible to convert any values
of type \lstinline!Bind! to \lstinline!FMap! because it is impossible
to determine whether a given function of type \lstinline!A => Free3[B]!
is expressible in the form \lstinline!(f andThen pure)! with some
\lstinline!f: A => B!.

It follows that \lstinline!free3toFree4! is injective while \lstinline!free4toFree3!
is surjective. In this sense, the encoding \lstinline!Free4! is \textsf{``}larger\textsf{''}
than \lstinline!Free3!. However, \lstinline!Free4! does not express
any more functionality than \lstinline!Free3!. After running the
corresponding \lstinline!Free3! and \lstinline!Free4! DSL programs,
the results will be the same:
\begin{lstlisting}
runFree4(runner)(free4program) == runFree3(runner)(free4toFree3(free4program))
runFree3(runner)(free3program) == runFree4(runner)(free3toFree4(free3program))
\end{lstlisting}
To verify this, we first note that the case classes \lstinline!Val!,
\lstinline!Bind!, and \lstinline!Op! within the types \lstinline!Free3!
and \lstinline!Free4! will be evaluated in exactly the same way by
both runners. So, DSL programs in \lstinline!Free3! and \lstinline!Free4!
containing those case classes will give the same results when run.

It remains to verify that the runners will produce the same results
for a \lstinline!Free4! program containing an \lstinline!FMap! case
class and for the corresponding \lstinline!Free3! program. Running
a \lstinline!Free4! program of the form \lstinline!p = FMap(q)(f)!,
we will get:
\begin{lstlisting}
runFree4(runner)(p) == runFree4(runner)(FMap(q)(f)) == f(runFree4(runner)(q))
\end{lstlisting}
The \lstinline!Free3! program corresponding to \lstinline!p! is:
\begin{lstlisting}
free4toFree3(p) == Bind(q)(f andThen Free3.pure)
\end{lstlisting}
Running the program \lstinline!free4toFree3(p)! with \lstinline!Free3!\textsf{'}s
runner will give:
\begin{lstlisting}
runFree3(runner)(free4toFree3(p)) == runFree3(runner)(Bind(free4toFree3(q))(f andThen Free3.pure))
   == runFree3(runner)(Free3.pure(f(runFree3(runner)(free4toFree3(q)))))
   == runFree3(runner)(Pure(f(runFree3(runner)(free4toFree3(q)))))
   == f(runFree3(runner)(free4toFree3(q))))
\end{lstlisting}
The last expression differs from the result of evaluating \lstinline!runFree4(runner)(p)!
only in replacing \lstinline!runFree4! by \lstinline!runFree3!.
So, it remains to show that:
\begin{lstlisting}
f(runFree4(runner)(q)) == f(runFree3(runner)(free4toFree3(q))))
\end{lstlisting}
Note that \lstinline!q! is a \emph{smaller} monadic program (contains
fewer case classes) than \lstinline!p!. If \lstinline!q! contains
case classes other than \lstinline!FMap!, we already showed that
\lstinline!runFree4! and \lstinline!runFree3! give the same results.
If \lstinline!q! again contains the \lstinline!FMap! case class,
we will use the inductive assumption that \lstinline!runFree4! and
\lstinline!runFree3! give the same results when evaluating smaller
monadic programs.

Let us now derive \lstinline!Free2! from \lstinline!Free3!. A conversion
function \lstinline!free2toFree3! needs to replace \lstinline!Free2!\textsf{'}s
case classes (\lstinline!Return! and \lstinline!Bind!) by \lstinline!Free3!\textsf{'}s
case classes (\lstinline!Pure!, \lstinline!Suspend!, and \lstinline!FlatMap!).
The \lstinline!Return! case class corresponds to \lstinline!Pure!.
Trying to replace \lstinline!Bind! by \lstinline!FlatMap!, we find
that the type of their data are not the same: the first part of \lstinline!Bind!
has type \lstinline!F[A]! while the first part of \lstinline!FlatMap!
has type \lstinline!Free3[F, A]!. We note that \lstinline!Suspend!
converts \lstinline!F[A]! into \lstinline!Free3[F, A]!. So, we write
code like this:
\begin{lstlisting}
def free2toFree3[F[_], A]: Free2[F, A] => Free3[F, A] = {
  case Return(a)    => Pure(a)
  case Bind(p, g)   => FlatMap(Suspend(p), g andThen free2toFree3)
}
\end{lstlisting}

The inverse conversion function (\lstinline!free3toFree2!) is more
complicated because \lstinline!Suspend! and \lstinline!FlatMap!
are not straightforwardly mapped into \lstinline!Free2!\textsf{'}s case classes.{*}{*}{*}
\begin{lstlisting}
def free3toFree2[F[_], A]: Free3[F, A] => Free2[F, A] = {
  case Pure(a)         => Return(a)
  case Suspend(f)      => Bind(f, a => Return(a))
  case FlatMap(p, g)   => ???
}
\end{lstlisting}
{*}{*}{*}Some of these conversions are injective.

\subsection{Types with existential quantifiers}

The previous section showed all derivations in the Scala code syntax
rather than in the code notation. The reason is that the constructions
\lstinline!Free2!, \lstinline!Free3!, and \lstinline!Free4! involve
a special use of type parameters that is not supported by the type
and code notations shown in this book so far. The missing feature
is types with an \textbf{existential quantifier}\index{existential quantifier (exists)@existential quantifier ($\exists$)},
which is denoted by the symbol $\exists$ (pronounced \textsf{``}exists\textsf{''}).

To clarify the usage of the symbol $\exists$, we begin by recalling
the definition of the type \lstinline!MonadDSL!:
\begin{lstlisting}
sealed trait MonadDSL[F[_], T] {
  def flatMap[A](...) = ...
  def map[A](f: T => A): MonadDSL[F, A] = Bind(this)(f andThen MonadDSL.pure)
}
final case class Val[F[_], T](t: T)                                          extends MonadDSL[F, T]
final case class Op[F[_], T](f: F[T])                                        extends MonadDSL[F, T]
final case class Bind[F[_], T, A](p: MonadDSL[F, A])(g: A => MonadDSL[F, T]) extends MonadDSL[F, T]
\end{lstlisting}
The case class \lstinline!Bind[F, T, A]! uses the type parameter
\lstinline!A! in a special way. Whenever a value of type \lstinline!Bind[F, T, A]!
is constructed, the type parameter \lstinline!A! must be set to a
specific type. However, the result will be a value of type \lstinline!MonadDSL[F, T]!,
which is \emph{not} parameterized by \lstinline!A!. The extra type
parameter (\lstinline!A!) is hidden inside the constructed value
of type \lstinline!Bind[F, T, A]!.

To see this in a code example, let us apply \lstinline!map! to a
given value \lstinline!p! of type \lstinline!MonadDSL[F, Int]!:
\begin{lstlisting}
val p: MonadDSL[F, Int] = ...
val q: MonadDSL[F, String] = p.map { i: Int => s"value = $i" }     // Creates a Bind[F, String, Int].
\end{lstlisting}
The value \lstinline!q! is declared to be of type \lstinline!MonadDSL[F, T]!
with \lstinline!T = String!. However, the actual data structure in
\lstinline!q! contains a value of type \lstinline!Bind[F, T, A]!
with a type parameter \lstinline!A! chosen as \lstinline!A = Int!.
The type declaration \lstinline!Bind[F, T, A](...) extends MonadDSL[F, T]!
hides the type parameter \lstinline!A! from the rest of the code,
although that type parameter will be needed when constructing a value
\lstinline!q! of type \lstinline!Bind!. This usage of a type parameter
is called an \textbf{existentially quantified} type and is denoted
by $\exists A$.

The other type parameters (\lstinline!F!, \lstinline!T!) in \lstinline!Bind[F, T, A]!
are not existentially quantified because they appear both in the case
class and in the parent trait. So, we write the notation for \lstinline!Bind[F, T, A]!
as: 
\[
\exists A.\,\text{Bind}^{F,T,A}\triangleq\exists A.\,\text{MonadDSL}^{F,A}\times(A\rightarrow\text{MonadDSL}^{F,T})\quad.
\]
Adding the type notation for the case classes \lstinline!Val! and
\lstinline!Op!, we get a definition of the type \lstinline!MonadDSL!:
\begin{align*}
\text{MonadDSL}^{F,T} & \triangleq\text{Val}^{F,T}+\text{Op}^{F,T}+\exists A.\,\text{Bind}^{F,T,A}\\
 & \quad\quad=T+F^{T}+\exists A.\,\text{MonadDSL}^{F,A}\times(A\rightarrow\text{MonadDSL}^{F,T})\quad.
\end{align*}

To interpret the name \textsf{``}existential\textsf{''}, we may imagine that a type
parameter \lstinline!A! \textsf{``}still exists\textsf{''} inside the value \lstinline!q: MonadDSL[F, T]!,
since \lstinline!q! must have been created as \lstinline!Bind[F, T, A](...)(...)!
with a specific (somehow chosen) type \lstinline!A!. However, we
cannot inspect or obtain the type \lstinline!A! if we only have the
value \lstinline!q!. No pattern-matching or other operations on \lstinline!q!
can determine whether the type \lstinline!A! is, say, \lstinline!Int!
or \lstinline!String!. We can use the value \lstinline!q! in our
code as long as we treat \lstinline!A! as an unknown, arbitrary,
but fixed type.

Scala gives two ways of defining types with existential quantifiers:
via case classes with an extra type parameter, or via a class with
a type member. To illustrate these techniques, consider a type expression
$\exists C.\,L^{A,B,C}$ where $L$ is a type constructor with type
parameters $A$, $B$, $C$ and an existential quantifier on $C$.
Note that the type parameter\index{bound type parameter} $C$ is
\textbf{bound} by the quantifier and will not be visible outside the
type expression $\exists C.\,L^{A,B,C}$. The type parameters $A$
and $B$ remain free in $\exists C.\,L^{A,B,C}$.

An example of such a type expression is $\exists C.\,A\times C\times\left(C\rightarrow B\right)$.
Let us implement this type via case classes and via type members.
The code using case classes may look like this:
\begin{lstlisting}
sealed trait L[A, B]
final case class L1[A, B, C](a: A, c: C, p: C => B) extends L[A, B]
\end{lstlisting}

The type notation for \lstinline!L[A, B]! is:
\[
L^{A,B}\triangleq\exists C.\,\text{L1}^{A,B,C}=\exists C.\,A\times C\times(C\rightarrow B)\quad.
\]

When we create a value of type \lstinline!L[A, B]!, we need to assign
the type $C$:
\begin{lstlisting}
val q1: L[Int, Int] = L1[Int, Int, String](1, "abc", _.length)
\end{lstlisting}
External code may use data of type \lstinline!L[A, B]! as long as
it does not need to know the type assigned to $C$:
\begin{lstlisting}
def toInt: L[Int, Int] => Int = {
  case L1(a, c, p) => a + p(c) // May apply p: C => B to c: C without knowing what C is.
}

scala> toInt(q1)
res0: Int = 4
\end{lstlisting}
In this code, the expression \lstinline!p(c)! uses data of unknown
type \lstinline!C! but does not try to inspect that type.

To implement the type $\exists C.\,A\times C\times\left(C\rightarrow B\right)$
via a trait with a type member, we write:
\begin{lstlisting}
trait L2[A, B] {
  type C
  val a: A
  val c: C
  val p: C => B
}
val q2: L2[Int, Int] = new L2[Int, Int] {
  type C = String
  val a: Int = 1
  val c: String = "abc"
  val p: String => Int = _.length
}
def toInt(q: L2[Int, Int]): Int = q.a + q.p(q.c)

scala> toInt(q2)
res1: Int = 4
\end{lstlisting}
The code is more verbose but has equivalent functionality to the code
that uses a case class. Each time we create a value of type \lstinline!L[A, B]!
or \lstinline!L2[A, B]!, we will have to specify some type for \lstinline!C!.
Code external to the trait \lstinline!L2! will no longer know what
type was chosen as $C$. It will be a type error if external code
depends on the actual type assigned to \lstinline!C!:
\begin{lstlisting}
scala> val x: q2.C = "abc"        // The type q2.C is String but the code may not use that knowledge.
                    ^
error: type mismatch;
found   : String("abc")
required: q2.C
\end{lstlisting}
External code must treat the type \lstinline!q2.C! as an unknown,
arbitrary type.

We will use the existential quantifier notation for proofs of properties
of free monads and other constructions. With the new notation for
existential types, the free monad constructions are written as:
\begin{align*}
{\color{greenunder}\text{free monad on }F\text{ in a reduced encoding}:}\quad & \text{Free}_{2}^{F,T}\triangleq T+\exists A.\,F^{A}\times(A\rightarrow\text{Free}_{2}^{F,T})\quad,\\
{\color{greenunder}\text{free monad on }F\text{ in a reduced encoding}:}\quad & \text{Free}_{3}^{F,T}\triangleq T+F^{T}+\exists A.\,\text{Free}_{3}^{F,A}\times(A\rightarrow\text{Free}_{3}^{F,T})\quad,\\
{\color{greenunder}\text{free monad on }F\text{ in a raw tree encoding}:}\quad & \text{Free}_{4}^{F,A}\triangleq A+F^{A}+\exists B.\,\text{Free}_{4}^{F,B}\times(B\rightarrow A)\\
 & \quad\quad+\exists B.\,\text{Free}_{4}^{F,B}\times(B\rightarrow\text{Free}_{4}^{F,A})\quad.
\end{align*}


\subsection{Expressing existential quantifiers via universal quantifiers}

We will now motivate and define the connection between existential
and universal quantifiers.

The previous section shows that a type expression with an existentially
quantified type, such as $\exists C.\,A\times C\times\left(C\rightarrow B\right)$,
hides the actual type under the parameter $C$ and only exposes its
existence. Fully parametric\index{fully parametric!code} external
code may work with values of type $C$ as long as $C$ is treated
as an unknown and arbitrary type. This agrees with the restriction
that fully parametric code may not make decisions based on the actual
type assigned to a type parameter.

Let us formulate this property in more precise terms. An example of
\textsf{``}external code\textsf{''} is the function \lstinline!toInt! shown in the
previous section. The type signature and the code of \lstinline!toInt!
is written in the short notation as:
\[
\text{toInt}:\left(\exists C.\,\text{Int}\times C\times(C\rightarrow\text{Int})\right)\rightarrow\text{Int}\quad,\quad\quad\text{toInt}\triangleq(\exists C.\,a^{:\text{Int}}\times c^{:C}\times p^{:C\rightarrow\text{Int}})\rightarrow a+p(c)\quad.
\]
Generalizing from this example, we say that \textsf{``}code external to the
existential quantifier\textsf{''} means any function having an argument of
an existentially quantified type. For instance, this could be a function
of type $(\exists C.\,F^{C})\rightarrow D$ where $F^{C}$ is any
type expression and $D$ is any type. The existential quantifier allows
us to use values of the type $C$ as long as the code does not depend
on a specific type that is hidden under $C$. This means treating
$C$ as a \emph{type parameter}. Functions with type parameters have
type signatures with the \emph{universal} quantifier, such as $\forall C.\:F^{C}\rightarrow G^{C}$,
showing that the same code works with any type $C$. So, we a fully
parametric function of type $(\exists C.\,F^{C})\rightarrow D$ must
be a function of type $F^{C}\rightarrow D$ that works in the same
way for all types $C$. We usually write the types of such functions
as $\forall C.\,F^{C}\rightarrow D$. We conclude that the following
types are equivalent:
\begin{equation}
\text{for any fixed type }D:\quad(\exists C.\,F^{C})\rightarrow D\cong\forall C.\,(F^{C}\rightarrow D)\quad.\label{eq:existential-via-universal}
\end{equation}

It is important that the universal quantifier in $\forall C.\,F^{C}\rightarrow D$
is \emph{outside} the entire type expression $F^{C}\rightarrow D$.
(The type notations $\forall C.\,(F^{C}\rightarrow D)$ and $\forall C.\,F^{C}\rightarrow D$
are equivalent.) In contrast, the type $(\exists C.\,F^{C})\rightarrow D$
contains the existential quantifier ($\exists C$) \emph{inside} a
function argument.

To illustrate the type equivalence~(\ref{eq:existential-via-universal}),
we may rewrite the function \lstinline!toInt! as:
\begin{lstlisting}
def toIntL1[C]: L1[Int, Int, C] => Int = { case L1(a, c, p) => a + p(c) }
\end{lstlisting}
The function body of \lstinline!toIntL1! is the same as that of \lstinline!toInt!,
although the type signature changed.

To get more intuition for Eq.~(\ref{eq:existential-via-universal}),
first consider a value with a universally quantified type:
\begin{lstlisting}
def f[A]: F[A] = ...
\end{lstlisting}
The code of the function \lstinline!f! can work with any type \lstinline!A!.
If Scala did not support type parameters, we would need to define
the function \lstinline!f! separately for each possible type, as
if in a giant infinite tuple: \lstinline!(f[Int], f[String], f[List[Int]], ...)!.
In this sense, the definition of \lstinline!f[A]! replaces an \textsf{``}infinite
product\textsf{''} ranging over all possible types:
\[
f:\forall A.\,F^{A}\quad,\quad\quad\forall A.\,F^{A}=F^{\text{Int}}\times F^{\text{String}}\times F^{\text{List}^{\text{Int}}}\times...
\]
This formula is not rigorous (the \textsf{``}infinite product\textsf{''} is not clearly
defined). Importantly, this formula does not express the requirement
that the code of the function \lstinline!f! must work in the same
way for all types \lstinline!A!. We will use this formula only as
a heuristic illustration.

A value of an existentially quantified type, such as $\exists C.\,F^{C}$,
must be created by using a specific type for $C$. So, we may view
the type $\exists C.\,F^{C}$ as an \textsf{``}infinite disjunction\textsf{''} ranging
over all possible types that could have been used for $C$:
\[
\exists C.\,F^{C}=F^{\text{Int}}+F^{\text{String}}+F^{\text{List}^{\text{Int}}}+...
\]
Now look at the following type equivalence where a disjunctive type
is in the function argument:
\[
\left(A+B\right)\rightarrow D\cong\left(A\rightarrow D\right)\times\left(B\rightarrow D\right)\quad.
\]
Write the same type equivalence using the infinite product and the
infinite disjunction:
\[
(F^{\text{Int}}+F^{\text{String}}+F^{\text{List}^{\text{Int}}}+...)\rightarrow D\cong(F^{\text{Int}}\rightarrow D)\times(F^{\text{String}}\rightarrow D)\times(F^{\text{List}^{\text{Int}}}\rightarrow D)\times...
\]
This (non-rigorous) formula can be rewritten in terms of type quantifiers
as:
\[
(\exists C.\,F^{C})\rightarrow D\cong\forall C.\,(F^{C}\rightarrow D)\quad.
\]
This is the same as Eq.~(\ref{eq:existential-via-universal}).

Another way to see why Eq.~(\ref{eq:existential-via-universal})
works is to view the case class constructor \lstinline!L1[A, B, C]()!
as a function from a triple of type \lstinline!(A, C, C => B)! to
a value of type \lstinline!L[A, B]!. For clarity, let us denote that
function temporary by \lstinline!f! and write:
\begin{lstlisting}
def f[A, B, C](a: A, c: C, p: C => B): L[A, B] = L1(a, c, p) 
\end{lstlisting}
This code is just a function with some type parameters; that is, a
function that works in the same way for all types. So, the type notation
for the function \lstinline!f! must be written via the \emph{universal}
quantifiers for each type parameter:
\[
f:\forall(A,B,C).\,A\times C\times(C\rightarrow B)\rightarrow L^{A,B}\quad.
\]
The equivalent notation with the existential quantifier for $C$ looks
like this:
\[
f:\forall(A,B).\,\big(\exists C.\,A\times C\times(C\rightarrow B)\big)\rightarrow L^{A,B}=\forall(A,B).\,\big(\exists C.\,\text{L1}^{A,B,C})\rightarrow L^{A,B}\quad.
\]
This explains why the existential quantifier is represented in Scala
by a case class with an extra type parameter, such as \lstinline!L1[A, B, C]!.
The type parameter \lstinline!C! is existentially quantified because
it does not appear in \lstinline!L[A, B]!, while the two other parameters
(\lstinline!A! and \lstinline!B!) do appear in \lstinline!L[A, B]!
and are therefore universally quantified.

Motivated by these considerations, we may \emph{define} the meaning
of the symbol $\exists$ through Eq.~(\ref{eq:existential-via-universal}).
It is more convenient to use another formula that expresses $\exists C$
via $\forall C$:

\subsubsection{Statement \label{subsec:Statement-type-equivalence-existential-universal-Yoneda}\ref{subsec:Statement-type-equivalence-existential-universal-Yoneda}}

For any type constructor $F^{\bullet}$ (not necessarily covariant
or contravariant):
\begin{equation}
\exists C.\,F^{C}\cong\forall D.\,(\forall C.\,(F^{C}\rightarrow D))\rightarrow D\quad.\label{eq:existential-via-universal-Yoneda}
\end{equation}


\subparagraph{Proof}

The covariant Yoneda identity (Statement \ref{subsec:Statement-covariant-yoneda-identity-for-types})
shows that $Z\cong\forall D.\,(Z\rightarrow D)\rightarrow D$, where
$Z$ is any fixed type (independent of $D$). Set $Z\triangleq\exists C.\,F^{C}$
and find:
\begin{align*}
 & \gunderline{\exists C.\,F^{C}}\\
{\color{greenunder}\text{by covariant Yoneda identity}:}\quad & \cong\forall D.\,(\gunderline{(\exists C.\,F^{C})\rightarrow D})\rightarrow D\\
{\color{greenunder}\text{by Eq.~(\ref{eq:existential-via-universal})}:}\quad & \cong\forall D.\,(\gunderline{\forall C.\,(F^{C}\rightarrow D)})\rightarrow D\quad.
\end{align*}
$\square$

\section{Free constructions for other typeclasses}

The free monad was motivated by implementing a type-safe DSL with
variable binding. However, we may view the free monad as just a trick
that wraps an arbitrary type constructor in some case classes to obtain
the features of a monad. Are there similar tricks for adding the features
of an applicative functor, a filterable functor, etc., to an arbitrary
type constructor? 

Looking at the raw tree encoding and other encodings of the free monad,
we find a recipe that we can generalize to many other typeclasses.
Let us now formulate this recipe more formally.

The first step is to define the raw tree encoding of the free typeclass.
For the free monad, we wrote a case class for each of the monad\textsf{'}s
standard methods (\lstinline!map!, \lstinline!flatMap!, \lstinline!pure!)
and another case class for wrapping the given set of DSL operations.
The same recipe gives a raw tree encoding for many other free typeclasses,
as long as the typeclass operations are of the form of functions whose
last return type is again of the same typeclass. For instance, a monad
\lstinline!M!\textsf{'}s \lstinline!flatMap! has the type signature of the
form \lstinline!... => M[A]!, where the last return type uses the
same monad \lstinline!M!.

The second step is to implement the \textsf{``}universal runner\textsf{''} that transforms
a free typeclass value into a value of another type belonging to the
same typeclass. For instance, the universal runner for the free monad
on \lstinline!F! takes a polymorphic function of type $\forall A.\,F^{A}\rightarrow M^{A}$,
where $M$ is any other monad, and runs the free monad\textsf{'}s effects into
$M$\textsf{'}s effects.

Typically, the raw tree encoding will not satisfy the laws of the
typeclass. (However, the laws will hold after applying the runner.)
The third step is to impose the typeclass laws and to obtain a reduced
encoding that uses a smaller number of case classes and satisfies
the laws automatically. The code of the universal runner needs to
be revised to work with the reduced encoding.

The following sections will show several examples of these constructions.

\subsection{Free pointed types}

One of the simplest typeclasses is the \textbf{pointed}\index{pointed type}
type, that is, a type that has a designated default value. This is
the \lstinline!HasDefault! typeclass from Example~\ref{subsec:tc-Example-Pointed-type}.
Let us now apply the free typeclass construction to this example.
We will obtain a type constructor \lstinline!FreeDefault[T]! that
wraps an arbitrary type \lstinline!T! and has a \lstinline!HasDefault!
type instance.

The first step is to formulate the required methods of the typeclass
as functions with known type signatures. The \lstinline!HasDefault!
typeclass for a pointed type \lstinline!P! has only one operation:
obtaining a value \lstinline!default! of type \lstinline!P!. This
operation is equivalent to a function of type $\bbnum 1\rightarrow P$.
The free typeclass will model this operation via a case class containing
a value of unit type (equivalently, a named unit). We may write the
code like this:
\begin{lstlisting}
sealed trait FreeDefault[T]
final case class Default[T](unit: Unit) extends FreeDefault[T]
final case class Op[T](op: T) extends FreeDefault[T]
\end{lstlisting}
In the type notation, this is written as:
\[
\text{FreeDefault}^{T}\triangleq\bbnum 1+T\quad.
\]
 We find that \lstinline!FreeDefault[T]! is equivalent to \lstinline!Option[T]!,
so we will define it that way:
\begin{lstlisting}
type FreeDefault[T] = Option[T]
\end{lstlisting}


\subsubsection{Definition \label{subsec:Definition-free-pointed-type}\ref{subsec:Definition-free-pointed-type}}

The \textbf{free pointed type} on\index{free pointed type} a given
type $T$ is the type $\bbnum 1+T$.

The \lstinline!HasDefault! typeclass has no laws, so the raw tree
encoding ($\bbnum 1+T$) cannot be reduced by imposing any typeclass
laws. 

The free pointed typeclass comes with a \textsf{``}universal runner\textsf{''}, which
is a function from \lstinline!FreeDefault[T]! to a chosen pointed
type $P$. The runner needs to know how to translate $T$ into $P$,
and the code can be written as:
\begin{lstlisting}
def runner[T, P: HasDefault](run: T => P): Option[T] => P = {
  case Some(t)   => run(t)
  case None      => implicitly[HasDefault[P]].value          // The default value of type P.
}
\end{lstlisting}
This logic repeats the Scala standard library\textsf{'}s \lstinline!getOrElse!
method for \lstinline!Option!. For any value \lstinline!x: Option[T]!:
\begin{lstlisting}
runner(run)(x) == x.map(run).getOrElse(implicitly[HasDefault[P]].value)
\end{lstlisting}
So, we can view \lstinline!getOrElse! as a general form of the universal
runner for the free pointed typeclass.

What if the type $T$ is already pointed? The free pointed type on
$T$ is $\bbnum 1+T$, which is never equivalent to $T$. However,
the universal runner can be applied to the identity function of type
$T\rightarrow T$ and gives a function of type $\bbnum 1+T\rightarrow T$.
When $T$ is itself of the form $\bbnum 1+U$ then that function (of
type $\bbnum 1+\bbnum 1+U\rightarrow\bbnum 1+U$) is the standard
method \lstinline!flatten! defined on \lstinline!Option! types.

In this way, \lstinline!Option!\textsf{'}s standard methods \lstinline!getOrElse!
and \lstinline!flatten! are seen as regular properties of the free
pointed type construction.

\subsection{Free semigroups}

A semigroup (see Example~\ref{subsec:tc-Example-Semigroups}) is
a typeclass with a single method called \lstinline!combine!. A common
notation for \lstinline!combine! is $\oplus$, used as an infix binary
operation with type signature $\oplus:T\times T\rightarrow T$. The
semigroup\textsf{'}s law is the associativity law for the operation $\oplus$.

How can we convert an arbitrary type $T$ into a semigroup? Following
the general recipe, we first construct the raw tree encoding of a
free semigroup on a given type $T$. There is one case class for the
binary operation and another for wrapping a value of type $T$.
\begin{lstlisting}
sealed trait FSR[T]
final case class Combine[T](left: FSR[T], right: FSR[T]) extends FSR[T]
final case class Wrap[T](value: T) extends FSR[T]
\end{lstlisting}
The short notation for this type constructor is:
\[
\text{FSR}^{T}\triangleq T+\text{FSR}^{T}\times\text{FSR}^{T}\quad.
\]
We can now see that \lstinline!FSR[T]! is a binary tree with leaf
values of type $T$ (see Section~\subsecref{Binary-trees}).

We can implement a \lstinline!Semigroup! typeclass instance for \lstinline!FSR[T]!
like this:
\begin{lstlisting}
implicit def semigroupFSR[T]: Semigroup[FSR[T]] = Semigroup((l, r) => Combine(l, r)) *** verify code
\end{lstlisting}

For convenience, we will define a syntax extension so that we can
use the infix binary operation \lstinline!|+|!:
\begin{lstlisting}
implicit class SemigroupOp[S: Semigroup](s: S) {
  def |+|(other: S): S = implicitly[Semigroup[S]].combine(s, other)
}*** check if it works
\end{lstlisting}

As usual with raw tree encodings, the free semigroup\textsf{'}s binary operation
\lstinline!|+|! does not perform any computations but simply wraps
its arguments into the case class \lstinline!Combine!. A \textsf{``}free
semigroup program\textsf{''} (specifically, an \lstinline!FSR!-program) is
an unevaluated expression tree containing a number of nested \lstinline!Combine!
case classes as well as some values of type \lstinline!T! wrapped
in \lstinline!Wrap!. 

The next step is to implement a universal runner that will evaluate
that expression tree. Given any semigroup \lstinline!S! and a function
\lstinline!T => S!, we can run \lstinline!FSR[T]! into \lstinline!S!
like this:
\begin{lstlisting}
def runner[S: Semigroup, T](runT: T => S): FSR[T] => S = {
  case Combine(left, right)   => runner(runT)(left) |+| runner(runT)(right)
  case Wrap(value)            => runT(value)
}
\end{lstlisting}

This code is analogous to the code of \lstinline!foldMap! \index{foldMap function@\texttt{foldMap} function}for
aggregating tree-like data (Section~\subsecref{Aggregating-tree-like-data-bfs}).

Let us see an example of an \lstinline!FSR!-program for a free semigroup
on \lstinline!String!:
\begin{lstlisting}
val fsfProgram: FSR[String] = Wrap("abc") |+| (Wrap("xyz") |+| Wrap(""))
\end{lstlisting}
 To run this program, we need to choose another semigroup (\lstinline!S!)
and provide a function that maps \lstinline!String! to \lstinline!S!.
We choose \lstinline!S = Int!, a semigroup with respect to integer
addition. The function \lstinline!runT: String => Int! will return
the length of the string. In this way, we can compute the total length
of all strings within the \lstinline!FSR!-program:
\begin{lstlisting}
*** test that this works
implicit semigroupInt: Semigroup[Int] = Semigroup(_ + _)

scala> runner(_.length)(fsfProgram)
res0: Int = 6
\end{lstlisting}

The associativity law of \lstinline!|+|! will hold after applying
the runner to an \lstinline!FSR!-program because associativity is
assumed to hold for the operation \lstinline!|+|! of the semigroup
\lstinline!S!. However, the raw tree encoding itself does not obey
the associativity law because the nested data structure \lstinline!Combine(Combine(x, y), z)!
is not equal to \lstinline!Combine(x, Combine(y, z))!. The next step
is to look for a reduced encoding of the free semigroup that obeys
the associativity law.

The associativity law would hold if the result of \lstinline!Combine(x, y) |+| z!
were not \lstinline!Combine(Combine(x, y), z)! but \lstinline!Combine(x, Combine(y, z))!.
To achieve this, we could redefine the \lstinline!|+|! operation
by modifying the \lstinline!Semigroup! typeclass instance:
\begin{lstlisting}
implicit def semigroupFSR[T]: Semigroup[FSR[T]] = Semigroup((l, r) => l match {
  case Wrap(value)     => Combine(l, r)
  case Combine(p, q)   => p |+| (q |+| r) // Recursive call of |+|.
}) *** verify that this code works
\end{lstlisting}
The data structure from the new \lstinline!|+|! operation will be
of the form \lstinline!Combine(Wrap(x), Combine(Wrap(y), ...))!,
and the associativity law will always hold. 

The new data structure is equivalent to a non-empty list containing
values of type \lstinline!Wrap[T]!. The resulting type (\lstinline!NEL[Wrap[T]]!)
can be simplified to just \lstinline!NEL[T]! since a nested \lstinline!Wrap!
carries no functionality by itself. So, we can reuse the non-empty
list type \lstinline!NEL! and its \lstinline!concat! function (see
Example~\ref{subsec:Disjunctive-Example-non-empty-list-foldLeft}
and Exercise~\ref{subsec:Disjunctive-Exercise-non-empty-list-2}).
The universal runner is similar to the code of the \lstinline!foldLeft!
function shown in Example~\ref{subsec:Disjunctive-Example-non-empty-list-foldLeft}:
\begin{lstlisting}
implicit def semigroupNEL[T]: Semigroup[NEL[T]] = Semigroup((l, r) => concat(l, r))
 
@tailrec def runner[S: Semigroup, T](runT: T => S)(n: NEL[T]): S = n match {
  case Last(x)        => runT(x)
  case More(x, tail)  => runner(runT)(tail)
}
\end{lstlisting}

This defines \lstinline!NEL[T]! as a reduced encoding of the free
semigroup on \lstinline!T!. 

Comparing the raw tree encoding \lstinline!FSR[T]! and the reduced
encoding \lstinline!NEL[T]!, we find some differences in run-time
performance. For \lstinline!NEL[T]!, the binary operation \lstinline!|+|!
involves concatenating two lists, which may require traversing the
lists. The raw tree encoding\textsf{'}s binary operation takes constant time
as it only wraps the data in a new case class. However, \lstinline!NEL[T]!\textsf{'}s
run operation may be implemented with tail recursion while \lstinline!FSR[T]!
is a binary tree whose traversal cannot be tail-recursive.

\subsection{Free monoid and its partially lawful encodings\label{subsec:Free-monoids}}

A monoid (see Example~\ref{subsec:tc-Example-Monoids}) is a typeclass
with a two methods: \lstinline!combine! and \lstinline!empty!. The
monoid\textsf{'}s laws are the associativity law and two identity laws.

To convert an arbitrary type $T$ into a free monoid on $T$, we follow
the general recipe and write the raw tree encoding. There is one case
class for the binary operation, one case class for \lstinline!empty!,
and one for wrapping a value of type $T$.
\begin{lstlisting}
sealed trait FMR[T]
final case class Combine[T](left: FMR[T], right: FMR[T]) extends FMR[T]
final case class Empty[T]() extends FMR[T]
final case class Wrap[T](value: T) extends FMR[T]
\end{lstlisting}
The short notation for this type constructor is:
\[
\text{FMR}^{T}\triangleq\bbnum 1+T+\text{FMR}^{T}\times\text{FMR}^{T}\quad.
\]
We can see that \lstinline!FMR[T]! is just a binary tree with leaf
values of type $\bbnum 1+T$:
\[
\text{FMR}^{T}=\text{Tree2}^{\bbnum 1+T}\quad.
\]
The binary tree type \lstinline!Tree2! was defined in Section~\ref{subsec:Binary-trees}.
The data type $\text{FMR}^{T}$ represents an \emph{unevaluated} expression
tree built from the monoid operations and from values of type $T$,
for example:

\begin{wrapfigure}{l}{0.6\columnwidth}%
\vspace{-0.4\baselineskip}
\begin{lstlisting}
val exampleFMR: FMR[Int] = Combine(Empty(), Combine( Combine(Wrap(456), Empty()), Wrap(123)))
\end{lstlisting}
\vspace{0.2\baselineskip}
\end{wrapfigure}%

\noindent {\tiny{}\hspace{0.1\columnwidth}}{\tiny{} \Tree[ [ $e$ ] [ [ [ $456$ ] [ $e$ ] ] [ $123$ ] ] ] }{\tiny\par}

We can implement a \lstinline!Monoid! typeclass instance for \lstinline!FMR[T]!
like this:
\begin{lstlisting}
implicit def monoidFMR[T]: Monoid[FMR[T]] = Monoid((l, r) => Combine(l, r), Empty())
\end{lstlisting}
We define a syntax extension for the infix binary operation \lstinline!|+|!
as in the previous section.

As usual with raw tree encodings, this free monoid\textsf{'}s operations not
perform any computations but only create nested case classes. Those
nested case classes represent an unevaluated expression tree of an
\textsf{``}\lstinline!FMR!-program\textsf{''}. The next step is to implement a universal
runner that will evaluate that expression tree using the operations
of any chosen monoid \lstinline!M!. Given a function \lstinline!T => M!,
we can convert any \lstinline!FMR!-program (a value of type \lstinline!FMR[T]!)
into a value of type \lstinline!M! like this:
\begin{lstlisting}
def runnerFMR[M: Monoid, T](runT: T => M)(fmr: FMR[T]): M = fmr match {
  case Combine(left, right)   => runnerFMR(runT)(left) |+| runnerFMR(runT)(right)
  case Empty()                => Monoid[M].empty
  case Wrap(value)            => runT(value)
}
\end{lstlisting}

The raw tree encoding \lstinline!FMR[T]! does not satisfy any of
the monoid laws (the associativity law and the two identity laws).
This is not a problem in practice, since the laws will hold after
running an \lstinline!FMR!-program into any lawful monoid \lstinline!M!.
Imposing the monoid laws will help us find reduced encodings of the
free monoid.

As with the free semigroup, the associativity law will hold if we
replace a binary tree by a non-empty list. The result is a non-empty
list of values of type $\bbnum 1+T$. The type \lstinline!NEL[Option[T]]!
is a possible encoding of the free monoid; it satisfies the associativity
law but fails the identity laws. The empty value of the free monoid
is represented by a single-element list containing \lstinline!None!
(in the code notation, $[1+\bbnum 0^{:T}]$). The identity laws of
the monoid would hold if lists of the form: 
\[
\left[\bbnum 0+x_{1},...,\bbnum 0+x_{m},1+\bbnum 0,\bbnum 0+y_{1},...,\bbnum 0+y_{n}\right]
\]
were replaced by lists $\left[x_{1},...,x_{m},y_{1},...,y_{n}\right]$
that do not contain any \lstinline!None! values. This would mean
that it is enough to use \lstinline!NEL[T]! instead of \lstinline!NEL[Option[T]]!,
except for the possibility that a non-empty list contains only \lstinline!None!
values. For simplicity, we can represent that situation by an \emph{empty}
list. So, we may replace \lstinline!NEL[Option[T]]! by simply \lstinline!List[T]!.
The binary operation for \lstinline!List[T]! is just the \lstinline!concat!
function for lists; the empty list is the empty monoid value.

The type \lstinline!List[T]! is the shortest reduced encoding for
the free monoid on $T$, and it satisfies all monoid laws. The runner
is the same as the \lstinline!foldMap! function for lists (see Section~\ref{subsec:From-reduce-and-foldleft-to-foldmap}):\index{foldMap function@\texttt{foldMap} function}
\begin{lstlisting}
def runnerList[M: Monoid, T](runT: T => M): List[T] => M = foldMap[M, T](runT)
\end{lstlisting}

There exist other reduced encodings that satisfy only a subset of
the monoid laws. As an example, let us define a reduced encoding of
the free monoid that satisfies the identity laws but not the associativity
law. To impose the identity laws on $\text{Tree2}^{\bbnum 1+T}$,
we note that the identity laws reduce expression trees creating \textsf{``}empty\textsf{''}
leaf values ($1+\bbnum 0^{:T}$) to expression trees that do not contain
any \textsf{``}empty\textsf{''} values in the leaves. For instance, the value \lstinline!exampleFMR!
defined above will be reduced to just \lstinline!Combine(Wrap(456), Wrap(123))!.
If all leaves of the expression tree are \lstinline!Empty!, the tree
must be reduced to just a single empty value. This means we can simplify
the encoding from $\text{Tree2}^{\bbnum 1+T}$ to $\bbnum 1+\text{Tree2}^{T}$.

To summarize, we have obtained four different \textsf{``}partially lawful\textsf{''}
free monoid encodings:\\
\textbf{1)} The encoding $F_{1}^{T}\triangleq\text{Tree2}^{\bbnum 1+T}$
(called \lstinline!FMR[T]! above) satisfies none of the monoid laws.
The code is:
\begin{lstlisting}
type F1[T] = Tree2[Option[T]]
def wrapF1[T](t: T): F1[T] = Leaf(Some(t))
implicit def monoidF1[T]: Monoid[F1[T]] = Monoid((l, r) => Branch(l, r), Leaf(None))
def runnerF1[M: Monoid, T](runT: T => M)(fmr: F1[T]): M = fmr match {
  case Branch(left, right)   => runnerF1(runT)(left) |+| runnerF1(runT)(right)
  case Leaf(None)            => Monoid[M].empty
  case Leaf(Some(value))     => runT(value)
}
\end{lstlisting}

\textbf{2)} The encoding $F_{2}^{T}\triangleq\text{NEL}^{\bbnum 1+T}$
satisfies only the associativity law. The code is:
\begin{lstlisting}
type F2[T] = NEL[Option[T]]
def wrapF2[T](t: T): F2[T] = (Some(t), Nil)
implicit def monoidF2[T]: Monoid[F2[T]] = Monoid(NEL.concat, (None, Nil))
def runnerF2[M: Monoid, T](runT: T => M)(fmr: F2[T]): M = foldMap(runT).apply(fmr.toList.flatten) 
\end{lstlisting}
For completeness, here is a simple implementation of non-empty lists
and some methods on them:
\begin{lstlisting}
type NEL[T] = (T, List[T])
object NEL {
  def concat[T]: (NEL[T], NEL[T]) => NEL[T] = {
    case ((head1, tail1), (head2, tail2)) => (head1, tail1 ++ List(head2) ++ tail2)
  }
  implicit class ToList[T](nel: NEL[T]) {
    def toList: List[T] = nel._1 +: nel._2
  }
}
\end{lstlisting}

\textbf{3)} The encoding $F_{3}^{T}\triangleq\bbnum 1+\text{Tree2}^{T}$
satisfies only the identity laws. The code is:
\begin{lstlisting}
type F3[T] = Option[Tree2[T]]
def wrapF3[T](t: T): F3[T] = Some(Leaf(t))
def concatF3[T]: (F3[T], F3[T]) => F3[T] = {
  case (None, x)            => x
  case (x, None)            => x
  case (Some(a), Some(b))   => Some(Branch(a, b))
}
def wrapF3[T](t: T): F3[T] = Some(Leaf(t))
implicit def monoidF3[T]: Monoid[F3[T]] = Monoid(concatF3, None)
def runnerTree2[M: Monoid, T](runT: T => M)(tree2: Tree2[T]): M = tree2 match {
  case Leaf(a)               => runT(a)
  case Branch(left, right)   => runnerTree2(runT)(left) |+| runnerTree2(runT)(right)
}
def runnerF3[M: Monoid, T](runT: T => M)(fmr: F3[T]): M = fmr match {
  case Some(t)   => runnerTree2(runT)(t)
  case None      => Monoid[M].empty
}
\end{lstlisting}

\textbf{4)} The encoding $F_{4}^{T}\triangleq\text{List}^{T}$ satisfies
all the monoid laws. The code is:
\begin{lstlisting}
type F4[T] = List[T]
def wrapF4[T](t: T): F4[T] = List(t)
implicit def monoidF4[T]: Monoid[F4[T]] = Monoid(_ ++ _, Nil)
def runnerF4[M: Monoid, T](runT: T => M)(fmr: F4[T]): M = foldMap(runT).apply(fmr)
\end{lstlisting}

To get more intuition about using these encodings, let us explore
whether the types \lstinline!F1!, \lstinline!F2!, \lstinline!F3!,
\lstinline!F4! can be mapped into each other. All of those encodings
have a \lstinline!Monoid! instance, so we can use their runner functions
to map any encoding into any other:
\begin{lstlisting}
def f1_to_f2[T]: F1[T] => F2[T] = runnerF1(wrapF2[T](_))
def f3_to_f2[T]: F3[T] => F2[T] = runnerF3(wrapF2[T](_))
def f4_to_f3[T]: F4[T] => F3[T] = runnerF4(wrapF3[T](_)) // And so on.
\end{lstlisting}
But it turns out that some of those mappings fail to preserve the
monoid operations. For instance, converting a list $\left[1,2,3\right]$
of type \lstinline!F4[Int]! to the type \lstinline!F3[Int]! will
create the following tree:
\begin{lstlisting}
scala> f4_to_f3(List(1, 2, 3))
res0: F3[Int] = Some(Branch(Branch(Leaf(1), Leaf(2)), Leaf(3)))
\end{lstlisting}
The same value \lstinline!List(1, 2, 3)! can be computed via \lstinline!F4!\textsf{'}s
monoid operation as \lstinline!List(1) |+| List(2, 3)!. However,
converting the two shorter lists to \lstinline!F3[Int]! and combining
them via \lstinline!F3!\textsf{'}s monoid operation will give a different
tree:
\begin{lstlisting}
scala> f4_to_f3(List(1)) |+| f4_to_f3(List(2, 3))
res1: F3[Int] = Some(Branch(Leaf(1), Branch(Leaf(2), Leaf(3))))
\end{lstlisting}
The trees are not the same because \lstinline!F3! does not obey the
monoid associativity law while \lstinline!F4! does.

{*}{*}{*}Show injectivity of those transformations

Looking at these examples, we find that whenever a free monoid encoding
\lstinline!P! obeys \emph{more laws} than another encoding \lstinline!Q!,
the transformation of type \lstinline!P => Q! does not preserve the
monoid operations (while the opposite one, \lstinline!Q => P!, does).
At the same time, the transformation of type \lstinline!P => Q! is
injective, suggesting that the encoding is \textsf{``}smaller\textsf{''} when it satisfies
more laws. These observations will be generalized in Section~\ref{subsec:Free--typeclasses-that-satisfy-laws}
to a rigorous theory of free typeclass encodings that satisfy only
a subset of the laws of a given typeclass.

\subsection{Free functors}

Consider the \lstinline!Functor! typeclass whose only method is \lstinline!fmap!:
\[
\text{fmap}:\left(A\rightarrow B\right)\rightarrow F^{A}\rightarrow F^{B}\quad.
\]
For some type constructors $F$, the \lstinline!fmap! method is not
available. An example is when $F$ is a contrafunctor or a GADT. (See
Section~\ref{subsec:Examples-of-non-functors} for more examples.)
Let us now apply the raw tree encoding recipe to the \lstinline!Functor!
typeclass. The result will be a new type constructor that we call
a \textbf{free functor on} $F$.\index{free functor} Here $F$ is
the effect constructor and does not need to be covariant with respect
to its type parameter.

The recipe tells us to define a case class for the \lstinline!fmap!
method and another case class to wrap the given type constructor $F$.
So, the raw tree encoding of a free functor on $F$ looks like this:
\begin{lstlisting}
sealed trait FFR[F[_], A] {
  def map[B](f: A => B): FFR[F, B] = FMap(f, this)
}
final case class FMap[F[_], X, Y](f: X => Y, p: FFR[F, X]) extends FFR[F, Y]
final case class Op[F[_], A](op: F[A]) extends FFR[F, A]
\end{lstlisting}

This code corresponds to the following notation for the lifting $f^{\uparrow\text{FFR}}$:
\begin{align}
 & \text{FFR}^{F^{\bullet},A}\triangleq F^{A}+\exists X.\,(X\rightarrow A)\times\text{FFR}^{F^{\bullet},X}\quad,\label{eq:definition-FFR-existential-type}\\
 & p^{:\text{FFR}^{F^{\bullet},A}}\triangleright(f^{:A\rightarrow B})^{\uparrow\text{FFR}^{F^{\bullet},\bullet}}\triangleq\bbnum 0^{:F^{B}}+\exists^{A}.\,f^{:A\rightarrow B}\times p^{:\text{FFR}^{F^{\bullet},A}}\quad.\nonumber 
\end{align}
The notation $\exists^{A}$ means that we bind the type $A$ to the
existentially quantified type $X$ in the definition~(\ref{eq:definition-FFR-existential-type})
of $\text{FFR}^{F^{\bullet},B}$. This notation expresses the requirement
that the existentially quantified type must be assigned to a specific
type every time we create a specific value.

A \textsf{``}free functor program\textsf{''} is a value of type \lstinline!FFR[F, A]!.
To construct such values, we need to begin with a wrapped \lstinline!F!-operation
followed by some \lstinline!map! methods. To use a free functor program
in practice, we need to apply a runner to it. A simple runner is a
function of type $\forall A.\,\text{FFR}^{F,A}\rightarrow A$ that
extracts a value of type $A$ from a free functor program. To obtain
a runner, we need to know how to extract values from the effect constructor
$F$. That information is given by a function of type $\forall C.\,F^{C}\rightarrow C$
(an \index{effect runner}effect runner for $F$). To implement such
functions, we use the trait \lstinline!Runner! defined in Section~\ref{subsec:A-first-recipe-monadic-dsl}.
Now we can write the code of the runner for $\text{FFR}^{F,A}$:
\begin{lstlisting}
def runFFR[F[_], A](runner: Runner[F]): FFR[F, A] => A = {
  case FMap(f, p)   => f(runFFR(runner)(p))
  case Op(op)       => runner.apply(op)
}*** check if this works
\end{lstlisting}
The code notation for this function is:
\begin{align*}
 & \text{runFFR}^{F^{\bullet},A}:(\forall C.\,F^{C}\rightarrow C)\rightarrow\text{FFR}^{F^{\bullet},A}\rightarrow A\quad,\\
 & \text{runFFR}(\text{run}:\forall C.\,F^{C}\rightarrow C)\triangleq\forall B.\,\,\begin{array}{|c||c|}
 & A\\
\hline F^{A} & \text{run}\\
(B\rightarrow A)\times\text{FFR}^{F^{\bullet},B} & f^{:B\rightarrow A}\times p^{:FFR^{F^{\bullet},B}}\rightarrow p\triangleright\big(\overline{\text{runFFR}}(\text{run})\big)\triangleright f
\end{array}\quad.
\end{align*}
The outside universal quantifier $\forall B$ replaces $\exists B$
in the function argument, according to Eq.~(\ref{eq:existential-via-universal}).

More generally, we may want to run the effects of $F$ into the effects
of a given functor $G$. (The functor $G$ could, for example, describe
errors or asynchronous execution.) The corresponding runner will have
type $\forall C.\,F^{C}\rightarrow G^{C}$, and the code is: 
\begin{align*}
 & \text{runFFR}^{F^{\bullet},G^{\bullet},A}:(\forall C.\,F^{C}\rightarrow G^{C})\rightarrow\text{FFR}^{F^{\bullet},A}\rightarrow G^{A}\quad,\\
 & \text{runFFR}\,(\text{run})\triangleq\forall B.\,\,\begin{array}{|c||c|}
 & G^{A}\\
\hline F^{A} & \text{run}\\
(B\rightarrow A)\times\text{FFR}^{F^{\bullet},B} & f^{:B\rightarrow A}\times p^{:FFR^{F^{\bullet},B}}\rightarrow p\triangleright\big(\overline{\text{runFFR}}\,(\text{run})\big)\triangleright f^{\uparrow G}
\end{array}\quad.
\end{align*}

The type constructor \lstinline!FFR! is a \index{free functor!raw tree encoding}raw
tree encoding of the free functor and does not satisfy the functor
laws. This is not a problem in practice, because the functor laws
will be satisfied after we run an \lstinline!FFR!-program into any
lawful functor $G$:

\subsubsection{Statement \label{subsec:Statement-free-functor-raw-tree-encoding-satisfies-laws}\ref{subsec:Statement-free-functor-raw-tree-encoding-satisfies-laws}}

Take any free functor ($\text{FFR}^{F^{\bullet},A}$) and any runner
($\text{run}:\forall C.\,F^{C}\rightarrow G^{C}$), where $G$ is
a lawful functor. Denote for brevity $f^{\uparrow\text{FFR}}\triangleq f^{\uparrow\text{FFR}^{F^{\bullet},\bullet}}$.
The functor laws will hold if we apply the runner function, denoted
for brevity by $\rho\triangleq\text{runFFR}\,(\text{run})$,{*}{*}{*}replace
$\rho$ with some other letter{*}{*}{*} to both sides of the laws:
\begin{align*}
{\color{greenunder}\text{identity law}:}\quad & \text{id}^{\uparrow\text{FFR}}\bef\text{runFFR}\,(\text{run})=\text{runFFR}\,(\text{run})\quad,\\
{\color{greenunder}\text{composition law}:}\quad & f^{\uparrow\text{FFR}}\bef g^{\uparrow\text{FFR}}\bef\text{runFFR}\,(\text{run})=(f\bef g)^{\uparrow\text{FFR}}\bef\text{runFFR}\,(\text{run})\quad.
\end{align*}
These equations hold even though $\text{id}^{\uparrow\text{FFR}}\neq\text{id}$
and $f^{\uparrow\text{FFR}}\bef g^{\uparrow\text{FFR}}\neq(f\bef g)^{\uparrow\text{FFR}}$.

\subparagraph{Proof}

Apply both sides of the laws to an arbitrary \lstinline!FFR!-program
$p^{:\text{FFR}^{F^{\bullet},A}}$:
\begin{align*}
{\color{greenunder}\text{identity law}:}\quad & p\triangleright\text{id}^{\uparrow\text{FFR}}\bef\rho=p\triangleright\rho\quad,\\
{\color{greenunder}\text{composition law}:}\quad & p\triangleright f^{\uparrow\text{FFR}}\triangleright g^{\uparrow\text{FFR}}\triangleright\rho=p\triangleright(f\bef g)^{\uparrow\text{FFR}}\triangleright\rho\quad.
\end{align*}

To verify the identity law, we write the code matrices of the functions:
\begin{align*}
{\color{greenunder}\text{expect to equal }p\triangleright\rho:}\quad & \gunderline{p\triangleright\text{id}^{\uparrow\text{FFR}}}\triangleright\rho\\
 & =\big(\bbnum 0+\text{id}\times p\big)\triangleright\,\begin{array}{||c|}
\text{run}\\
k\times p\rightarrow p\triangleright\rho\triangleright k^{\uparrow G}
\end{array}\,=p\triangleright\rho\triangleright\gunderline{\text{id}^{\uparrow G}}\\
{\color{greenunder}\text{identity law of }G:}\quad & =p\triangleright\rho\quad.
\end{align*}
To verify the composition law, begin by computing the left-hand side:
\begin{align*}
 & p\triangleright f^{\uparrow\text{FFR}}\triangleright g^{\uparrow\text{FFR}}\triangleright\rho=(\bbnum 0+f\times p)\triangleright g^{\uparrow\text{FFR}}\triangleright\rho=(\bbnum 0+g\times(\bbnum 0+f\times p))\triangleright\rho\\
 & =\big(\bbnum 0+g\times(\bbnum 0+f\times p)\big)\triangleright\,\begin{array}{||c|}
\text{run}\\
k\times p\rightarrow p\triangleright\rho\triangleright k^{\uparrow G}
\end{array}\,=\gunderline{(\bbnum 0+f\times p)\triangleright\rho}\triangleright g^{\uparrow G}\\
{\color{greenunder}\text{definition of }\rho:}\quad & =p\triangleright\rho\triangleright f^{\uparrow G}\triangleright g^{\uparrow G}\\
{\color{greenunder}\text{composition law of }G:}\quad & =p\triangleright\rho\triangleright(f\bef g)^{\uparrow G}\quad.
\end{align*}
The right-hand side is then simplified to the same code:
\begin{align*}
 & p\triangleright(f\bef g)^{\uparrow\text{FFR}}\triangleright\rho=(\bbnum 0+(f\bef g)\times p)\triangleright\rho\\
{\color{greenunder}\text{definition of }\rho:}\quad & =p\triangleright\rho\triangleright(f\bef g)^{\uparrow G}\quad.
\end{align*}
$\square$

To transform the raw tree encoding of the free functor into a reduced
encoding, we require that all functor laws should hold even before
applying a runner. We begin by finding out in detail why the functor
laws fail to hold for \lstinline!FFR[F, A]!.

The type \lstinline!FFR[F, A]! is a disjunction of two case classes,
\lstinline!FMap! and \lstinline!Op!. The functor\textsf{'}s composition law
says that the composition of lifted functions, $f^{\uparrow\text{FFR}}\bef g^{\uparrow\text{FFR}}$,
must be equal to the lifted composition: $(f\bef g)^{\uparrow\text{FFR}}$.
If we apply $(f\bef g)^{\uparrow\text{FFR}}$ to a value of the form
\lstinline!Op(op)!, we will get \lstinline!FMap(f andThen g, Op(op))!.
However, applying the composition $f^{\uparrow\text{FFR}}\bef g^{\uparrow\text{FFR}}$
to \lstinline!Op(op)!, we obtain a different value: \lstinline!FMap(g, FMap(f, Op(op)))!.
That value has nested \lstinline!FMap! classes instead of the composition
of \lstinline!f! and \lstinline!g!. The composition law would hold
if the \lstinline!map! method created a non-nested \lstinline!FMap!
class containing the composition of \lstinline!f! and \lstinline!g!.
To achieve that, let us define \lstinline!map! on the \lstinline!FMap!
case class like this:
\begin{lstlisting}
final case class FMap[F[_], X, Y](f: X => Y, p: FFR[F, X]) extends FFR[F, Y] {
  def map[Z](g: Y => Z): FFR[F, Z] = FMap[F, X, Z](f andThen g, p)
}
\end{lstlisting}

Turn now to the functor\textsf{'}s identity law, which says that the lifted
identity function, $\text{id}^{\uparrow\text{FFR}}$, must be again
an identity function. The new definition of \lstinline!map! for the
\lstinline!FMap! case class satisfies that law. However, applying
$\text{id}^{\uparrow\text{FFR}}$ to a value \lstinline!Op(op)! does
not return \lstinline!Op(op)! but instead gives \lstinline!FMap(identity, Op(op))!.
Values of the form \lstinline!Op(op)! represent \lstinline!F!-effects.
The functor identity law would hold if we instead represented $F$-effects
by the \lstinline!FMap! case class as \lstinline!FMap(identity, Op(op))!.

Any \lstinline!FFR!-program must have the form \lstinline!Op(x).map(y).map(z)...!,
having zero or more \lstinline!map! methods. If we represent \lstinline!F!-effects
by \lstinline!FMap(identity, Op(op))! and implement the \lstinline!map!
methods for \lstinline!FMap! as shown above, it will follow that
\emph{all} \lstinline!FFR!-programs always have the form \lstinline!FMap(f, Op(op))!
for some function \lstinline!f!. So, we may remove the \lstinline!Op!
case class altogether.

The result is a simplified definition of the free functor. The complete
code is:
\begin{lstlisting}
sealed trait FF[F[_], A] {
  def map[B](f: A => B): FF[F, B]
}
final case class FMap[F[_], X, Y](f: X => Y, p: F[X]) extends FF[F, Y] {
  def map[Z](g: Y => Z): FF[F, Z] = FMap[F, X, Z](f andThen g, p)
}
def runFF[F[_], A](runner: Runner[F]): FF[F, A] => A = {
  case FMap(f, p)   => f(runner.apply(p))
}*** check if this works
\end{lstlisting}

The code notation for this code and a general runner is:
\begin{align*}
 & \text{FF}^{F^{\bullet},A}\triangleq\exists C.\,\left(C\rightarrow A\right)\times F^{C}\quad,\quad\quad(\exists C.\,f^{:C\rightarrow A}\times p^{:F^{C}})\triangleright(g^{:A\rightarrow B})^{\uparrow\text{FR}}\triangleq\exists^{C}.\,(f\bef g)\times p\quad,\\
 & \text{runFF}:(\forall C.\,F^{C}\rightarrow G^{C})\rightarrow\text{FF}^{F^{\bullet},A}\rightarrow G^{A}\quad,\\
 & \text{runFF}\,(\text{run})\triangleq(\exists C.\,f^{:C\rightarrow A}\times p^{:F^{C}})\rightarrow p\triangleright\text{run}\triangleright f^{\uparrow G}\quad.
\end{align*}
This is the \textbf{reduced encoding}\index{free functor!reduced encoding}
of the free functor on $F$. This encoding was derived by imposing
the functor laws, so those laws will hold for values of type \lstinline!FF[F, A]!
even before applying a runner.

The free functor construction \lstinline!FF[F, A]! converts \emph{any}
type constructor \lstinline!F[_]! into a lawful functor. What if
\lstinline!F[_]! is already a functor? It turns out that the type
\lstinline!FF[F, A]! will then be \emph{equivalent} to \lstinline!F[A]!,
assuming that all code that uses \lstinline!FF[F, A]! is fully parametric.
This property of the reduced encoding is called the \textbf{co-Yoneda
identity}\index{co-Yoneda identity}:
\begin{align*}
{\color{greenunder}\text{covariant co-Yoneda identity}:}\quad & \exists C.\,\left(C\rightarrow A\right)\times F^{C}\cong F^{A}\quad\text{for any functor }F\quad.
\end{align*}
We will prove this type equivalence in Statement~\ref{subsec:Statement-co-Yoneda-two-identities}
below. 

We conclude that the reduced encoding of the free functor (\lstinline!FF[F, A]!)
has advantages over the raw tree encoding (\lstinline!FFR[F, A]!).
The reduced encoding contains only one case class, and the runner
code is not recursive because an \lstinline!FF!-program does not
contain any nested case classes. If $F$ is already a functor, the
reduced encoding of a free functor on $F$ is equivalent to $F$.

A disadvantage of the reduced encoding is that the function composition
is done in the code \lstinline!FMap(f andThen g, p)!. The Scala compiler
cannot directly handle the composition of a large number of functions
without causing a stack overflow. This problem can be resolved if
we postpone the function composition and instead create a list of
functions that need to be composed. The runner can evaluate the list
of functions without running into a stack overflow.

This gives us an idea for another encoding of the stack-safe free
functor, which we will call \lstinline!FFS!. First, we implement
a data structure called \lstinline!FuncSeq! for storing a list of
functions with matching types. A value of type \lstinline!FuncSeq[A, B]!
holds a list of functions with types $A\rightarrow C_{1}$, $C_{1}\rightarrow C_{2}$,
..., $C_{n-1}\rightarrow C_{n}$, $C_{n}\rightarrow B$, where $C_{i}$
are some chosen types. A list of with those types can be composed
to yield a function of type $A\rightarrow B$. To simplify code, we
will cast all intermediate types to \lstinline!Any! and back. Our
code will take care to construct \lstinline!FuncSeq! values with
correct types.\lstinline!final case class FuncSeq[X, Y](first: X => Any, funcs: Vector[Any => Any]) {  def append[Z](g: Y => Z): FuncSeq[X, Z] = FuncSeq(first, funcs :+ g.asInstanceOf[Any => Any])}!

To ensure stack safety when working with \lstinline!FuncSeq!, we
implement a tail-recursive function \lstinline!runSeq! that composes
all functions stored in the sequence and applies them to a given value.

\begin{lstlisting}
@tailrec def runSeq[X, Y](x: X, p: FuncSeq[X, Y]): Y = p.funcs.headOption match {
  case None => p.first(x).asInstanceOf[Y]
  case Some(second) => runSeq(p.first(x), FuncSeq(second, p.funcs.tail))
}
\end{lstlisting}
Now we can write the code of the free functor \lstinline!FFS!:
\begin{lstlisting}
sealed trait FFS[F[_], A] {
  def map[B](f: A => B): FFS[F, B]
}
final case class FMap[F[_], X, Y](f: FuncSeq[X, Y], p: F[X]) extends FFS[F, Y] {
  def map[Z](g: Y => Z): FFS[F, Z] = FMap[F, X, Z](f append g, p)
}
def runFF[F[_], A](runner: Runner[F]): FFS[F, A] => A = {
 case FMap(f, p) => runSeq(runner.apply(p), f)
}*** check if this works
\end{lstlisting}


\subsection{Free contrafunctors}

Method $\text{contramap}:C^{A}\times\left(B\rightarrow A\right)\rightarrow C^{B}$ 

Tree encoding: $\text{FreeCF}^{F^{\bullet},B}\triangleq F^{B}+\exists A.\text{FreeCF}^{F^{\bullet},A}\times\left(B\rightarrow A\right)$

Reduced encoding: $\text{FreeCF}^{F^{\bullet},B}\triangleq\exists A.F^{A}\times\left(B\rightarrow A\right)$ 

A value of type $\text{FreeCF}^{F^{\bullet},B}$ must be of the form
{\footnotesize{}
\[
\exists Z_{1}.\exists Z_{2}...\exists Z_{n}.F^{Z_{1}}\times\left(B\rightarrow Z_{n}\right)\times\left(Z_{n}\rightarrow Z_{n-1}\right)\times...\times\left(Z_{2}\rightarrow Z_{1}\right)
\]
}{\footnotesize\par}

The functions $B\rightarrow Z_{n}$, $Z_{n}\rightarrow Z_{n-1}$,
etc., are composed associatively

The equivalent type is $\exists Z_{1}.F^{Z_{1}}\times\left(B\rightarrow Z_{1}\right)$

The reduced encoding is non-recursive

Example: $F^{A}\triangleq A$, \textsf{``}interpret\textsf{''} into the contrafunctor
$C^{A}\triangleq A\rightarrow\text{String}$

\texttt{\textcolor{blue}{\footnotesize{}def prefixLog{[}A{]}(p: A): A
$\rightarrow$ String = a $\rightarrow$ p.toString + a.toString}}{\footnotesize\par}

If $F^{\bullet}$ is already a contrafunctor then $\text{FreeCF}^{F^{\bullet},A}\cong F^{A}$

\subsection{Free constructions that assume other typeclasses}

It is sometimes possible to find a simpler encoding of a free typeclass
on a type $T$ if we assume that $T$ already has another typeclass
instance.

The first example is the free monoid on $T$ if $T$ is already a
semigroup. The only thing missing in a semigroup compared with a monoid
is the empty element: a semigroup does not necessarily have one. We
also notice that the difference between the free monoid (\lstinline!List[T]!)
and the free semigroup (\lstinline!NEL[T]!) is just the empty element:
$\text{List}^{T}=\bbnum 1+\text{NEL}^{T}$. Motivated by these considerations,
we define the free monoid on $T$ as $\bbnum 1+T$ when $T$ is already
a semigroup. Indeed, we may implement the monoid instance:
\begin{lstlisting}
def monoidOnSemi[T: Semigroup]: Monoid[Option[T]] = Monoid(
  (l, r) => (l zip r).map { case (x, y) => x |+| y },
  None) *** verify code
\end{lstlisting}

The second example is found by considering the free monad encoding
\lstinline!Free2! (see Section~\ref{subsec:Motivation-free-monad-different-encodings}).
The encoding \lstinline!Free2! can be seen as \lstinline!Free1!
applied to the free functor \lstinline!FF[F, A]!. If the effect constructor
\lstinline!F! is already functor, the free functor \lstinline!FF[F, A]!
is equivalent to just \lstinline!F[A]!. So, the free monad on a functor
\lstinline!F! is the encoding \lstinline!Free1!. It is a simpler
data structure than \lstinline!Free2!, the free monad on an arbitrary
type constructor \lstinline!F!.

It also follows that the free monad encodings \lstinline!Free1! and
\lstinline!Free2! are equivalent when the effect constructor \lstinline!F!
is a functor.

The free functor construction can be viewed as a building block for
other free typeclasses. It is often simpler to construct a free typeclass
assuming that the effect constructor is already a functor. For type
constructors that are not functors, we can first apply the free functor
construction and then build the free typeclass based on a functor.
So, in the following sections we will restrict our attention to free
typeclasses on functors.

To gain some intuition about how to build typeclasses based on functors,
let us examine the definition of the free monad encoding \lstinline!Free1[F, A]!.
(That definition assumes that \lstinline!F! is a functor.) A monad
may be defined as a functor that additionally has the \lstinline!pure!
and \lstinline!flatten! methods satisfying suitable laws (the equivalence
of \lstinline!flatten! and \lstinline!flatMap! was proved in Statement~\ref{subsec:Statement-flatten-equivalent-to-flatMap}).
The raw tree encoding for a monad\textsf{'}s definition via \lstinline!pure!
and \lstinline!flatten! gives:
\begin{lstlisting}
sealed trait Free5[F[_], A]
final case class Pure[F[_], A](a: A) extends Free5[F, A]
final case class Wrap[F[_], A](fa: F[A]) extends Free5[F, A]
final case class Flatten[F[_], A](ff: Free5[F, Free5[F, A]]) extends Free5[F, A]
\end{lstlisting}
This code differs from \lstinline!Free1! in two ways. First, \lstinline!Free1!
does not use a \lstinline!Wrap! case class. Second, \lstinline!Free5!
has a recursive type definition of the form \lstinline!Free5[F, Free5[F, A]]!
that uses \lstinline!Free5! twice, while \lstinline!Free1! instead
uses a simpler type: \lstinline!F[Free1[F, A]]!. {*}{*}{*} We avoid
the simplification Free5{[}F, F{[}A{]}{]} because this creates a recursive
definition of Free5{[}F, A{]} whose recursive use modifies the type
parameter A of Free5

\subsection{Free pointed functors and contrafunctors}

\subsection{Free filterable functors and contrafunctors}

\subsection{Free applicative functors and contrafunctors}

\section{Advanced applications}

\subsection{Church encodings of free typeclasses}

\textsf{``}\textbf{Final} \textbf{Tagless} style\textsf{''} means \textsf{``}Church encoding
of free monad over $F^{\bullet}$\textsf{''}

Free monad over a functor $F^{\bullet}$ is $\text{FreeM}^{F^{\bullet},A}\triangleq A+F^{\text{FreeM}^{F^{\bullet},A}}$

Free monad $\text{FreeM}^{M^{\bullet},\bullet}$ over a monad $M^{\bullet}$
is not equivalent to $M^{\bullet}$

Free monad over a pointed functor $F^{\bullet}$ is {\footnotesize{}$\text{FreeM}^{F^{\bullet},A}\triangleq F^{A}+F^{\text{FreeM}^{F^{\bullet},A}}$}{\footnotesize\par}

start from half-reduced encoding $F^{A}+\exists Z.F^{Z}\times\big(Z\rightarrow\text{FreeM}^{F^{\bullet},A}\big)$ 

replace the existential type by an equivalent type $F^{\text{FreeM}^{F^{\bullet},A}}$

\paragraph{Another encoding: (to be studied in more detail):}

We have:
\[
\forall X^{:\text{MyTypeclass}}.\,(A\rightarrow X)\rightarrow X
\]
is the free \lstinline!MyTypeclass! in the lawful Church encoding.
The laws hold! This is more economical than the raw tree encoding,
see the \lstinline!Semigroup! example.

\section{Laws of free constructions}

This chapter developed the free monad via the implementation of a
simple type-safe DSL. We found different encodings of the free monad
(the raw tree encoding and the various reduced encodings) that have
different performance trade-offs and satisfy different subsets of
the monad laws. Free constructions of other typeclasses are motivated
by analogy with the free monad and its various encodings. Can we formulate
any properties or laws that validate the correctness of those constructions?
Are all the different encodings equally safe to use? We will now develop
the necessary theory for answering these questions in the case of
$P$-typeclasses for ordinary types. (The notion of a \textsf{``}$P$-typeclass\textsf{''}
was introduced in Section~\ref{subsec:P-typeclasses}.) We expect
that $P$-typeclasses for type constructors will have similar properties,
although the technical details of the proofs will be more difficult
to work out.

\subsection{Free constructions for $P$-typeclasses\label{subsec:Free-constructions-for-inductive-typeclasses}}

Some features are common to all the free typeclass constructions we
have seen. We begin by generalizing the features of the free monoid
construction to other similar typeclasses. We will then extend the
results to typeclasses for type constructors (such as \lstinline!Functor!
and \lstinline!Monad!).

The free monoid is a type constructor ($\text{FM}^{\bullet}$) that
transforms an arbitrary type $T$ into a new type ($\text{FM}^{T}$)
having a \lstinline!Monoid! typeclass instance. Values of type $T$
can be wrapped into values of type $\text{FM}^{T}$. For any given
monoid $M$ and a given function of type $T\rightarrow M$, a \textsf{``}free
monoid program\textsf{''} (i.e., a value of type $\text{FM}^{T}$) can be
\textsf{``}run into $M$\textsf{''}. The resulting runner (of type $\text{FM}^{T}\rightarrow M$)
will preserve the monoid operations between $\text{FM}^{T}$ and $M$.
So, the monoid laws will hold after running a \textsf{``}free monoid program\textsf{''},
even when the chosen encoding $\text{FM}^{T}$ violates some of the
monoid laws.

To generalize from monoids to other typeclasses, recall the definition
of a $P$-typeclass (Section~\ref{subsec:P-typeclasses}): For a
given (covariant) functor $P$, a $P$\textbf{-typeclass} \index{$P$-typeclass}
has the evidence data equivalent to a value of type $P^{A}\rightarrow A$.
For the \lstinline!Monoid! typeclass, the structure functor is $P^{A}\triangleq\bbnum 1+A\times A$,
and the evidence data has type $A\times\left(A\times A\rightarrow A\right)$,
which is equivalent to $P^{A}\rightarrow A$. The two parts of the
disjunctive type $\bbnum 1+A\times A$ correspond to the \emph{arguments}
of the monoid\textsf{'}s two operations: the empty value ($e_{A}$) and the
binary operation ($\oplus_{A}$). The $P$-typeclass combines all
methods of a typeclass into a single value (of type $P^{A}\rightarrow A$).

The next step is to generalize the property of \textsf{``}preserving the monoid\textsf{'}s
operations\textsf{''} to an arbitrary $P$-typeclass. Given two monoids $M$
and $N$, a function $f:M\rightarrow N$ that preserves the monoid\textsf{'}s
operations is a monoid morphism\index{monoid morphism} according
to Definition~\ref{subsec:Definition-monoid-morphism}. Can we describe
the laws in Definition~\ref{subsec:Definition-monoid-morphism} purely
in terms of the monoid\textsf{'}s structure functor $P^{A}=\bbnum 1+A\times A$?
As $M$ and $N$ are monoids, their typeclass instances must be available
as values $p_{M}$ and $p_{N}$: 
\begin{align*}
 & p_{M}:P^{M}\rightarrow M=\bbnum 1+M\times M\rightarrow M\quad,\quad\quad p_{M}\triangleq\,\begin{array}{|c||c|}
 & M\\
\hline \bbnum 1 & 1\rightarrow e_{M}\\
M\times M & a\times b\rightarrow a\oplus_{M}b
\end{array}\quad;\\
 & p_{N}:P^{N}\rightarrow N=\bbnum 1+N\times N\rightarrow N\quad,\quad\quad p_{N}\triangleq\,\begin{array}{|c||c|}
 & N\\
\hline \bbnum 1 & 1\rightarrow e_{N}\\
N\times N & c\times d\rightarrow c\oplus_{N}d
\end{array}\quad.
\end{align*}
So far, we have functions of types $P^{M}\rightarrow M$, $M\rightarrow N$,
and $P^{N}\rightarrow N$. It appears promising to arrange these functions
in a type diagram. The missing edge of the diagram is a function of
type $P^{M}\rightarrow P^{N}$.
\[
\xymatrix{\xyScaleY{1.4pc}\xyScaleX{3.0pc}P^{M}\ar[r]\sp(0.5){\ p_{M}}\ar[d]\sp(0.45){\,f^{\uparrow P}} & M\ar[d]\sp(0.45){\,f}\\
P^{N}\ar[r]\sp(0.5){~p_{N}} & N
}
\]
Let us see what happens if we use $f^{\uparrow P}$ as that function
and require that the resulting diagram should commute:
\begin{equation}
p_{M}\bef f=f^{\uparrow P}\bef p_{N}\quad.\label{eq:p-algebra-morphism-law}
\end{equation}
We simplify both sides of Eq.~(\ref{eq:p-algebra-morphism-law})
by using the definition of $f^{\uparrow P}$:
\begin{align*}
 & f^{\uparrow P}=\,\begin{array}{|c||cc|}
 & \bbnum 1 & N\times N\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
M\times M & \bbnum 0 & a\times b\rightarrow f(a)\times f(b)
\end{array}\quad,\\
 & p_{M}\bef f=\,\begin{array}{||c|}
1\rightarrow e_{M}\\
a\times b\rightarrow a\oplus_{M}b
\end{array}\,\bef f=\,\begin{array}{||c|}
1\rightarrow f(e_{M})\\
a\times b\rightarrow f(a\oplus_{M}b)
\end{array}\quad,\\
 & f^{\uparrow P}\bef p_{N}=\,\begin{array}{||cc|}
\text{id} & \bbnum 0\\
\bbnum 0 & a\times b\rightarrow f(a)\times f(b)
\end{array}\,\bef\,\begin{array}{||c|}
1\rightarrow e_{N}\\
c\times d\rightarrow c\oplus_{N}d
\end{array}\,=\,\begin{array}{||c|}
1\rightarrow e_{N}\\
a\times b\rightarrow f(a)\oplus_{N}f(b)
\end{array}\quad.
\end{align*}
Then Eq.~(\ref{eq:p-algebra-morphism-law}) is rewritten as:
\[
\begin{array}{||c|}
1\rightarrow f(e_{M})\\
a\times b\rightarrow f(a\oplus_{M}b)
\end{array}\,\overset{!}{=}\,\begin{array}{||c|}
1\rightarrow e_{N}\\
a\times b\rightarrow f(a)\oplus_{N}f(b)
\end{array}\quad.
\]
This equation is the same as the identity and composition laws in
Definition~\ref{subsec:Definition-monoid-morphism}. It is now clear
how to define the property of \textsf{``}preserving the typeclass operations\textsf{''}
for an arbitrary $P$-typeclass: we just need to impose Eq.~(\ref{eq:p-algebra-morphism-law}).
In this way, we have reformulated the typeclass preservation property
in terms of the functor $P$.

At this point it is helpful to borrow some definitions from \index{category theory}category
theory. 

\subsubsection{Definition \label{subsec:Definition-f-algebra}\ref{subsec:Definition-f-algebra}}

Given a functor $F$, a type $M$ is called an $F$\textbf{-algebra}
if there exists a morphism $p_{M}:F^{M}\rightarrow M$. The type $M$
is the \textbf{carrier} and the morphism $p_{M}$ is the \index{structure map of $F$-algebra}\textbf{structure
map} of the $F$-algebra. \index{$F$-algebra!structure map} All $F$-algebras
form a category whose objects are pairs $\left(M,p_{M}\right)$ and
morphisms are defined as functions $f^{:M\rightarrow N}$ satisfying
Eq.~(\ref{eq:p-algebra-morphism-law}) with $P=F$. Such functions
$f$ are called $F$-\textbf{algebra morphisms}.\index{$F$-algebra!morphism}
$\square$

To show that the category laws hold for $F$-algebras, we use the
following properties:

\subsubsection{Statement \label{subsec:Statement-category-of-P-algebras}\ref{subsec:Statement-category-of-P-algebras}}

Assume that $K$, $L$, $M$ are some $F$-algebras with structure
maps $p_{K}$, $p_{L}$, $p_{M}$.

\textbf{(a)} The identity function $\text{id}^{:M\rightarrow M}$
is an $F$-algebra morphism.

\textbf{(b)} If $g^{:K\rightarrow L}$ and $h^{:L\rightarrow M}$
are $F$-algebra morphisms then so is the composition $g\bef h$.

\subparagraph{Proof}

\textbf{(a)} The law~(\ref{eq:p-algebra-morphism-law}) holds with
$P=F$, $M=N$, and $f=\text{id}$ since both sides of the law are
equal to $p_{M}$:
\[
p_{M}\bef f=p_{M}\bef\text{id}=p_{M}\quad,\quad\quad f^{\uparrow F}\bef p_{N}=\text{id}^{\uparrow F}\bef p_{M}=p_{M}\quad.
\]

\textbf{(b)} To verify that the law~(\ref{eq:p-algebra-morphism-law})
holds for $f\triangleq g\bef h$ with $P=F$, we write:
\begin{align*}
{\color{greenunder}\text{expect to equal }f^{\uparrow F}\bef p_{M}:}\quad & p_{K}\bef\gunderline f=\gunderline{p_{K}\bef g}\bef h\\
{\color{greenunder}F\text{-algebra morphism law for }g^{:K\rightarrow L}:}\quad & =g^{\uparrow F}\bef\gunderline{p_{L}\bef h}\\
{\color{greenunder}F\text{-algebra morphism law for }h^{:L\rightarrow M}:}\quad & =\gunderline{g^{\uparrow F}\bef h^{\uparrow F}}\bef p_{M}=(\gunderline{g\bef h})^{\uparrow F}\bef p_{M}=f^{\uparrow F}\bef p_{M}\quad.
\end{align*}
$\square$

We can now formulate our findings about $P$-typeclasses in the language
of $F$-algebras. Using the functor $P$ instead of $F$, we say that
a $P$\textbf{-typeclass with laws} is\index{$P$-typeclass!with laws}
a $P$-algebra whose structure map needs to satisfy given laws. The
structure map ($p_{M}:P^{M}\rightarrow M$) describes at once all
the typeclass methods and so plays the role of an \emph{evidence value}
showing that a type $M$ belongs to the $P$-typeclass. If $M$ and
$N$ are two $P$-algebras and a function $f^{:M\rightarrow N}$ is
a $P$-algebra morphism then we say that $f$ \textsf{``}preserves the $P$-typeclass
operations\textsf{''}. 

The next step is to generalize the free monoid construction to a \textsf{``}free
$P$-typeclass\textsf{''} construction. We have seen that there are several
versions, or \textsf{``}encodings\textsf{''}, of the free monoid. Different encodings
satisfy different subsets of the monoid laws. By analogy with the
free monoid, we list the expected properties of an \textsf{``}encoding\textsf{''}
of a free $P$-typeclass. We should have a type constructor $E^{T}$
that wraps an arbitrary type $T$ and produces a $P$-typeclass instance
automatically. Values of type $E^{T}$ represent \textsf{``}$P$-typeclass
programs\textsf{''}, that is, unevaluated expression trees with primitive
values of type $T$. A \textsf{``}runner\textsf{''} can evaluate those expression
trees into values of a specific type $C$ as long as $C$ already
belongs to the $P$-typeclass and a function of type $T\rightarrow C$
is given:
\[
\text{run}_{E}^{T,C}:(T\rightarrow C)\rightarrow E^{T}\rightarrow C\quad.
\]

It turns out that we may simplify the definition of the runner so
that we no longer need to use a function $r:T\rightarrow C$. Since
$E$ is a functor, we may apply the lifted function $r^{\uparrow E}:E^{T}\rightarrow E^{C}$.
It remains to find a transformation of type $E^{C}\rightarrow C$.
That transformation (as we will show) is equivalent to $\text{run}_{E}^{T,C}$.

With these goals in mind, we define a free $P$-typeclass encoding:

\subsubsection{Definition \label{subsec:Definition-free-P-typeclass-encoding}\ref{subsec:Definition-free-P-typeclass-encoding}}

Given a functor $P$, a \textbf{free} $P$\textbf{-typeclass} \textbf{encoding}
is a functor $E$ such that:

\textbf{(a)} For any type $T$, the type $E^{T}$ has a $P$-typeclass
instance $p_{E}^{T}:P^{E^{T}}\rightarrow E^{T}$ natural in $T$:
\begin{equation}
\forall f^{:T\rightarrow U}:\quad f^{\uparrow E\uparrow P}\bef p_{E}^{U}=p_{E}^{T}\bef f^{\uparrow E}\quad.\label{eq:free-typeclass-encoding-P-naturality-law}
\end{equation}
 As a consequence of Eq.~(\ref{eq:free-typeclass-encoding-P-naturality-law}),
for any $f^{:T\rightarrow U}$ the function $f^{\uparrow E}:E^{T}\rightarrow E^{U}$
is a $P$-algebra morphism. The function $p_{E}^{T}$ may obey a subset
of the laws of the $P$-typeclass; that subset must be the same for
all $T$.

\textbf{(b)} The functor $E$ is pointed\index{pointed functor}:
there exists a natural transformation $\text{pu}_{E}^{T}:T\rightarrow E^{T}$.

\textbf{(c)} There exists an \textsf{``}evaluator\textsf{''} function ($\text{eval}_{E}^{C}:E^{C}\rightarrow C$)
whose type parameter $C$ is restricted to $P$-algebras $C$ whose
structure map $p_{C}:P^{C}\rightarrow C$ obeys all those $P$-typeclass
laws that $E^{T}$ obeys. The evaluator function must satisfy:
\begin{align}
{\color{greenunder}\text{left identity law}:}\quad & \text{pu}_{E}^{C}\bef\text{eval}_{E}^{C}=\text{id}^{:C\rightarrow C}\quad,\label{eq:free-typeclass-encoding-left-identity-law}\\
{\color{greenunder}\text{right identity law}:}\quad & (\text{pu}_{E}^{T})^{\uparrow E}\bef\text{eval}_{E}^{E^{T}}=\text{id}^{:E^{T}\rightarrow E^{T}}\quad,\label{eq:free-typeclass-encoding-right-identity-law}\\
{\color{greenunder}P\text{-algebra morphism law}:}\quad & p_{E}^{C}\bef\text{eval}_{E}^{C}=\big(\text{eval}_{E}^{C}\big)^{\uparrow P}\bef p_{C}\quad,\nonumber \\
{\color{greenunder}P\text{-algebra naturality law}:}\quad & \text{for any }P\text{-algebra morphism }g^{:C\rightarrow D}:\quad\text{eval}_{E}^{C}\bef g=g^{\uparrow E}\bef\text{eval}_{E}^{D}\quad.\label{eq:free-typeclass-encoding-P-algebra-naturality-law}
\end{align}
The requirement that $C$ should obey \textsf{``}all\textsf{''} the laws of $E^{T}$
means that, for any type $T$, if $E^{T}$ obeys a $P$-typeclass
law (such as an identity law, an associativity law, etc.) then $C$
must also obey the same law. The type $C$ might obey \emph{more}
laws than $E^{T}$, but any law that holds for $E^{T}$ must also
hold for $C$. (Section~\ref{subsec:Describing-laws-of-P-typeclasses-as-values}
will describe $P$-typeclass laws in more detail, but we do not yet
need the techniques developed there.)

\textbf{(d)} The evaluator function $\text{eval}_{E}^{C}$ has a uniqueness
property: any $P$-algebra morphism $f:E^{C}\rightarrow C$ obeying
the left identity law ($\text{pu}_{E}^{C}\bef f=\text{id}$) must
be equal to $f=\text{eval}_{E}^{C}$. $\square$

The uniqueness property reflects a programmer\textsf{'}s expectation that there
is only one correct way of running (i.e., evaluating) a free $P$-typeclass
program while preserving the typeclass\textsf{'}s operations. The \textsf{``}universal
runner\textsf{''} function, $\text{run}_{E}^{T,C}$, can be defined via $\text{eval}_{E}^{C}$
as:
\[
\text{run}_{E}^{T,C}:(T\rightarrow C)\rightarrow E^{T}\rightarrow C\quad,\quad\quad\text{run}_{E}^{T,C}(r^{:T\rightarrow C})\triangleq r^{\uparrow E}\bef\text{eval}_{E}^{C}\quad.
\]
The uniqueness property of the runner is proved in the next statement.

\subsubsection{Statement \label{subsec:Statement-some-properties-of-free-P-typeclass-encoding}\ref{subsec:Statement-some-properties-of-free-P-typeclass-encoding}}

Suppose $E$ is a free $P$-typeclass encoding and $T$ is any type
(not necessarily of the $P$-typeclass).

\textbf{(a)} If $C$ is a $P$-algebra that obeys all the laws of
$E$ then any $P$-algebra morphism $g:E^{T}\rightarrow C$ can be
expressed as: 
\[
g=\text{run}_{E}^{T,C}(r)\triangleq r^{\uparrow E}\bef\text{eval}_{E}^{C}\quad\quad,\quad\text{where we defined}\quad r^{:T\rightarrow C}\triangleq\text{pu}_{E}^{T}\bef g\quad.
\]
This is the universal runner\textsf{'}s uniqueness property: for any chosen
function $r:T\rightarrow C$, there is only one $P$-algebra morphism
$g:E^{T}\rightarrow C$ satisfying the condition $\text{pu}_{E}^{T}\bef g=r$,
namely $g=r^{\uparrow E}\bef\text{eval}_{E}^{C}$.

\textbf{(b)} If we assume that \textbf{(a)} holds then we can \emph{derive}
the right identity law~(\ref{eq:free-typeclass-encoding-right-identity-law}).

\subparagraph{Proof}

\textbf{(a)} Use the $P$-algebra naturality law~(\ref{eq:free-typeclass-encoding-P-algebra-naturality-law})
with $E^{T}$ and $C$ instead of $C$ and $D$:
\[
g^{\uparrow E}\bef\text{eval}_{E}^{C}=\text{eval}_{E}^{E^{A}}\bef g\quad.
\]
Now we can verify the uniqueness property:
\begin{align*}
{\color{greenunder}\text{expect to equal }g:}\quad & \text{run}_{E}^{T,C}(\text{pu}_{E}^{T}\bef g)=(\text{pu}_{E}^{T}\bef g)^{\uparrow E}\bef\text{eval}_{E}^{C}=(\text{pu}_{E}^{T})^{\uparrow E}\bef\gunderline{g^{\uparrow E}\bef\text{eval}_{E}^{C}}\\
{\color{greenunder}\text{use the }P\text{-algebra naturality law}:}\quad & =\gunderline{(\text{pu}_{E}^{T})^{\uparrow E}\bef\text{eval}_{E}^{E^{A}}}\bef g\\
{\color{greenunder}\text{use the right identity law (\ref{eq:free-typeclass-encoding-right-identity-law})}:}\quad & =\text{id}\bef g=g\quad.
\end{align*}

\textbf{(b)} Setting $C=E^{T}$ and $g=\text{id}$ in part \textbf{(a)},
we get:
\[
g\overset{!}{=}(\text{pu}_{E}^{T}\bef g)^{\uparrow E}\bef\text{eval}_{E}^{E^{T}}\quad.
\]
Substituting $g=\text{id}$, we obtain $\text{id}=(\text{pu}_{E}^{T})^{\uparrow E}\bef\text{eval}_{E}^{E^{T}}$,
which is the right identity law. $\square$

It is important that the definition of a free $P$-typeclass encoding
$E$ does not require that $E$ should obey \emph{all} of the $P$-typeclass
laws. For instance, we have seen that the raw tree encoding of free
monads, free monoids, and other typeclasses does not obey any of the
relevant laws. Because this does not lead to problems in practical
programming, we design our definition of free $P$-typeclasses to
admit encodings that obey only a subset of typeclass laws (possibly,
no laws at all).

The next step is to generalize the raw tree encoding from \lstinline!Monoid!
to an arbitrary $P$-typeclass and to show that it satisfies the definition
of a \textsf{``}free $P$-typeclass encoding\textsf{''}. Although the raw tree encoding
does not satisfy any typeclass laws, it gives us a valid and usable
encoding that we can use as a starting point to develop other, more
concise encodings for a free $P$-typeclass. 

The raw tree encoding of a free monoid (see Section~\ref{subsec:Free-monoids})
has the type: 
\[
\text{FMR}^{T}\triangleq\bbnum 1+T+\text{FMR}^{T}\times\text{FMR}^{T}\quad.
\]
The parts of the disjunctive type $\bbnum 1+T+\text{FMR}^{T}\times\text{FMR}^{T}$
correspond to three ways in which a free monoid value may be created:
from the empty value, from a value of type $T$, and from two existing
values of the free monoid type. The structure functor $P$ describes
two of these three ways. This suggests to rewrite the definition of
$\text{FMR}^{T}$ as $\text{FMR}^{T}\triangleq T+P^{\text{FMR}^{T}}$.
We can now generalize to arbitrary $P$-typeclasses and define the
raw tree encoding of a free $P$-typeclass (denoted by $\text{FPR}^{T}$)
as:
\[
\text{FPR}^{T}\triangleq T+P^{\text{FPR}^{T}}\quad.
\]
We notice that $\text{FPR}^{T}$ is the same as the free monad\index{free monad}
on $P$ (as defined in Statement~\ref{subsec:Statement-monad-construction-4-free-monad}).
The free monad on $P$ is a tree-like data structure whose branch
shape is described by the functor $P$. This data structure represents
an unevaluated expression tree built up from operations of type $P^{A}\rightarrow A$
and values of type $T$. 

\subsubsection{Statement \label{subsec:Statement-free-P-typeclass-raw-tree-encoding}\ref{subsec:Statement-free-P-typeclass-raw-tree-encoding}}

The free monad on $P$, denoted by $\text{FPR}^{T}\triangleq T+P^{\text{FPR}^{T}}$,
is a free $P$-typeclass encoding. The monad\textsf{'}s \lstinline!flatten!
method is the same as \lstinline!eval! applied to an argument of
type \lstinline!FPR[FPR[T]]!.

\subparagraph{Proof}

We need to verify the properties in Definition~\ref{subsec:Definition-free-P-typeclass-encoding}.

\textbf{(a)} To define $p_{\text{FPR}}^{T}$, we note the type equivalence
$T+P^{\text{FPR}^{T}}\cong\text{FPR}^{T}$ and rewrite the type signature
$p_{\text{FPR}}^{T}:P^{\text{FPR}^{T}}\rightarrow\text{FPR}^{T}$
equivalently as $p_{\text{FPR}}^{T}:P^{\text{FPR}^{T}}\rightarrow T+P^{\text{FPR}^{T}}$.
Then we define $p_{\text{FPR}}^{T}$ as:
\[
p_{\text{FPR}}^{T}:P^{\text{FPR}^{T}}\rightarrow T+P^{\text{FPR}^{T}}\quad,\quad\quad p_{\text{FPR}}(x)\triangleq\bbnum 0^{:T}+x^{:P^{\text{FPR}^{T}}}\quad.
\]
This code is fully parametric in $T$, so the naturality law holds:
for any $f:T\rightarrow U$, we have:
\[
p_{\text{FPR}}^{T}\bef f^{\uparrow\text{FPR}}=f^{\uparrow\text{FPR}\uparrow P}\bef p_{\text{FPR}}^{U}\quad.
\]
This equation is the same as the $P$-algebra morphism law for the
function $f^{\uparrow\text{FPR}}$.

\textbf{(b)} The function $\text{pu}_{\text{FPR}}^{T}:T\rightarrow\text{FPR}^{T}$
is defined as $\text{pu}_{\text{FPR}}^{T}(t^{:T})\triangleq t+\bbnum 0$.

\textbf{(c)} Given $p_{C}:P^{C}\rightarrow C$, the function $\text{eval}_{\text{FPR}}^{C}$
is defined recursively by:
\[
\text{eval}_{\text{FPR}}^{C}:\text{FPR}^{C}\rightarrow C\quad,\quad\quad\text{eval}_{\text{FPR}}^{C}\triangleq\,\begin{array}{|c||c|}
 & C\\
\hline C & \text{id}\\
P^{\text{FPR}^{C}} & \overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef p_{C}
\end{array}\quad.
\]

To verify the left identity law~(\ref{eq:free-typeclass-encoding-left-identity-law}):
\[
\text{pu}_{\text{FPR}}^{C}\bef\text{eval}_{\text{FPR}}^{C}=\,\begin{array}{|c||cc|}
 & C & P^{\text{FPR}^{C}}\\
\hline C & \text{id} & \bbnum 0
\end{array}\,\bef\,\begin{array}{|c||c|}
 & C\\
\hline C & \text{id}\\
P^{\text{FPR}^{C}} & \overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef p_{C}
\end{array}\,=\text{id}\quad.
\]

To verify the right identity law~(\ref{eq:free-typeclass-encoding-right-identity-law}),
we first show that the function $\text{eval}_{\text{FPR}}^{\text{FPR}^{T}}:\text{FPR}^{\text{FPR}^{T}}\rightarrow\text{FPR}^{T}$
is the same as the monad\textsf{'}s \lstinline!flatten! method for \lstinline!FPR!
given by the following code matrix (see Statement~\ref{subsec:Statement-monad-construction-4-free-monad}):
\[
\text{ftn}_{\text{FPR}}=\,\begin{array}{|c||cc|}
 & T & P^{\text{FPR}^{T}}\\
\hline T & \text{id} & \bbnum 0\\
P^{\text{FPR}^{T}} & \bbnum 0 & \text{id}\\
P^{\text{FPR}^{\text{FPR}^{T}}} & \bbnum 0 & \overline{\text{ftn}}_{\text{FPR}}^{\uparrow P}
\end{array}\quad.
\]
We use the definition of \lstinline!eval! given in \textbf{(a)} with
the type $\text{FPR}^{T}$ instead of $T$:
\[
\text{eval}_{\text{FPR}}^{\text{FPR}^{T}}=\,\begin{array}{|c||c|}
 & \text{FPR}^{T}\\
\hline \text{FPR}^{T} & \text{id}\\
P^{\text{FPR}^{\text{FPR}^{T}}} & \overline{\text{eval}_{\text{FPR}}^{\text{FPR}^{T}}}^{\uparrow P}\bef p_{\text{FPR}}
\end{array}\,=\,\begin{array}{|c||cc|}
 & T & P^{\text{FPR}^{T}}\\
\hline T & \text{id} & \bbnum 0\\
P^{\text{FPR}^{T}} & \bbnum 0 & \text{id}\\
P^{\text{FPR}^{\text{FPR}^{T}}} & \bbnum 0 & \overline{\text{eval}_{\text{FPR}}^{\text{FPR}^{T}}}^{\uparrow P}
\end{array}\,=\text{ftn}_{\text{FPR}}\quad.
\]
Now the required property follows from the monad\textsf{'}s right identity
law:
\[
(\text{pu}_{\text{FPR}})^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{\text{FPR}^{T}}=(\text{pu}_{\text{FPR}})^{\uparrow\text{FPR}}\bef\text{ftn}_{\text{FPR}}=\text{id}\quad.
\]

To verify the $P$-algebra morphism law~(\ref{eq:p-algebra-morphism-law})
for the function $\text{eval}_{\text{FPR}}^{C}$:
\[
p_{\text{FPR}}\bef\text{eval}_{\text{FPR}}^{C}=\,\begin{array}{|c||cc|}
 & C & P^{\text{FPR}^{C}}\\
\hline P^{\text{FPR}^{C}} & \bbnum 0 & \text{id}
\end{array}\,\bef\,\begin{array}{|c||c|}
 & C\\
\hline C & \text{id}\\
P^{\text{FPR}^{C}} & \overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef p_{C}
\end{array}\,=\overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef p_{C}\quad.
\]

To verify the $P$-algebra naturality law~(\ref{eq:free-typeclass-encoding-P-algebra-naturality-law}),
assume $g^{:C\rightarrow D}$ is a $P$-algebra morphism ($p_{C}\bef g=g^{\uparrow P}\bef p_{D}$)
and use the inductive assumption that $g^{\uparrow\text{FPR}}\bef\overline{\text{eval}_{\text{FPR}}^{D}}=\overline{\text{eval}_{\text{FPR}}^{C}}\bef g$
holds for recursive calls to $\text{eval}_{\text{FPR}}$:
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & g^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{D}=\,\begin{array}{|c||cc|}
 & D & P^{\text{FPR}^{D}}\\
\hline C & g & \bbnum 0\\
P^{\text{FPR}^{C}} & \bbnum 0 & g^{\uparrow\text{FPR}\uparrow P}
\end{array}\,\bef\,\begin{array}{|c||c|}
 & D\\
\hline D & \text{id}\\
P^{\text{FPR}^{D}} & \overline{\text{eval}_{\text{FPR}}^{D}}^{\uparrow P}\bef p_{D}
\end{array}\\
{\color{greenunder}\text{matrix composition}:}\quad & \quad\quad=\,\begin{array}{|c||c|}
 & D\\
\hline C & g\\
P^{\text{FPR}^{C}} & \overline{g^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{D}}^{\uparrow P}\bef p_{D}
\end{array}\\
{\color{greenunder}\text{inductive assumption}:}\quad & \quad\quad=\,\begin{array}{||c|}
g\\
\big(\overline{\text{eval}_{\text{FPR}}^{C}}\bef g\big)^{\uparrow P}\bef p_{D}
\end{array}\,=\,\begin{array}{||c|}
g\\
\overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef g^{\uparrow P}\bef p_{D}
\end{array}\quad;\\
{\color{greenunder}\text{right-hand side}:}\quad & \text{eval}_{E}^{C}\bef g=\,\begin{array}{|c||c|}
 & C\\
\hline C & \text{id}\\
P^{\text{FPR}^{C}} & \overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef p_{C}
\end{array}\,\bef g=\,\begin{array}{|c||c|}
 & D\\
\hline C & g\\
P^{\text{FPR}^{C}} & \overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef p_{C}\bef g
\end{array}\quad.
\end{align*}
The two code matrices are now equal due to the assumed law $p_{C}\bef g=g^{\uparrow P}\bef p_{D}$.

\textbf{(d)} For a given type $C$ with $P$-typeclass instance $p_{C}:P^{C}\rightarrow C$,
suppose a function $f:\text{FPR}^{C}\rightarrow C$ satisfies the
left identity law and is a $P$-algebra morphism:
\[
\text{pu}_{\text{FPR}}^{C}\bef f=\text{id}\quad,\quad\quad p_{\text{FPR}}\bef f=f^{\uparrow P}\bef p_{C}\quad.
\]
We need to show that $f=\text{eval}_{\text{FPR}}^{C}$. Since we have
the function $\text{eval}_{\text{FPR}}^{C}$ in matrix form, it is
convenient to rewrite $f$ also in that form:
\[
f:C+P^{\text{FPR}^{C}}\rightarrow C\quad,\quad\quad f\triangleq\,\begin{array}{|c||c|}
 & C\\
\hline C & g\\
P^{\text{FPR}^{C}} & h
\end{array}\quad,
\]
where $g$ and $h$ are new arbitrary functions of suitable types.
The identity law ($\text{pu}_{\text{FPR}}\bef f=\text{id}$) then
gives simply $g=\text{id}$, while the $P$-algebra morphism law gives:
\[
p_{\text{FPR}}\bef f=h\overset{!}{=}f^{\uparrow P}\bef p_{C}\quad.
\]
It remains to show that the following code matrices are equal:
\[
\text{eval}_{\text{FPR}}^{C}=\,\begin{array}{|c||c|}
 & C\\
\hline C & \text{id}\\
P^{\text{FPR}^{C}} & \overline{\text{eval}_{\text{FPR}}^{C}}^{\uparrow P}\bef p_{C}
\end{array}\,\overset{?}{=}f=\,\begin{array}{|c||c|}
 & C\\
\hline C & r\\
P^{\text{FPR}^{C}} & f^{\uparrow P}\bef p_{C}
\end{array}\quad.
\]
By the inductive assumption, the recursive call $\overline{\text{eval}_{\text{FPR}}^{C}}$
already satisfies the equation we need to prove: $f=\overline{\text{eval}_{\text{FPR}}^{C}}$.
So, the code matrices for $f$ and for $\text{eval}_{\text{FPR}}^{C}$
are equal. $\square$ 

As we will now show, \lstinline!FPR!\textsf{'}s \lstinline!flatten! function
is a $P$-algebra morphism; in other words, it preserves the $P$-typeclass
operations. So, it is not useful to apply the free $P$-typeclass
construction twice, as the result can be reduced to a single layer
of \lstinline!FPR[T]! while preserving the operations.

\subsubsection{Statement \label{subsec:Statement-free-P-typeclass-monad}\ref{subsec:Statement-free-P-typeclass-monad}}

The free monad\textsf{'}s \lstinline!flatten! function, $\text{ftn}_{\text{FPR}}:\text{FPR}^{\text{FPR}^{T}}\rightarrow\text{FPR}^{T}$,
is a $P$-algebra morphism.

\subparagraph{Proof}

By Statement~\ref{subsec:Statement-free-P-typeclass-raw-tree-encoding},
the \lstinline!flatten! function can be expressed as $\text{eval}_{\text{FPR}}^{\text{FPR}^{T}}$.
By the same statement, $\text{eval}_{\text{FPR}}^{C}$ is always a
$P$-algebra morphism as long as $C$ is a $P$-algebra obeying all
the laws of $\text{FPR}^{T}$. So, we may use $C=\text{FPR}^{T}$
and obtain the result that $\text{ftn}_{\text{FPR}}$ is also a $P$-algebra
morphism.

It is not accidental that the raw tree encoding ($\text{FPR}^{T}$)
is a monad. It turns out that \emph{all} free $P$-typeclass encodings
are monads (although not necessarily free monads):

\subsubsection{Statement \label{subsec:Statement-free-typeclass-encoding-is-a-monad}\ref{subsec:Statement-free-typeclass-encoding-is-a-monad}}

Any free $P$-typeclass encoding $E$ satisfying Definition~\ref{subsec:Definition-free-P-typeclass-encoding}
is a monad. The monad $E$\textsf{'}s \lstinline!flatten! function ($\text{ftn}_{E}$)
is equal to the unique $P$-algebra morphism $\text{eval}_{E}^{E^{A}}$
between $P$-algebras $E^{E^{A}}$ and $E^{A}$. The $P$-algebra
morphism law of $\text{ftn}_{E}$ is:
\[
\xymatrix{\xyScaleY{1.4pc}\xyScaleX{3.0pc}P^{E^{E^{A}}}\ar[r]\sp(0.5){\text{ftn}_{E}^{\uparrow P}}\ar[d]\sp(0.4){p_{E}^{E^{A}}} & P^{E^{A}}\ar[d]\sp(0.4){p_{E}^{A}}\\
E^{E^{A}}\ar[r]\sp(0.5){\text{ftn}_{E}} & E^{A}
}
\]
\begin{equation}
\text{ftn}_{E}^{\uparrow P}\bef p_{E}^{A}=p_{E}^{E^{A}}\bef\text{ftn}_{E}\quad.\label{eq:P-algebra-morphism-law-of-flatten}
\end{equation}


\subparagraph{Proof}

We need to implement the monad\textsf{'}s methods $\text{pu}_{E}$ and $\text{ftn}_{E}$
and show that the monad laws hold. The method $\text{pu}_{E}$ exists
by Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(b).
The \lstinline!flatten! method ($\text{ftn}_{E}$) is defined as:
\[
\text{ftn}_{E}:E^{E^{A}}\rightarrow E^{A}\quad,\quad\quad\text{ftn}_{E}\triangleq\text{eval}_{E}^{E^{A}}\quad.
\]
The code for $\text{ftn}_{E}$ uses the evaluator function $\text{eval}_{E}^{C}$
with $C=E^{A}$. This is justified because $E^{A}$ is a $P$-algebra.
The condition that $C$ should satisfy all the laws of $E^{A}$ holds
trivially, since $C=E^{A}$.

By Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(c),
we find that $\text{ftn}_{E}$ is a $P$-algebra morphism. 

The monad\textsf{'}s two identity laws follow from the identity laws given
in Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(c):
\begin{align*}
 & \text{pu}_{E}\bef\text{ftn}_{E}=\text{pu}_{E}\bef\text{eval}_{E}^{E^{A}}=\text{id}\quad.\\
 & \text{pu}_{E}^{\uparrow E}\bef\text{ftn}_{E}=\text{pu}_{E}^{\uparrow E}\bef\text{eval}_{E}^{E^{A}}=\text{id}\quad.
\end{align*}

The remaining monad law is written as:
\begin{align}
{\color{greenunder}\text{associativity law of }E:}\quad & (\text{ftn}_{E}^{A})^{\uparrow E}\bef\text{ftn}_{E}^{A}\overset{?}{=}\text{ftn}_{E}^{E^{A}}\bef\text{ftn}_{E}^{A}\quad.\label{eq:associativity-law-of-E-derivation1}
\end{align}
Let us denote by $g$ and $h$ the two sides of Eq.~(\ref{eq:associativity-law-of-E-derivation1}):
\[
g\triangleq(\text{ftn}_{E}^{A})^{\uparrow E}\bef\text{ftn}_{E}^{A}=(\text{ftn}_{E}^{A})^{\uparrow E}\bef\text{eval}_{E}^{E^{A}}\quad,\quad\quad h\triangleq\text{ftn}_{E}^{E^{A}}\bef\text{ftn}_{E}^{A}=\text{eval}_{E}^{E^{E^{A}}}\bef\text{eval}_{E}^{E^{A}}\quad.
\]
 We notice that $g$ has the form $f^{\uparrow E}\bef\text{eval}_{E}^{E^{A}}$
with some function $f$. By Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(a),
the function $f^{\uparrow E}$ is a $P$-algebra morphism. So, the
left-hand is a composition of two $P$-algebra morphisms. The right-hand
side is also such a composition. It follows that both $g$ and $h$
are $P$-algebra morphisms of type $E^{E^{E^{A}}}\rightarrow E^{A}$. 

It remains to show that $g=h$. For that, it is convenient to use
the uniqueness property in Statement~\ref{subsec:Statement-some-properties-of-free-P-typeclass-encoding}(a).
In order to be able to use that property, we need to show that there
exists a function $r:E^{E^{A}}\rightarrow E^{A}$ such that $\text{pu}_{E}\bef g=\text{pu}_{E}\bef h=r$.
It will then follow that both $g$ and $h$ are equal to $r^{\uparrow E}\bef\text{eval}_{E}^{E^{A}}$.
A suitable $r$ is just $r\triangleq\text{ftn}_{E}^{A}=\text{eval}_{E}^{E^{A}}$.
So, we write:
\begin{align*}
{\color{greenunder}\text{expect to equal }r:}\quad & \text{pu}_{E}\bef g=\gunderline{\text{pu}_{E}\bef(\text{ftn}_{E}^{A})^{\uparrow E}}\bef\text{eval}_{E}^{E^{A}}\\
{\color{greenunder}\text{naturality of }\text{pu}_{E}:}\quad & \quad\quad=\text{ftn}_{E}^{A}\bef\gunderline{\text{pu}_{E}\bef\text{eval}_{E}^{E^{A}}}\\
{\color{greenunder}\text{left identity law~(\ref{eq:free-typeclass-encoding-left-identity-law})}:}\quad & \quad\quad=\text{ftn}_{E}^{A}=r\quad;\\
{\color{greenunder}\text{expect to equal }r:}\quad & \text{pu}_{E}\bef h=\gunderline{\text{pu}_{E}\bef\text{eval}_{E}^{E^{A}}}\bef\text{eval}_{E}^{E^{A}}=\text{eval}_{E}^{E^{A}}=r\quad.
\end{align*}
$\square$

\subsection{Describing laws of $P$-typeclasses as values\label{subsec:Describing-laws-of-P-typeclasses-as-values}}

Usually, typeclasses impose some laws on their methods. We will now
develop a rigorous description of $P$-typeclass laws where all laws
are represented by values of a certain type.

For motivation, look at the laws for a monoid type $A$:
\begin{align*}
{\color{greenunder}\text{left identity law}:}\quad & \text{for all }x^{:A}\quad:\quad e_{_{A}}\oplus_{_{A}}x=x\quad,\\
{\color{greenunder}\text{right identity law}:}\quad & \text{for all }x^{:A}\quad:\quad x\oplus_{_{A}}e_{_{A}}=x\quad,\\
{\color{greenunder}\text{associativity law}:}\quad & \text{for all }x^{:A},y^{:A},z^{:A}\quad:\quad(x\oplus_{_{A}}y)\oplus_{_{A}}z=x\oplus_{_{A}}(y\oplus_{_{A}}z)\quad,\\
{\color{greenunder}\text{commutativity law}:}\quad & \text{for all }x^{:A},y^{:A}\quad:\quad x\oplus_{_{A}}y=y\oplus_{_{A}}x\quad.
\end{align*}
Each law is an equation between some expressions of the same type
$A$. These expressions are computed via the monoid\textsf{'}s operations using
arbitrary values ($x$, $y$, $z$), which are also of type $A$.
To generalize this situation, we write the monoid laws as equations
of the form $f_{1}(...)=f_{2}(...)$:
\[
\text{for all }x^{:A},y^{:A},z^{:A}\quad:\quad f_{1}(\oplus_{_{A}},e_{_{A}},x,y,z)=f_{2}(\oplus_{_{A}},e_{_{A}},x,y,z)\quad.
\]
For the associativity law, we need to choose the functions $f_{1}$
and $f_{2}$ as:
\begin{align*}
{\color{greenunder}\text{for the associativity law}:}\quad & f_{1}(\oplus,e,x,y,z)\triangleq(x\oplus y)\oplus z\quad,\quad\quad f_{2}(\oplus,e,x,y,z)\triangleq x\oplus(y\oplus z)\quad.
\end{align*}
The functions $f_{1}$ and $f_{2}$ for the identity laws do not depend
on $y$ and $z$, for instance:
\begin{align*}
{\color{greenunder}\text{for the left identity law}:}\quad & f_{1}(\oplus,e,x,y,z)\triangleq e\oplus x\quad,\quad\quad f_{2}(\oplus,e,x,y,z)\triangleq x\quad.
\end{align*}
The functions $f_{1}$ and $f_{2}$ for the commutativity law will
not depend on $z$.

The data in the pair $(\oplus_{_{A}},e_{_{A}})$ is a value of type
$P^{A}\rightarrow A$, where $P^{A}\triangleq\bbnum 1+A\times A$
for the \lstinline!Monoid! typeclass (but $P$ will be different
for other typeclasses). So, the functions $f_{1}$ and $f_{2}$ have
type $(P^{A}\rightarrow A)\times A\times A\times A\rightarrow A$.
The pair $(f_{1},f_{2})$ is equivalent to a single value of type
$(P^{A}\rightarrow A)\times A\times A\times A\rightarrow A\times A$.
Each law corresponds to a specific value of that type, which we will
call a \index{law function}\textbf{law function}. A law function
computes the two sides of the law at once as a single value of type
$A\times A$. The law then requires that the two values in that pair
should be equal. If $p:A\times A$ is a pair of values of type $A$
then we will write the condition: 
\[
p\triangleright\pi_{1}=p\triangleright\pi_{2}
\]
to indicate that the two values in the pair are equal.

The monoid laws use up to three arbitrary values of type $A$, but
laws for other typeclasses might require more than three arbitrary
values. To make the definition of a law function more general, we
replace an arbitrary value of type $A\times A\times A$ by an arbitrary
function $f$ of type $\text{Int}\rightarrow A$. Instead of values
$x$, $y$, $z$ we will then use the values $f(1)$, $f(2)$, $f(3)$,
etc., which are arbitrary values of type $A$ since $f$ is an arbitrary
function. This allows us to generalize the definition of the \lstinline!Monoid!
laws to other typeclasses of similar form:

\subsubsection{Definition \label{subsec:Definition-law-function-P-typeclass}\ref{subsec:Definition-law-function-P-typeclass}}

A \textbf{law function} for a $P$-typeclass \index{$P$-typeclass!law function}
\index{law function of a $P$-typeclass} is a value $l$ of type:
\begin{equation}
\text{LawF}_{P}\triangleq\forall A.\,(P^{A}\rightarrow A)\times(\text{Int}\rightarrow A)\rightarrow A\times A\quad.\label{eq:P-typeclass-law-type}
\end{equation}
Given a function $l$ of type \lstinline!LawF!, we say that an evidence
value $p_{T}:P^{T}\rightarrow T$ \textbf{satisfies the $l$-law}
if:
\begin{align}
{\color{greenunder}p_{T}\text{ satisfies the }l\text{-law}:}\quad & \text{for all }f^{:\text{Int}\rightarrow T}\quad:\quad\big(l^{T}(p_{T},f)\big)\triangleright\pi_{1}=\big(l^{T}(p_{T},f)\big)\triangleright\pi_{2}\quad.\label{eq:P-typeclass-law}
\end{align}
Here $l^{T}$ is the law function $l$ used with the type parameter
$T$.

A $P$\textbf{-typeclass with laws} \index{$P$-typeclass!with laws}has
specific chosen law functions $l_{1}$, $l_{2}$, ..., $l_{k}$ and
imposes each of the $l_{i}$-laws (for $i=1$, $2$, ..., $k$) on
the evidence values. A type $T$ belongs to that $P$-typeclass if
there exists an evidence value $p_{T}:P^{T}\rightarrow T$ that satisfies
the $l_{i}$-law~(\ref{eq:P-typeclass-law}) for each of the specified
law functions $l_{i}$. For brevity, we also say that the $l_{i}$-laws
\textsf{``}\textbf{hold for} $T$\textsf{''} as long as it is clear what evidence
value $p_{T}$ is implied. $\square$

Another approach to typeclass laws is by describing the two sides
of a law via expression trees. The raw tree encoding of a free $P$-typeclass
($\text{FPR}^{T}$) is a type that represents arbitrary expression
trees with leaf values of type $T$. We can use a pair of values of
type $\text{FPR}^{T}$ as two sides of the law. The two sides can
be evaluated as expression trees using the $P$-operations of a specific
type $T$. The result will be two values of type $T$; the law holds
if these two values are equal.

To see in detail how this approach works, consider again the \lstinline!Monoid!
typeclass with its three laws. Suppose the type $T$ already has the
monoid methods ($\oplus_{_{T}}$ and $e_{_{T}}$), and we would like
to check whether the monoid laws hold for $T$. We will use the raw
tree encoding of the free monoid on $T$, that is, the type \lstinline!FMR[T]!
defined in Section~\ref{subsec:Free-monoids}. Begin with the left
identity law of monoids: it says that for any value $t^{:T}$ we must
have $e_{_{T}}\oplus_{_{T}}t=t$. The two sides of that law are two
expressions involving the monoid $T$\textsf{'}s operations as well as an arbitrary
value $t$ of type $T$. We first consider those two expressions as
unevaluated expression trees. Those \textsf{``}law expression trees\textsf{''} are
two values of the type \lstinline!FMR[T]! that we may implement in
Scala code like this:
\begin{lstlisting}
def lhs1[T](t: T): FMR[T] = Combine(Empty(), Wrap(t))
def rhs1[T](t: T): FMR[T] = Wrap(t)
\end{lstlisting}
The two sides of the law must be defined as \emph{functions} of type
$T\rightarrow\text{FMR}^{T}$ because the law should hold for arbitrary
values $t^{:T}$. In order to verify that the law holds, we now need
to apply the \lstinline!runner! function to the values \lstinline!lhs1!
and \lstinline!rhs1!. To evaluate the expression trees of type $\text{FMR}^{T}$
into values of type $T$, we specify an identity function (of type
$T\rightarrow T$) as the first argument of the \lstinline!runner!
function:
\begin{lstlisting}
def lhs1Evaluated[T: Monoid](t: T): T = runner[T, T](identity)(lhs1(t))
def rhs1Evaluated[T: Monoid](t: T): T = runner[T, T](identity)(rhs1(t))
\end{lstlisting}
The law says that both sides should be equal as values of type $T$.
We could test that:
\begin{lstlisting}
forAll { t: T =>               // Using the scalacheck library.
  lhs1Evaluated(t) shouldEqual rhs1Evaluated(t)
}
\end{lstlisting}

The right identity law is treated similarly. Turning now to the associativity
law, we find that we need \emph{three} arbitrary values of type $T$,
so the \textsf{``}law expression trees\textsf{''} are:
\begin{lstlisting}
def lhs3[T](t1: T, t2: T, t3: T): FMR[T] = Combine(Combine(Wrap(t1), Wrap(t2)), Wrap(t3))
def rhs3[T](t1: T, t2: T, t3: T): FMR[T] = Combine(Wrap(t1), Combine(Wrap(t2), Wrap(t3)))
\end{lstlisting}
To verify that the law holds for $T$, we again evaluate both expression
trees into values of type $T$ using the \lstinline!runner! function:
\begin{lstlisting}
def lhs3Evaluated[T: Monoid](t1: T, t2: T, t3: T): T = runner[T, T](identity)(lhs3(t1, t2, t3))
def rhs3Evaluated[T: Monoid](t1: T, t2: T, t3: T): T = runner[T, T](identity)(rhs3(t1, t2, t3))
\end{lstlisting}
To test that the law holds:
\begin{lstlisting}
forAll { (t1: T, t2: T, t3: T) =>               // Using the scalacheck library.
  lhs3Evaluated(t1, t2, t3) shouldEqual rhs3Evaluated(t1, t2, t3)
}
\end{lstlisting}

We can now generalize the type of \textsf{``}law expression trees\textsf{''} from
\lstinline!Monoid! to an arbitrary $P$-typeclass. The two sides
of the law are functions that take as arguments one or more arbitrary
values of type $T$ and will return a value of type $\text{FPR}^{T}$.
In order to be able to describe any number of arbitrary values of
type $T$, we use an arbitrary function of type $\text{Int}\rightarrow T$.
So, the law is expressed by a function of type $(\text{Int}\rightarrow T)\rightarrow\text{FPR}^{T}\times\text{FPR}^{T}$.
Since the law is supposed to work in the same way for all types $T$,
we add a universal quantifier ($\forall T$). The type of \textsf{``}pairs
of law expression trees\textsf{''} (\lstinline!LawET!) becomes:
\begin{equation}
\text{LawET}\triangleq\forall T.\,(\text{Int}\rightarrow T)\rightarrow\text{FPR}^{T}\times\text{FPR}^{T}\quad.\label{eq:law-expression-tree-type}
\end{equation}

How does a given value \lstinline!et: LawET! specify a law of a $P$-typeclass
(the \textsf{``}\lstinline!et!-law\textsf{''})? Suppose we need to verify whether
a type $T$ with a $P$-algebra structure map $p_{T}$ obeys the \lstinline!et!-law.
First, we apply \lstinline!et! to an arbitrary function \lstinline!f: Int => T!
and obtain a pair \lstinline!(lhs, rhs)! of expression trees of type
\lstinline!FPR[T]!:
\begin{lstlisting}
val f: Int => T = ...
val (lhs: FPR[T], rhs: FPR[T]) = et(f)
\end{lstlisting}
Then we evaluate those expression trees using $T$\textsf{'}s operations (that
is, data from the structure map $p_{T}$):
\begin{lstlisting}
val (lhsT: T, rhsT: T) = (runner(id)(lhs), runner(id)(rhs))
\end{lstlisting}
The \lstinline!et!-law is then the condition \lstinline!lhsT == rhsT!.

The types \lstinline!LawF! and \lstinline!LawET! turn out to be
\emph{equivalent}:

\subsubsection{Statement \label{subsec:Statement-equivalence-law-function-law-expression-tree-P-typeclass}\ref{subsec:Statement-equivalence-law-function-law-expression-tree-P-typeclass}}

The types of fully parametric functions \lstinline!LawF! and \lstinline!LawET!
(defined by Eq.~(\ref{eq:P-typeclass-law-type}) and Eq.~(\ref{eq:law-expression-tree-type})
respectively) are equivalent to each other and to the type $\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$.

\subparagraph{Proof}

To verify the first type equivalence ($\text{LawF}\cong\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$):
\begin{align*}
 & \forall A.\,(P^{A}\rightarrow A)\,\gunderline{\times}\,(\text{Int}\rightarrow A)\rightarrow A\times A\\
 & \cong\forall A.\,(P^{A}+\text{Int}\rightarrow A)\rightarrow\gunderline{A\times A}\\
 & \cong\forall A.\,(P^{A}+\text{Int}\rightarrow A)\rightarrow\bbnum 2\rightarrow A\\
 & \cong\bbnum 2\rightarrow\forall A.\,(P^{A}+\text{Int}\rightarrow A)\rightarrow A\quad.
\end{align*}
The type $\forall A.\,(P^{A}+\text{Int}\rightarrow A)\rightarrow A$
is a Church encoding (see Section~\ref{subsec:The-Church-encoding-of-recursive-types})
of the recursive type $U$ defined as the least fixpoint of the type
equation $U\cong P^{U}+\text{Int}$. The least fixpoint $U$ is the
same as the type we denote by $\text{FPR}^{\text{Int}}$ according
to the definition of $\text{FPR}^{T}$.

To verify the second type equivalence ($\text{LawET}\cong\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$),
use the Yoneda lemma:
\[
\forall T.\,(\gunderline{\text{Int}}\rightarrow T)\rightarrow\gunderline{\text{FPR}^{T}\times\text{FPR}^{T}}\cong\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}\quad.
\]
\vspace{-1\baselineskip}

The types \lstinline!LawF! and \lstinline!LawET! are equivalent
because they are both equivalent to the same type. $\square$

Since the types \lstinline!LawF!, \lstinline!LawET!, and $\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$
are equivalent, we may use either of them according to convenience
within a particular derivation or proof. As an illustration, let us
see how a value of type $\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$
gives rise to a $P$-typeclass law.

Denote for brevity $\text{LawE}^{T}\triangleq\text{FPR}^{T}\times\text{FPR}^{T}$.
Given a value $e:\text{LawE}^{\text{Int}}$ and a $P$-algebra $M$
with a structure map $p_{M}:P^{M}\rightarrow M$, we take an arbitrary
function $f:\text{Int}\rightarrow M$ and compute a value $c$ of
type $M\times M$:
\[
c^{:M\times M}\triangleq e\triangleright f^{\uparrow\text{LawE}}\triangleright\big(\text{run}_{\text{FPR}^{M}}^{M,M}(\text{id})\boxtimes\text{run}_{\text{FPR}^{M}}^{M,M}(\text{id})\big)***eval,not\ run!\quad.
\]
Now, the $e$-law consists of the requirement that $c$ must be a
pair of equal values, for any $f$. In this way, a law expression
$e$ of type $\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$
is a pair of unevaluated expression trees where arbitrary values of
type $M$ are labeled by integers (the same integers must correspond
to the same values of type $M$). When evaluated to a final value
of type $M$, the two expression trees must give the same value. The
$e$-law holds if this is true for arbitrary choices of values of
type $M$.

As an explicit example of a law expression, consider the associativity
law of the \lstinline!Monoid! typeclass :

{*}{*}{*} add an explicit code example with monoid laws{*}{*}{*}

It turns out that laws of a $P$-typeclass are closely connected with
$P$-algebra morphisms. In particular, $P$-algebra morphisms preserve
the typeclass laws and hide the law violations, as the following statements
shows.

\subsubsection{Statement \label{subsec:Statement-P-algebra-morphisms-and-laws}\ref{subsec:Statement-P-algebra-morphisms-and-laws}}

For any $P$-algebras $M$ and $N$ with structure maps $p_{M}$ and
$p_{N}$; for any $P$-algebra morphism $\phi:M\rightarrow N$; and
for any fully parametric law function $l:\text{LawF}_{P}$ that defines
an $l$-law:

\textbf{(a)} Suppose that the $l$-law holds for $M$ and $\phi$
is \emph{surjective}. Then the $l$-law also holds for $N$. (In this
sense, surjective $P$-algebra morphism \textsf{``}preserve\textsf{''} the $P$-typeclass
laws.)

\textbf{(b)} Suppose the $l$-law holds for $N$ but \emph{not} for
$M$. The $l$-law for $M$ has the form of Eq.~(\ref{eq:P-typeclass-law})
with $T=M$. Suppose a violation of the $l$-law for $M$ is found
using a specific $f:\text{Int}\rightarrow M$ as:
\begin{equation}
\big(l^{M}(p_{M},f)\big)\triangleright\pi_{1}\neq\big(l^{M}(p_{M},f)\big)\triangleright\pi_{2}\quad.\label{eq:p-typeclass-law-violation}
\end{equation}
Then this law violation will disappear after applying $\phi$:
\begin{equation}
\big(l^{M}(p_{M},f)\big)\triangleright\pi_{1}\bef\phi=\big(l^{M}(p_{M},f)\big)\triangleright\pi_{2}\bef\phi\quad.\label{eq:p-typeclass-law-violation-hidden}
\end{equation}
(In this sense, a $P$-algebra morphism \textsf{``}hides\textsf{''} any violations
of the $P$-typeclass laws.)

\subparagraph{Proof}

First, we prove that any fully parametric law function $l$ obeys
the strong dinaturality law (Section~\ref{subsec:Strong-dinaturality.-General-properties}).
By Statement~\ref{subsec:Statement-post-wedge-entails-strong-dinaturality},
the function $l$ is strongly dinatural if the argument type of $l$
can be expressed through a profunctor with the post-wedge property.
The type \lstinline!LawF! is:
\[
\text{LawF}_{P}=\forall A.\,(P^{A}\rightarrow A)\times(\text{Int}\rightarrow A)\rightarrow A\times A=\forall A.\,R^{A,A}\rightarrow S^{A}\quad,
\]
where we defined the profunctor $R^{X,Y}\triangleq(P^{X}\rightarrow Y)\times(\text{Int}\rightarrow Y)$
and the functor $S^{A}\triangleq A\times A$. The argument type of
$l$ is $R^{A,A}$, and indeed we find, via Statement~~\ref{subsec:Statement-post-wedge}
and Example~\ref{subsec:Example-strong-dinaturality-for-some-type-signatures}(b),
that $R$ has the post-wedge property. To write the strong dinaturality
law of $l$, we use Eq.~(\ref{eq:strong-dinaturality-law}) with
types $A=M$, $B=N$, and $t=l$, $f=\phi$. For all $x^{:P^{M}\rightarrow M}$,
$u^{:\text{Int}\rightarrow M}$, $y^{:P^{N}\rightarrow N}$, $v^{:\text{Int}\rightarrow N}$
we have:
\begin{equation}
\text{when}\quad x\bef\phi=\phi^{\uparrow P}\bef y\quad\text{and}\quad u\bef\phi=v\quad\text{then}\quad l^{M}(x,u)\triangleright\phi^{\uparrow S}=l^{N}(y,v)\quad.\label{eq:strong-dinaturality-of-l-general}
\end{equation}
When we write the equation for the $l$-law, we will apply the function
$l$ as, say, $l^{M}(p_{M},u)$. Indeed, we may use $x=p_{M}$ and
$y=p_{N}$ in Eq.~(\ref{eq:strong-dinaturality-of-l-general}) because
the condition $x\bef\phi=\phi^{\uparrow P}\bef y$ is the same as
the $P$-algebra morphism law~(\ref{eq:p-algebra-morphism-law})
of $\phi$, which is assumed to hold. Then Eq.~(\ref{eq:strong-dinaturality-of-l-general})
is simplified to:
\begin{equation}
\text{for all }u^{:\text{Int}\rightarrow M}:\quad l^{M}(p_{M},u)\triangleright\phi^{\uparrow S}=l^{N}(p_{N},u\bef\phi)\quad.\label{eq:strong-dinaturality-of-typeclass-law-function-l}
\end{equation}

\textbf{(a)} The two sides of the $l$-law for any $u^{:\text{Int}\rightarrow M}$
are contained in the value $l^{M}(p_{M},u)$ of type $M\times M$.
That value is a pair of \emph{equal} values of type $M$ because it
is given that the $l$-law holds for $M$:
\[
l^{M}(p_{M},u)\triangleright\pi_{1}=l^{M}(p_{M},u)\triangleright\pi_{2}.
\]
Applying $\phi^{\uparrow S}$ to $l^{M}(p_{M},u)$, we obtain again
a pair of equal numbers. To see this more formally, we use the naturality
laws of $\pi_{1}$ and $\pi_{2}$:
\[
\phi^{\uparrow S}\bef\pi_{1}=\pi_{1}\bef\phi\quad,\quad\quad\phi^{\uparrow S}\bef\pi_{2}=\pi_{2}\bef\phi\quad,
\]
to find:
\[
l^{M}(p_{M},u)\triangleright\phi^{\uparrow S}\triangleright\pi_{1}=l^{M}(p_{M},u)\triangleright\pi_{1}\triangleright\phi=l^{M}(p_{M},u)\triangleright\pi_{2}\triangleright\phi=l^{M}(p_{M},u)\triangleright\phi^{\uparrow S}\triangleright\pi_{2}\quad.
\]
Using Eq.~(\ref{eq:strong-dinaturality-of-typeclass-law-function-l}),
we obtain:
\[
l^{N}(p_{N},u\bef\phi)\triangleright\pi_{1}=l^{N}(p_{N},u\bef\phi)\triangleright\pi_{2}\quad.
\]
This is not yet enough to prove that the $l$-law holds for $N$.
We need to prove that $l^{N}(p_{N},v)$ is a pair of equal values
for \emph{arbitrary} $v^{:\text{Int}\rightarrow N}$, but so far we
have only proved it for $v$ of the form $u\bef\phi$. So, it remains
to show that for an arbitrary $v^{:\text{Int}\rightarrow N}$ there
exists some $u_{v}^{:\text{Int}\rightarrow M}$ such that $v=u_{v}\bef\phi$.
By assumption, $\phi$ is surjective, which means that there exists
a function $\chi:N\rightarrow M$ such that $\chi\bef\phi=\text{id}$.
Then we define $u_{v}\triangleq\chi(v)$ and obtain $u_{v}\bef\phi=v\triangleright\chi\bef\phi=v$
as required. This definition of $u_{v}$ gives: 
\[
l^{N}(p_{N},v)=l^{N}(p_{N},u_{v}\bef\phi)\quad,\quad\text{and so}:\quad l^{N}(p_{N},v)\triangleright\pi_{1}=l^{N}(p_{N},v)\triangleright\pi_{2}\quad.
\]
 This holds for all $v^{:\text{Int}\rightarrow N}$, which shows that
the $l$-law holds for the type $N$.

\textbf{(b)} The $l$-law violation is witnessed by the inequality~(\ref{eq:p-typeclass-law-violation}).
To show that Eq.~(\ref{eq:p-typeclass-law-violation-hidden}) holds,
we write:
\begin{align*}
{\color{greenunder}\text{expect to equal }\big(l^{M}(p_{M},f)\big)\triangleright\pi_{2}\bef\phi:}\quad & \big(l^{M}(p_{M},f)\big)\triangleright\gunderline{\pi_{1}\bef\phi}\\
{\color{greenunder}\text{naturality law of }\pi_{1}:}\quad & =\gunderline{\big(l^{M}(p_{M},f)\big)\triangleright\phi^{\uparrow S}}\bef\pi_{1}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:strong-dinaturality-of-typeclass-law-function-l})}:}\quad & =l^{N}(p_{N},f\bef\phi)\bef\gunderline{\pi_{1}}\\
{\color{greenunder}\text{the }l\text{-law holds for }N:}\quad & =l^{N}(p_{N},f\bef\phi)\bef\pi_{2}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:strong-dinaturality-of-typeclass-law-function-l})}:}\quad & =\big(l^{M}(p_{M},f)\big)\triangleright\gunderline{\phi^{\uparrow S}\bef\pi_{2}}\\
{\color{greenunder}\text{naturality law of }\pi_{2}:}\quad & =\big(l^{M}(p_{M},f)\big)\triangleright\pi_{2}\bef\phi\quad.
\end{align*}
$\square$

The property of \textsf{``}hiding\textsf{''} the law violations justifies the practical
use of free typeclass encodings (e.g., the raw tree encoding) that
do not satisfy laws. In practice, a free monad program will be interpreted
(or \textsf{``}run\textsf{''}) into a lawful monad such as \lstinline!Try!, and the
runner will preserve the monad operations. Statement~\ref{subsec:Statement-P-algebra-morphisms-and-laws}(b)
then shows that no law violations will be observable after the runner
is applied. We have proved this for our free monad DSL in Section~\ref{subsec:A-first-recipe-monadic-dsl}.
Now we see that this is a general property that applies to all $P$-typeclasses.
It is safe to use a free typeclass encoding (even if it violates some
laws) as long as its runner preserves the typeclass operations and
the target typeclass is lawful. In the next section we will study
such \textsf{``}partially lawful\textsf{''} free typeclass encodings.

\subsection{Free $P$-typeclasses that satisfy a subset of the laws\label{subsec:Free--typeclasses-that-satisfy-laws}}

In Section~\ref{subsec:Free-monoids}, we have seen four different
encodings of the free monoid (denoted by \lstinline!F1!, \lstinline!F2!,
\lstinline!F3!, and \lstinline!F4!). It turns out that all those
encodings satisfy the requirements of Definition~\ref{subsec:Definition-free-P-typeclass-encoding},
although they obey different subsets of the laws of monoids. We will
now generalize that situation to $P$-typeclasses and study the properties
of free $P$-typeclass constructions that satisfy only a subset of
the typeclass\textsf{'}s laws. The resulting theory will make it simpler to
prove that a given type constructor $E^{\bullet}$ is indeed a valid
free $P$-typeclass encoding as specified by Definition~\ref{subsec:Definition-free-P-typeclass-encoding}.

Namely, the next statement shows that a functor $E$ is a free $P$-typeclass
encoding if it is a strict subset of the raw tree encoding (\lstinline!FPR!)
and has certain additional properties. In this way, we can use \lstinline!FPR!
to validate other free $P$-typeclass encodings with less work than
if we were applying Definition~\ref{subsec:Definition-free-P-typeclass-encoding}
directly.

\subsubsection{Statement \label{subsec:Statement-compatible-retract-of-free-monad}\ref{subsec:Statement-compatible-retract-of-free-monad}}

Let $P$ be a polynomial functor and let $E$ be a functor such that:

1. For any type $T$, the type $E^{T}$ is a $P$-algebra with a structure
map $p_{E}^{T}:P^{E^{T}}\rightarrow E^{T}$ natural in $T$. 

2. There exist natural transformations $\text{in}_{E}^{T}:E^{T}\rightarrow\text{FPR}^{T}$
(which is \emph{not} required to be a $P$-algebra morphism) and $\text{pu}_{E}^{T}:T\rightarrow E^{T}$.

3. The following properties hold:
\begin{equation}
\text{pu}_{E}^{T}\bef\text{in}_{E}^{T}=\text{pu}_{\text{FPR}}^{T}\quad,\quad\quad\text{in}_{E}^{T}\bef(\text{pu}_{E}^{T})^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{E^{T}}=\text{id}^{:E^{T}\rightarrow E^{T}}\quad.\label{eq:laws-of-in-E-free-P-typeclass-encoding}
\end{equation}
The last requirement says that the function $(\text{pu}_{E}^{T})^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{E^{T}}$
of type $\text{FPR}^{T}\rightarrow E^{T}$ is the left inverse to
the function $\text{in}_{E}^{T}$. This indicates that $\text{in}_{E}^{T}:E^{T}\rightarrow\text{FPR}^{T}$
is injective\index{injective function}. So, $E^{T}$ is a subset
of $\text{FPR}^{T}$ in this sense.

4. The function $\text{ftn}_{E}:E^{E^{T}}\rightarrow E^{T}$ defined
by $\text{ftn}_{E}\triangleq\text{in}_{E}^{E^{T}}\bef\text{eval}_{\text{FPR}}^{E^{T}}$
is a $P$-algebra morphism.

5. The $P$-algebra $E^{T}$ satisfies some (or all) of the $P$-typeclass
laws but \emph{no other} laws. {*}{*}{*}This is misleading, as in
fact $E^{T}$ does satisfy more laws for some $T$; say for $T=\bbnum 0$.{*}{*}{*}To
formulate this requirement precisely, we use law expressions $e:\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$
for describing $P$-typeclass laws (see Section~\ref{subsec:Describing-laws-of-P-typeclasses-as-values}).
We say that $E^{T}$ obeys \textsf{``}no other laws than those of the $P$-typeclass\textsf{''}
if for any $P$-algebra $C$ that obeys all the $P$-typeclass laws
and for any $e:\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$
whose corresponding $e$-law holds for $E^{T}$, the same $e$-law
will also hold for $C$. (A counterexample is an $E^{T}$ that satisfies
all the standard monoid laws and in addition the commutativity law.
By Statement~\ref{subsec:Statement-P-algebra-morphisms-and-laws},
there cannot be a surjective monoid morphism $E^{M}\rightarrow M$
when $M$ is a non-commutative monoid. Yet, that morphism would have
existed if $E$ were a valid encoding of a free monoid.)

If assumptions 1-5 hold then:

\textbf{(a)} The functor $E$ is a free $P$-typeclass encoding. When
the function $\text{in}_{E}$ is itself a $P$-algebra morphism then
the encoding $E$ is equivalent to \lstinline!FPR!. (We do \emph{not}
require $\text{in}_{E}^{T}$ to be a $P$-algebra morphism. Then we
are able to describe free $P$-typeclass encodings $E$ that are different
from $\text{FPR}$.)

\textbf{(b)} The universal evaluator $\text{eval}_{E}^{C}$ does not
depend on the choice of the function $\text{in}_{E}$ as long as the
same assumptions hold for that function.

\subparagraph{Proof}

\textbf{(a)} If $\text{in}_{E}^{T}$ is a $P$-algebra morphism then
the function $g_{E}^{T}$ defined by:
\[
g_{E}^{T}:\text{FPR}^{T}\rightarrow\text{FPR}^{T}\quad,\quad\quad g_{E}^{T}\triangleq\text{run}_{\text{FPR}}^{T,E^{T}}(\text{pu}_{E}^{T})\bef\text{in}_{E}^{T}=(\text{pu}_{E}^{T})^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{E^{T}}\bef\text{in}_{E}^{T}\quad,
\]
will be also a $P$-algebra morphism (as a composition of several
$P$-algebra morphisms). However, $P$-algebra morphisms of type $\text{FPR}^{T}\rightarrow C$
are unique when a function $r:T\rightarrow C$ is fixed (Statement~\ref{subsec:Statement-some-properties-of-free-P-typeclass-encoding}).
In the present case, we have $C=\text{FPR}^{T}$ and the function
of type $T\rightarrow C$ is $\text{pu}_{\text{FPR}}$. Let us apply
Statement~\ref{subsec:Statement-some-properties-of-free-P-typeclass-encoding}(a).
We first need to compute $r$ as: 
\begin{align*}
 & r\triangleq\text{pu}_{\text{FPR}}^{T}\bef g_{E}^{T}=\gunderline{\text{pu}_{\text{FPR}}^{T}\bef(\text{pu}_{E}^{T})^{\uparrow\text{FPR}}}\bef\text{eval}_{\text{FPR}}^{E^{T}}\bef\text{in}_{E}^{T}\\
{\color{greenunder}\text{naturality of }\text{pu}_{\text{FPR}}:}\quad & =\text{pu}_{E}^{T}\bef\gunderline{\text{pu}_{\text{FPR}}^{E^{T}}\bef\text{eval}_{\text{FPR}}^{E^{T}}}\bef\text{in}_{E}^{T}\\
{\color{greenunder}\text{left identity law~(\ref{eq:free-typeclass-encoding-left-identity-law}) for }\text{FPR}:}\quad & =\text{pu}_{E}^{T}\bef\text{in}_{E}^{T}\\
{\color{greenunder}\text{assumption~(\ref{eq:laws-of-in-E-free-P-typeclass-encoding})}:}\quad & =\text{pu}_{\text{FPR}}^{T}\quad.
\end{align*}
By Statement~\ref{subsec:Statement-some-properties-of-free-P-typeclass-encoding}(a),
there exists only one $P$-algebra morphism with this $r$, namely
$r^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}$. That morphism
is, however, equal to the identity function due to Eq.~(\ref{eq:free-typeclass-encoding-right-identity-law}):
\[
\gunderline{r^{\uparrow\text{FPR}}}\bef\text{eval}_{\text{FPR}}=\text{pu}_{\text{FPR}}^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}=\text{id}^{:\text{FPR}^{T}\rightarrow\text{FPR}^{T}}\quad.
\]
We find that we must have $g_{E}^{T}=\text{id}$. It means that the
$P$-algebra morphisms $\text{in}_{E}^{T}$ and $g$ are inverses
of each other and give a $P$-algebra \emph{isomorphism} (a type equivalence
that preserves the $P$-typeclass operations) between $E^{T}$ and
$\text{FPR}^{T}$. 

To show that $E$ is a $P$-typeclass encoding, we look at the conditions
in Definition~\ref{subsec:Definition-free-P-typeclass-encoding}.

Conditions (a) and (b) of Definition~\ref{subsec:Definition-free-P-typeclass-encoding}
are satisfied by our assumptions 1 and 2.

To verify condition (c), we assume that $C$ is any $P$-algebra that
obeys all the $P$-typeclass laws that $E$ obeys. We then \emph{define}
$\text{eval}_{E}^{C}$ via $\text{eval}_{\text{FPR}}^{C}$:
\[
\text{eval}_{E}^{C}:E^{C}\rightarrow C\quad,\quad\quad\text{eval}_{E}^{C}\triangleq\text{in}_{E}^{C}\bef\text{eval}_{\text{FPR}}^{C}\quad.
\]
Now we need to show that $\text{eval}_{E}^{C}$ satisfies the required
properties.

To verify the left identity law:
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{id}^{:C\rightarrow C}:}\quad & \text{pu}_{E}^{C}\bef\text{eval}_{E}^{C}=\gunderline{\text{pu}_{E}^{C}\bef\text{in}_{E}^{C}}\bef\text{eval}_{\text{FPR}}^{C}\\
{\color{greenunder}\text{use Eq.~(\ref{eq:laws-of-in-E-free-P-typeclass-encoding})}:}\quad & =\gunderline{\text{pu}_{\text{FPR}}^{C}\bef\text{eval}_{\text{FPR}}^{C}}\\
{\color{greenunder}\text{left identity law~(\ref{eq:free-typeclass-encoding-left-identity-law}) of }\text{FPR}:}\quad & =\text{id}^{:C\rightarrow C}\quad.
\end{align*}

To verify the right identity law:
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{id}^{:E^{T}\rightarrow E^{T}}:}\quad & (\text{pu}_{E}^{T})^{\uparrow E}\bef\text{eval}_{E}^{E^{T}}=\gunderline{(\text{pu}_{E}^{T})^{\uparrow E}\bef\text{in}_{E}^{E^{T}}}\bef\text{eval}_{\text{FPR}}^{E^{T}}\\
{\color{greenunder}\text{naturality law of }\text{in}_{E}^{E^{T}}:}\quad & =\text{in}_{E}^{T}\bef(\text{pu}_{E}^{T})^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{E^{T}}\\
{\color{greenunder}\text{assumption in Eq.~(\ref{eq:laws-of-in-E-free-P-typeclass-encoding})}:}\quad & =\text{id}^{:E^{T}\rightarrow E^{T}}\quad.
\end{align*}

To verify the $P$-algebra naturality law~(\ref{eq:free-typeclass-encoding-P-algebra-naturality-law}),
write its left-hand side:
\begin{align*}
{\color{greenunder}\text{expect to equal }g^{\uparrow E}\bef\text{eval}_{E}:}\quad & \text{eval}_{E}^{C}\bef g=\text{in}_{E}\bef\gunderline{\text{eval}_{\text{FPR}}\bef g}\\
{\color{greenunder}P\text{-algebra naturality law of }\text{eval}_{\text{FPR}}:}\quad & =\gunderline{\text{in}_{E}\bef g^{\uparrow\text{FPR}}}\bef\text{eval}_{\text{FPR}}\\
{\color{greenunder}\text{naturality law of }\text{in}_{E}:}\quad & =g^{\uparrow E}\bef\gunderline{\text{in}_{E}\bef\text{eval}_{\text{FPR}}}=g^{\uparrow E}\bef\text{eval}_{E}\quad.
\end{align*}

Next, we prove the $P$-algebra morphism law of $\text{eval}_{E}$.
We rewrite it as:
\begin{align}
p_{E^{C}}\bef\text{in}_{E}^{C}\bef\text{eval}_{\text{FPR}}^{C}\overset{?}{=}\big(\text{in}_{E}^{C}\bef\text{eval}_{\text{FPR}}^{C}\big)^{\uparrow P}\bef p_{C}\quad.\label{eq:P-algebra-morphism-law-for-in-r-derivation1}
\end{align}
Verifying Eq.~(\ref{eq:P-algebra-morphism-law-for-in-r-derivation1})
takes more work. We first note that for any $C$ satisfying the given
assumptions, the $P$-algebra morphism law already holds for $\text{eval}_{\text{FPR}}^{C}$:
\[
p_{\text{FPR}^{C}}\bef\text{eval}_{\text{FPR}}^{C}=\big(\text{eval}_{\text{FPR}}^{C}\big)^{\uparrow P}\bef p_{C}\quad.
\]
Then the $P$-algebra morphism law for $r_{E}^{T,C}$ becomes:
\[
p_{E^{C}}\bef\text{in}_{E}^{C}\bef\text{eval}_{\text{FPR}}^{C}\overset{?}{=}\big(\text{in}_{E}^{C}\big)^{\uparrow P}\bef p_{\text{FPR}^{C}}\bef\text{eval}_{\text{FPR}}^{C}\quad.
\]
Apply both sides of the last equation to an arbitrary fixed value
$x:P^{E^{T}}$ and rewrite the equation as: 
\[
r_{\text{FPR}}^{T,C}(a)\overset{?}{=}r_{\text{FPR}}^{T,C}(b)\quad,\quad\quad a^{:\text{FPR}^{T}}\triangleq x\triangleright p_{E^{T}}\bef\text{in}_{E}^{T}\quad,\quad\quad b^{:\text{FPR}^{T}}\triangleq x\triangleright\big(\text{in}_{E}^{T}\big)^{\uparrow P}\bef p_{\text{FPR}^{T}}\quad.
\]

The values $a$ and $b$ play a similar role to the two parts of a
law expression $e:\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$.
We note that Eq.~(\ref{eq:P-algebra-morphism-law-for-in-r-derivation1})
holds for $C=E^{T}$ due to the assumption $\text{in}_{E}^{T}\bef r_{\text{FPR}}^{T,E^{T}}=\text{id}$:
\begin{align*}
{\color{greenunder}\text{left-hand side of Eq.~(\ref{eq:P-algebra-morphism-law-for-in-r-derivation1}) with }C=E^{T}:}\quad & p_{E^{T}}\bef\gunderline{\text{in}_{E}^{T}\bef r_{\text{FPR}}^{T,E^{T}}}=p_{E^{T}}\bef\text{id}=p_{E^{T}}\quad,\\
{\color{greenunder}\text{right-hand side of Eq.~(\ref{eq:P-algebra-morphism-law-for-in-r-derivation1}) with }C=E^{T}:}\quad & \big(\gunderline{\text{in}_{E}^{T}\bef r_{\text{FPR}}^{T,E^{T}}}\big)^{\uparrow P}\bef p_{E^{T}}=\text{id}^{\uparrow P}\bef p_{E^{T}}=p_{E^{T}}\quad.
\end{align*}
The fact that Eq.~(\ref{eq:P-algebra-morphism-law-for-in-r-derivation1})
holds for $C=E^{T}$ can be expressed via $a$, $b$ as:
\[
r_{\text{FPR}}^{T,E^{T}}(a)\overset{!}{=}r_{\text{FPR}}^{T,E^{T}}(b)\quad.
\]
This resembles the statement of a typeclass law that holds in $E^{T}$,
except that $a$ and $b$ are specific values of type $\text{FPR}^{T}$.
We have the assumption that all laws of $E$ also hold for $C$. This
assumption will allow us to complete the proof of Eq.~(\ref{eq:P-algebra-morphism-law-for-in-r-derivation1})
once we represent the relevant laws as values of type $\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}$.

We first set $T=\text{Int}$. For any $x:P^{E^{\text{Int}}}$ we define
a law expression $e$ as:
\[
e:\text{FPR}^{\text{Int}}\times\text{FPR}^{\text{Int}}\quad,\quad\quad e\triangleq a\times b\quad,\quad\quad a\triangleq(x\triangleright p_{E^{\text{Int}}}\bef\text{in}_{E}^{\text{Int}})\quad,\quad\quad b\triangleq x\triangleright\big(\text{in}_{E}^{\text{Int}}\big)^{\uparrow P}\bef p_{\text{FPR}^{\text{Int}}}\quad.
\]
Since $r_{\text{FPR}}^{\text{Int},E^{\text{Int}}}(a)=r_{\text{FPR}}^{\text{Int},E^{\text{Int}}}(b)$,
the $e$-law holds in $E^{\text{Int}}$.{*}{*}{*}Clarify that in the
previous section! 

We need to write explicitly a law that holds in $E^{T}$.

{*}{*}{*}

This concludes the proof that $\text{eval}_{E}^{C}$ is a $P$-algebra
morphism. It remains to show that any other $P$-algebra morphism
$g:E^{C}\rightarrow C$ satisfying the left identity law ($\text{pu}_{E}^{C}\bef g=\text{id}$)
is equal to $\text{eval}_{E}^{C}$. 

Given such a function $g$, define a function $h:\text{FPR}^{C}\rightarrow C$
by $h\triangleq\text{pu}_{E}^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{E^{C}}\bef g$.
We will now show that $h$ is always the same as $\text{eval}_{\text{FPR}}$.
The function $h$ is a composition of $P$-algebra morphisms, and
so $h$ is itself one. The function $h$ satisfies $\text{pu}_{\text{FPR}}^{C}\bef h=\text{id}$
because:
\begin{align*}
\text{expect to equal } & \text{pu}_{\text{FPR}}^{C}\bef h=\gunderline{\text{pu}_{\text{FPR}}^{C}\bef\text{pu}_{E}^{\uparrow\text{FPR}}}\bef\text{eval}_{\text{FPR}}^{E^{C}}\bef g\\
 & =\text{pu}_{E}^{C}\bef\gunderline{\text{pu}_{\text{FPR}}^{E^{C}}\bef\text{eval}_{\text{FPR}}^{E^{C}}}\bef g\\
 & =\text{pu}_{E}^{C}\bef g=\text{id}\quad.
\end{align*}
The uniqueness property of $\text{eval}_{\text{FPR}}$ in Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(d)
gives $h=\text{eval}_{\text{FPR}}^{C}$.

We can now prove that $g=\text{eval}_{E}$ by using the definition
$\text{eval}_{E}\triangleq\text{in}_{E}\bef\text{eval}_{\text{FPR}}$:
\begin{align*}
{\color{greenunder}\text{expect to equal }g:}\quad & \text{eval}_{E}^{C}=\text{in}_{E}^{C}\bef\gunderline{\text{eval}_{\text{FPR}}^{C}}=\text{in}_{E}^{C}\bef\gunderline h\\
{\color{greenunder}\text{by definition of }h:}\quad & =\gunderline{\text{in}_{E}^{C}\bef\text{pu}_{E}^{\uparrow\text{FPR}}\bef\text{eval}_{\text{FPR}}^{E^{C}}}\bef g\\
{\color{greenunder}\text{use Eq.~(\ref{eq:laws-of-in-E-free-P-typeclass-encoding}) with }T=C:}\quad & =g\quad.
\end{align*}

\textbf{(b)} Given a new function $\text{in}_{E}^{\prime}$ that also
satisfies Eq.~(\ref{eq:laws-of-in-E-free-P-typeclass-encoding}),
we define the corresponding new evaluator function: $\text{eval}_{E}^{\prime C}\triangleq\text{in}_{E}^{\prime C}\bef\text{eval}_{\text{FPR}}^{C}$.
Now we will show that $\text{eval}_{E}^{\prime}=\text{eval}_{E}$.
Part \textbf{(a)} of the proof says that $\text{eval}_{E}^{\prime}$
has the same properties as $\text{eval}_{E}$. In particular, $\text{eval}_{E}^{\prime C}$
is a $P$-algebra morphism of type $E^{C}\rightarrow C$ and satisfies
the left identity law ($\text{pu}_{E}^{C}\bef\text{eval}_{E}^{\prime C}=\text{id}^{:C\rightarrow C}$).
By Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(d),
there is only one $P$-algebra morphism of type $E^{C}\rightarrow C$
obeying the left identity law, namely $\text{eval}_{E}^{C}$. So,
$\text{eval}_{E}^{\prime C}=\text{eval}_{E}^{C}$. $\square$

\subsection{Imposing laws of $P$-typeclasses via monad algebras}

We have shown in Statement~\ref{subsec:Statement-free-typeclass-encoding-is-a-monad}
that any free $P$-typeclass encoding $E$ is always a monad. It turns
out that we may may use $E$\textsf{'}s monad methods to impose $P$-typeclass
laws on a given $P$-algebra. The required technique is based on the
notion of a \textsf{``}\index{monad algebra}monad algebra\textsf{''}:

\subsubsection{Definition \label{subsec:Definition-monad-algebra}\ref{subsec:Definition-monad-algebra}}

Given a monad $E$, a type $C$ is an $E$-\textbf{monad algebra}
if $C$ is an $E$-algebra with a structure map $s:E^{C}\rightarrow C$
that additionally obeys the following laws:
\[
\xymatrix{\xyScaleY{1.4pc}\xyScaleX{2.5pc}C\ar[r]\sp(0.5){\text{pu}_{E}}\ar[dr]\sb(0.5){\,\text{id}} & E^{C}\ar[d]\sp(0.45){s} & E^{E^{C}}\ar[d]\sb(0.45){s^{\uparrow E}}\ar[r]\sp(0.55){\text{ftn}_{E}} & E^{C}\ar[d]\sb(0.45){s}\\
 & C & E^{C}\ar[r]\sp(0.5){s} & C
}
\]
\begin{align*}
{\color{greenunder}\text{identity law of monad algebras}:}\quad & \text{pu}_{E}^{C}\bef s=\text{id}^{:C\rightarrow C}\quad,\\
{\color{greenunder}\text{composition law of monad algebras}:}\quad & \text{ftn}_{E}\bef s=s^{\uparrow E}\bef s\quad.
\end{align*}
$\square$

\subsubsection{Statement \label{subsec:Statement-Monad-algebra-is-P-typeclass}\ref{subsec:Statement-Monad-algebra-is-P-typeclass}}

Suppose $E$ is a free $P$-typeclass encoding according to Definition~\ref{subsec:Definition-free-P-typeclass-encoding}.
A monad structure for $E$ is given by Statement~\ref{subsec:Statement-free-typeclass-encoding-is-a-monad}.
Then the type of $E$-monad algebras is equivalent to the type of
$P$-algebras that obey all the laws of $E$. In more detail:

\textbf{(a)} Any $E$-monad algebra $C$ is also a $P$-algebra. The
structure map $s:E^{C}\rightarrow C$ is a surjective $P$-algebra
morphism.

\textbf{(b)} Any $P$-algebra $C$ that satisfies all the laws of
$E^{\bullet}$ is also an $E$-monad algebra.

\textbf{(c)} The $P$-algebra structures and the $E$-monad algebra
structures are in a 1-to-1 correspondence.

\subparagraph{Proof}

\textbf{(a)} To show that $C$ is a $P$-algebra, we define the structure
map $p_{C}:P^{C}\rightarrow C$ by:
\[
p_{C}:P^{C}\rightarrow C\quad,\quad\quad p_{C}\triangleq\text{pu}_{E}^{\uparrow P}\bef p_{E}^{C}\bef s\quad.
\]

To show that $s$ is a $P$-algebra morphism, we write the law~(\ref{eq:p-algebra-morphism-law})
with $f=s$:
\begin{align*}
{\color{greenunder}\text{expect to equal }p_{E}^{C}\bef s:}\quad & s^{\uparrow P}\bef\gunderline{p_{C}}=\gunderline{s^{\uparrow P}\bef\text{pu}_{E}^{\uparrow P}}\bef p_{E}^{C}\bef s=(\gunderline{s\bef\text{pu}_{E}})^{\uparrow P}\bef p_{E}^{C}\bef s\\
{\color{greenunder}\text{naturality law of }\text{pu}_{E}:}\quad & =\gunderline{(\text{pu}_{E}\bef s^{\uparrow E})^{\uparrow P}}\bef p_{E}^{C}\bef s=\text{pu}_{E}^{\uparrow P}\bef\gunderline{s^{\uparrow E\uparrow P}\bef p_{E}^{C}}\bef s\\
{\color{greenunder}\text{naturality law~(\ref{eq:free-typeclass-encoding-P-naturality-law}) of }p_{E}^{C}:}\quad & =\text{pu}_{E}^{\uparrow P}\bef p_{E}^{E^{C}}\bef\gunderline{s^{\uparrow E}\bef s}\\
{\color{greenunder}E\text{-monad algebra composition law of }s:}\quad & =\text{pu}_{E}^{\uparrow P}\bef\gunderline{p_{E}^{E^{C}}\bef\text{ftn}_{E}}\bef s\\
{\color{greenunder}P\text{-algebra morphism law~(\ref{eq:P-algebra-morphism-law-of-flatten}) of }\text{ftn}_{E}:}\quad & =\gunderline{\text{pu}_{E}^{\uparrow P}\bef\text{ftn}_{E}^{\uparrow P}}\bef p_{E}^{C}\bef s=(\gunderline{\text{pu}_{E}\bef\text{ftn}_{E}})^{\uparrow P}\bef p_{E}^{C}\bef s\\
{\color{greenunder}\text{left identity law of }E:}\quad & =p_{E}^{C}\bef s\quad.
\end{align*}
The $E$-monad algebra identity law ($\text{pu}_{E}\bef s=\text{id}$)
means that $s$ is surjective.

We note that this part of the proof does not use the uniqueness property
of $E$. So, $C$ is also a $P$-algebra under the weaker assumption
that $E$ is any monad with a $P$-algebra structure, appropriate
naturality laws, and the property that $\text{ftn}_{E}$ is a $P$-algebra
morphism. 

\textbf{(b)} If $C$ is a $P$-algebra, we define an $E$-algebra
structure map $s:E^{C}\rightarrow C$ by:
\[
s:E^{C}\rightarrow C\quad,\quad\quad s\triangleq\text{run}_{E}(\text{id}^{:C\rightarrow C})\quad.
\]
As $C$ satisfies all the laws of $E$, we find from Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(c)
that $s=\text{run}_{E}(\text{id})$ is a $P$-algebra morphism. It
remains to verify that $s$ obeys the monad algebra\textsf{'}s laws:
\begin{align*}
{\color{greenunder}\text{identity law}:}\quad & \text{pu}_{E}^{C}\bef s\overset{?}{=}\text{id}^{:C\rightarrow C}\quad,\\
{\color{greenunder}\text{composition law}:}\quad & \text{ftn}_{E}\bef s\overset{?}{=}s^{\uparrow E}\bef s\quad.
\end{align*}

The identity law is verified by using Eq.~(\ref{eq:free-typeclass-encoding-left-identity-law})
with $T=C$ and $r=\text{id}$:
\[
\text{pu}_{E}^{C}\bef s=\text{pu}_{E}^{C}\bef\text{run}_{E}^{C,C}(\text{id}^{:C\rightarrow C})=\text{id}^{:C\rightarrow C}\quad.
\]

To verify the composition law, we rewrite it in terms of $\text{run}_{E}$
using the fact that $\text{ftn}_{E}=\text{run}_{E}(\text{id})$:
\[
\gunderline{\text{ftn}_{E}}\bef s=\text{run}_{E}^{E^{C},E^{C}}(\text{id}^{:E^{C}\rightarrow E^{C}})\bef s\overset{?}{=}s^{\uparrow E}\bef\gunderline s=s^{\uparrow E}\bef\text{run}_{E}^{C,C}(\text{id}^{:C\rightarrow C})\quad.
\]
The $P$-algebraic naturality law~(\ref{eq:free-typeclass-encoding-P-algebra-naturality-law})
with{*}{*}{*} we modified that law to use eval instead of run, so
rewrite this proof too!{*}{*}{*} $g=s$ and $r=\text{id}^{:E^{C}\rightarrow E^{C}}$
gives for the left-hand side:
\[
\text{run}_{E}^{E^{C},E^{C}}(\text{id}^{:E^{C}\rightarrow E^{C}})\bef s=\text{run}_{E}^{E^{C},C}(\gunderline{\text{id}^{:E^{C}\rightarrow E^{C}}\bef s})=\text{run}_{E}^{E^{C},C}(s)\quad.
\]
The right-hand side is simplified using {*}{*}{*} we modified that
law to use eval instead of run, so rewrite this proof too!{*}{*}{*}the
naturality law~(\ref{eq:free-typeclass-encoding-P-algebra-naturality-law})
with $f=s$ and $r=\text{id}^{:E^{C}\rightarrow E^{C}}$:
\[
s^{\uparrow E}\bef\text{run}_{E}^{C,C}(\text{id}^{:E^{C}\rightarrow E^{C}})=\text{run}_{E}^{E^{C},C}(s\bef\text{id}^{:E^{C}\rightarrow E^{C}})=\text{run}_{E}^{E^{C},C}(s)\quad.
\]
Both sides of the composition law are now equal to $\text{run}_{E}^{E^{C},C}(s)$.

\textbf{(c)} We have mapped an $E$-monad algebra to a $P$-algebra
and back. Now we will show that this mapping is an isomorphism in
both directions.

For a given $E$-monad algebra $C$ with a structure map $s:E^{C}\rightarrow C$,
we defined a structure map $p_{C}$:
\[
p_{C}:P^{C}\rightarrow C\quad,\quad\quad p_{C}\triangleq\text{pu}_{E}^{\uparrow P}\bef p_{E}^{C}\bef s\quad.
\]
Since $C$ is now a $P$-algebra, we can define a new $E$-monad algebra
structure map, $s\textsf{'}\triangleq\text{run}_{E}^{C,C}(\text{id})$. To
show that $s\textsf{'}=s$, note that $s$ is a $P$-algebra morphism, as we
proved in part \textbf{(a)}. Additionally, $s$ satisfies $\text{pu}_{E}\bef s=\text{id}$.
Then we may apply the uniqueness property of $\text{run}_{E}$ from
Definition~\ref{subsec:Definition-free-P-typeclass-encoding}(d)
and get $s=\text{run}_{E}^{C,C}(\text{id})=s\textsf{'}$.

For a given $P$-algebra $C$ that satisfies all the laws of $E$,
we define the $E$-monad algebra structure map by $s\triangleq\text{run}_{E}(\text{id})$.
Now we can define a new $P$-algebra structure map $p_{C}^{\prime}\triangleq\text{pu}_{E}^{\uparrow P}\bef p_{E}^{C}\bef s$.
To prove that $p_{C}^{\prime}=p_{C}$, we use the $P$-algebra morphism
law of $s$:
\[
p_{E}^{C}\bef s=s^{\uparrow P}\bef p_{C}\quad,
\]
as well as the identity law $\text{pu}_{E}\bef s=\text{id}$ to obtain:
\[
p_{C}^{\prime}=\text{pu}_{E}^{\uparrow P}\bef\gunderline{p_{E}^{C}\bef s}=\gunderline{\text{pu}_{E}^{\uparrow P}\bef s^{\uparrow P}}\bef p_{C}=(\gunderline{\text{pu}_{E}\bef s})^{\uparrow P}\bef p_{C}=\gunderline{\text{id}^{\uparrow P}}\bef p_{C}=p_{C}\quad.
\]
$\square$

\subsubsection{Exercise \label{subsec:Exercise-P-algebras-monad-algebras}\ref{subsec:Exercise-P-algebras-monad-algebras}}

Suppose $E$ is a free $P$-typeclass encoding according to Definition~\ref{subsec:Definition-free-P-typeclass-encoding}.
If $C$ and $D$ are any given $E$-algebras, the proof of Statement~\ref{subsec:Statement-Monad-algebra-is-P-typeclass}
defines functions $p_{C}$, $p_{D}$ that make $C$ and $D$ into
$P$-algebras. If $f:C\rightarrow D$ is any $E$-algebra morphism,
show that $f$ is also a $P$-algebra morphism between the $P$-algebras
$C$ and $D$. $\square$

We can now use monad algebras to prove that certain typeclass constructions
always give new and lawful typeclass instances. {*}{*}{*}

\subsection{Church encodings of free $P$-typeclasses\label{subsec:Church-encodings-for-free-P-typeclasses}}

\subsection{Free constructions on more than one generator}

Can combine two or more DSLs in a disjunction: $\text{DSL}^{F+G+H,A}$ 

- combine semigroup and pointed to get a monoid

\section{Slides }


\paragraph{Mapping a free semigroup to different targets}

What if we interpret $\text{FS}^{X}$ into \emph{another} free semigroup?

Given $Y\rightarrow Z$, can we map $\text{FS}^{Y}\rightarrow\text{FS}^{Z}$?

Need to map $\text{FS}^{Y}\triangleq Y+\text{FS}^{Y}\times\text{FS}^{Y}\rightarrow Z+\text{FS}^{Z}\times\text{FS}^{Z}$

This is straightforward since $\text{FS}^{X}$ is a functor in $X$:

\texttt{\textcolor{blue}{\footnotesize{}def fmap{[}Y, Z{]}(f: Y $\rightarrow$
Z): FS{[}Y{]} $\rightarrow$ FS{[}Z{]} = \{}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}  case Wrap(y) $\rightarrow$
Wrap(f(y))}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}  case Comb(a, b) $\rightarrow$
Comb(fmap(f)(a), fmap(f)(b))}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}\}}}{\footnotesize\par}

Now we can use \texttt{\textcolor{blue}{\footnotesize{}run}} to interpret
$\text{FS}^{X}\rightarrow\text{FS}^{Y}\rightarrow\text{FS}^{Z}\rightarrow S$,
etc.

Functor laws hold for $\text{FS}^{X}$, so \texttt{\textcolor{blue}{\footnotesize{}fmap}}
is composable as usual

The \textsf{``}interpreter\textsf{''} commutes with \texttt{\textcolor{blue}{\footnotesize{}fmap}}
as well (naturality law):{\footnotesize{}}{\footnotesize{}
\[
\xymatrix{\xyScaleY{0.2pc}\xyScaleX{3pc} & \text{FS}^{Y}\ar[rd]\sp(0.6){\ \text{run}^{S}g^{:Y\rightarrow S}}\\
\text{FS}^{X}\ar[ru]\sp(0.45){\text{fmap}\,f^{:X\rightarrow Y}}\ar[rr]\sb(0.5){\text{run}^{S}(f\bef g)^{:X\rightarrow S}} &  & S
}
\]
}{\footnotesize\par}

Combine two free semigroups: $\text{FS}^{X+Y}$; inject parts: $\text{FS}^{X}\rightarrow\text{FS}^{X+Y}$ 


\paragraph{Church encoding I: Motivation}

Multiple target semigroups $S_{i}$ require many \textsf{``}extractors\textsf{''}
$\text{ex}_{i}:Z\rightarrow S_{i}$

Refactor extractors $\text{ex}_{i}$ into evidence of a typeclass
constraint on $S_{i}$

\textcolor{darkgray}{\footnotesize{}// Typeclass ExZ{[}S{]} has a
single method, extract: Z $\rightarrow$ S.}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}implicit val exZ: ExZ{[}MySemigroup{]}
= \{ z $\rightarrow$ ... \}}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}def run{[}S: ExZ : Semigroup{]}(fs: FS{[}Z{]}): S
= fs match \{}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}  case Wrap(z) $\rightarrow$
implicitly{[}ExZ{[}S{]}{]}.extract(z)}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}  case Comb(x, y) $\rightarrow$
run(x) |+| run(y)}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}\}}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}run()}} replaces case classes
by fixed functions parameterized by \texttt{\textcolor{blue}{\footnotesize{}S:~ExZ}};
instead we can represent \texttt{\textcolor{blue}{\footnotesize{}FS{[}Z{]}}}
directly by such functions, for example:

\texttt{\textcolor{blue}{\footnotesize{}def wrap{[}S: ExZ{]}(z: Z): S
= implicitly{[}ExZ{[}S{]}{]}.extract(z)}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}def x{[}S: ExZ : Semigroup{]}: S
= wrap(1) |+| wrap(2)}}{\footnotesize\par}

The type of \texttt{\textcolor{blue}{\footnotesize{}x}} is {\footnotesize{}$\forall S.\left(Z\rightarrow S\right)\times\left(S\times S\rightarrow S\right)\rightarrow S$};
an equivalent type is{\footnotesize{}
\[
\forall S.\left(\left(Z+S\times S\right)\rightarrow S\right)\rightarrow S
\]
}{\footnotesize\par}

This is the \textsf{``}\textbf{Church encoding}\textsf{''} (of the free semigroup
over $Z$)

The Church encoding is based on the theorem {\footnotesize{}$A\cong\forall X.\left(A\rightarrow X\right)\rightarrow X$} 

this \emph{resembles} the type of the continuation monad, $\left(A\rightarrow R\right)\rightarrow R$ 

but $\forall X$ makes the function fully generic, like a natural
transformation


\paragraph{Church encoding II: Disjunction types}

Consider the Church encoding for the disjunction type $P+Q$ 

The encoding is {\footnotesize{}$\forall X.\left(P+Q\rightarrow X\right)\rightarrow X\cong\forall X.\left(P\rightarrow X\right)\rightarrow\left(Q\rightarrow X\right)\rightarrow X$}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}trait Disj{[}P, Q{]} \{ def
run{[}X{]}(cp: P $\rightarrow$ X)(cq: Q $\rightarrow$ X): X \}}}{\footnotesize\par}

Define some values of this type:

\texttt{\textcolor{blue}{\footnotesize{}def left{[}P, Q{]}(p: P) =
new Disj{[}P, Q{]} \{}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{} def run{[}X{]}(cp: P $\rightarrow$
X)(cq: Q $\rightarrow$ X): X = cp(p) }}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}\}}}{\footnotesize\par}

Now we can implement the analog of the \texttt{\textcolor{blue}{\footnotesize{}case}}
expression simply as

\texttt{\textcolor{blue}{\footnotesize{}val result = disj.run \{p
$\rightarrow$ ...\} \{q $\rightarrow$ ...\}}}{\footnotesize\par}

This works in programming languages that have no disjunction types

General recipe for implementing the Church encoding: 

\texttt{\textcolor{blue}{\footnotesize{}trait Blah \{ def run{[}X{]}(cont: ... $\rightarrow$
X): X \}}}{\footnotesize\par}

For convenience, define a type class \texttt{\textcolor{blue}{\footnotesize{}Ex}}
describing the inner function:

\texttt{\textcolor{blue}{\footnotesize{}trait Ex{[}X{]} \{ def cp: P
$\rightarrow$ X; def cq: Q $\rightarrow$ X \}}}{\footnotesize\par}

Different methods of this class return \texttt{\textcolor{blue}{\footnotesize{}X}};
convenient with disjunctions

Church-encoded types have to be \textsf{``}run\textsf{''} for pattern matching to
work on the results


\paragraph{Church encoding III: How it works}

Why is the type $\text{Ch}^{A}\triangleq\forall X.\left(A\rightarrow X\right)\rightarrow X$
equivalent to the type $A$?

\texttt{\textcolor{blue}{\footnotesize{}trait Ch{[}A{]} \{ def run{[}X{]}(cont: A
$\rightarrow$ X): X \}}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}}}%
\begin{minipage}[t]{0.65\textwidth}%
\begin{itemize}
\item If we have a value of $A$, we can get a $\text{Ch}^{A}$
\end{itemize}
\begin{lyxcode}
\textcolor{blue}{\footnotesize{}def~a2c{[}A{]}(a:~A):~Ch{[}A{]}~=~new~Ch{[}A{]}~\{~}{\footnotesize\par}

\textcolor{blue}{\footnotesize{}~~def~run{[}X{]}(cont:~A~$\rightarrow$~X):~X~=~cont(a)}{\footnotesize\par}

\textcolor{blue}{\footnotesize{}\}}{\footnotesize\par}
\end{lyxcode}
\begin{itemize}
\item If we have a $\text{ch}:\text{Ch}^{A}$, we can get an $a:A$ 
\end{itemize}
\begin{lyxcode}
\textcolor{blue}{\footnotesize{}def~c2a{[}A{]}(ch:~Ch{[}A{]}):~A~=~ch.run{[}A{]}(a$\rightarrow$a)}{\footnotesize\par}
\end{lyxcode}
%
\end{minipage}\texttt{\textcolor{blue}{\footnotesize{}\hfill{}}}%
\begin{minipage}[t]{0.3\columnwidth}%
{\footnotesize{}
\[
\xymatrix{\xyScaleY{1pc}\xyScaleX{3pc}\text{id}:\left(A\rightarrow A\right)\ar[r]\sp(0.65){\text{ch}.\text{run}^{A}}\ar[d]\sp(0.5){\text{fmap}_{\text{Reader}_{A}}\left(f\right)} & A\ar[d]\sp(0.45){f}\\
f:\left(A\rightarrow X\right)\ar[r]\sb(0.65){\text{ch}.\text{run}^{X}} & X
}
\]
}%
\end{minipage}\texttt{\textcolor{blue}{\footnotesize{}\hfill{}}}{\footnotesize\par}

The functions \texttt{\textcolor{blue}{\footnotesize{}a2c}} and \texttt{\textcolor{blue}{\footnotesize{}c2a}}
are inverses of each other

To implement a value $\text{ch}^{:\text{Ch}^{A}}$, we must compute
an $x^{:X}$ given $f^{:A\rightarrow X}$, for \emph{any} $X$, which
\emph{requires} having a value $a^{:A}$ available

To show that \texttt{\textcolor{blue}{\footnotesize{}ch = a2c(c2a(ch))}},
apply both sides to an \texttt{\textcolor{blue}{\footnotesize{}f:~A$\rightarrow$X}}
and get \texttt{\textcolor{blue}{\footnotesize{}ch.run(f) = a2c(c2a(ch)).run(f)
= f(c2a(ch)) = f(ch.run(a$\rightarrow$a))}} 

This is naturality of \texttt{\textcolor{blue}{\footnotesize{}ch.run}}
as a transformation between \texttt{\textcolor{blue}{\footnotesize{}Reader}}
and \texttt{\textcolor{blue}{\footnotesize{}Id}} 

Naturality of \texttt{\textcolor{blue}{\footnotesize{}ch.run}} follows
from parametricity of its code

It is straightforward to compute \texttt{\textcolor{blue}{\footnotesize{}c2a(a2c(a))
= identity(a) = a}} 

Church encoding satisfies laws: it is built up from parts of \texttt{\textcolor{blue}{\footnotesize{}run}}
method

\paragraph{Worked example III: Free functor I}

The \texttt{\textcolor{blue}{\footnotesize{}Functor}} type class has
one method, \texttt{\textcolor{blue}{\footnotesize{}fmap}}: $\left(Z\rightarrow A\right)\rightarrow F^{Z}\rightarrow F^{A}$ 

The tree encoding of a free functor over $F^{\bullet}$ needs two
case classes:

\texttt{\textcolor{blue}{\footnotesize{}sealed trait FF{[}F{[}\_{]},
A{]}}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}case class Wrap{[}F{[}\_{]},
A{]}(fa: F{[}A{]}) extends FF{[}F, A{]}}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}case class Fmap{[}F{[}\_{]},
A, Z{]}(f: Z => A)(ffz: FF{[}F, Z{]}) extends FF{[}F, A{]}}}{\footnotesize\par}

The constructor \texttt{\textcolor{blue}{\footnotesize{}Fmap}} has
an extra type parameter $Z$, which is \textsf{``}hidden\textsf{''}

Consider a simple example of this:

\texttt{\textcolor{blue}{\footnotesize{}sealed trait Q{[}A{]}; case
class QZ{[}A, Z{]}(a: A, z: Z) extends Q{[}A{]}}}{\footnotesize\par}

Need to use specific type $Z$ when constructing a value of \texttt{\textcolor{blue}{\footnotesize{}Q{[}A{]}}},
e.g.,

\texttt{\textcolor{blue}{\footnotesize{}val q: Q{[}Int{]} = QZ{[}Int,
String{]}(123, \textquotedbl abc\textquotedbl )}}{\footnotesize\par}

The type $Z$ is hidden inside $q:Q^{\text{Int}}$; all we know is
that $Z$ \textsf{``}exists\textsf{''}

Type notation for this: $Q^{A}\triangleq\exists Z.A\times Z$

The existential quantifier applies to the \textsf{``}hidden\textsf{''} type parameter

The constructor \texttt{\textcolor{blue}{\footnotesize{}QZ}} has type
$\exists Z.\left(A\times Z\rightarrow Q^{A}\right)$

It is not $\forall Z$ because a specific $Z$ is used when building
up a value

The code does not show $\exists Z$ explicitly! We need to keep track
of that


\paragraph{Encoding with an existential type: How it works}

Show that $P^{A}\triangleq\exists Z.Z\times\left(Z\rightarrow A\right)\cong A$

\texttt{\textcolor{blue}{\footnotesize{}sealed trait P{[}A{]}; case
class PZ{[}A, Z{]}(z: Z, f: Z $\rightarrow$ A) extends P{[}A{]}}}{\footnotesize\par}

How to construct a value of type $P^{A}$ for a given $A$?

Have a function $Z\rightarrow A$ and a $Z$, construct $Z\times\left(Z\rightarrow A\right)$

Particular case: $Z\triangleq A$, have $a:A$ and build $a\times\text{id}^{:A\rightarrow A}$

\texttt{\textcolor{blue}{\footnotesize{}def a2p{[}A{]}(a: A): P{[}A{]}
= PZ{[}A, A{]}(a, identity)}}{\footnotesize\par}

Cannot extract $Z$ out of $P^{A}$ \textendash{} the type $Z$ is
hidden

\emph{Can} extract $A$ out of $P^{A}$ \textendash{} do not need
to know $Z$

\texttt{\textcolor{blue}{\footnotesize{}def p2a{[}A{]}: P{[}A{]} $\rightarrow$
A = \{ case PZ(z, f) $\rightarrow$ f(z) \}}}{\footnotesize\par}

Cannot transform $P^{A}$ into anything else other than $A$

A value of type $P^{A}$ is observable only via \texttt{\textcolor{blue}{\footnotesize{}p2a}} 

Therefore the functions \texttt{\textcolor{blue}{\footnotesize{}a2p}}
and \texttt{\textcolor{blue}{\footnotesize{}p2a}} are \textsf{``}observational\textsf{''}
inverses (i.e.~we need to use \texttt{\textcolor{blue}{\footnotesize{}p2a}}
in order to compare values of type $P^{A}$)

If $F^{\bullet}$ is a functor then $Q^{A}\triangleq\exists Z.F^{Z}\times\left(Z\rightarrow A\right)\cong F^{A}$

A value of $Q^{A}$ can be observed only by extracting an $F^{A}$
from it

Can define \texttt{\textcolor{blue}{\footnotesize{}f2q}} and \texttt{\textcolor{blue}{\footnotesize{}q2f}}
and show that they are observational inverses


\paragraph{Worked example III: Free functor II}

Tree encoding of \texttt{\textcolor{blue}{\footnotesize{}FF}} has
type $\text{FF}^{F^{\bullet},A}\triangleq F^{A}+\exists Z.\text{FF}^{F^{\bullet},Z}\times\left(Z\rightarrow A\right)$

Derivation of the reduced encoding:

A value of type $\text{FF}^{F^{\bullet},A}$ must be of the form {\footnotesize{}
\[
\exists Z_{1}.\exists Z_{2}...\exists Z_{n}.F^{Z_{n}}\times\left(Z_{n}\rightarrow Z_{n-1}\right)\times...\times\left(Z_{2}\rightarrow Z_{1}\right)\times\left(Z_{1}\rightarrow A\right)
\]
}{\footnotesize\par}

The functions $Z_{1}\rightarrow A$, $Z_{2}\rightarrow Z_{1}$, etc.,
must be composed associatively

The equivalent type is $\exists Z_{n}.F^{Z_{n}}\times\left(Z_{n}\rightarrow A\right)$

Reduced encoding: $\text{FreeF}^{F^{\bullet},A}\triangleq\exists Z.F^{Z}\times\left(Z\rightarrow A\right)$

Substituted $F^{Z}$ instead of $\text{FreeF}^{F^{\bullet},Z}$ and
eliminated the case $F^{A}$

The reduced encoding is non-recursive

Requires a proof that this encoding is equivalent to the tree encoding

If $F^{\bullet}$ is already a functor, can show $F^{A}\cong\exists Z.F^{Z}\times\left(Z\rightarrow A\right)$

Church encoding (starting from the tree encoding): $\text{FreeF}^{F^{\bullet},A}\triangleq\forall P^{\bullet}.\left(\forall C.\big(F^{C}+\exists Z.P^{Z}\times\left(Z\rightarrow C\right)\big)\leadsto P^{C}\right)\rightarrow P^{A}$

The structure of the type expression: $\forall P^{\bullet}.\left(\forall C.(...)^{C}\leadsto P^{C}\right)\rightarrow P^{A}$

Cannot move $\forall C$ or $\exists Z$ to the outside of the type
expression!


\paragraph{Church encoding IV: Recursive types and type constructors}

Consider the recursive type {\footnotesize{}$P\triangleq Z+P\times P$}
(tree with $Z$-valued leaves)

The Church encoding is {\footnotesize{}$\forall X.\left(\left(Z+X\times X\right)\rightarrow X\right)\rightarrow X$}{\footnotesize\par}

This is \emph{non-recursive}: the inductive use of $P$ is replaced
by $X$

Generalize to recursive type $P\triangleq S^{P}$ where $S^{\bullet}$
is a \textsf{``}induction functor\textsf{''}:

The Church encoding of $P$ is {\footnotesize{}$\forall X.\left(S^{X}\rightarrow X\right)\rightarrow X$}{\footnotesize\par}

Church encoding of recursive types is non-recursive

Example: Church encoding of \texttt{\textcolor{blue}{\footnotesize{}List{[}Int{]}}} 

Church encoding of a type constructor $P^{\bullet}$:

Notation: $P^{\bullet}$ is a type function; Scala syntax is \texttt{\textcolor{blue}{\footnotesize{}P{[}\_{]}}} 

The Church encoding is {\footnotesize{}$\text{Ch}^{P^{\bullet},A}=\forall F^{\bullet}.\left(\forall X.P^{X}\rightarrow F^{X}\right)\rightarrow F^{A}$}{\footnotesize\par}

Note: $\forall X.P^{X}\rightarrow F^{X}$ or $P^{\bullet}\leadsto F^{\bullet}$
resembles a natural transformation

Except that $P^{\bullet}$ and $F^{\bullet}$ are not necessarily
functors, so no naturality law

Example: Church encoding of \texttt{\textcolor{blue}{\footnotesize{}Option{[}\_{]}}} 

Church encoding of a \emph{recursively} defined type constructor $P^{\bullet}$:

Definition: $P^{A}\triangleq S^{P^{\bullet},A}$ where $S^{P^{\bullet},A}$
describes the \textsf{``}induction principle\textsf{''}

Notation: {\footnotesize{}$S^{\bullet^{\bullet},A}$} is a higher-order
type function; Scala syntax: \texttt{\textcolor{blue}{\footnotesize{}S{[}\_{[}\_{]},A{]}}} 

Example: $\text{List}^{A}\triangleq1+A\times\text{List}^{A}\triangleq S^{\text{List}^{\bullet},A}$
where $S^{P^{\bullet},A}\triangleq1+A\times P^{A}$ 

The Church encoding of $P^{A}$ is {\footnotesize{}$\text{Ch}^{P^{\bullet},A}=\forall F^{\bullet}.\big(S^{F^{\bullet}}\leadsto F^{\bullet}\big)\rightarrow F^{A}$}{\footnotesize\par}

The Church encoding of \texttt{\textcolor{blue}{\footnotesize{}List{[}\_{]}}}
is non-recursive

\paragraph{Details: Why Church encoding of a free semigroup is a semigroup}

- it\textsf{'}s not obvious

FS = forall S. (Z => S) \texttimes{} (S \texttimes{} S => S) => S
is a semigroup.  We need to define the binary operation |+| on values
of type FS. A value f of type FS is a function with a type parameter,
that we can use as f{[}S{]}(e, c) to compute a value of any given
type S from arguments e : Z => S and c: S \texttimes{} S => S. Scala
code for f will be

def f{[}S{]}(empty: Z => S, combine: (S, S) => S): S = ???

So, given f and g of this type, we need to somehow define a new function
h = f |+| g also of the same type. Begin to write code for that function:

def h{[}S{]}(empty: Z => S, combine: (S, S) => S): S = ???

The free semigroup in the tree encoding defines the binary operation
as a formal operation that does not compute anything. In the Church
encoding, however, we have the binary operation as the argument \textquotedbl combine\textquotedbl{}
of h, and so we should call that function. So, we use it:

def h{[}S{]}(empty: Z => S, combine: (S, S) => S): S = combine(???,
???)

We need to fill the typed holes ??? of type S. It is clear that we
should use f and g somehow. We can use f and g simply by calling those
functions on the arguments `empty` and `combine`. Since f and g both
have a universally quantified type parameter, we can just use the
given type S for them.

def h{[}S{]}(empty: Z => S, combine: (S, S) => S): S = combine(f{[}S{]}(empty,
combine), g{[}S{]}(empty, combine))

The types match, and we have used both functions f and g in a way
that is intuitively correct. We have preserved information. So, this
is likely the correct implementation. It remains to verify the associativity
law. To do that, we need to assume that `combine` is associative for
the actual type $S$ on which we use the Church encoding (i.e. a non-free,
lawful semigroup)

To show equivalence between FSZ and Chz, write code for the type ChZ
and the two directions of the isomorphism,
\begin{lstlisting}
trait FSCh[Z] { def run[S](empty: Z => S, combine: (S, S) => S): S }
def fsz2ch[Z](fsz: NEList[Z]): FSCh[Z] = ???
def ch2fsz[Z](ch: FSCh[Z]): NEList[Z] = ???
\end{lstlisting}


\paragraph{Church encoding V: Type classes}

Look at the Church encoding of the free semigroup:{\footnotesize{}
\[
\text{ChFS}^{Z}\triangleq\forall X.\left(Z\rightarrow X\right)\times\left(X\times X\rightarrow X\right)\rightarrow X
\]
}{\footnotesize\par}

If $X$ is constrained to the \texttt{\textcolor{blue}{\footnotesize{}Semigroup}}
typeclass, we will already have a value {\footnotesize{}$X\times X\rightarrow X$},
so we can omit it: {\footnotesize{}$\text{ChFS}^{Z}=\forall X^{:\text{Semigroup}}.\left(Z\rightarrow X\right)\rightarrow X$}{\footnotesize\par}

The \textsf{``}induction functor\textsf{''} for \textsf{``}semigroup over $Z$\textsf{''} is {\footnotesize{}$\text{SemiG}^{X}\triangleq Z+X\times X$}{\footnotesize\par}

So, the Church encoding is $\forall X.\big(\text{SemiG}^{X}\rightarrow X\big)\rightarrow X$

Generalize to arbitrary type classes:

Type class $C$ is defined by its operations{\footnotesize{} $C^{X}\rightarrow X$}
(with a suitable $C^{\bullet}$)

call $C^{\bullet}$ the \textbf{structure functor} of the $P$-typeclass
$C$

Tree encoding of \textsf{``}free $C$ over $Z$\textsf{''} is recursive, $\text{FreeC}^{Z}\triangleq Z+C^{\text{FreeC}^{Z}}$

Church encoding is $\text{FreeC}^{Z}\triangleq\forall X.\left(Z+C^{X}\rightarrow X\right)\rightarrow X$

Equivalently, $\text{FreeC}^{Z}\triangleq\forall X^{:C}.\left(Z\rightarrow X\right)\rightarrow X$

Laws of the typeclass are satisfied automatically after \textsf{``}running\textsf{''}

Works similarly for type constructors: operations $C^{P^{\bullet},A}\rightarrow P^{A}$

Free typeclass $C$ over $F^{\bullet}$ is $\text{FreeC}^{F^{\bullet},A}\triangleq\forall P^{\bullet:C}.\left(F^{\bullet}\leadsto P^{\bullet}\right)\rightarrow P^{A}$

\paragraph{Properties of free type constructions}

Generalizing from our examples so far:

We \textsf{``}enriched\textsf{''} $Z$ to a monoid $\text{FM}^{Z}$, and $F^{A}$
to a monad $\text{DSL}^{F,A}$ 

The \textsf{``}enrichment\textsf{''} adds case classes representing the needed operations

Works for a generating type $Z$ and for a generating type constructor
$F^{A}$

Obtain a \textbf{free type construction}, which performs no computations

$\text{FM}^{Z}$ wraps $Z$ in \textsf{``}just enough\textsf{''} stuff to make it
look like a monoid

$\text{FreeF}^{F^{\bullet},A}$ wraps $F^{A}$ in \textsf{``}just enough\textsf{''}
stuff to make it look like a functor

A value of a free construction can be \textsf{``}run\textsf{''} to yield non-free
values 

Questions:

Can we construct a free typeclass $C$ over any type constructor $F^{A}$?

Yes, with typeclasses: (contra)functor, filterable, monad, applicative

Which of the possible encodings to use?

Tree encoding, reduced encodings, Church encoding

What are the laws for the{\footnotesize{} $\text{FreeC}^{F,A}$} \textendash{}
\textsf{``}free instance of $C$ over $F$\textsf{''}?

For all $F^{\bullet}$, must have \texttt{\textcolor{blue}{\footnotesize{}wrap{[}A{]}}}
$:F^{A}\rightarrow\text{FreeC}^{F,A}$ or $F^{\bullet}\leadsto\text{FreeC}^{F,\bullet}$

For all $M^{\bullet}:C$, must have \texttt{\textcolor{blue}{\footnotesize{}run}}
$:\left(F^{\bullet}\leadsto M^{\bullet}\right)\rightarrow\text{FreeC}^{F,\bullet}\leadsto M^{\bullet}$

The laws of typeclass $C$ must hold after interpreting into an $M^{\bullet}:C$

Given any \texttt{\textcolor{blue}{\footnotesize{}t}}$:F^{\bullet}\leadsto G^{\bullet}$,
must have \texttt{\textcolor{blue}{\footnotesize{}fmap(t)}}$:\text{FreeC}^{F,\bullet}\leadsto\text{FreeC}^{G,\bullet}$


\paragraph{Recipes for encoding free typeclass instances}

Build a free instance of typeclass $C$ over $F^{\bullet}$, as a
type constructor $P^{\bullet}$ 

The typeclass $C$ can be functor, contrafunctor, monad, etc.

Assume that $C$ has methods $m_{1}$, $m_{2}$, ..., with type signatures
{\footnotesize{}$m_{1}:Q_{1}^{P^{\bullet},A}\rightarrow P^{A}$},
{\footnotesize{}$m_{2}:Q_{2}^{P^{\bullet},A}\rightarrow P^{A}$},
etc., where $Q_{i}^{P^{\bullet},A}$ are covariant in $P^{\bullet}$ 

\textbf{Inductive typeclass} is defined via a methods functor, $S^{P^{\bullet}}\leadsto P^{\bullet}$

The tree encoded $\text{FC}^{A}$ is a disjunction defined recursively
by{\footnotesize{}
\[
\text{FC}^{A}\triangleq F^{A}+Q_{1}^{\text{FC}^{\bullet},A}+Q_{2}^{\text{FC}^{\bullet},A}+...
\]
}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}sealed trait FC{[}A{]}; case
class Wrap{[}A{]}(fa: F{[}A{]}) extends FC{[}A{]}}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}case class Q1{[}A{]}(...)
extends FC{[}A{]}}}{\footnotesize\par}

\texttt{\textcolor{blue}{\footnotesize{}case class Q2{[}A{]}(...)
extends FC{[}A{]}; ...}}{\footnotesize\par}

Any type parameters within $Q_{i}$ are then existentially quantified

\texttt{\textcolor{blue}{\footnotesize{}run()}} maps $F^{\bullet}\leadsto M^{\bullet}$
in the disjunction and recursively for other parts

Derive a reduced encoding via reasoning about possible values of $\text{FC}^{A}$
and by taking into account the laws of the typeclass $C$

A Church encoding can use the tree encoding or the reduced encoding

Church encoding is \textsf{``}automatically reduced\textsf{''}, but performance may
differ


\paragraph{Properties of inductive typeclasses}

If a typeclass $C$ is inductive with methods $C^{X}\rightarrow X$
then:

A free instance of $C$ over $Z$ can be tree-encoded as {\footnotesize{}$\text{FreeC}^{Z}\triangleq Z+C^{\text{FreeC}^{Z}}$} 

All inductive typeclasses have free instances, $\text{FreeC}^{Z}$

If $P^{:C}$ and $Q^{:C}$ then $P\times Q$ and $Z\rightarrow P$
also belong to typeclass $C$

but not necessarily $P+Q$ or $Z\times P$

Proof: can implement $(C^{P}\rightarrow P)\times(C^{Q}\rightarrow Q)\rightarrow C^{P\times Q}\rightarrow P\times Q$
and $\left(C^{P}\rightarrow P\right)\rightarrow C^{Z\rightarrow P}\rightarrow Z\rightarrow P$,
but cannot implement $\left(...\right)\rightarrow P+Q$

Analogous properties hold for type constructor typeclasses

Methods described as $C^{F^{\bullet},A}\rightarrow F^{A}$ with type
constructor parameter $F^{\bullet}$

What typeclasses \emph{cannot} be tree-encoded (or have no \textsf{``}free\textsf{''}
instances)?

Any typeclass with a method \emph{not ultimately returning} a value
of $P^{A}$

Example: a typeclass with methods $\text{pt}:A\rightarrow P^{A}$
and $\text{ex}:P^{A}\rightarrow A$

Such typeclasses are not inductive nor co-inductive

Typeclasses with methods of the form $P^{A}\rightarrow...$ are \textbf{co-inductive}


\paragraph{Worked example V: Free pointed functor}

Over an arbitrary type constructor $F^{\bullet}$:

Pointed functor methods {\footnotesize{}$\text{pt}:A\rightarrow P^{A}$}
and {\footnotesize{}$\text{map}:P^{A}\times\left(A\rightarrow B\right)\rightarrow P^{B}$}{\footnotesize\par}

Tree encoding: {\footnotesize{}$\text{FreeP}^{F^{\bullet},A}\triangleq A+F^{A}+\exists Z.\text{FreeP}^{F^{\bullet},Z}\times\left(Z\rightarrow A\right)$}{\footnotesize\par}

Derivation of the reduced encoding:

The tree encoding of a value $\text{FreeP}^{F^{\bullet},A}$ is either{\footnotesize{}
\[
\exists Z_{1}.\exists Z_{2}...\exists Z_{n}.F^{Z_{n}}\times\left(Z_{n}\rightarrow Z_{n-1}\right)\times...\times\left(Z_{2}\rightarrow Z_{1}\right)\times\left(Z_{1}\rightarrow A\right)
\]
}or{\footnotesize{}
\[
\exists Z_{1}.\exists Z_{2}...\exists Z_{n}.Z_{n}\times\left(Z_{n}\rightarrow Z_{n-1}\right)\times...\times\left(Z_{2}\rightarrow Z_{1}\right)\times\left(Z_{1}\rightarrow A\right)
\]
}{\footnotesize\par}

Compose all functions by associativity; one function $Z_{n}\rightarrow A$
remains

The case $\exists Z_{n}.Z_{n}\times\left(Z_{n}\rightarrow A\right)$
is equivalent to just $A$

Reduced encoding: {\footnotesize{}$\text{FreeP}^{F^{\bullet},A}\triangleq A+\exists Z.F^{Z}\times\left(Z\rightarrow A\right)$,
}non-recursive

This reuses the free functor as $\text{FreeP}^{F^{\bullet},A}=A+\text{FreeF}^{F^{\bullet},A}$

If the type constructor $F^{\bullet}$ is \emph{already} a functor,
$\text{FreeF}^{F^{\bullet},A}\cong F^{A}$ and so:

Free pointed functor over a functor $F^{\bullet}$ is simplified:
$A+F^{A}$

If $F^{\bullet}$ is already a pointed functor, need not use the free
construction

If we do, we will have $\text{FreeP}^{F^{\bullet},A}\not\cong F^{A}$ 

only functors and contrafunctors do not change under \textsf{``}free\textsf{''}


\paragraph{Worked example VI: Free filterable functor}

(See Chapter 6.) Methods:
\begin{align*}
\text{map} & :F^{A}\rightarrow\left(A\rightarrow B\right)\rightarrow F^{B}\\
\text{mapOpt} & :F^{A}\rightarrow\left(A\rightarrow1+B\right)\rightarrow F^{B}
\end{align*}

We can recover \texttt{\textcolor{blue}{\footnotesize{}map}} from
\texttt{\textcolor{blue}{\footnotesize{}mapOpt}}, so we keep only
\texttt{\textcolor{blue}{\footnotesize{}mapOpt}} 

Tree encoding: $\text{FreeFi}^{F^{\bullet},A}\triangleq F^{A}+\exists Z.\text{FreeFi}^{F^{\bullet},Z}\times\left(Z\rightarrow1+A\right)$

If $F^{\bullet}$ is already a functor, can simplify the tree encoding
using the identity $\exists Z.P^{Z}\times\left(Z\rightarrow1+A\right)\cong P^{A}$
and obtain $\text{FreeFi}^{F^{\bullet},A}\triangleq F^{A}+\text{FreeFi}^{F^{\bullet},1+A}$,
which is equivalent to $\text{FreeFi}^{F^{\bullet},A}=F^{A}+F^{1+A}+F^{1+1+A}+...$

Reduced encoding: $\text{FreeFi}^{F^{\bullet},A}\triangleq\exists Z.F^{Z}\times\left(Z\rightarrow1+A\right)$,
non-recursive

Derivation: $\exists Z_{1}...\exists Z_{n}.F^{Z_{n}}\times\left(Z_{n}\rightarrow1+Z_{n-1}\right)\times...\times\left(Z_{1}\rightarrow1+A\right)$
is simplified using the laws of \texttt{\textcolor{blue}{\footnotesize{}mapOpt}}
and Kleisli composition, and yields $\exists Z_{n}.F^{Z_{n}}\times\left(Z_{n}\rightarrow1+A\right)$.
Encode $F^{A}$ as $\exists Z.F^{Z}\times\left(Z\rightarrow0+Z\right)$.

If $F^{\bullet}$ is already a functor, the reduced encoding is $\text{FreeFi}^{F^{\bullet},A}=F^{1+A}$

Free filterable over a filterable functor $F^{\bullet}$ is not equivalent
to $F^{\bullet}$

Free filterable contrafunctor is constructed in a similar way


\paragraph{Worked example VII: Free monad}


\paragraph{Worked example VIII: Free applicative functor}

Methods:
\begin{align*}
\text{pure} & :A\rightarrow F^{A}\\
\text{ap} & :F^{A}\rightarrow F^{A\rightarrow B}\rightarrow F^{B}
\end{align*}

We can recover \texttt{\textcolor{blue}{\footnotesize{}map}} from
\texttt{\textcolor{blue}{\footnotesize{}ap}} and \texttt{\textcolor{blue}{\footnotesize{}pure}},
so we omit \texttt{\textcolor{blue}{\footnotesize{}map}} 

Tree encoding: {\footnotesize{}$\text{FreeAp}^{F^{\bullet},A}\triangleq F^{A}+A+\exists Z.\text{FreeAp}^{F^{\bullet},Z}\times\text{FreeAp}^{F^{\bullet},Z\rightarrow A}$}{\footnotesize\par}

Reduced encoding:{\footnotesize{} $\text{FreeAp}^{F^{\bullet},A}\triangleq A+\exists Z.F^{Z}\times\text{FreeAp}^{F^{\bullet},Z\rightarrow A}$}{\footnotesize\par}

Derivation: a $\text{FreeAp}^{A}$ is either $\exists Z_{1}...\exists Z_{n}.Z_{1}\times\text{FreeAp}^{Z_{1}\rightarrow Z_{2}}\times...$
or $\exists Z_{1}...\exists Z_{n}.F^{Z_{1}}\times\text{FreeAp}^{Z_{1}\rightarrow Z_{2}}\times...$;
encode $Z_{1}\times\text{FreeAp}^{Z_{1}\rightarrow Z_{2}}$ equivalently
as $\text{FreeAp}^{Z_{1}\rightarrow Z_{2}}\times\left(\left(Z_{1}\rightarrow Z_{2}\right)\rightarrow Z_{2}\right)$
using the identity law; so the first $\text{FreeAp}^{Z}$ is always
$F^{A}$, or we have a pure value 

Free applicative over a functor $F^{\bullet}$: 
\begin{align*}
\text{FreeAp}^{F^{\bullet},A} & \triangleq A+\text{FreeZ}^{F^{\bullet},A}\\
\text{FreeZ}^{F^{\bullet},A} & \triangleq F^{A}+\exists Z.F^{Z}\times\text{FreeZ}^{F^{\bullet},Z\rightarrow A}
\end{align*}

$\text{FreeZ}^{F^{\bullet},\bullet}$ is the reduced encoding of \textsf{``}free
zippable\textsf{''} (no \texttt{\textcolor{blue}{\footnotesize{}pure}})

$\text{FreeAp}^{F^{\bullet},\bullet}$ over an applicative functor
$F^{\bullet}$ is not equivalent to $F^{\bullet}$


\paragraph{Laws for free typeclass constructions}

Consider an inductive typeclass $C$ with methods $C^{A}\rightarrow A$

Define a free instance of $C$ over $Z$ recursively, {\footnotesize{}$\text{FreeC}^{Z}\triangleq Z+C^{\text{FreeC}^{Z}}$}{\footnotesize\par}

$\text{FreeC}^{Z}$ has an instance of $C$, i.e.~we can implement
$C^{\text{FreeC}^{Z}}\rightarrow\text{FreeC}^{Z}$

$\text{FreeC}^{Z}$ is a functor in $Z$; {\footnotesize{}$\text{fmap}_{\text{FreeC}}:\left(Y\rightarrow Z\right)\rightarrow\text{FreeC}^{Y}\rightarrow\text{FreeC}^{Z}$}{\footnotesize\par}

{\footnotesize{}\vspace{-0.45cm}}%
\begin{minipage}[t]{0.64\columnwidth}%
\begin{itemize}
\item For a $P^{:C}$ we can implement the functions {\footnotesize{}
\begin{align*}
\text{run}^{P} & :\left(Z\rightarrow P\right)\rightarrow\text{FreeC}^{Z}\rightarrow P\\
\text{wrap} & :Z\rightarrow\text{FreeC}^{Z}
\end{align*}
}
\end{itemize}
%
\end{minipage}{\footnotesize{}}%
\begin{minipage}[t]{0.36\columnwidth}%
{\footnotesize{}}{\footnotesize{}
\[
\xymatrix{\xyScaleY{1.5pc}\xyScaleX{5pc}\text{FreeC}^{Y}\ar[d]\sb(0.45){\text{fmap}\,f^{:Y\rightarrow Z}}\ar[rd]\sp(0.65){\ \text{run}\left(f\bef g\right)}\\
\text{FreeC}^{Z}\ar[r]\sp(0.5){\text{run}(g^{:Z\rightarrow P})} & P
}
\]
}%
\end{minipage}\hfill{}

Law 1: {\footnotesize{}$\text{run}\left(\text{wrap}\right)=\text{id}$};
law 2: {\footnotesize{}$\text{fmap}\,f\bef\text{run}\,g=\text{run}\left(f\bef g\right)$}
(naturality of \texttt{\textcolor{blue}{\footnotesize{}run}})

For any $P^{:C},Q^{:C},g^{:Z\rightarrow P}$, and a typeclass-preserving
$f^{:P\rightarrow Q}$, we have{\footnotesize{}
\[
\text{run}^{P}(g)\bef f=\text{run}^{Q}\left(g\bef f\right)\quad\quad\text{\textendash\ \textquotedblleft universal property\textquotedblright\ of }\text{run}
\]
}{\footnotesize{}
\[
\xymatrix{\xyScaleY{2.0pc}\xyScaleX{3pc}\text{FreeC}^{Z}\ar[d]\sb(0.4){\text{run}^{P}(g^{:Z\rightarrow P})}\ar[rd]\sp(0.55){\quad\text{run}^{Q}(g\bef f)} &  &  & C^{P}\ar[d]\sb(0.4){\text{fmap}_{S}f}\ar[r]\sp(0.5){\text{ops}_{P}} & P\ar[d]\sb(0.4){f}\\
P\ar[r]\sp(0.5){f^{:P\rightarrow Q}} & Q &  & C^{Q}\ar[r]\sp(0.5){\text{ops}_{Q}} & Q
}
\]
}{\footnotesize\par}

$f^{:P\rightarrow Q}$ \textbf{preserves typeclass} $C$ if the diagram
on the right commutes


\paragraph{Combining the generating constructors in a free typeclass}

Consider $\text{FreeC}^{Z}$ for an inductive typeclass $C$ with
methods $C^{X}\rightarrow X$

We would like to combine generating constructors $Z_{1}$, $Z_{2}$,
etc.

In a monadic DSL \textendash{} combine different operations defined
separately

Note: monads do not compose in general

To combine generators, use $\text{FreeC}^{Z_{1}+Z_{2}}$; an \textsf{``}instance
over $Z_{1}$ and $Z_{2}$\textsf{''}

but need to inject parts into disjunction, which is cumbersome

Church encoding makes this easier to manage:

{\footnotesize{}$\text{FreeC}^{Z}\triangleq\forall X.\left(Z\rightarrow X\right)\times\big(C^{X}\rightarrow X\big)\rightarrow X$}
and then {\footnotesize{}
\[
\text{FreeC}^{Z_{1}+Z_{2}}\triangleq\forall X.\left(Z_{1}\rightarrow X\right)\times\left(Z_{2}\rightarrow X\right)\times\big(C^{X}\rightarrow X\big)\rightarrow X
\]
}{\footnotesize\par}

Encode the functions $Z_{i}\rightarrow X$ via typeclasses \texttt{\textcolor{blue}{\footnotesize{}ExZ1}},
\texttt{\textcolor{blue}{\footnotesize{}ExZ2}}, etc., where typeclass
\texttt{\textcolor{blue}{\footnotesize{}ExZ1}} has method $Z_{1}\rightarrow X$,
etc.

Then {\footnotesize{}
\[
\text{FreeC}^{Z_{1}+Z_{2}}=\forall X^{:E_{Z_{1}}:E_{Z_{2}}}.\big(C^{X}\rightarrow X\big)\rightarrow X
\]
}or equivalently{\footnotesize{}
\[
\text{FreeC}^{Z_{1}+Z_{2}}=\forall X^{:C~:E_{Z_{1}}:E_{Z_{2}}}.X
\]
}{\footnotesize\par}

The code is easier to maintain

This works for all typeclasses $C$ and any number of generators $Z_{i}$

\paragraph{Combining different free typeclasses}

To combine free instances of different typeclasses $C_{1}$ and $C_{2}$:

Option 1: use functor composition, $\text{FreeC}_{12}^{Z}\triangleq\text{FreeC}_{1}^{\text{FreeC}_{2}^{Z}}$

Order of composition matters!

Operations of $C_{2}$ need to be lifted into $C_{1}$

Works only for inductive typeclasses

Encodes $C_{1}^{C_{2}}$ but not $C_{2}^{C_{1}}$

Option 2: use disjunction of method functors, $C^{X}\triangleq C_{1}^{X}+C_{2}^{X}$,
and build the free typeclass instance using $C^{X}$

Church encoding: $\text{FreeC}_{12}^{Z}\triangleq\forall X.\left(Z\rightarrow X\right)\times\big(C_{1}^{X}+C_{2}^{X}\rightarrow X\big)\rightarrow X$

Example 1: $C_{1}$ is functor, $C_{2}$ is contrafunctor

Interpret a free functor/contrafunctor into a profunctor

Example 2: $C_{1}$ is monad, $C_{2}$ is applicative functor

Interpret into a monad that has a non-standard \texttt{\textcolor{blue}{\footnotesize{}zip}}
implementation

Example: interpret into \texttt{\textcolor{blue}{\footnotesize{}Future}}
and convert \texttt{\textcolor{blue}{\footnotesize{}zip}} into parallel
execution

Each \texttt{\textcolor{blue}{\footnotesize{}zip}} creates parallel
branch, each \texttt{\textcolor{blue}{\footnotesize{}flatMap}} creates
sequential chain


\subsection{Exercises}

\subsubsection{Exercise \label{subsec:Exercise-free-monad-example}\ref{subsec:Exercise-free-monad-example}\index{exercises}}

The \textbf{interactive input-output}\index{monads!interactive input-output monad}
monad is defined recursively by:
\begin{lstlisting}
sealed trait TIO[A]
final case class Pure[A](a: A) extends TIO[A]
final case class Read[A](read: P => TIO[A]) extends TIO[A]
final case class Write[A](output: Q, next: TIO[A]) extends TIO[A]
\end{lstlisting}
In the type notation, this is written as:
\[
\text{TIO}^{A}\triangleq A+(P\rightarrow\text{TIO}^{A})+Q\times\text{TIO}^{A}\quad,
\]
Here $P$ and $Q$ are fixed types. The monad \lstinline!TIO! represents
computations that may consume an input value of type $P$ or produce
an output value of type $Q$. Use the free monad construction to show
that \lstinline!TIO! is a lawful monad. Implement a monad instance
for \lstinline!TIO!.

\subsubsection{Exercise \label{subsec:Exercise-free-type-1}\ref{subsec:Exercise-free-type-1}}

Implement a free semigroup on a type $Z$ in the tree encoding and
in the reduced encoding. Show that the semigroup laws hold for the
reduced encoding but \emph{not} for the tree encoding. Show that the
laws hold for the tree encoding after interpreting into a lawful semigroup
$S$.

\subsubsection{Exercise \label{subsec:Exercise-free-type-2}\ref{subsec:Exercise-free-type-2}}

For a fixed monoid $L$, define a typeclass $\text{Mod}_{L}$ (called
\textsf{``}$L$-module\textsf{''}). Type $P$ is an $L$-module if the monoid $L$
\textsf{``}acts\textsf{''} on $P$ via a function act$:L\rightarrow P\rightarrow P$,
with laws $\text{act}\,x\bef\text{act}\,y=\text{act}\left(x\bef y\right)$
and $\text{act}\left(e_{L}\right)=\text{id}$. - Monoid morphism between
$L$ and $\text{MF}^{P}$. Show that $\text{Mod}_{L}$ is a $P$-typeclass.
Implement a free $L$-module on a type $Z$. 

\subsubsection{Exercise \label{subsec:Exercise-free-type-3}\ref{subsec:Exercise-free-type-3}}

\textbf{(a)} Implement a monadic DSL with operations \lstinline!put: A => Unit!
and \lstinline!get: Unit => A!. These operations should store and
retrieve a state value of type \lstinline!A!. Test on some example
programs written in that DSL. 

\textbf{(b)} Implement a monadic DSL with operations \lstinline!put: A => Unit!,
\lstinline!get: Unit => Option[A]!, and \lstinline!clear: Unit => Unit!.
These operations should store and retrieve a state value of type \lstinline!A!.
Running \lstinline!clear! should delete the state value. When there
is no state value, \lstinline!get! should return \lstinline!None!.
Test on some example programs.

\subsubsection{Exercise \label{subsec:Exercise-free-type-4}\ref{subsec:Exercise-free-type-4}}

Implement the Church encoding of the type constructor $P^{A}\triangleq\text{Int}+A\times A$.
For the resulting type constructor, implement a \lstinline!Functor!
instance.

\subsubsection{Exercise \label{subsec:Exercise-free-type-5}\ref{subsec:Exercise-free-type-5}}

Describe the monoid type class via a method functor $C^{\bullet}$
(such that the monoid\textsf{'}s operations are combined into the type $S^{M}\rightarrow M$).
Using $S^{\bullet}$, implement the free monoid on a type $Z$ in
the Church encoding.

\subsubsection{Exercise \label{subsec:Exercise-free-type-6}\ref{subsec:Exercise-free-type-6}}

Assuming that $F^{\bullet}$ is a functor, define $Q^{A}\triangleq\exists Z.F^{Z}\times\left(Z\rightarrow A\right)$
and implement \lstinline!f2q!$:F^{A}\rightarrow Q^{A}$ and \lstinline!q2f!$:Q^{A}\rightarrow F^{A}$.
Show that these functions are natural transformations, and that they
are inverses of each other \textsf{``}observationally\textsf{''}, i.e., after applying
\lstinline!q2f! in order to compare values of $Q^{A}$.

\subsubsection{Exercise \label{subsec:Exercise-free-type-7}\ref{subsec:Exercise-free-type-7}}

Prove the following type equivalences involving quantified types:

\textbf{(a)} $\forall A.\,A\times A\cong\bbnum 0\quad.$

\textbf{(b)} $\forall A.\,\left(A\times A\times A\rightarrow A\right)\cong\bbnum 1+\bbnum 1+\bbnum 1\quad.$

\textbf{(c)} $\exists Z.\,Z\cong\bbnum 1\quad.$

\textbf{(d)} $\exists Z.\,Z\times\left(A\rightarrow Z\right)\times\left(Z\rightarrow B\right)\cong B\times\left(A\rightarrow B\right)\quad.$

\subsubsection{Exercise \label{subsec:Exercise-free-type-9-1}\ref{subsec:Exercise-free-type-9-1}}

Prove the following type equivalences involving quantified type constructors.
The types $A$, $B$, $C$, $D$ are fixed, and the quantifier $\forall F^{\bullet}$
assumes that $F$ is a (covariant) functor and that all functions
are fully parametric.

\textbf{(a)} $\forall F^{\bullet}.\,F^{A}\cong\bbnum 0\quad.$

\textbf{(b)} $\forall F^{\bullet}.\,F^{A}\rightarrow B\cong B\quad.$

\textbf{(c)} $\forall F^{\bullet}.\,F^{A}\rightarrow F^{B}\cong A\rightarrow B\quad.$

\textbf{(d)} $\forall F^{\bullet}.\,\left(A\rightarrow F^{B}\right)\rightarrow C+F^{D}\cong C+A\times\left(B\rightarrow D\right)\quad.$

\textbf{(e)} $\forall F^{\bullet}.\,\left(A\rightarrow F^{B}\right)\rightarrow C\rightarrow F^{D}\cong\left(C\rightarrow A\right)\times\left(C\times B\rightarrow D\right)\quad.$

\subsubsection{Exercise \label{subsec:Exercise-free-type-8}\ref{subsec:Exercise-free-type-8}}

Derive a reduced encoding for a free applicative functor on a pointed
functor.

\subsubsection{Exercise \label{subsec:Exercise-free-type-9}\ref{subsec:Exercise-free-type-9}}

Implement a \textsf{``}free pointed filterable\textsf{''} typeclass (combining pointed
and filterable) on a type constructor $F^{\bullet}$ in the tree encoding.
Derive a reduced encoding. Simplify these encodings when $F^{\bullet}$
is already a functor.

\paragraph{Corrections}

The slides say that the \textsf{``}universal property\textsf{''} of the runner is
$\text{run}^{P}g\bef f=\text{run}^{Q}\left(g\bef f\right)$, however,
this is not true; it is the right naturality property of $\text{run}^{P}:\left(Z\rightarrow P\right)\rightarrow\text{FreeC}^{Z}\rightarrow P$
with respect to the type parameter $P$. The universal property is
$f=\text{wrap}\bef\text{run}^{P}f$ for any $f:Z\rightarrow P$ and
any type $P$ that belongs to the typeclass $C$.

The \textsf{``}logarithm\textsf{''} $\text{Lg}\,(F^{\bullet})\triangleq\forall A.\,F^{A}\rightarrow A$
is an operation with bizarre properties. Examples: $\forall A.\,\left(Z\rightarrow A\right)\rightarrow A\cong Z$,
so $\text{Lg}\,(Z\rightarrow\bullet)=Z$. This might motivate the
name \textsf{``}logarithm\textsf{''}. But $\text{Lg}\,(F^{\bullet}+G^{\bullet})=\text{Lg}\,(F)\times\text{Lg}\,(G)$,
which resembles the distributive law for the \emph{exponential} function
rather than for the logarithm. Also, $\forall A.\,(Z\times A\times A)\rightarrow A\cong Z\times\bbnum 2$,
so $\text{Lg}\,(Z\times(\bbnum 2\rightarrow\bullet))=Z\times\bbnum 2$.
However, for a constant functor, $\text{Lg}\,(Z)=\bbnum 0$. This
shows that $\text{Lg}\,(F^{\bullet}\times G^{\bullet})\not\cong\text{Lg}\,(F)\times\text{Lg}\,(G)$.
We also have $\text{Lg}\,(\text{Opt})=\bbnum 0$.

\section{Properties of free constructions}

\subsection{Free monad}

The free monad on a functor $F$ is defined by
\[
\text{Free}^{F,A}\triangleq A+F^{\text{Free}^{F,A}}\quad.
\]
It was shown in Statement~\ref{subsec:Statement-monad-construction-4-free-monad}
that $\text{Free}^{F,A}$ is a lawful monad for any functor $F$.
We will now derive some further properties of the free monad construction.

The next statement shows that one can change the underlying functor
$F$ while preserving the free monad operations.

\subsubsection{Statement \label{subsec:Statement-free-monad-monadic-naturality}\ref{subsec:Statement-free-monad-monadic-naturality}}

For any functor $G$ and any natural transformation $\phi:F^{A}\rightarrow G^{A}$,
the corresponding transformation $\psi(\phi):\text{Free}^{F,A}\rightarrow\text{Free}^{G,A}$
defined by:
\[
\psi(\phi):\text{Free}^{F,A}\rightarrow\text{Free}^{G,A}\quad,\quad\quad\psi\triangleq\,\begin{array}{|c||cc|}
 & A & G^{\text{Free}^{G,A}}\\
\hline A & \text{id} & \bbnum 0\\
F^{\text{Free}^{F,A}} & \bbnum 0 & \overline{\psi}^{\uparrow F}\bef\phi
\end{array}
\]
is a monad morphism. In other words, the free monad $\text{Free}^{F}$
is natural in the functor $F$. 

\subparagraph{Proof}

Since $\phi$ is fixed, we can write $\psi(\phi)$ as simply $\psi$
for brevity. Denote $P\triangleq\text{Free}^{F}$ and $Q\triangleq\text{Free}^{G}$;
we need to show that $\psi:P\leadsto Q$ is a monad morphism.

To verify the identity law:
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{pu}_{Q}:}\quad & \text{pu}_{P}\bef\psi=\,\begin{array}{|c||cc|}
 & A & F^{P^{A}}\\
\hline A & \text{id} & \bbnum 0
\end{array}\,\bef\,\begin{array}{|c||cc|}
 & A & G^{Q^{A}}\\
\hline A & \text{id} & \bbnum 0\\
F^{P^{A}} & \bbnum 0 & \overline{\psi}^{\uparrow F}\bef\phi
\end{array}\\
 & =\,\begin{array}{|c||cc|}
 & A & G^{Q^{A}}\\
\hline A & \text{id} & \bbnum 0
\end{array}\,=\text{pu}_{Q}\quad.
\end{align*}

To verify the composition law, write the two sides separately:
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & \text{ftn}_{P}\bef\psi=\,\begin{array}{|c||cc|}
 & A & F^{P^{A}}\\
\hline A & \text{id} & \bbnum 0\\
F^{P^{A}} & \bbnum 0 & \text{id}\\
F^{P^{P^{A}}} & \bbnum 0 & \overline{\text{ftn}}_{P}^{\uparrow F}
\end{array}\,\bef\,\begin{array}{|c||cc|}
 & A & G^{Q^{A}}\\
\hline A & \text{id} & \bbnum 0\\
F^{P^{A}} & \bbnum 0 & \overline{\psi}^{\uparrow F}\bef\phi
\end{array}\\
 & \quad=\,\begin{array}{|c||cc|}
 & A & G^{Q^{A}}\\
\hline A & \text{id} & \bbnum 0\\
F^{P^{A}} & \bbnum 0 & \overline{\psi}^{\uparrow F}\bef\phi\\
F^{P^{P^{A}}} & \bbnum 0 & \overline{\text{ftn}}_{P}^{\uparrow F}\bef\overline{\psi}^{\uparrow F}\bef\phi
\end{array}\quad,\\
{\color{greenunder}\text{right-hand side}:}\quad & \psi^{\uparrow P}\bef\psi\bef\text{ftn}_{Q}=\,\begin{array}{|c||ccc|}
 & A & G^{Q^{A}} & F^{P^{Q^{A}}}\\
\hline A & \text{id} & \bbnum 0 & \bbnum 0\\
F^{P^{A}} & \bbnum 0 & \psi^{\uparrow F}\bef\phi & \bbnum 0\\
F^{P^{P^{A}}} & \bbnum 0 & \bbnum 0 & \overline{\psi}^{\uparrow P\uparrow F}
\end{array}\,\bef\,\begin{array}{|c||ccc|}
 & A & G^{Q^{A}} & G^{Q^{Q^{A}}}\\
\hline A & \text{id} & \bbnum 0 & \bbnum 0\\
G^{Q^{A}} & \bbnum 0 & \text{id} & \bbnum 0\\
F^{P^{Q^{A}}} & \bbnum 0 & \bbnum 0 & \overline{\psi}^{\uparrow F}\bef\phi
\end{array}\,\bef\text{ftn}_{Q}\\
 & =\,\begin{array}{|c||ccc|}
 & A & G^{Q^{A}} & G^{Q^{Q^{A}}}\\
\hline A & \text{id} & \bbnum 0 & \bbnum 0\\
F^{P^{A}} & \bbnum 0 & \psi^{\uparrow F}\bef\phi & \bbnum 0\\
F^{P^{P^{A}}} & \bbnum 0 & \bbnum 0 & \overline{\psi}^{\uparrow P\uparrow F}\bef\overline{\psi}^{\uparrow F}\bef\phi
\end{array}\,\bef\,\begin{array}{|c||cc|}
 & A & G^{Q^{A}}\\
\hline A & \text{id} & \bbnum 0\\
G^{Q^{A}} & \bbnum 0 & \text{id}\\
G^{Q^{Q^{A}}} & \bbnum 0 & \overline{\text{ftn}}_{Q}^{\uparrow G}
\end{array}\\
 & =\,\,\begin{array}{|c||cc|}
 & A & G^{Q^{A}}\\
\hline A & \text{id} & \bbnum 0\\
F^{P^{A}} & \bbnum 0 & \psi^{\uparrow F}\bef\phi\\
F^{P^{P^{A}}} & \bbnum 0 & \overline{\psi}^{\uparrow P\uparrow F}\bef\overline{\psi}^{\uparrow F}\bef\phi\bef\overline{\text{ftn}}_{Q}^{\uparrow G}
\end{array}\quad.
\end{align*}
The remaining difference is between the last rows of the matrices:
\[
\overline{\text{ftn}}_{P}^{\uparrow F}\bef\overline{\psi}^{\uparrow F}\bef\phi\overset{?}{=}\overline{\psi}^{\uparrow P\uparrow F}\bef\overline{\psi}^{\uparrow F}\bef\phi\bef\overline{\text{ftn}}_{Q}^{\uparrow G}\quad.
\]
By the inductive assumption, the law already holds for recursive calls
of $\overline{\psi}$:
\[
\text{ftn}_{P}\bef\overline{\psi}=\overline{\psi}^{\uparrow P}\bef\overline{\psi}\bef\text{ftn}_{Q}\quad.
\]
So, it remains to show that
\[
(\overline{\psi}^{\uparrow P}\bef\overline{\psi}\bef\text{ftn}_{Q}\big)^{\uparrow F}\bef\phi\overset{?}{=}\overline{\psi}^{\uparrow P\uparrow F}\bef\overline{\psi}^{\uparrow F}\bef\phi\bef\overline{\text{ftn}}_{Q}^{\uparrow G}\quad.
\]
This holds due to the naturality law of $\phi$, in the form $\phi\bef f^{\uparrow G}=f^{\uparrow F}\bef\phi$.
$\square$

Heuristically, a free monad on a functor $F$ will wrap $F$ in a
more complicated type constructor such that the resulting type has
the required monad operations. If $F$ is already a monad, constructing
the free monad on $F$ is unnecessary. Indeed, a value of type $\text{Free}^{F,A}$
can be always mapped back to $F^{A}$ while preserving the monad operations:

\subsubsection{Statement \label{subsec:Statement-free-monad-on-a-monad-mapped}\ref{subsec:Statement-free-monad-on-a-monad-mapped}}

Assume that $F$ is itself a monad, and denote $T\triangleq\text{Free}^{F}$
for brevity.

\textbf{(a)} There is a monad morphism $p:T^{A}\rightarrow F^{A}$
defined by
\[
p\triangleq\,\begin{array}{|c||c|}
 & F^{A}\\
\hline A & \text{pu}_{F}\\
F^{T^{A}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F}
\end{array}\quad.
\]

\textbf{(b)} The function $q:F^{A}\rightarrow T^{A}$ defined by $q(f)\triangleq\bbnum 0+f\triangleright(a^{:A}\rightarrow a+\bbnum 0)^{\uparrow F}$
is \emph{not} a monad morphism.

{*}{*}{*} but $q\bef f=\text{id}$?

\subparagraph{Proof}

\textbf{(a)} To verify the identity law of $p$:
\begin{align*}
{\color{greenunder}\text{expect to equal }\text{pu}_{F}:}\quad & \text{pu}_{T}\bef p=\,\begin{array}{|c||cc|}
 & A & F^{T^{A}}\\
\hline A & \text{id} & \bbnum 0
\end{array}\,\bef\,\begin{array}{|c||c|}
 & F^{A}\\
\hline A & \text{pu}_{F}\\
F^{T^{A}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F}
\end{array}\,=\text{pu}_{F}\quad.
\end{align*}

To verify the composition law, write its two sides separately:
\begin{align*}
{\color{greenunder}\text{left-hand side}:}\quad & \text{ftn}_{T}\bef p=\,\begin{array}{|c||cc|}
 & A & F^{T^{A}}\\
\hline A & \text{id} & \bbnum 0\\
F^{T^{A}} & \bbnum 0 & \text{id}\\
F^{T^{T^{A}}} & \bbnum 0 & \overline{\text{ftn}}_{T}^{\uparrow F}
\end{array}\,\bef\,\begin{array}{|c||c|}
 & F^{A}\\
\hline A & \text{pu}_{F}\\
F^{T^{A}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F}
\end{array}\\
 & \quad=\,\begin{array}{|c||c|}
 & F^{A}\\
\hline A & \text{pu}_{F}\\
F^{T^{A}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F}\\
F^{T^{T^{A}}} & \overline{\text{ftn}}_{T}^{\uparrow F}\bef\overline{p}^{\uparrow F}\bef\text{ftn}_{F}
\end{array}\quad,\\
{\color{greenunder}\text{right-hand side}:}\quad & p^{\uparrow T}\bef p\bef\text{ftn}_{F}=\,\begin{array}{|c||cc|}
 & F^{A} & F^{T^{F^{A}}}\\
\hline A & \text{pu}_{F} & \bbnum 0\\
F^{T^{A}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F} & \bbnum 0\\
F^{T^{T^{A}}} & \bbnum 0 & \overline{p}^{\uparrow T\uparrow F}
\end{array}\,\bef\,\begin{array}{|c||c|}
 & F^{F^{A}}\\
\hline F^{A} & \text{pu}_{F}\\
F^{T^{F^{A}}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F}
\end{array}\,\bef\text{ftn}_{F}\\
 & \quad=\,\begin{array}{|c||c|}
 & F^{A}\\
\hline A & \text{pu}_{F}\bef\gunderline{\text{pu}_{F}\bef\text{ftn}_{F}}\\
F^{T^{A}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F}\bef\gunderline{\text{pu}_{F}\bef\text{ftn}_{F}}\\
F^{T^{T^{A}}} & \overline{p}^{\uparrow T\uparrow F}\bef\overline{p}^{\uparrow F}\bef\gunderline{\text{ftn}_{F}\bef\text{ftn}_{F}}
\end{array}\,=\,\begin{array}{|c||c|}
 & F^{A}\\
\hline A & \text{pu}_{F}\\
F^{T^{A}} & \overline{p}^{\uparrow F}\bef\text{ftn}_{F}\\
F^{T^{T^{A}}} & \overline{p}^{\uparrow T\uparrow F}\bef\overline{p}^{\uparrow F}\bef\text{ftn}_{F}^{\uparrow F}\bef\text{ftn}_{F}
\end{array}\quad.
\end{align*}
The last two matrices differ only in the last rows, and the difference
is
\[
\overline{\text{ftn}}_{T}^{\uparrow F}\bef\overline{p}^{\uparrow F}\overset{?}{=}\overline{p}^{\uparrow T\uparrow F}\bef\overline{p}^{\uparrow F}\bef\text{ftn}_{F}^{\uparrow F}\quad.
\]
Omitting the lifting to $F$, we get:
\[
\overline{\text{ftn}}_{T}\bef\overline{p}\overset{?}{=}\overline{p}^{\uparrow T}\bef\overline{p}\bef\text{ftn}_{F}\quad.
\]
This holds by the inductive assumption that the recursive calls to
$\overline{p}$ already obey the composition law.

\textbf{(b)} The function $q\triangleq f\rightarrow\bbnum 0+f\triangleright(x\rightarrow x+\bbnum 0)^{\uparrow F}$
fails the monad morphism identity law. Given $f\triangleq\text{pu}_{F}(a)$,
we compute: 
\[
q(f)=\bbnum 0+a\triangleright\text{pu}_{F}\triangleright(x\rightarrow x+\bbnum 0)^{\uparrow F}=\bbnum 0+a\triangleright(x\rightarrow x+\bbnum 0)\triangleright\text{pu}_{F}=\bbnum 0+\text{pu}_{F}(a+\bbnum 0)\quad.
\]
However, the expected value is $\text{pu}_{T}(a)=a+\bbnum 0$, which
cannot equal  $\bbnum 0+\text{pu}_{F}(a+\bbnum 0)$.

\section{Working with quantified types}

{*}{*}{*}Move all this to an appendix? {*}{*}{*} also discuss existential
types?

In the notation used in this book, there is a key difference between
the quantified type $\forall X.\,F^{X}$ and the type expression $F^{X}$
that contains the type parameter $X$. In both cases, $X$ is a completely
unknown type parameter, and an example of Scala code implementing
those types would be:
\begin{lstlisting}
def f[X]: F[X] = ???
\end{lstlisting}
However, the type quantifier $\forall X$ implies that all values
of type $\forall X.\,F^{X}$ must be implemented via fully parametric
code. The code of the function \lstinline!f[X]! may not make decisions
based on the actual type passed at run time as the type parameter
\lstinline!X! into the function. The assumption of full parametricity
enables us to reason about quantified types in a special way. This
section explores the techniques of this reasoning.

\subsection{The Yoneda identities for type constructors}

The Yoneda identities (see Section~\ref{subsec:Yoneda-identities})
can be extended to many other contexts. For instance, a Yoneda identity
holds for types parameterized by a type constructor:

\subsubsection{Statement \label{subsec:Statement-covariant-yoneda-identity-for-type-constructors}\ref{subsec:Statement-covariant-yoneda-identity-for-type-constructors}
(covariant Yoneda identity for functors)\index{Yoneda identity!for functors}}

Assume that $P^{\bullet}$ is any type constructor and $S$ is a higher-order
functor\index{functor!higher-order}\index{higher-order functor}.
That is, $S^{F^{\bullet}}$ is a type that depends covariantly on
an arbitrary type constructor $F^{\bullet}$. (An example of such
$S$ is $S^{F^{\bullet}}\triangleq F^{\text{Int}}\times F^{\text{String}}$.)
Then the type $S^{P^{\bullet}}$ is equivalent to the function type
$\forall F^{\bullet}.\,(P^{\bullet}\leadsto F^{\bullet})\rightarrow S^{F^{\bullet}}$,
where the function is required to be natural in the parameter $F^{\bullet}$.
The corresponding naturality law for functions $\sigma$ of type $\forall F^{\bullet}.\,(P^{\bullet}\leadsto F^{\bullet})\rightarrow S^{F}$
involves arbitrary type constructors $Q^{\bullet}$, $R^{\bullet}$,
and arbitrary functions $f:P^{\bullet}\leadsto Q^{\bullet}$ and $g:Q^{\bullet}\leadsto R^{\bullet}$,
and may be written as
\begin{equation}
\sigma^{Q}(f)\bef g^{\uparrow S}=\sigma^{R^{\bullet}}(f\bef g)\quad.\label{eq:assumed-naturality-of-argument-sigma}
\end{equation}
Here, $g^{\uparrow S}$ has type $S^{Q^{\bullet}}\rightarrow S^{R^{\bullet}}$
and is a lifting of the function $g:Q^{\bullet}\leadsto R^{\bullet}$
to the higher-order functor $S$. At the same time, the functions
$f$ and $g$ do \emph{not} have to be natural transformations, and
the type constructors $F^{\bullet}$, $P^{\bullet}$, $Q^{\bullet}$,
$R^{\bullet}$ are \emph{not} required to be functors.

\subparagraph{Proof}

{*}{*}{*}rewrite the proof in a simpler way like in chapter 10{*}{*}{*}For
brevity, we will write just $F$ and $P$ instead of $F^{\bullet}$
and $P^{\bullet}$.

The isomorphism is implemented via two functions \lstinline!toC!
and \lstinline!fromC!:
\begin{align*}
\text{toC}:S^{P}\rightarrow\forall F.\,(P\leadsto F)\rightarrow S^{F}\quad, & \quad\quad\text{toC}\triangleq s^{:S^{P}}\rightarrow\forall F.\,g^{:P\leadsto F}\rightarrow s\triangleright g^{\uparrow S}\quad,\\
\text{fromC}:(\forall F.\,(P\leadsto F)\rightarrow S^{F})\rightarrow S^{P}\quad, & \quad\quad\text{fromC}\triangleq\sigma^{:\forall F.\,(P\leadsto F)\rightarrow S^{F}}\rightarrow\sigma^{P}(\text{id}^{:P\leadsto P})\quad.
\end{align*}
In the last line, the function $\sigma$ is required to be natural
in its type parameter $Q$.

We need to show that $\text{fromC}\bef\text{toC}=\text{id}$ and $\text{toC}\bef\text{fromC}=\text{id}$.
To verify that $\text{fromC}\bef\text{toC}=\text{id}$, apply both
sides to an arbitrary function $\sigma^{:\forall F.\,(P\leadsto F)\rightarrow S^{F}}$:
\begin{align*}
{\color{greenunder}\text{expect to equal }\sigma:}\quad & \sigma^{:\forall F.\,(P\leadsto F)\rightarrow S^{F}}\triangleright\text{fromC}\bef\text{toC}=\sigma^{P}(\text{id})\triangleright\text{toC}=\forall F.\,g^{:P\leadsto F}\rightarrow\sigma^{P}(\text{id})\triangleright g^{\uparrow S}\quad.
\end{align*}
Since by assumption $\sigma$ satisfies the naturality law~(\ref{eq:assumed-naturality-of-argument-sigma}),
we may apply that law with $Q=P$, $R=F$, and $f=\text{id}$:
\[
\sigma^{P}(\text{id})\bef g^{\uparrow S}=\sigma^{F}(\text{id}\bef g)=F^{F}(g)\quad.
\]
It follows that the function $\sigma\triangleright\text{fromC}\bef\text{toC}$
is the same as $\sigma$:
\[
\sigma\triangleright\text{fromC}\bef\text{toC}=\forall F.\,g^{:P\leadsto F}\rightarrow\sigma^{F}(g)=\forall F.\,\sigma^{F}=\sigma\quad.
\]

To verify that $\text{toC}\bef\text{fromC}=\text{id}$, apply both
sides to an arbitrary $s^{:S^{P}}$:
\begin{align*}
{\color{greenunder}\text{expect to equal }s:}\quad & s^{:S^{P}}\triangleright\text{toC}\bef\text{fromC}=s\triangleright\text{toC}\triangleright\text{fromC}=(\forall F.\,g^{:P\leadsto F}\rightarrow s\triangleright g^{\uparrow S})\triangleright\text{fromC}\\
 & =(g^{:P\leadsto P}\rightarrow s\triangleright g^{\uparrow S})(\text{id}^{:P\leadsto P})=s\triangleright\text{id}^{\uparrow S}=s\quad.
\end{align*}
It remains to check that the function $\sigma^{F}\triangleq g^{:P\leadsto F}\rightarrow s\triangleright g^{\uparrow S}$,
used as an argument of \lstinline!fromC!, is natural in $F$. To
verify the naturality law~(\ref{eq:assumed-naturality-of-argument-sigma}):
\begin{align*}
{\color{greenunder}\text{expect to equal }\sigma^{R}(f\bef g):}\quad & \sigma^{Q}(f)\bef g^{\uparrow S}=s\triangleright f^{\uparrow S}\bef g^{\uparrow S}=s\triangleright(f\bef g)^{\uparrow S}=\sigma^{R}(f\bef g)\quad.
\end{align*}


\subsection{Recursive type equations with different fixpoints}

A recursive type is defined as a \textbf{fixpoint} of\index{fixpoint of a functor}
a functor. A fixpoint means a solution of a type equation\index{recursive type equation}
of the form $T\cong F^{T}$, where $F$ is a \textsf{``}structure functor\textsf{''}
that specifies the details of the type recursion. A solution of the
type equation $T\cong F^{T}$ is a type $T$ that is equivalent to
$F^{T}$ via two isomorphisms:
\[
\text{fix}:F^{T}\rightarrow T\quad,\quad\quad\text{unfix}:T\rightarrow F^{T}\quad,\quad\quad\text{fix}\bef\text{unfix}=\text{id}\quad,\quad\text{unfix}\bef\text{fix}=\text{id}\quad.
\]
Section~\ref{subsec:Recursive-types-and-the-existence-of-their-values}
gave a condition for implementability of such types $T$. We will
now consider the question of whether there can be several fixpoints
$T$.

A functor $F$ may have several \emph{inequivalent} fixpoints $T_{1}$,
$T_{2}$, etc. It means that each $T_{i}$ separately satisfies the
fixpoint equation $T\cong F^{T}$. An example is the fixpoint equation
for the \textsf{``}lazy list\textsf{''}:
\begin{equation}
L^{A}\cong\bbnum 1+(\bbnum 1\rightarrow A\times L^{A})\quad.\label{eq:fixpoint-type-equation-for-oncall-list}
\end{equation}
We may write the same equation using a recursion scheme $F$ like
this:
\[
L^{A}\cong F^{A,L^{A}}\quad,\quad\quad F^{A,R}\triangleq\bbnum 1+(\bbnum 1\rightarrow A\times R)\quad.
\]
A solution of this fixpoint equation can be visualized (non-rigorously)
as the type:
\[
L^{A}=F^{A,F^{A,F^{A,...}}}=\bbnum 1+(\bbnum 1\rightarrow A\times(\bbnum 1+(\bbnum 1\rightarrow A\times(...))))\quad,
\]
representing an \textsf{``}on-call\textsf{''} list of values of type $A$. To get
the next value of type $A$, one must evaluate a function call. In
this way, the elements of the on-call list are computed only when
needed. It could happen that a value of type $L^{A}$ will \emph{never}
stop yielding new values of type $A$ if we keep requesting the next
elements of the list.

To show rigorously that the type $L^{A}$ is a solution of the type
equation $L^{A}\cong F^{A,L^{A}}$, {*}{*}{*}

To see that the fixpoint equation~(\ref{eq:fixpoint-type-equation-for-oncall-list})
has (at least) three inequivalent solutions, consider a function \lstinline!toList!
that converts a value of type $L^{A}$ into a sequence of type \lstinline!List[A]!,
whose elements are eagerly evaluated. The function \lstinline!toList!
keeps recursively requesting new elements of the on-call list and
accumulates the resulting values:
\[
\text{toList}:L^{A}\rightarrow\text{List}^{A}\quad,\quad\quad\text{toList}\triangleq\begin{array}{|c||cc|}
 & \bbnum 1 & \bbnum 1+A\times\text{List}^{A}\\
\hline \bbnum 1 & \text{id} & \bbnum 0\\
\bbnum 1\rightarrow A\times L^{A} & \bbnum 0 & p\rightarrow p(1)\triangleright(\text{id}\boxtimes\overline{\text{toList}})
\end{array}\quad.
\]
Does this function terminate? It is clear that \lstinline!toList!
will terminate only if the on-call list eventually stops yielding
new values of type $A$. On the other hand, if the on-call list never
stops yielding new values of type $A$, the function \lstinline!toList!
will not terminate. So, \lstinline!toList! must be a partial function. 

Let us denote by $L_{\text{fin}}^{A}$ the subtype of $L^{A}$ consisting
of finite lists, i.e., on-call lists that eventually stop yielding
new values of type $A$. Then the function:
\[
\text{toList}:L_{\text{fin}}^{A}\rightarrow\text{List}^{A}
\]
is total. On-call lists of type $L_{\text{fin}}^{A}$ contain a finite
number of values and thus are equivalent to eager lists. To make this
equivalence formal, we may define isomorphism functions, $\text{toList}:L_{\text{fin}}^{A}\rightarrow\text{List}^{A}$
and $\text{fromList}:\text{List}^{A}\rightarrow L_{\text{fin}}^{A}$. 

Let us also denote by $L_{\text{inf}}^{A}$ the subtype corresponding
to \textsf{``}always infinite\textsf{''} on-call lists, i.e., those that \emph{never}
stop yielding new values of type $A$. Then the function \lstinline!toList!
does not terminate for any argument of type $L_{\text{inf}}^{A}$.
So, the types $L_{\text{fin}}^{A}$ and $L_{\text{inf}}^{A}$ are
\emph{not} equivalent. Were they equivalent, we would have an isomorphism
$q:L_{\text{inf}}^{A}\rightarrow L_{\text{fin}}^{A}$, and then we
could compose $q$ with \lstinline!toList! to obtain a function $\text{toList}:L_{\text{inf}}^{A}\rightarrow\text{List}^{A}$
that terminates, which is impossible.

To show that both types ($L_{\text{fin}}^{A}$ and $L_{\text{inf}}^{A}$)
satisfy the fixpoint type equation~(\ref{eq:fixpoint-type-equation-for-oncall-list}),
we can implement the corresponding isomorphisms \lstinline!fix! and
\lstinline!unfix!. Each of these functions will either add or remove
one element at the beginning of the list. These operations keep finite
lists finite and infinite lists infinite. So, a composition (such
as, $\text{unfix}\bef\text{fix}$) of these isomorphisms will act
as an identity function on $L_{\text{fin}}^{A}$ or on $L_{\text{inf}}^{A}$.

The type $L^{A}$ is an on-call list that may or may not terminate.
So, $L^{A}$ is equivalent to a disjunction $L_{\text{fin}}^{A}+L_{\text{inf}}^{A}$.
We see that the type equation~(\ref{eq:fixpoint-type-equation-for-oncall-list})
has three inequivalent solutions: $L_{\text{fin}}^{A}$, $L_{\text{inf}}^{A}$,
and $L^{A}$.

Some fixpoints represent \textsf{``}larger\textsf{''} types than other fixpoints.
For instance, $L^{A}$ is \textsf{``}larger\textsf{''} than either of $L_{\text{fin}}^{A}$
and $L_{\text{inf}}^{A}$. To see this formally, we consider the functions
$f_{1}:L_{\text{fin}}^{A}\rightarrow L^{A}$ and $f_{2}:L_{\text{inf}}^{A}\rightarrow L^{A}$.
The function $f_{1}$ embeds values of type $L_{\text{fin}}^{A}$
(finite lists) in the type $L^{A}$ that includes both finite and
infinite lists. The functions $f_{1}$ and $f_{2}$ are injective
because they are functions of type $P\rightarrow P+Q$ for some $P$
and $Q$.

The functions $f_{1}$ and $f_{2}$ are in a sense \textsf{``}well-adapted\textsf{''}
to the fixpoint structure of the types. The following definition makes
this property precise:

\subsubsection{Definition \label{subsec:Definition-fixpoint-preserving-function}\ref{subsec:Definition-fixpoint-preserving-function}}

Suppose a functor $F$ has two fixpoint types $T_{1}$ and $T_{2}$
with corresponding functions $\text{fix}_{1}:F^{T_{1}}\rightarrow T_{1}$,
$\text{unfix}_{1}:T_{1}\rightarrow F^{T_{1}}$, $\text{fix}_{2}:F^{T_{2}}\rightarrow T_{2}$,
and $\text{unfix}_{2}:T_{2}\rightarrow F^{T_{2}}$. A function $f:T_{1}\rightarrow T_{2}$
is \index{fixpoint-preserving function}\textbf{fixpoint-preserving}
if the compatibility law holds:
\[
\xymatrix{\xyScaleY{1.0pc}\xyScaleX{3pc}T_{1}\ar[d]\sp(0.45){f}\ar[r]\sp(0.5){\text{unfix}_{1}} & F^{T_{1}}\ar[d]\sp(0.4){f^{\uparrow F}}\ar[r]\sp(0.5){\text{fix}_{1}} & T_{1}\ar[d]\sp(0.45){f}\\
T_{2}\ar[r]\sp(0.5){\text{unfix}_{2}} & F^{T_{2}}\ar[r]\sp(0.5){\text{fix}_{2}} & T_{2}
}
\]
\begin{align*}
 & \text{fix}_{1}\bef f=f^{\uparrow F}\bef\text{fix}_{2}\quad,\\
 & \text{unfix}_{1}\bef f^{\uparrow F}=f\bef\text{unfix}_{2}\quad.
\end{align*}

To show that both $f_{1}$ and $f_{2}$ are fixpoint-preserving, we
note that {*}{*}{*}

As an example of a function that is \emph{not} fixpoint-preserving,
consider truncating an infinite list at a fixed length of, say, $100$
elements. {*}{*}{*}

\subsubsection{Example \label{subsec:Example-fixpoint-list}\ref{subsec:Example-fixpoint-list}}

The standard type \lstinline!List[A]! is a solution of the type equation:
\[
\text{List}^{A}\cong\bbnum 1+A\times\text{List}^{A}\quad.
\]
We can write that equation in the form $\text{List}^{A}\cong F^{\text{List}^{A}}$
where $F^{R}\triangleq\bbnum 1+A\times R$, and we consider $A$ to
be a fixed type. Consider a modified recursion scheme:
\[
G^{R}\triangleq P+A\times R\quad,
\]
where $P$ is another fixed type. Can we find a type $T$ that solves
the type equation $T\cong G^{T}$?

\subparagraph{Solution}

First, we will guess the answer. Intuitively, we imagine $\text{List}^{A}$
to be an \textsf{``}infinite disjunction\textsf{''} of the form:
\begin{align*}
\text{List}^{A} & =\bbnum 1+A\times(\bbnum 1+A\times(\bbnum 1+...))\quad.\\
 & =\bbnum 1+A+A\times A+A\times A\times A+...
\end{align*}
Similarly, we write the type $T$ in that form and find:
\begin{align*}
T & =P+A\times(P+A\times(P+...))\\
 & =P+A\times P+A\times A\times P+A\times A\times A\times P+...\\
 & =P\times(\bbnum 1+A+A\times A+A\times A\times A+...)\\
 & =P\times\text{List}^{A}\quad.
\end{align*}

The infinite type expressions are suggestive but not rigorous. To
prove that $T\triangleq P\times\text{List}^{A}$ is a fixpoint of
the type equation $T\cong G^{T}$, we need to demonstrate an isomorphism
between the types $T$ and $P+A\times T$. For that, we just need
to implement two functions, \lstinline!fix! and \lstinline!unfix!,
that are inverses of each other: 
\begin{align*}
 & \text{fix}:P\times\text{List}^{A}\rightarrow P+A\times(P\times\text{List}^{A})\quad,\\
 & \text{unfix}:P+A\times(P\times\text{List}^{A})\rightarrow P\times\text{List}^{A}\quad,\\
 & \text{fix}\bef\text{unfix}=\text{id}\quad,\quad\quad\text{unfix}\bef\text{fix}=\text{id}\quad.
\end{align*}
We write the code for \lstinline!fix! and \lstinline!unfix! in matrix
form, expanding the disjunctive type as $P\times\text{List}^{A}\cong P\times(\bbnum 1+A\times\text{List}^{A})$:
\begin{align*}
 & \text{fix}:P\times\text{List}^{A}\rightarrow P+A\times(P\times\text{List}^{A})\quad,\\
 & \text{fix}\triangleq\,\begin{array}{|c||cc|}
 & P & A\times(P\times\text{List}^{A})\\
\hline P\times\bbnum 1 & p\times1\rightarrow p & \bbnum 0\\
P\times(A\times\text{List}^{A}) & \bbnum 0 & p\times(a\times l)\rightarrow a\times(p\times l)
\end{array}\quad,\\
 & \text{unfix}:P+A\times(P\times\text{List}^{A})\rightarrow P\times\text{List}^{A}\quad,\\
 & \text{unfix}\triangleq\,\begin{array}{|c||cc|}
 & P\times\bbnum 1 & P\times(A\times\text{List}^{A})\\
\hline P & p\rightarrow p\times1 & \bbnum 0\\
A\times(P\times\text{List}^{A}) & \bbnum 0 & a\times(p\times l)\rightarrow p\times(a\times l)
\end{array}\quad.
\end{align*}
To prove that \lstinline!fix! and \lstinline!unfix! are inverses
of each other: 
\begin{align*}
 & \text{fix}\bef\text{unfix}\\
 & =\,\begin{array}{||cc|}
p\times1\rightarrow p & \bbnum 0\\
\bbnum 0 & p\times(a\times l)\rightarrow a\times(p\times l)
\end{array}\,\bef\,\begin{array}{||cc|}
p\rightarrow p\times1 & \bbnum 0\\
\bbnum 0 & a\times(p\times l)\rightarrow p\times(a\times l)
\end{array}\\
 & =\,\,\begin{array}{||cc|}
p\times1\rightarrow p\times1 & \bbnum 0\\
\bbnum 0 & p\times(a\times l)\rightarrow p\times(a\times l)
\end{array}\,=\,\begin{array}{||cc|}
\text{id} & \bbnum 0\\
\bbnum 0 & \text{id}
\end{array}\,=\text{id}\quad.
\end{align*}
\begin{align*}
 & \text{unfix}\bef\text{fix}\\
 & =\,\begin{array}{||cc|}
p\rightarrow p\times1 & \bbnum 0\\
\bbnum 0 & a\times(p\times l)\rightarrow p\times(a\times l)
\end{array}\,\bef\,\begin{array}{||cc|}
p\times1\rightarrow p & \bbnum 0\\
\bbnum 0 & p\times(a\times l)\rightarrow a\times(p\times l)
\end{array}\\
 & =\,\,\begin{array}{||cc|}
p\rightarrow p & \bbnum 0\\
\bbnum 0 & a\times(p\times l)\rightarrow a\times(p\times l)
\end{array}\,=\,\begin{array}{||cc|}
\text{id} & \bbnum 0\\
\bbnum 0 & \text{id}
\end{array}\,=\text{id}\quad.
\end{align*}


\subsubsection{Example \label{subsec:Exampleexample-double-recursive-coproduct}\ref{subsec:Exampleexample-double-recursive-coproduct}}

Let $F^{\bullet,\bullet}$ be a bifunctor and define $P^{\bullet}$
and $Q$ by:
\[
P^{A}\cong F^{P^{A},A}\quad,\quad\quad Q\cong P^{Q}\quad.
\]
Show that $Q$ is a fixpoint of the type equation $Q\cong F^{Q,Q}$.

\subparagraph{Solution}

Substitute $A=Q$ into the definition of $P^{A}$ and find:
\[
P^{Q}\cong F^{P^{Q},Q}\quad.
\]
We note that $P^{A}$ is covariant in $A$ due to the recursive functor
construction (Statement~\ref{subsec:functor-Statement-functor-recursive}).
So, we can lift the isomorphism $Q\cong P^{Q}$ to the corresponding
isomorphism $F^{Q}\cong F^{P^{Q}}$ and get $Q\cong F^{Q,Q}$.

\subsection{The Church encoding of recursive types\label{subsec:The-Church-encoding-of-recursive-types}}

Any given type can be represented in a \textbf{Church encoding}\index{Church encoding},
which is a function type with a universally quantified type parameter.
A simple Church encoding is given by the type equivalence
\[
T\cong\forall X.\,\left(T\rightarrow X\right)\rightarrow X\quad,
\]
which follows from the covariant Yoneda identity (Statement~\ref{subsec:Statement-covariant-yoneda-identity-for-types}
with the functor $F\triangleq\text{Id}$). 

There is rarely an advantage in replacing a simple type $T$ by a
more complicated function type, $\forall X.\,(T\rightarrow X)\rightarrow X$.
However, the Church encoding has a different form when $T$ is a \emph{recursive}
type.\footnote{The \textsf{``}Boehm-Berarducci encoding\textsf{''} discussed in \texttt{\href{http://okmij.org/ftp/tagless-final/course/Boehm-Berarducci.html}{http://okmij.org/ftp/tagless-final/course/Boehm-Berarducci.html}}
can be seen as a curried form of the Church encoding.}

Consider a recursive type $T$ defined by a fixpoint equation $T\triangleq F^{T}$
with a given structure functor $F$. It turns out that a useful Church
encoding for $T$ is:
\begin{equation}
T\cong\forall X.\,(F^{X}\rightarrow X)\rightarrow X\quad\text{if the type }T\text{ is defined by }T\triangleq F^{T}\quad.\label{eq:Church-encoding-recursive-type}
\end{equation}
The Scala code for the type $\forall X.\,(F^{X}\rightarrow X)\rightarrow X$
is:
\begin{lstlisting}
trait TC[F[_]] { def run[X](fold: F[X] => X): X }
\end{lstlisting}
In this section, we will study the type equivalence~(\ref{eq:Church-encoding-recursive-type}).

Note that the Yoneda lemma cannot be used to prove Eq.~(\ref{eq:Church-encoding-recursive-type}).
The Yoneda lemma only applies to types of the form $\forall X.\,(A\rightarrow X)\rightarrow F^{X}$,
where the type $A$ cannot depend on the quantified type $X$. 

The following statement\footnote{See also the papers \texttt{\href{https://web.archive.org/web/20110601105059/http://www.cs.ioc.ee/~tarmo/papers/fics10.pdf}{http://www.cs.ioc.ee/$\sim$tarmo/papers/fics10.pdf}}
and \texttt{\href{https://kodu.ut.ee/~varmo/papers/aplas04.ps.gz}{https://kodu.ut.ee/$\sim$varmo/papers/aplas04.ps.gz}}.} shows that the Church encoding~(\ref{eq:Church-encoding-recursive-type})
is a fixpoint of $F$:

\subsubsection{Statement \label{subsec:Statement-Church-encoding-recursive-type-covariant}\ref{subsec:Statement-Church-encoding-recursive-type-covariant}}

For a given recursion scheme $F$, define the type $T$ as:
\[
T\triangleq\forall X.\,(F^{X}\rightarrow X)\rightarrow X\quad.
\]
Additionally, we require all values $t$ of type $T$ to satisfy the
strong dinaturality law,\index{strong dinaturality law!of Church encoding}
which for the given type $T$ has the following form: for any $r^{:F^{A}\rightarrow A}$,
$s^{:F^{B}\rightarrow B}$, and $f^{:A\rightarrow B}$: 

\begin{equation}
\text{if }\quad r\bef f=f^{\uparrow F}\bef s\quad\text{ then }\quad r^{:F^{A}\rightarrow A}\triangleright t^{A}\triangleright f^{:A\rightarrow B}=s^{:F^{B}\rightarrow B}\triangleright t^{B}\quad.\label{eq:strong-dinaturality-for-church-encoded-fix-unfix}
\end{equation}
Defined in this way, the type $T$ is a solution of the fixpoint equation
$T\cong F^{T}$. (Strong dinaturality holds for all fully parametric
functions of type $T$. This follows from Example~\ref{subsec:Example-strong-dinaturality-for-some-type-signatures}(b)
with $G^{A}\triangleq A$ and $L^{X,Y}\triangleq Y$.)

\subparagraph{Proof}

First, we use typed holes to derive the code for the isomorphisms:
\[
\text{fix}:F^{T}\rightarrow T\quad,\quad\quad\text{unfix}:T\rightarrow F^{T}\quad.
\]
Begin by writing out the type signature of \lstinline!fix! and an
implementation with a typed hole:
\begin{align*}
 & \text{fix}:F^{\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow\forall Y.\,(F^{Y}\rightarrow Y)\rightarrow Y\quad,\\
 & \text{fix}\triangleq f^{:F^{\forall X.\,(F^{X}\rightarrow X)\rightarrow X}}\rightarrow\forall Y.\,q^{:F^{Y}\rightarrow Y}\rightarrow\text{???}^{:Y}\quad.
\end{align*}
The only way of computing a value of type $Y$ is to apply $q$ to
an argument of type $F^{Y}$:
\[
\text{fix}=f^{:F^{\forall X.\,(F^{X}\rightarrow X)\rightarrow X}}\rightarrow\forall Y.\,q^{:F^{Y}\rightarrow Y}\rightarrow\big(\text{???}^{:F^{Y}}\big)\triangleright q\quad.
\]
The functor $F$ is arbitrary, so the only way of computing a value
of type $F^{Y}$ is to use the given value $f$ with a \lstinline!map!
method (the only method we can use with any functor $F$):
\[
\text{???}^{:F^{Y}}=f\triangleright(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow\text{???}^{:Y})^{\uparrow F}\quad.
\]
Since the type parameter $X$ is universally quantified inside $p$,
we may set $X$ to any type as needed. So, we set $X=Y$ and use the
given value $q^{:F^{Y}\rightarrow Y}$ to fill the typed hole:
\[
\text{???}^{:F^{Y}}=f\triangleright(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y})^{\uparrow F}\quad.
\]
This allows us to complete the code of \lstinline!fix!:
\[
\text{fix}\triangleq f^{:F^{\forall X.\,(F^{X}\rightarrow X)\rightarrow X}}\rightarrow\forall Y.\,q^{:F^{Y}\rightarrow Y}\rightarrow f\triangleright\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y}\big)^{\uparrow F}\triangleright q\quad.
\]
Omitting type annotations, we may write \lstinline!fix! as:
\[
\text{fix}\triangleq f\rightarrow\,^{Y}\rightarrow q\rightarrow f\triangleright(p\rightarrow q\triangleright p^{Y})^{\uparrow F}\bef q\quad.
\]

We turn to implementing \lstinline!unfix!:
\begin{align*}
 & \text{unfix}:\big(\forall Y.\,(F^{Y}\rightarrow Y)\rightarrow Y\big)\rightarrow F^{\forall X.\,(F^{X}\rightarrow X)\rightarrow X\big)}\quad,\\
 & \text{unfix}\triangleq t^{:\forall Y.\,(F^{Y}\rightarrow Y)\rightarrow Y}\rightarrow\text{???}^{:F^{T}}\quad.
\end{align*}
The only way of filling the typed hole $\text{???}^{:F^{T}}$ is to
apply $t^{Y}$ while setting the type parameter $Y$ to $F^{T}$:
\[
\text{unfix}=t^{:\forall Y.\,(F^{Y}\rightarrow Y)\rightarrow Y}\rightarrow t^{F^{T}}\big(\text{???}^{:F^{F^{T}}\rightarrow F^{T}}\big)\quad.
\]
We can now fill the typed hole $\text{???}^{:F^{F^{T}}\rightarrow F^{T}}$
by lifting \lstinline!fix! to the functor $F$:
\[
\text{unfix}\triangleq t^{:\forall Y.\,(F^{Y}\rightarrow Y)\rightarrow Y}\rightarrow t^{F^{T}}\big(\text{fix}^{\uparrow F}\big)\quad.
\]

It remains to show that \lstinline!fix! and \lstinline!unfix! are
inverses. Start with one direction:
\begin{align*}
{\color{greenunder}\text{expect to equal }t:}\quad & t^{:T}\triangleright\text{unfix}\bef\text{fix}=t^{F^{T}}(\text{fix}^{\uparrow F})\triangleright\text{fix}\\
 & =\forall Y.\,q^{:F^{Y}\rightarrow Y}\rightarrow\text{fix}^{\uparrow F}\triangleright t^{F^{T}}\triangleright\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y}\big)^{\uparrow F}\triangleright q\quad.
\end{align*}
The resulting function will be equal to $t$ if we show that it gives
the same result when applied to an arbitrary argument $q^{:F^{Y}\rightarrow Y}$
(where the type parameter $Y$ is free):
\begin{equation}
\text{fix}^{\uparrow F}\triangleright t^{F^{T}}\triangleright\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow p^{Y}(q)\big)^{\uparrow F}\triangleright q\overset{?}{=}t^{Y}(q^{:F^{Y}\rightarrow Y})\quad.\label{eq:unfix-fix-identity-derivation1}
\end{equation}
To proceed, we need to use the strong dinaturality law~(\ref{eq:strong-dinaturality-for-church-encoded-fix-unfix})
of $t$ with suitable $r$, $s$, and $f$. That law will reproduce
Eq.~(\ref{eq:unfix-fix-identity-derivation1}) if we choose $r$,
$s$, and $f$ such that:
\[
r=\text{fix}^{\uparrow F}\quad,\quad\quad f=\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y}\big)^{\uparrow F}\bef q\quad,\quad\quad s=q\quad.
\]
For these equations to hold, the type parameters $A$ and $B$ must
be set appropriately in Eq.~(\ref{eq:strong-dinaturality-for-church-encoded-fix-unfix}).
The type of $\text{fix}^{\uparrow F}$ is $F^{F^{T}}\rightarrow F^{T}$,
which means that $A=F^{T}$. The type of $q$ is $F^{Y}\rightarrow Y$,
so $B=Y$. This agrees with the type of $f^{:A\rightarrow B}$. So,
the strong dinaturality law~(\ref{eq:strong-dinaturality-for-church-encoded-fix-unfix})
will yield Eq.~(\ref{eq:unfix-fix-identity-derivation1}) as long
as the chosen variables satisfy the condition
\[
r\bef f\overset{?}{=}f^{\uparrow F}\bef s\quad.
\]
It remains to verify that the last line holds. Substituting the values
of the variables, we get:
\begin{align*}
 & \text{fix}^{\uparrow F}\bef f\overset{?}{=}f^{\uparrow F}\bef q\quad,\\
{\color{greenunder}\text{or equivalently}:}\quad & \text{fix}^{\uparrow F}\bef\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y}\big)^{\uparrow F}\bef q\\
 & \quad\overset{?}{=}\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y}\big)^{\uparrow F\uparrow F}\bef q^{\uparrow F}\bef q\quad.
\end{align*}
Evaluate the function composition in the left-hand side, and make
both sides equal:
\begin{align*}
 & \gunderline{\text{fix}}^{\uparrow F}\bef\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y}\big)^{\uparrow F}\bef q\\
{\color{greenunder}\text{expand function}:}\quad & =\big((f^{:F^{T}}\rightarrow f\triangleright\text{fix})\bef(p\rightarrow q\triangleright p^{Y})\big)^{\uparrow F}\bef q=\big(f^{:F^{T}}\rightarrow q\triangleright(f\triangleright\gunderline{\text{fix}})^{Y}\big)^{\uparrow F}\bef q\\
{\color{greenunder}\text{definition of }\text{fix}:}\quad & =\big(\gunderline{f^{:F^{T}}\rightarrow f\,\triangleright}\,(p\rightarrow q\triangleright p^{Y})^{\uparrow F}\bef q\big)^{\uparrow F}\bef q=\big((p\rightarrow q\triangleright p^{Y})^{\uparrow F}\bef q\big)^{\uparrow F}\bef q\quad.
\end{align*}
The last expression is equal to the right-hand side.

This proves one direction of the isomorphism between $T$ and $F^{T}$,
namely: $\text{unfix}\bef\text{fix}=\text{id}$.

To verify the opposite direction of the isomorphism, we write:
\begin{align*}
{\color{greenunder}\text{expect to equal }f:}\quad & f^{:F^{T}}\triangleright\text{fix}\triangleright\text{unfix}=\big(\forall Y.\,q^{:F^{Y}\rightarrow Y}\rightarrow f\triangleright\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow q\triangleright p^{Y}\big)^{\uparrow F}\triangleright q\big)\triangleright\text{unfix}\\
 & =f\triangleright\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow p^{F^{T}}(\text{fix}^{\uparrow F})\big)^{\uparrow F}\triangleright\text{fix}^{\uparrow F}\\
 & =f\triangleright\big(p^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow p^{F^{T}}(\text{fix}^{\uparrow F})\triangleright\text{fix}\big)^{\uparrow F}\quad.
\end{align*}
The last value will be equal to $f$ if the function under $(...)^{\uparrow F}$
is an identity function:
\[
p^{F^{T}}(\text{fix}^{\uparrow F})\triangleright\text{fix}\overset{?}{=}p\quad.
\]
Since $p$ is of function type, both sides must be equal when applied
to an arbitrary $s^{:F^{B}\rightarrow B}$:
\begin{equation}
s\triangleright(p^{F^{T}}(\text{fix}^{\uparrow F})\triangleright\text{fix})\overset{?}{=}s\triangleright p\quad.\label{eq:fix-unfix-derivation2}
\end{equation}
To prove the last equation, we use the assumption that all values
of type $T$ satisfy the strong dinaturality law. So, the law must
apply to the value $p$:
\[
r\triangleright p\triangleright f=s\triangleright p\quad.
\]
This law reproduces Eq.~(\ref{eq:fix-unfix-derivation2}) if we define
$r$ and $f$ by:
\[
r\triangleq\text{fix}^{\uparrow F}\quad,\quad\quad f\triangleq u^{:F^{T}}\rightarrow s\triangleright(u\triangleright\text{fix})^{B}\quad.
\]
Substituting the definition of \lstinline!fix!, we get a simplified
formula for $f$:
\begin{align*}
 & f=u^{:F^{T}}\rightarrow s\triangleright(u\triangleright\text{fix})^{B}\\
 & =u^{:F^{T}}\rightarrow u\triangleright(q^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow s\triangleright q^{B})^{\uparrow F}\bef s\\
 & =(q^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow s\triangleright q^{B})^{\uparrow F}\bef s\quad.
\end{align*}
It remains to verify that the assumption of the strong dinaturality
law holds:
\begin{align*}
 & r\bef f\overset{?}{=}f^{\uparrow F}\bef s\quad,\\
{\color{greenunder}\text{or equivalently}:}\quad & \text{fix}^{\uparrow F}\bef(q\rightarrow s\triangleright q^{B})^{\uparrow F}\bef s\overset{?}{=}f^{\uparrow F}\bef s\quad.
\end{align*}
To prove the last equation, it is sufficient to prove that:
\[
\text{fix}\bef(q\rightarrow s\triangleright q^{B})=f\quad.
\]
Rewrite the left-hand side above until it becomes equal to the right-hand
side:
\begin{align*}
 & \text{fix}\bef(q\rightarrow s\triangleright q^{B})\\
 & =(u^{:F^{T}}\rightarrow u\triangleright\text{fix})\bef(q\rightarrow s\triangleright q^{B})\\
 & =u^{:F^{T}}\rightarrow s\triangleright(u\triangleright\text{fix})^{B}=f.
\end{align*}
The two sides are now equal. $\square$

A curious property of the type $T$ is that it is a function with
argument of type $F^{X}\rightarrow X$, where $X$ can be any type,
including $T$ itself. But we already have a function of type $F^{T}\rightarrow T$;
it is the function \lstinline!fix!. So, applying a value $t$ of
type $T$ to the function \lstinline!fix! yields again a value of
type $T$. As the next statement shows, that value is the same as
$t$:

\subsubsection{Statement \label{subsec:Statement-strong-dinaturality-property-of-fix}\ref{subsec:Statement-strong-dinaturality-property-of-fix}}

Consider the Church-encoded type $T$ and the function \lstinline!fix!
defined in Statement~\ref{subsec:Statement-Church-encoding-recursive-type-covariant}.
It follows from the strong dinaturality law\footnote{\index{Dan Doel}Dan Doel gave a proof using relational parametricity:
see \texttt{\href{https://cs.stackexchange.com/questions/131901/}{https://cs.stackexchange.com/questions/131901/}}} for any value $t^{:T}$ that:
\begin{equation}
t^{T}(\text{fix})=t\quad.\label{eq:fix-unfix-property-of-T}
\end{equation}


\subparagraph{Proof}

We use the strong dinaturality law~(\ref{eq:strong-dinaturality-for-church-encoded-fix-unfix}):
\[
\text{if }\quad r\bef f=f^{\uparrow F}\bef s\quad\text{ then }\quad r\triangleright t^{A}\triangleright f=s\triangleright t^{B}\quad.
\]
It remains to choose suitable values $r^{:F^{A}\rightarrow A}$, $s^{:F^{B}\rightarrow B}$,
and $f^{:A\rightarrow B}$ so that the law~(\ref{eq:strong-dinaturality-for-church-encoded-fix-unfix})
reproduces Eq.~(\ref{eq:fix-unfix-property-of-T}). Since the law
always involves applying the function $t$ to some arguments, while
the right-hand side of Eq.~(\ref{eq:fix-unfix-property-of-T}) contains
just $t$, let us apply both sides of Eq.~(\ref{eq:fix-unfix-property-of-T})
to an arbitrary value $s^{:F^{B}\rightarrow B}$, where the type $B$
is also arbitrary:
\[
s\triangleright(\text{fix}\triangleright t^{T})\overset{?}{=}s\triangleright t^{B}\quad.
\]
The left-hand side will have the form $r\triangleright t^{A}\triangleright f$
if we set $A=T$, $r=\text{fix}$, and $f$ a function that applies
its argument to $s$:
\[
f^{:T\rightarrow B}\triangleq u^{:T}\rightarrow s\triangleright u^{B}\quad.
\]
It remains to verify the assumption of the strong dinaturality law~(\ref{eq:strong-dinaturality-for-church-encoded-fix-unfix}):
\begin{align*}
 & r\bef f\overset{?}{=}f^{\uparrow F}\bef s\quad,\\
{\color{greenunder}\text{or equivalently}:}\quad & \text{fix}\bef(u^{:T}\rightarrow s\triangleright u^{B})\overset{?}{=}(u^{:T}\rightarrow s\triangleright u^{B})^{\uparrow F}\bef s\quad.
\end{align*}
Rewrite the left-hand side of the last line above:
\begin{align*}
 & \text{fix}\bef(u^{:T}\rightarrow s\triangleright u^{B})=f^{:F^{T}}\rightarrow s\triangleright(f\triangleright\text{fix})^{B}\\
{\color{greenunder}\text{definition of }\text{fix}:}\quad & =\gunderline{f^{:F^{T}}\rightarrow f\,\triangleright}\,(q\rightarrow s\triangleright q)^{\uparrow F}\bef s\\
{\color{greenunder}\text{unexpand function}:}\quad & =(q\rightarrow s\triangleright q)^{\uparrow F}\bef s\quad.
\end{align*}
This is equal to the left-hand side after renaming $s$ to $u$. $\square$

The Church encoding $T\triangleq\forall X.\,(F^{X}\rightarrow X)\rightarrow X$
of the fixpoint has a special property: for any other fixpoint $R$,
there is a unique fixpoint-preserving function of type $T\rightarrow R$
called a \textbf{catamorphism}\index{catamorphism}. To define the
catamorphism, assume that the fixpoint $R$ has a known function $\text{fix}_{R}:F^{R}\rightarrow R$
and write:
\[
\text{cata}:T\rightarrow R\quad,\quad\quad\text{cata}\triangleq t^{:\forall X.\,(F^{X}\rightarrow X)\rightarrow X}\rightarrow t^{R}(\text{fix}_{R})\quad.
\]


\subsubsection{Statement \label{subsec:Statement-catamorphism-church-encoding}\ref{subsec:Statement-catamorphism-church-encoding}}

\textbf{(a)} The function \lstinline!cata! (defined above) is a fixpoint-preserving
function.

\textbf{(b)} Any other fixpoint-preserving function of type $T\rightarrow R$
is equal to \lstinline!cata!.

\subparagraph{Proof}

{*}{*}{*}

\subsection{The co-Yoneda identities}

The Yoneda identities allow us in many cases to simplify type expressions
with universal quantifiers. Similar identities hold for existentially
quantified types. 

\subsubsection{Statement \label{subsec:Statement-co-Yoneda-two-identities}\ref{subsec:Statement-co-Yoneda-two-identities}}

For any functor $F$ and any contrafunctor $H$, the following identities
hold:
\begin{align*}
{\color{greenunder}\text{\textbf{(a)} }\text{covariant co-Yoneda identity}:}\quad & \exists A.\,(A\rightarrow R)\times F^{A}\cong F^{R}\quad,\\
{\color{greenunder}\text{\textbf{(b)} }\text{contravariant co-Yoneda identity}:}\quad & \exists A.\,(R\rightarrow A)\times H^{A}\cong H^{R}\quad.
\end{align*}


\subparagraph{Proof}

We use Eq.~(\ref{eq:existential-via-universal-Yoneda}) to express
$\exists A$ via $\forall A$. 

\textbf{(a)} We write:
\begin{align*}
{\color{greenunder}\text{expect to equal }F^{R}:}\quad & \exists A.\,(A\rightarrow R)\times F^{A}\\
{\color{greenunder}\text{definition of }\exists\text{ in Eq.~}(???):}\quad & \cong\forall B.\,\big(\forall A.\,\gunderline{(A\rightarrow R)\times F^{A}}\rightarrow B\big)\rightarrow B\\
{\color{greenunder}\text{uncurry arguments}:}\quad & \cong\forall B.\,\big(\gunderline{\forall A.\,(A\rightarrow R)\rightarrow F^{A}\rightarrow B}\big)\rightarrow B\\
{\color{greenunder}\text{contravariant Yoneda identity}:}\quad & \cong\gunderline{\forall B.\,\big(F^{R}\rightarrow B\big)\rightarrow B}\\
{\color{greenunder}\text{covariant Yoneda identity}:}\quad & \cong F^{R}\quad.
\end{align*}

\textbf{(b)} We write:
\begin{align*}
{\color{greenunder}\text{expect to equal }H^{R}:}\quad & \exists A.\,(R\rightarrow A)\times H^{A}\\
{\color{greenunder}\text{definition of }\exists\text{ in Eq.~}(???):}\quad & \cong\forall B.\,\big(\forall A.\,\gunderline{(R\rightarrow A)\times H^{A}}\rightarrow B\big)\rightarrow B\\
{\color{greenunder}\text{uncurry arguments}:}\quad & \cong\forall B.\,\big(\gunderline{\forall A.\,(R\rightarrow A)\rightarrow H^{A}\rightarrow B}\big)\rightarrow B\\
{\color{greenunder}\text{covariant Yoneda identity}:}\quad & \cong\gunderline{\forall B.\,\big(H^{R}\rightarrow B\big)\rightarrow B}\\
{\color{greenunder}\text{covariant Yoneda identity}:}\quad & \cong H^{R}\quad.
\end{align*}
$\square$

The Scala type \lstinline!Any! closely corresponds to the type $\exists X.\,X$,
which is observationally equivalent to \lstinline!Unit!. The advantage
of using \lstinline!Any! instead of \lstinline!Unit! is that \lstinline!Any!
is understood by the Scala compiler as a supertype of \emph{all} Scala
types (while \lstinline!Unit! is not). Indeed, for any type $T$
there is an injective function $T\rightarrow\exists X.\,X$, This
function corresponds to a function of type \lstinline!T => Any! in
Scala:
\begin{lstlisting}
def toAny[T](t: T): Any = t
\end{lstlisting}
 This is just an identity function that relabels the types; so, this
function establishes the subtyping relation \lstinline!T <: Any!.

\subsection{Exercises\index{exercises}}

\subsubsection{Exercise \label{subsec:Exercise-Yoneda}\ref{subsec:Exercise-Yoneda}}

Use a Yoneda identity to prove that there are no fully parametric
functions with this type:

\begin{lstlisting}
def f[A]: Option[A] => A
\end{lstlisting}


\section{Discussion}

\subsection{Universally quantified function types cover all other types}

It turns out that all fully parametric type expressions are equivalent
to some type expressions that use only two type constructions: the
function type ($A\rightarrow B$) and the universal quantifier ($\forall A.\,F^{A}$).
If a programming language only supports these two type constructions,
one can write a library that implements all other type constructions.

We will now show the required type expressions and prove their equivalence.
The main tools in those proofs are the Church encoding and the Yoneda
lemma.

\paragraph{Void type}

The void type ($\bbnum 0$) is equivalent to the type expression $\forall A.\,A$.
To prove that $\forall A.\,A\cong\bbnum 0$, we may use the Yoneda
lemma:
\[
\forall A.\,A\cong\forall A.\,\bbnum 1\rightarrow A\cong\forall A.\,(\bbnum 0\rightarrow A)\rightarrow A\cong\bbnum 0\quad.
\]


\paragraph{Unit type}

The unit type ($\bbnum 1$) is equivalent to $\forall A.\,A\rightarrow A$.
To prove that, we may use the Yoneda lemma:
\[
\forall A.\,A\rightarrow A\cong\forall A.\,(\bbnum 1\rightarrow A)\rightarrow A\cong\bbnum 1\quad.
\]


\paragraph{Products}

The type $A\times B$ is equivalent to $\forall T.\,(A\rightarrow B\rightarrow T)\rightarrow T$.
To prove that, we use uncurrying and the Yoneda lemma:
\[
\forall T.\,(A\rightarrow B\rightarrow T)\rightarrow T\cong\forall T.\,(A\times B\rightarrow T)\rightarrow T\cong A\times B\quad.
\]


\paragraph{Co-products}

The type $A+B$ is equivalent to $\forall T.\,(A\rightarrow T)\rightarrow(B\rightarrow T)\rightarrow T$.
To prove that, we use the Yoneda lemma:
\begin{align*}
 & \forall T.\,(A\rightarrow T)\rightarrow(B\rightarrow T)\rightarrow T\cong\forall T.\,(A\rightarrow T)\times(B\rightarrow T)\rightarrow T\\
 & \quad\cong\forall T.\,(A+B\rightarrow T)\rightarrow T\cong A+B\quad.
\end{align*}


\paragraph{Recursive types}

A recursive type $T$ defined via the type equation $T\triangleq F^{T}$,
where $F$ is a covariant functor, is equivalent to the Church encoding
of $T$:
\[
T\cong\forall A.\,(F^{A}\rightarrow A)\rightarrow A\quad.
\]
This is proved in Statement~\ref{subsec:Statement-Church-encoding-recursive-type-covariant}.
By the inductive assumption, the type $F^{A}$ is equivalent to some
type expression containing only function types and universally quantified
type parameters.

\paragraph{Existential types}

We have the following equivalence:
\[
\exists A.\,F^{A}\cong\forall T.\,(\forall A.\,F^{A}\rightarrow T)\rightarrow T\quad.
\]
To prove this equivalence, begin with the Yoneda identity:
\[
\exists A.\,F^{A}\cong\forall T.\,\big((\exists A.\,F^{A})\rightarrow T\big)\rightarrow T\quad.
\]
It remains to show the type equivalence: 
\[
(\exists A.\,F^{A})\rightarrow T\cong\forall A.\,F^{A}\rightarrow T\quad.
\]
But this is just the definition of observational equivalence for existential
types.{*}{*}{*}

It is important that the type expression $\forall A.\,F^{A}\rightarrow T$
puts the universal quantifier \emph{inside} the function argument.
The type with both quantifiers outside, $\forall T.\,\forall A.\,(F^{A}\rightarrow T)\rightarrow T$
is \emph{not} equivalent to $\exists A.\,F^{A}$.

\paragraph{Free constructions in mathematics: Example I}

Consider the Cyrillic letter \foreignlanguage{russian}{\textcyr{\cyrc}}
(ts\`{e}) and the Chinese word \shui~(shu\textipa{\v i})

We want to \emph{multiply} \foreignlanguage{russian}{\textcyr{\cyrc}}
by \shui. Multiply how?

Say, we want an associative (but noncommutative) product of them

So, we want to define a \emph{semigroup} that \emph{contains} \foreignlanguage{russian}{\textcyr{\cyrc}}
and \shui~as elements

while we still know nothing about \foreignlanguage{russian}{\textcyr{\cyrc}}
and \shui

Consider the set of all \emph{unevaluated expressions} such as \foreignlanguage{russian}{\textcyr{\cyrc}}$\cdot$\shui$\cdot$\shui$\cdot$\foreignlanguage{russian}{\textcyr{\cyrc}}$\cdot$\shui

Here \foreignlanguage{russian}{\textcyr{\cyrc}}$\cdot$\shui~is
different from \shui$\cdot$\foreignlanguage{russian}{\textcyr{\cyrc}}
but $\left(a\cdot b\right)\cdot c=a\cdot\left(b\cdot c\right)$

All these expressions form a \textbf{free semigroup} generated by
\foreignlanguage{russian}{\textcyr{\cyrc}} and \shui

This is the most unrestricted semigroup that contains \foreignlanguage{russian}{\textcyr{\cyrc}}
and \shui

Example calculation: (\shui$\cdot$\shui)$\cdot$(\foreignlanguage{russian}{\textcyr{\cyrc}}$\cdot$\shui)$\cdot$\foreignlanguage{russian}{\textcyr{\cyrc}}
$=$ \shui$\cdot$\shui$\cdot$\foreignlanguage{russian}{\textcyr{\cyrc}}$\cdot$\shui$\cdot$\foreignlanguage{russian}{\textcyr{\cyrc}}

How to represent this as a data type:

\textbf{Tree encoding}: the full expression tree: (((\shui,\shui),(\foreignlanguage{russian}{\textcyr{\cyrc}},\shui)),\foreignlanguage{russian}{\textcyr{\cyrc}})

Implement the operation $a\cdot b$ as pair constructor (easy)

\textbf{Reduced encoding}, as a \textsf{``}smart\textsf{''} structure: List(\shui,\shui,\foreignlanguage{russian}{\textcyr{\cyrc}},\shui,\foreignlanguage{russian}{\textcyr{\cyrc}})

Implement $a\cdot b$ by concatenating the lists (more expensive)


\paragraph{Free constructions in mathematics: Example II}

Want to define a product operation for $n$-dimensional vectors: $\mathbf{v}_{1}\otimes\mathbf{v}_{2}$

The $\otimes$ must be linear and distributive (but not commutative):
\begin{align*}
\mathbf{u}_{1}\otimes\mathbf{v}_{1}+\left(\mathbf{u}_{2}\otimes\mathbf{v}_{2}+\mathbf{u}_{3}\otimes\mathbf{v}_{3}\right) & =\left(\mathbf{u}_{1}\otimes\mathbf{v}_{1}+\mathbf{u}_{2}\otimes\mathbf{v}_{2}\right)+\mathbf{u}_{3}\otimes\mathbf{v}_{3}\\
\mathbf{u}\otimes\left(a_{1}\mathbf{v}_{1}+a_{2}\mathbf{v}_{2}\right) & =a_{1}\left(\mathbf{u}\otimes\mathbf{v}_{1}\right)+a_{2}\left(\mathbf{u}\otimes\mathbf{v}_{2}\right)\\
\left(a_{1}\mathbf{v}_{1}+a_{2}\mathbf{v}_{2}\right) & \otimes\mathbf{u}=a_{1}\left(\mathbf{v}_{1}\otimes\mathbf{u}\right)+a_{2}\left(\mathbf{v}_{2}\otimes\mathbf{u}\right)
\end{align*}

We have such a product for 3-dimensional vectors; but it cannot be
made to work for 2 or 4-dimensional vectors

Consider \emph{unevaluated} \emph{expressions} of the form $\mathbf{u}_{1}\otimes\mathbf{v}_{1}+\mathbf{u}_{2}\otimes\mathbf{v}_{2}+...$

A free vector space generated by pairs of vectors

Impose the equivalence relationships shown above

The result is known as the \textbf{tensor product}

Tree encoding: full unevaluated expression tree

A list of any number of vector pairs $\sum_{i}\mathbf{u}_{i}\otimes\mathbf{v}_{i}$

Reduced encoding: an $n\times n$ matrix

Reduced encoding requires proofs and more complex operations

\subsection{Beyond Yoneda: simplifying quantified types}

The covariant Yoneda identity,
\[
\forall R.\,(A\rightarrow R)\rightarrow F^{R}\cong F^{A}\quad,
\]
and other similar identities hold for fully parametric code. If we
assume parametricity, we can also simplify certain expressions containing
quantified types where the Yoneda identities cannot be applied.

\subsubsection{Statement \label{subsec:Statement-quantifier-across-functor}\ref{subsec:Statement-quantifier-across-functor}}

For any polynomial functor $F$ and for any profunctor $P^{X,Y}$,
the types $\forall A.\,F^{P^{A,A}}$ and $F^{\forall A.\,P^{A,A}}$
are equivalent when restricted to fully parametric implementations. 

\subparagraph{Proof}

{*}{*}{*}

\subsubsection{Statement \label{subsec:Statement-existential-quandifier-via-Church-encoding}\ref{subsec:Statement-existential-quandifier-via-Church-encoding}}

\textbf{(a)} For any profunctor $P^{X,Y}$, the types $\exists A.\,P^{A,A}$
and $\forall B.\,(\forall A.\,(P^{A,A}\rightarrow B))\rightarrow B$
are equivalent when restricted to fully parametric implementations.
{*}{*}{*} I already talked about this earlier in this chapter. Move
proof here?

\textbf{(b)} Without the outer quantifier ($\forall B$), this property
does not hold: the types $(\exists A.\,P^{A,A})\rightarrow B$ and
$\forall A.\,(P^{A,A}\rightarrow B)$ are \emph{not} equivalent, at
least for some profunctors $P$.

\subparagraph{Proof}

{*}{*}{*}

\begin{comment}
jatin or the functional programming tutorial the focus of this chapter
is on three type constructions to begin let us consider the interpreter
pattern this is a design pattern where you present your program as
a data structure and you program an interpreter to run your data structure
so as an example consider this domain specific language for complex
numbers it\textsf{'}s a very simple language it has three operations to create
a complex number out of string to multiply complex numbers and to
compute the complex conjugate number if I want to represent this computation
as data in other words not to run it yet but to write down the operations
as data then I could imagine implementing it like this I can implement
some case classes in a disjunction like this so I have a program type
it has three parts of the disjunction which is either a string which
will represent this operation parsing a string into a complex number
multiplication of two complex numbers and computing the complex conjugate
number and then I can imagine that instead of this program I will
have a data structure with nested case classes like this in order
to be able to define such a data structure in my case classrooms should
have these types so for instance multiplication case class will contain
two parts and each can be itself another program so that\textsf{'}s why the
types of the parts of these schemes classes are again the type program
itself so in this way having defined these type parts of the case
class as programs I enable myself to write down arbitrary nested case
classes so this has type program I can use this as part of another
case class like MO or conjugate so in this way I have created a domain-specific
language that expresses computations with complex numbers as data
structures in order to actually compute anything with any complex
numbers I would need to run this program this dsl program as I would
say the interpreter will be a function of the type signature it may
be like this it will take an argument of type program and it will
return a pair of double numbers which would represent a complex number
that is the result of computing this program so why would you use
the interpreter pattern because it has certain benefits in certain
cases one main main benefit is that you represent a certain domain
specific language that is a number of operations that are specific
to a certain task set or a domain such as complex number of computations
you encapsulate all these operations in a data type that fully describes
what needs to be done without actually doing it so you present as
data what otherwise you would write as executable code data is much
more easily composable it can be manipulated transformed before running
it so before you run here DSO program you can store it in some data
structure you can put it on disk in a file read it back send it over
the internet and compose it with other DSL programs in the larger
DSL program all that is data manipulation that has nothing running
yet nothing has computed yet when you're ready you call the run function
and actually compute the results so this very simple DSL domain-specific
language has shortcomings specifically it works only with simple expressions
it represents expressions as unev a lated expression trees so every
operation needs to be some vertex of the tree but that\textsf{'}s that\textsf{'}s okay
but we don't have enough different operations defined so that for
instance you cannot express variable binding and conditions here for
instance we can imagine that this a could be used somehow in these
operations but I cannot express it here all I can express is multiplying
two complex numbers converting strings to complex numbers and computing
a complex conjugate number there is no way to express that I have
a variable in my language in the DSL not color variable Scala variables
I can of of course have I can say Val x equals this but that is not
at the level of the domain-specific language the language itself doesn't
know as so far anything about defining variables and because of this
I cannot use any code that is not expressed in this DSL so for example
I could imagine calling a numerical algorithms library to compute
some special function of the complex number and that could be a complicated
algorithm but I cannot put it into a DSL I would have to express the
entire algorithm using DSL operations if I wanted to do that so let\textsf{'}s
try to overcome these shortcomings these are certainly not due to
interpreter pattern itself it\textsf{'}s just that our DSL is too simple so
let\textsf{'}s see how we can do variable binding in a DSL like this now let\textsf{'}s
consider another example for this which is a DSL for reading and writing
files but let\textsf{'}s just look at reading files for now so the DSL will
have two operations first so this on the left is a non DSL program
is a program that we write in Scala we want to replace this with a
DSL program within data structure so the functionality we want to
implement is to create a path for a given file name so this could
check that it exists or whatever translate this into some URL if necessary
we don't know so right now we just say there is some operation that
creates Bath\textsf{'}s out of strings and there is another operation that
reads a file at the given path and the result is a string so you read
the contents of a file so then suppose we have this logic we read
one file and if its contents is not empty and then we interpret its
contents as another file name and we read that and then we want to
return the string that is in the second file if it\textsf{'}s an empty file
then we return an error string like this so how can we implement this
logic in the DSL well we need to bind a variable such as here STR
to a value that is computed by the DSL at runtime and we need to evaluate
some condition or generally we need to use the value of this variable
while constructing further DSL expressions so to understand how we
can implement this consider that in the DSL everything must be some
kind of expression tree and this part of the program needs to be also
represented by an expression tree and this expression tree is actually
a function of the variable STR so the variable STR will be assigned
when we run this DSL program and actually read the files but before
we do that the DSL already needs to specify that this entire rest
of the program is a function of this variable so in order to represent
that we need a special construction in the expression tree and I call
this construction bind which is just the name of a case class and
this case class will have an argument which is a function actually
a scholar function from a Scala variable STR to another tree and so
this is how I implement this domain-specific language again we I have
a seal trade program or probe which now has four case classes and
the three case classes here are the ones that I would need to implement
functionality so for example I need Val strings so I'll represent
that with this Val case class I need paths whose contents are maybe
programs again because I don't know path can be computed and I need
to read again I need to read something which could be another DSL
program so that\textsf{'}s what I do in these three case classes and I also
had a case class bind which represents binding enum DSL variable to
a value which is computed when you run the DSL and then so I have
the first part of this case class is a DSL program which when run
will give me a value of type string and the second part of the case
class is a function from string to another DSL programmer so this
function is a scalar function is not a DSL function is a scholar function
which is now part of my data structure in this way I can inject arbitrary
Scala code in principle in the code of this function including conditions
or creating another dsl program by using the values of these variables
in an arbitrary way so this variable will be the argument of F so
here is an example I make a bind so this entire thing becomes a blind
of this which is read path Val file and this which is a scholar function
that executes my conditional computation and then returns a value
of type program again so it returns a DSL program so this is a function
that takes a string and returns a program so that is how I can easily
implement the requirement that the DSL should express variable binding
conditional computations arbitrary Scala code in those calculations
and using the scala variables such as this one in creating expression
trees so I still have an expression tree this entire thing is still
expression tree and still undervalued but now I have a lot more flexibility
in what sort of computations I can implement with the DSL the interpreter
for the DSL will still have the same type signature it will be perhaps
slightly more complicated so let\textsf{'}s look at a code examples so first
the DSL for complex numbers which is what we saw before so the only
interesting code here is in running a DSL program and here\textsf{'}s how we
run we basically take the value of the program which is going to be
one of these three case classes and we match it in each case we run
what\textsf{'}s inside so in this strain case the inside is a definition of
a complex number by string such as this one we need to parse it so
I have some regular expression that I parse this with and the result
is going to be one value than a sign and another value and then I
create a complex number out of that a multiplication is a standard
formula for complex multiplication but notice that both of these are
programs so the mall case class contains two programs that first have
to be run in order to get a complex numbers out of them and then I
execute a complex multiplication similarly the conjugate operation
first I have to run the program that is the argument here and then
I execute the operation so here\textsf{'}s a test conjugate of multiply of
this which is equal to this complex number so in order to get it I
do run of program so when I do this nothing is wrong yet it\textsf{'}s a data
structure and I could have code that for example simplifies this in
some way maybe or prints it or whatever it\textsf{'}s a data structure that
is available for me to work with I could type set this in latex if
I wanted to before running it so then I also can run it so this is
the power of the interpreter pattern let\textsf{'}s look at implementing the
DSL for file operations that I described in order to run this I will
have a mock file system which we just a map from string to string
so that the filename is mapped to the text inside the farm so that
this is just so that my tests are easy and I don't need to write a
lot of code actually reading and writing files so I declare my probe
type as a disjunction like this like shown in the slide and now I
need to define the run now run is similar to what we had in the complex
number case and that for example I need to always run the arguments
first and then I do something with them so for simplicity path will
just evaluate your string and read will look up the file contents
in the dictionary so note we cannot guarantee that three is a path
here he is just a program it could it is evaluated to a string but
so maybe it surpassed maybe maybe not we have to be careful what right
right writing this program the runner cannot check what the program
makes sense and finally let\textsf{'}s look at how we implement the bind so
the bind is actually easy to implement so key as a type program we
need to run it to get a string out of it F has a private string to
program so we run the P then we apply F to that result which is a
straining so then F of string is another program which we again run
so that\textsf{'}s how mind works and that\textsf{'}s the entire implementation of variable
binding for our four in claim which for the DSL domain-specific language
here is an example program this is what is shown in the slide and
we can run it and see that it is equal to text this is equal to text
because first we read the file 1 which gives us the string and we
will read the file at this path which gives us the string so that\textsf{'}s
the text now notice that as DSL is not typesafe it allows us to read
to write nonsensical programs like this when you read read read and
that is nonsensical because you can only read the path and the result
of a read is not a path as a string and the program doesn't know about
it and just it gives us an exception key not found text which is a
kind of a runtime exception since we don't have a file named text
in our file system but this should not be the error the error should
be you cannot read a Val string you must read a class on the file
system which would have been a type error if this were a type safe
language so that\textsf{'}s the next concern our DSL so far has no type safety
every value in it is a program and it\textsf{'}s evaluated per string so what
can we do if we wanted to avoid errors such that for example read
of raid shouldn't even compile it should be impossible to write programs
like this and compile them and run so the way to solve this problem
is to change the type of the program data type to a type constructor
so let us denote by this program of a a DSL program that when run
will return a value of type a now in our case right now is going to
be string but let\textsf{'}s make sure it\textsf{'}s string and not some other type
such as a file fast so here\textsf{'}s how we do it we define a disjunction
type characterised by type a type parameter in and everything else
remains the same except now we explicitly say that for example the
argument of bind is a program that has a string result and a function
will take that result and output another program with string result
whereas previously bind had a program and this function returned the
program now we explicitly demand the result must be of type string
and then we can apply F to that result so Val will also give us a
program returning a string and path will take a program that returns
a string but it will heal the program that has the past in Iowa file
path type in other words it\textsf{'}s not a program returning string and the
read will take that kind of program and return a program that evaluates
the string so in this way we can achieve type safety so the program
remains mostly the same except for the type the interpreter remains
mostly the same except now it has type safety let\textsf{'}s see how that works
now so let\textsf{'}s implement instead of nio Java file types let\textsf{'}s just
have a mock type that represents a file path so now how do we implement
run you know it\textsf{'}s the same except now it\textsf{'}s impossible to have pass
in a program of type string so the program of type strain can only
be by and Val or read it cannot be a path because that\textsf{'}s a program
of type the are G of F path so we don't need this case here and instead
we just implement directly this case where we have a read of the text
because there is nothing else we can have so now the code is type
safe it still works the same code works but a program like this doesn't
compile this is a compile time error so we will not be able to even
create data structures that represent incorrect expressions that\textsf{'}s
the advantage of making the DSL file save our types a so here is our
DSL so far there is a problem with it which is it basically only binds
variables of type string it cannot bind variables of other types or
it cannot also return variables of other values of other types because
our runner returns string and requires a program of strings so still
the string type is very special and limiting us so for example we
cannot do this we must have a program that returns at rest so we cannot
directly read the past and if we wanted to compute this path using
a scholar program then we cannot convert this into a program of path
because there is no way to do that Val can only take a string and
extends program of string so let\textsf{'}s fix these problems now so first
of all let\textsf{'}s make Val a fully parameterize declaration so that it\textsf{'}s
Val of a and it returns program of a for any a and secondly let\textsf{'}s
replace this string by a parameter a as well so that would be a parameter
even will be an aid to program of B so we want to now have arbitrary
types instead of string here so we introduce two type parameters in
Bound and we will have this generality everything else stays the same
and except we get rid of this program of string and program of path
because now we have a Val and the Val can always convert a string
into a program of strain in the path into a program of path with no
problem so we don't need to have programs as types here if we need
this kind of thing we just bind a variable and we'll get get what
we need so now this is an interesting type because the signatures
of bind and Val are very similar to signatures of flat map and pure
if you look at this carefully so Val is of type a to program of a
bind is of this type program of a a to program of B and it returns
program will be so if we imagine that this is a function from here
to here then this is going to be just type signature flatmap and actually
it is in some sense a function binding dot apply is a function that
takes these as arguments and returns a value of this type except it\textsf{'}s
not just any function so type constructor so this function is defined
in a special way so essentially this type has methods of type signature
flat map and pure it looks like this type is a moment so let\textsf{'}s actually
define these methods flat map map and pure and it\textsf{'}s very easy to do
that flat map will just create a data structure with the case class
bind map we defined automatically by a flat map on theorem as we know
that in a wallet you can define Maps through flat map and pure the
pure is defined as just Val case closed so these methods don't actually
compute anything they don't run the DSL they create further unevaluated
data structures in other words these methods create DSL programs out
of previously defined DSL programs these are combinators innocence
but usually says then the combinators data are functions that take
values of some type and circle those and create new values of the
same type the advantage of Khalid affined in flat map map and pure
is that we can write the assault programs as functor blocks and we
can compose them very easily so for example if you look at the previous
program we have a bit of a repetition to have this read past Val which
we are using twice so how can we reuse that well they are easily make
a function that returns a string value program like this so we take
a path we read that files contents and this is a standard Scala syntax
for the Thunderer block as I call it for yield block and we can use
this syntax now because we have defined flat map and map in the program
trade and now we can easily combine and reuse the mimetic values in
another factor block so we can write this code as functor blocks as
we would do with any other moaner let\textsf{'}s see what the interpreter looks
like for this one I think DSL now I have full dramatization of types
defined viewer and map and flatmap and before as a shown in the slide
now there is a bit of ugliness in the runner because of the problems
with type pattern matching scholar has this problem where you want
to have image at least closet has type parameters it\textsf{'}s not easy to
do that so I have to do a bit of dancing around first I match the
bind and then I imagine a result I cannot put I parameters here that
won't compile I think maybe it will but I wasn't able to do it right
let me see if I can do it in one go Ashley you can see this was entirely
wrong a great simplification maybe my idea is not the Val and other
things are the same except now I have to do typecast so again Scala
is not great when you have to do type parameters on a case class and
the dual match expression so that\textsf{'}s a bit of ugliness but that\textsf{'}s not
so bad perhaps so let\textsf{'}s see that all of this actually works and so
now we are pretty happy we can a monadic DSL now it\textsf{'}s perhaps a little
too cumbersome because you need to define all these things every time
so if I wanted to define a DSL for complex numbers in the same way
as this DSL then I would have to add the bind and the Val and these
definitions every time so I would have to repeat this code every time
note that there are no code changes between this DSL for the file
operations and this DSL for complex numbers up to here so this is
completely the same the custom code starts later when we define some
more case classes so let\textsf{'}s refactor the DSL so that the common code
is separated and the custom code is just wrapped in some type constructor
called F so here\textsf{'}s how we do that we say there\textsf{'}s a DSL type constructor
that is paralyzed by the type a is minus 1 and it type constructor
F that will encapsulate always custom code so the type constructor
F will have the definition like this just like our first first try
at DSL so this could be once we add the type parameter this could
be the type constructor F and then we define just the typeclass the
case classes that are necessary to implement the moon add functionality
to bind and Val case classes and then we have this case class ops
for operations which contain a value of type F of n and so this is
a wrapper over whatever custom operations we have in our DSL and notice
here DSL does not have programmers parameters here has the complex
as parameters it\textsf{'}s up to us we could have programmers parameters it\textsf{'}s
a matter of convenience what important in it but whatever that is
it\textsf{'}s going to be encapsulated now in the case class ops so this entire
code is going to be generic in operations of your DSL so the type
constructor F represents the operations of the DSL and power the our
tech constructor DSL is a melodic DSL is permit rised by that tightness
factor f so this car is now engineered in the operations of your Union
now the cost of this is that the interpreter now needs to know how
to interpret your operations so you have to write extra code as opposed
to hard coding is you just write extra code that converts your operations
to values so you evaluate your operation so for example this operation
would be the domain specific part inside this F type constructor it
needs to be evaluated to yield this path so let\textsf{'}s see how that works
so the DSL will be general so all this part of code is generic it
does not depend on the domain all the domain-specific operations are
encapsulated by the type constructor S which is defined later in a
different place of your code so in this way we penalize by this type
constructor in this code is fully generic in any domain so now we
need to have the extractor the value extractor were evaluated for
your domain so this needs to be a function as I showed of this type
I would like to emphasize of this type is actually parameterize by
a typewriter a inside the expression it is not business for all a
I quantifier needs to be inside here it cannot be over there when
the reason is that when we run the DSL it takes a program that evaluates
a value of type a but intermediate steps could have different types
it could be that in order to compute a value of type a you first need
to compute some value of pi b r c and so on and when you run those
programs you need to extract a value of type b from some domain-specific
operation or a type c so you actually need to have a function in the
extractor that is parametrized by an arbitrary other type it\textsf{'}s not
going to be of the same type a as the runner and that\textsf{'}s why we cannot
use in scala just a type parameter you need to have an extra trait
that encapsulate inside but another type parameter so the extractor
is not parameterize by eight here this parameter is just by F and
it\textsf{'}s function applied or extract or whatever you want to call it just
has a single method and this method is paralyzed itself by the type
aid so in this way if the runner has a parameter which is the extractor
the runner is able to call the function extract on arbitrary types
here not necessarily the same type as this one so this I could rename
for clarity that\textsf{'}s necessary for the correct operation so that\textsf{'}s why
this parameter of the runner is not characterized by a it\textsf{'}s only parameterize
by F and inside that drag that that value there is a function that
works for every X for every type X so that is a little clunky in Scala
Scala does not have right now a good syntax that expresses such a
function but the cats library has a case class but essentially does
this so you can use that it\textsf{'}s called the natural transformation however
so in the cats library this will be like that it\textsf{'}s a natural transformation
which has code something like that now in this case F does not have
to be a factor you see if you look at our code for our domain-specific
language this program is not a factor because we have specific types
here now we do have a map function but only on the entire DSL the
F will only encapsulate these two case classes because we are now
separating the custom code from the generic monadic wrapper the binding
Val and the F type constructor will only encapsulate the domain-specific
code which has specific types here and does not have a map method
so it cannot be a functor it\textsf{'}s a partial type two type function that\textsf{'}s
only defined for specific type parameters and that cannot be a factor
and so it\textsf{'}s not really a natural transformation in the usual sense
because natural transformations are defined between factors but it\textsf{'}s
very similar it\textsf{'}s kind of a generic or maybe more general case of
a natural transformation which you don't need a name for it\textsf{'}s basically
this generic mapping from f of X to G of X for any given X so that\textsf{'}s
the Scala code that expresses this and this now needs to be the argument
of run so the first argument of run is this extractor and the second
argument of run is this DSL program so how do we implement run very
similarly to what we have before except now we have this extra argument
extract if you compare this with the previous Runner code same code
except we have run of extract here every time run extract run extract
and the ops case is slightly different very similar to those other
things but here we already take care of any custom operations because
the extract function knows how to evaluate them so extract of F is
the apply method which will give you an X out of f of X whatever X
might might be and so this ops doesn't know what type it is doesn't
it\textsf{'}s parameterize by a type and that\textsf{'}s fine so the result of this
extract is is an f of a and so some kind of f of a for unknown type
really not there\textsf{'}s necessarily the same as this a so let\textsf{'}s see now
how we use this so we now define a type constructor just for the custom
file operations so this is going to be the F here so we called File
ops and now this is just the domain-specific operations there are
no bind case constants were Vally classes we don't need those those
are going to be provided generically extractor needs to be defined
only for these so this is the domain specific code how to read files
how to create file paths or verify them or whatever this needs to
be so this is going to be actual domain specific code and then how
do we write programs the same way we just need to wrap our domain
specific operations in ops case class that\textsf{'}s all we could define helper
functions to have less boilerplate in this code but that doesn't really
matter right now what matters is that we are able to simply write
monadic code with their little boilerplate so imagine that all this
up here with a runner it\textsf{'}s completely generic it\textsf{'}s in the library
our code is just this it\textsf{'}s only the domain-specific operations and
then we just use the DSL type constructor from the and we're done
we use the oops from the library so cats library provides this it\textsf{'}s
called Freeman art and it works let\textsf{'}s see how we can use now this
is interesting yes L know we don't just want to rewrite code in a
fancy way we want to have value out of this generality so one example
of how we extract great value from this code is that now we can easily
handle errors so previously we evaluated a DSL of FA to a now we can
evaluate it to either of error and a all we need to do is to provide
a different extractor an extractor would be of this type so instead
of going FA to a and goes to fheo some error type was in it and the
code of the interpreter is almost unchanged except so this is the
same except the pure needs to put the or the Val case cause it\textsf{'}s a
pure function in the Monad it needs to put this into the right or
the either and the bind needs to use the flat map on the either other
than that it\textsf{'}s exactly the same so how does this code work well it
goes through the expression tree when it finds the bind expression
it will now use the flat map of the either when Al it will first run
the same it\textsf{'}s the same around functions recursive will run on the
P so we have a bind of P and F run the PETA gives you an either when
you use the flat map on that either with a function that runs on the
result and then applies the run to the result of the run ISM is a
curried function so that I can write this more easily F and then run
so the flat map here is from the ether moment and this is the pure
function of the ether moment so it\textsf{'}s very interesting to see that
the code of runner only uses flat map and pure from the ether moment
it\textsf{'}s not otherwise aware of the fact that we are running to evaluate
things into the ether moment and that\textsf{'}s very good because it means
we can very easily generalize to any other model except instead of
this one so let\textsf{'}s look at the code for the either one and the way
to do that so see the program remains the same we do not change the
program at all we just evaluate it into a different unit into the
ether moment instead of evaluating it to just the value a which is
actually the identity moment so previously we evaluated the code into
the identity monad now we are going to evaluate it into the either
movement so all we need to do when define a new extractor which are
called e\textasciicircum x just for brevity a new Runner which is
aware of an arbitrary well it\textsf{'}s aware of the either one I'm actually
not arbitrable not yet and I just rewrite things a little bit so that
I compile as : Scala and I find that these type parameters are required
but that\textsf{'}s all right so the code works in the same way as in the slides
and it applies this functional F which is of type that it doesn't
know it\textsf{'}s not really of type in E it\textsf{'}s of type type parameter that
I have here but it doesn't know that so this function f computes a
DSL program which I then run so I applied a runner to that program
so that\textsf{'}s exactly the same code as I had before except I'm extremely
inserting a flight map from the either Monat and here is the implementation
of the extractor so need a new extractor which will run domain-specific
code and catch exceptions so I would very easily do it like this now
I have an extractor that takes my file operations and from file operations
of a gives me an either of throneworld name so that\textsf{'}s all I need to
run my program now you see I running exactly the same program as before
I did not have to change that code but domain-specific language and
I wrote here in order to add error extraction arrogantly that is a
great power so I can just replace the extractor here and I run exactly
the same program so this program could be computed by one part of
the code and the extractor could be prepared by another part of the
code completely independently and here I have shown how we can interpret
the program with the result being an either so I call this to interpret
the DSL into a monad and so here we interpreted this DSL into the
ether moment we can just as easily interpret it into any other modern
by adding the moolaade here is a type parameter and getting rid of
either here and that\textsf{'}s it the changes will be minimal because we're
not actually using a specifics of either here we'll have to replace
this by pure that\textsf{'}s all so let us see what the resulting construction
actually is we start with an Operations type constructor denoted by
F such as this one v oops so this is a type constructor that needs
to have a type parameter and it needs to encapsulate your domain specific
operations in a very special way namely it takes the arguments of
the operations as parts of the case class and the return type of the
operation becomes the type parameter of this type constructor so that\textsf{'}s
the encoding this is because I remind you that this means a program
that when run will compute a value of type a so this is a program
that when run will compute a value of type path and that\textsf{'}s how we
encode domain-specific operations so this operation could be a function
from string to file path and this is a function from file path to
string so that\textsf{'}s what we need to encompassed and often this type constructor
will be not a factor maybe it will be a partial type to type function
not a factor that needs to be a total type to type function always
then we use this DSL which is a library construction that is written
once for all F the interpreter again has written once for all F and
then we run that program once we prepare a program value actually
which we can do using a functor block or in any other way or we can
do it directly using helper functions for instance we do ops of something
and so on flat map we can just write by hand map flatmap and so on
so in this way we can prepare a value of this type by combining value
so this is very composable it\textsf{'}s pure value it doesn't yet run anything
can be stored in variables and arrays whatever you want then you prepare
an extractor value that will run just your operations or your custom
operations and represents their values in some monad so this mu naught
can be identity mu naught if you already want just the final results
it could be an error gathering monad it could be some other moment
for instance could be a state monad if you want to represent your
operations purely as a state updates or someone base it can be a combination
of monads it can be anything that is a monad it could be another DSL
with a different F it could be anything so once you have this extractor
you run the program like this and this computes a value of that moment
which could be just a or it could be error something or and so on
so to summarize so far we begin with a number of operations and these
operations could have these types we define a type constructor then
like this typically well this could be more arguments and I'll have
more parts in the case class if I have no arguments then I would have
a case class with zero arguments but I need to have a type here so
usually a domain-specific language would have functions like this
with some return types so you just put them into your type constructor
like this and then you do what I just described now there are some
other things you can do which I will not discuss in a lot of detail
in this chapter for instance you can choose a different monad and
then you can interpret this value that you have into another moment
so this transformation you can define separately and if this itself
is a different DSL created in the same way then this will be the runner
for that DSL that evaluated into yet another will not in so this could
be very useful if you want to say test your your program so you have
exactly the same program and you run a test interpreter into someone
and that catches all the calls to something and prints Diagnostics
or whatever or you could give design a different kinetic DSL that
is more optimal let\textsf{'}s say more low-level and then you can have a sophisticated
optimizer that translates one DSL into another and the second DSL
will be run later in a yet another runner you can use monad transformers
since this is a monad API and you can combine these cells very easily
using disjunction so you have several factors or type constructors
not necessarily factors you can define a disjunction factor and the
DSL of that contains all the operations from each of these factors
in a single DSL so in this way you can define separately several dia
cells using these different F\textsf{'}s you could have F G H and so on and
then you put all of them at once into a monadic wrapper so this is
what I call DSL of something is really a monadic wrapper over type
constructors so these are all the benefits that you get by modeling
operations one article so let\textsf{'}s see whether this dsl program respond
which i and keep calling it an attic DSL is it really omona does it
satisfy Monad laws it turns out that no it does not satisfy mana flows
but it actually does satisfy them once you evaluate the program once
you interpret it so after you run the program that\textsf{'}s when the Monad
laws are satisfied and that is a very interesting property let\textsf{'}s see
why that is so so consider one more nut law this this is one of the
identity laws so flatmap applied to pure must be identity let\textsf{'}s see
if this is so now both sides of this law are functions on the moon'll
so Munna is this so it\textsf{'}s a function from this to this so we need to
apply both sides to some arbitrary program of this type and we need
to get the new value and see if that value is the same because that
should be identity so let\textsf{'}s see so what happens if we take a program
and we execute dot flatmap of pure on it now flatmap according to
our definition just makes bind data structure since nothing is really
evaluated we'll just put more these classes on the data structure
so that that is going to be the result now this value is a new data
structure it\textsf{'}s not equal to program PRG it cannot be equal because
it contains that thing inside a case class it cannot be itself equal
to a PRG so it means that this monitor law fails and we find that
other laws also fail because those laws usually say that something
is equal to something but all our operations if you look at the implementation
of flatmap and mount all they do is put more case classes on top of
things they don't actually simplify anything ever so for this reason
it cannot simplify this to PRT it will create a new bind and all the
other monad operations will create new case classes and never reduce
anything so basically the laws fail if you demand that they hold Vally
like this so our data structure DSL is not a lawful munna it does
not satisfy the laws but once you interpret this data structure into
a target monad and assuming that this monad satisfies the Lord then
the resulting values will satisfy the Lord and that\textsf{'}s a very interesting
property let\textsf{'}s see how that works so let\textsf{'}s run this value so how would
you run this value if you apply a run to this and by definition of
the code it needs to first run this and then apply flatmap with this
function and then run the results of this function so that is the
code and if we now symbolically evaluate this code will find that
the runner of the Val it will just give you a write of a let\textsf{'}s say
in the ether moment it will be really pure of a in general but I'm
just substituting the code from the previous line and because this
is a pure for the either moment the either moment has the wall satisfied
and so flat map of error is identity and so the result will be equal
to running the program PRG so in this way assuming that the laws will
hold for the monel m this both sides when we run them will won't be
the same so all other laws also hold I will show that next but think
about what it means it means that the violations of the Monad laws
that this data structure has are not observable once you run the computation
so the data structure and they have some extra information inside
that gets computed away it gets reduced or simplified when you run
or when you evaluate this into or interpret this into some target
unit so in this sense I would say that the moral law violations are
not observable when you actually observe or run or interpret this
program there are no violations so these violations are hidden somewhere
in this data structure and they don't change the results they don't
make the results invalid and so it\textsf{'}s okay to have those violations
so let me show you now in the code why the moon at law was called
after evaluating entire law faloona so we will reason by taking an
arbitrary DSL program and just denote by M the result of running this
program for brevity and let\textsf{'}s see what happens when we run monadic
operations on this program so for example let\textsf{'}s say that program is
a pure of something when we run that then we execute the code of the
runner and that code is a pure in the case of the either mona this
was the right of X but in the case of a general one other will be
pure of X so therefore running the pure of the DSL gives you the pure
of the target monad let\textsf{'}s now run the map in the DSL and get some
other ESL program with some arbitrary function f and by definition
is going to be translated into this and we run this we have to translate
that into flatmap because that\textsf{'}s how buying is translated and then
we get this combination now we know that when we do run dot flat map
this is a flat map in them monad M now if we look at this this is
a run of the pure so that is already as we know Emma dot pure so now
we have a flat map in the moon at M of F followed by pure so that
is the definition in the monad M of map so now this is equal to map
in limited M in other words running the results of map in the DSL
gives you the result of melt in the target monad and the same happens
with flat map if you run the result of flat mapping in the DSL which
is another DSL program and F is a function from some type a to a different
ESL program now we still need to interpret the result of this F in
the mana dem so this will give us a function G of this type instead
of a going to DSL of B it\textsf{'}s going to be a going to M of B this function
is like this is f and then run so now if we interpret the bind it
is going to be the flat map in the model M of F and then run and if
you just look at what that is that\textsf{'}s the function G that we defined
which is the evaluating of the result of the function f so in this
sense evaluating flatmap first in the DSL and then running the results
is the same as evaluating in the Monad M with a function G which is
obtained from F by running its results so in this sense all the Monad
operations in the DSL are directly translated by the interpreter into
the corresponding one at operations in the target one of them now
if we consider the laws it\textsf{'}s very easy to see that they hold after
interpreting now we already saw that in the slides for this right
identity long let\textsf{'}s look at the left identity law this it needs to
be verified we have apply run to both sides and we have to show that
run of this is equal to run of that so let\textsf{'}s evaluate the run if we
do the pure flat map then this is translated into that we run that
get run of Val which is just M of pure so you have a pure followed
by flat map of this but pure followed by flat map is going to be in
the Monon m and that is equivalent to just this function which is
G so that\textsf{'}s why the run of the two sides is the same because the run
of this is G of X the natural T law for pure is like this so the DSL
peer of X of f of X is the slf map of f of dsl P of X so now if we
evaluate run on both sides then this becomes ampere this becomes MF
map this becomes ampere so now obviously this hold because M has this
law too and finally associative 84 flat map it is this one so that
lets apply both sides to some program PRG and then apply run to both
sides so we have the run of this should be equal to the run of that
so if we now simplify this into the Monad m operations then we get
this now this flat map G is still a bit complicated because G is not
yet run in the moon and heaven into the moon and M so let\textsf{'}s use the
law and let\textsf{'}s rewrite somehow this expression so that we get associative
et law for the moon at M now the left hand side is this and it should
be equal to run of this which is flat map of F and the run flat map
of G and then run now notice these flat maps are in the m1 had this
flat map is in the M walnut but the argument of that flat map is complicated
so we do have the same law for the moon at em but we just need to
rewrite this a little bit so because that this is going to be M flat
map something flat map something needs to be simplified into M flat
map this and then that so how do we figure that out we rewrite this
complicated expression as an explicit function from a to - what well
first we apply F to a size F of a then we apply map of G which is
this and then we apply run so let\textsf{'}s run over all this so let\textsf{'}s simplify
now so run of F of a now if we run a flat map that\textsf{'}s the same as running
this flat mapping of running that so what\textsf{'}s this and equivalently
we can say this is just F and then run applied to a and then this
is flat map genome then run so if we get rid of this a now then we
get just a function f and then run and then M\textsf{'}s flat map of G and
then run so that\textsf{'}s exactly what we have in the associativity wall
for EM it\textsf{'}s M flat map of this is equal to that so now FM and GM are
just these FM then run is FM G and the run is G M so we get the associativity
law the naturality was for flat map could be verified as well we don't
need to do that since our code is purely type parametric and naturality
is automatic for that code so I mentioned that this construction is
called a free Monat and in the cat\textsf{'}s library is called free why this
word free what does it mean free why do we call it a free construction
well this terminology comes from mathematics in mathematics usually
free construction is a group or mono end or vector space or some other
kind of right construction that is generated by certain data with
no constraints so free means no constraints so let me illustrate this
is a bit vague so let me illustrate in two by two examples consider
two things and I will choose things that mean very little by themselves
the Russian lettered said and the Chinese word way the water say it
doesn't really mean anything by itself it\textsf{'}s just a letter of acrylic
alphabet and the Chinese word sway it means water but it doesn't matter
for now so now suppose what I wanted to multiply them I wanted to
multiply say by Chui so what does it mean to multiply how would I
multiply them so mathematicians first asked what kind of product do
you want do you want associative commutative distributive product
so let\textsf{'}s say we want an associative product not necessarily commutative
so mathematicians would then say very very well what you want is to
define some kind of semi group in other words a structure that has
an associative but not necessarily too negative product and you want
a semi group that contains say and Shui as elements that\textsf{'}s what you
want you don't and and you would say well but I have no idea what
these are would say in Shui is I've no idea no no worries I'll get
you a semi group that contains them and if you have a semi group that
contains on a semi group is a set and these will be elements of that
set and if you have a semi group that contains them then you can take
a product of them so here\textsf{'}s how the mathematicians would do it they
would consider the set of all unevaluated expressions of this kind
any onion valued expression with the multiplication sign or a product
symbol dot which I have here and one of these symbols say say or Shui
so this would be an unrelated expression this will be another undervalued
expression but we will have the law that this product is associative
so see this expression isn't equal to another letter of the Russian
alphabet or another Chinese word it\textsf{'}s not equal to any of those things
it\textsf{'}s just an expression that\textsf{'}s not evaluative it\textsf{'}s a new thing so
we have a set of a lot of new things and say and Troy is our one of
those things but there are a lot more of those things in the set because
we are considering the set of all unevaluated expressions of this
kind so the set of all these expressions is called a free semi group
generated by of the elements say and Shui and in some sense it\textsf{'}s the
most unrestricted semi group that contains these two things you could
have a lot of semi groups that contain these two things as elements
but this one is the least restrictive it\textsf{'}s the most free of all arbitrary
restrictions as long as of course you have associative 'ti of multiplication
so you can calculate in this semi group for example this is a calculation
that I can do I take these two expressions I take their product and
then I multiplied by this expression and I get this expression as
a result these are calculations that I would do in this free seminar
and what would I do with that well I could interpret the semigroup
value into another semi group for example integers imagine integers
as a semi group with multiplication as a semi group operation I say
that say is 17 and Troy is 3 so then these are just going to be 3
370 370 will take a product of all of those and I have a number so
I have evaluated this so in other words this is going to be some kind
of symbolic program that will later be evaluated in some way and that\textsf{'}s
very similar to what we have been doing with our DSL was a symbolic
program that was interpreted at the end into a specific values but
we can do calculations like this before evaluation and this is a similar
to combining parts of a DSL into a larger DSL program and while we're
doing this we still have the illusion we are performing these operations
so how do we represent this as a data type now the easiest thing and
what we have been doing so far is what I call the tree encoding in
other words we represent the free semi group as a full expression
tree so here\textsf{'}s an example each operation of product is just a pair
in the data structure so I have a tuple of this and this and I'm missing
one parentheses on the left I will insert that in the slides and after
the recording yeah so I have a tuple and this tuple represents the
free product of the tube Shui then I have this tuple which is a free
product then I have a free product of these two and finally a free
product of the result and it\textsf{'}s a and so that in this way I represent
my expressions it\textsf{'}s very easy and operations are very easy to implement
because in order to do for example multiplication I just put the two
parts into pop and I'm done so this is exactly equivalent to adding
one more case class on top and having a nested structure and in this
way I implement all my required operations but there is a another
encoding which I call reduced encoding and this encoding is smarter
it is less redundant and in this case it\textsf{'}s going to be a list of all
these things taken in this order this list is equivalent to what you
would write on paper because the associativity law means that it doesn't
matter where the parentheses are you can omit all parentheses and
they will still get the correct result and so since we know about
that we are clever and smart and we realize that the list of these
things in this order is sufficient it is sufficient information to
represent a value in the threesome Anoop now if we want to implement
the multiplication operation you cannot just put the two lists in
a tuple you need to actually concatenate the two lists and that could
be more expensive depending on your implementation of Lists it could
be a very quick Big O of one operation or it could be a more expensive
operation but this structure has no redundancy whereas this structure
has redundancy you could put parentheses in different order and it
will be a different expression tree although the final value is supposedly
the same let\textsf{'}s consider another example which is a product of n dimensional
vectors so what if I wanted to define a product of two n dimensional
vectors or we have such a product for three dimensional vectors this
is the well-known vector product in the usual euclidean three-dimensional
space but let\textsf{'}s ignore that and in any case I want product for n dimensional
vectors with any n and that doesn't seem to be generalizable from
three dimensional vectors so how do I do that all a mathematician
again will ask me what kind of product do I want I say well it\textsf{'}s a
product of vectors so I expect it to be linear and distributive not
necessarily commutative but I want a product that has these properties
for example I want to be able to add so linear means I supposed to
be able to add different products together and that should be associative
and I'm supposed to do this so if I have a linear combination of vectors
under a product I should be able to pull this thing out and expand
the parentheses and that\textsf{'}s a distributive law and the distributive
law should hold for left and for right as well all right says the
mathematician you need a free vector space generated by all kinds
of pairs of vectors from your own dimensional space so let\textsf{'}s do it
in this way we consider all unevaluated expressions of this form where
u and v are arbitrary vectors from your n-dimensional space so this
is a the first step the second step is to impose the equivalence relationship
so before this you gather just a free vector space you have all all
possible linear combinations of all possible products that\textsf{'}s the first
step the second step is to impose equivalence relations so you will
consider certain pairs of expressions to be equivalent according to
these laws the result is usually called the tensor product of vectors
and again we can have two in codings for the tensor product the first
encoding is the full onion valuated expression tree and that will
be just a list of these vector pairs and that could be a very inefficient
representation if you have a lot of those pairs but it could also
be a very efficient representation if you have a very sparse tensor
product the reduced encoding that is the encoding that has no redundancy
is to represent tensor product as an N by n matrix of vector coordinates
in some basis now reducing this expression to the matrix form requires
computation and it could be well first we need to prove that you're
encoding is adequate that for example this expression and this expression
always corresponds to the same encoding and then your laws would be
satisfied your preferences will be satisfied and any component operations
so we'll translate this into matrix and add matrices and so on but
do that so that\textsf{'}s a choice so this is why we use the word free construction
so basically we can use the mathematician the mathematics intuition
to implement data structures with properties generated by things that
don't have these properties you see the the common topic here is that
I wanted to define an operation for things that don't have this operation
like I wanted to multiply a Chinese and Russian together its word
and the latter it\textsf{'}s it\textsf{'}s not defined but I wanted to define it in
some way and I can in a free way so in the programming language we
just saw an example where I was able to define a monad out of a type
constructor that isn't even a function let\textsf{'}s look at some other examples
and here would be an example of a semigroup that\textsf{'}s generated by two
types so that\textsf{'}s kind of similar to my chinese and russian example
so how do we define that so let\textsf{'}s see how that works so let\textsf{'}s call
it FS is which is free semigroup from integer and string so a value
of FS is could be an integer or it could be a string also or if x
and y are already of type of a silenced and so is this combination
of ex-wife co-come the case class so i straightforwardly translate
this specification into the datatype and this will be the three encoding
it\textsf{'}s a full expression tree unevaluated and but that\textsf{'}s okay it\textsf{'}s a
good encoding for some usages the short type notation for this is
going to be this is recursive type that is defined by this type equation
so let\textsf{'}s think about how we can use it now if we have an actual semigroup
as a specific 7u and we know how to map integers and strings into
that same group then we can map this FS is interested in you that\textsf{'}s
our interpretation so let\textsf{'}s see how that works it\textsf{'}s a little too specific
with integers and strings let\textsf{'}s just put all of these domain types
into a type Z and make that type of parameter so then the three encoding
would look like this it\textsf{'}s a recursive type that\textsf{'}s defined like this
so I omit the Scour definition let me just write the definitions of
the methods so the method of semigroup operation is very easy I just
put the two arguments into a case class and the run method takes a
semigroup and an extractor function which Maps my Z into a semigroup
and that\textsf{'}s equivalent to the two functions that I assumed here before
just a single function from Z to s so then I get a function from my
free semigroup generated by Z to us how would that work I match on
the free Simon group it has two cases the case of F well I call it
rap here let\textsf{'}s call it f then I just oops I just extract I have a
value of Z and I call this function extract and to extract the value
of semigroup s from it and if I have a combination then I first run
these two and then I get two values of type s and I just combined
them in the seven group operation of s quite similarly the semigroup
laws will hold after I try this run they did not hold before applying
rather why is that it\textsf{'}s well it\textsf{'}s very easy to see that social Timothy
does not hold because I would have a comp nested in different order
and that\textsf{'}s not equal so it\textsf{'}s only after applying the interpreter that
laws will start holding and the reduced encoding is a non-empty list
of Z\textsf{'}s so that\textsf{'}s a reduced encoding actually I should have said here
it\textsf{'}s non empty list I didn't make that that remark MFG lists cannot
be constructed because you have to start with either sell or Shui
and apply the semigroup operation there is no empty value possible
so that\textsf{'}s why it\textsf{'}s a non empty list and then the combination operation
will require when you run this you'll have to concatenate the lists
but maybe the run operation will become faster because then you have
fewer structures to traverse as another example let\textsf{'}s implement implement
the feel annoyed the Fremen are generated by type Z it\textsf{'}s very similar
to a free summer the value of free monoid of Z can be empty because
it\textsf{'}s a monoid or it can be a Z and then you have a multiplication
so I should have called it comm not law so therefore the female noid
of Z in the tree encoding has these case classes the empty the wrap
which has the inside and the chemical combination which has two values
of F M of Z inside the short type notation for this is just like that
so here\textsf{'}s an implementation of there brother the plus operation simply
puts to the occasion top and the runner just does the same thing as
before and it puts the MS empty and Emma being Illinois it has an
empty element instead of this so when we interpret this tree structure
we just substitute specific operations of the monoi M except for the
wrapped case when we use the extractor and Malloy Clause will hold
after we apply this function so this was the tree encoding and the
reduced encoding is just a simple list where this operation is concatenate
in the lists the empty is the empty list and the wrap is a list over
one element and so it\textsf{'}s interesting actually to notice that after
running the trillion coding and the reduced encoding would give you
the same result there are just different in coulombs of the same value
there are not equivalent in terms of their performance perhaps and
memory requirements are different our equivalent in terms of the resulting
value let\textsf{'}s look at the code so here is an implementation of the free
moderate generated by type Z so Z is some domain specific type and
we have this combination and we just implement what I said in the
slides and here\textsf{'}s an example of using this definition so first I define
an annoyed of integers in the standard way and then I want to do a
free monoid over this this was my example in the slides so I define
Z to be that then I if I an extractor extractor is a function from
z to integer so how do I do that well if I have an integer I just
leave it there if I have a string I have length of the string it\textsf{'}s
just for this illustration so now I construct a free monoid value
so how do I do that well I use the wrap constructor to do specific
values of Z so either left of interest right of strength so I wrap
them and then I combine them with the plus operation so this is a
free monoid value which I can then run with my extractor and the result
is 16 because it\textsf{'}s 12 and then 3 the length of this and then 0 because
it\textsf{'}s empty and then one so all this must be added so that\textsf{'}s why it\textsf{'}s
16 so let me also verify that the monoid laws would hold after running
so let\textsf{'}s just maybe make extract into an implicit argument and not
not right every time or something just I'll just run of excellent
yes miss oh shit a beauty law so I run this and I should get the same
result as when I'm running it with people other order of parentheses
when I run this I run over this structure now you see this structure
still has the information about the order of parenthesis but when
they run it each comb is translated into the monoid operation plus
in the target memory M and so when I run it the second time I get
this result which is in the target monoid m and it has now no more
information about the order of parentheses and so when I run the other
order of parentheses I get the same result let\textsf{'}s check the identity
law this must be equal to the result of running X now this is not
actually equal to X because it\textsf{'}s this combination this class so as
usual the laws do not hold before you run because you are piling up
case classes but when you run that iran identity that becomes m empty
then you're on of X and that\textsf{'}s a monoid law in humanoid m that this
should be equal to run of X and so running of empty + X gives you
the same result as running X and the same will be for the other order
now in the reduced encoding it\textsf{'}s obvious that all of this works because
it\textsf{'}s just a list we know that list as I will know it so there\textsf{'}s not
much to implement and the runner however needs to go over the entire
list so the runner I'm implementing it using a fold over list and
I'm folding with the monoid operation in the target one with and I'm
running exactly the same code as before with pretty much the same
code except here I'm using a helper function to wrap my values I get
again exactly the same result so what if we interpret this free semi
group that we had before into another free semi group well that would
be an interesting thing to do in general we can interpret if we have
so for example free semi group generated by Y into a free semi group
generated by Z we can interpret if we have an embedding from Y into
the free seminar of Z that is certainly what we can do but we know
it\textsf{'}s a free semi group so what if we just haven't been emitting from
Y to Z not from Y to the free Simon group of Z there\textsf{'}s a free semi
group is a big thing it\textsf{'}s not maybe it\textsf{'}s much easier to do this indeed
that\textsf{'}s very easy because we just need to map this into that and it\textsf{'}s
straightforward because this is a fun trip so this type constructor
is a factor as you see it has the type parameter always in a covariant
position for positive position so this is a standard code that you
would write with your eyes closed to implement the map for this function
so now we can use that and have a chain like this we first map map
and then run let\textsf{'}s think about how we can simplify this well first
of all this is a functor so functor laws hold for its of' map is composable
we can compose these two functions from X to Y and from Y to Z into
a single function from X to Z and just F map once instead of F mapping
twice what\textsf{'}s interesting is that the interpreter also composes with
F map in a way and this is done by this diagram so if you first so
I'm killing the Z here so I have just FS x FS y and s if the first
F map X to Y and then run through some function G that is the extractor
from Y to s we should get the same result as when we are running with
the composition of these two functions indeed that is a law that the
interpreter satisfies and we can combine the semigroups in this way
and we can also combine them in disjunctive way why is that well consider
this semigroup we have obviously an injection from X to the disjunction
X plus y so then we can F map it and we automatically get this injection
which means that a free semigroup generated by a disjunction of some
types contains a free seminar generated by one of these types so in
this way we can combine semigroups in easily if we know the types
of free semigroups to combine free semigroups if we know the types
from which they were generated so next we will consider what we can
do further to simplify mapping free semigroups to different targets 
\end{comment}

\begin{comment}
if we need to map a free semigroup into multiple targets in groups
say s1 s2 and so on then it would require many extractor functions
with this type signature each extractor function will have to convert
the generating element Z over the free semi group into a specific
segment Rufus 1 as 2 and so on we can refactor these extractors it
into evidence of a typeclass constraint so instead of saying we have
a semi group s and we have this function for that semi group it would
say we have a semi group s that additionally has a typeclass constraint
and so we define a new typeclass let\textsf{'}s call it X Z for extracting
from Z and it has a single method of this type signature then we can
refactor the run function into this form it will be now parameterize
by a semi group s that additionally to the semi group typeclass also
has an extract Z typeclass instance and that would mean would have
an evidence on value of this type which would contain this function
so that\textsf{'}s very similar to what we had before when we had the run method
it had an argument containing the extract now we will have no such
argument we'll just have an argument specifying the free semi group
value and additionally we'll have a typeclass constraint which in
Scala is translated into an implicit argument of the type exe of Seminole
which will just contain this extract function so far this is a refactoring
that doesn't seem to bring a lot of benefit except that now this code
is going to be completely the same for all extractors and we just
need to define different extractor typeclasses for different semi
groups so another refactoring that will follow from this is found
if we look at the structure of this run function so what does it do
it translates the free semi group value into a value of the specific
semi group s by pattern matching on the case classes from the free
semi group and the free semi group has two case classes the rapp and
the combined case class what the run does is that it replaces these
case classes by some fixed functions and these fixed functions are
permit rised by a semi group having this extractor constraint so all
we have done is first we have created a value of free semigroup which
will be some case classes and then we just translate these case classes
mechanically into these fixed functions so the main idea of what is
called the church encoding is to represent the free semi group directly
by these functions just skip the case classes all these cases class
case classes do is to denote what needs to be done what these functions
will have to do when we run the free value so instead of representing
a free semigroup through these case classes represented directly through
these pieces of the run function in other words instead of saying
that the free symmetric value is of type rap we say it is equal to
this function which will be terrorized by this semi group s with two
typeclass constraints so here\textsf{'}s what will happen if we do that we
will have two functions so one would be the combining function and
one would be the wrapping function but the combining function actually
is defined in the semi group s it is not something we define so really
we just need to define the wrapping function so this wrapping function
will be this part of the room and the combining function is already
defined because the plus operation is part of the semi group typeclass
so the definition of the free semi group just becomes the definition
of a wrap function which is parameter I'll begin by by this we don't
need the semi group constraint right now for this function we could
have written it but we wouldn't have used it and then suppose we want
to define the value X of type free semigroup which would be say combination
of wrapping one and wrap in two instead of doing that we just write
down this so you know what these are values of the free semi group
and these values are now deaf because they're they're not vowels their
deaths because they're actually functions parametrized by a type parameter
and having implicit arguments so they cannot really be valid anymore
because they're parameterize by a type parameter that\textsf{'}s another difference
so now we have encoded this X so this X is basically a function that
already runs it\textsf{'}s waiting for you to give it a semigroup yes but once
you give it then it will run and all the implicit arguments will be
substituted and you will have a value in your signature but until
then you have defined it and it\textsf{'}s waiting for you to run it so this
is then the encoding of the free semigroup using functions using directly
pieces of the run function so we don't need a run function anymore
we already encode values on the free semigroup through the pieces
of the run function that would be run in the previous encoding so
the previous including is a tree encoding or the expression tree encoding
this encoding is called the Trojan Colin let\textsf{'}s look at the type of
X explicitly let\textsf{'}s drop all this syntax what is the type of X well
it\textsf{'}s first of all is parameterize by a semi group type s and so this
is a function that will work for any type s so let\textsf{'}s write it down
explicitly as a universal quantifier which will be read for all s
so for all s we have a function that takes the extract Z typeclass
evidence which is a function type z2 s it takes the semigroup class
Evelyn\textsf{'}s likewise evidence which is this method and it produces the
value of s so in other words it is this function which is parameterized
by type s so this should work for every s and we want to write those
explicitly using the universal quantifier now we can simplify this
type using an identity but the product of these two functions is equivalent
to a single function from disjunction of Z and s times s to s so now
this type which is equivalent to this type which is equivalent to
this this is the church encoding of the free semi group over Z or
free semi group generated by a type Z I call this charge encoding
for reasons that I will explain but look at this type signature this
type signature looks a little bit like a continuation monad continuation
monad would have this type now we have this and then these two nested
functions they are very similar to a continuation monad but it isn't
really that it\textsf{'}s it\textsf{'}s not really a continuation monad because of this
quantified type the continuation monad has a fixed result type R it
is not quantified over that type does not permit rised by that type
and does not have for all our in front of this but we do have for
all s because this is our type parameter in the function so each value
over the free Simon group is a function parameterize by an arbitrary
s s being a concrete non free semi group or github perhaps another
free semi group but eventually it must have must be a non free Simon
group in order to get any values onto this non free actual useful
values so that\textsf{'}s the type now there is a theorem in type theory which
is that this type expression is equivalent to just a type a I will
present a derivation of this somewhat informally but this is the basic
fact that is at the basis of the entire idea of the church encoding
what I call the church encoding of a type a is this type expression
so whatever type a is you can just say I have a type a or you can
say I have this function parameterize by an arbitrary X with this
type signature that\textsf{'}s equivalent to having a type a so I call this
the church encoding of other type a and so unlike the continuation
monad the the presence of the universal quantifier makes this function
fully generic in X and it becomes like a natural transformation between
this factor and this identity factor so this is a reader factor with
type a being read X is the parameter and this is the identity function
with X as the parameter so this is resembling a natural transformation
between these two functions and we know that if this is a a function
with fully parametric code in other words code that does not use any
type information about X then this will actually be a natural transformation
so there is however a bit of difficulty in understanding how to work
with Church encoded types there are complicated there is this function
whose argument is again a function and it\textsf{'}s parameterize over arbitrary
X it\textsf{'}s actually not easy to reason about such types so in order to
develop intuition let us consider a simpler example where we take
a disjunction type just an ordinary disjunction type not a functor
nothing like that just an ordinary disjunction of types P and Q and
let\textsf{'}s work with its Church in Korea so by definition the church encoding
of this type is this type expression now we can simplify this because
it\textsf{'}s a disjunction in a function argument and this is equivalent to
a product of two functions from P to X and from Q to X and this is
equivalent to a curried function with this type so so far I have done
nothing but I have equivalently transformed this type into this for
convenience now in Scala in order to implement such things I have
to hide this type parameter somehow I cannot have a type so I need
to have a type that has inside it inside of it a def with type parameter
so in order to hide it I have this Scala code which is the usual pattern
for putting a universally quantified value into star distance car
does not have the universally quantified values it must be a def as
I did before now this is not very convenient you want to have a Val
with the universal quantification inside so in order to do that you
define a trait let\textsf{'}s call this trait disjunction it\textsf{'}s going to be
church and call it disjunction P and Q are going to be just parameters
for it I didn't necessarily have to do it this way importantly the
street has a method inside that is parameterize by X and this X is
not one of these type parameters so this type parameter X is hidden
inside the trait in this way as a method of the trait and when that
happens when a type parameterize function is a method of the trait
it means that you can call this method with any type parameter X so
in this way it implements the universally quantified type X and it\textsf{'}s
very easy to just write down this function signature like this so
how can we define values of this type so for example we define left
given some ULP we want to define a left part of the disjunction we
need to create a value of type disjunction so in Scala this would
be creating a new anonymous class by extending this trait and implementing
the method round so this is Scala\textsf{'}s boilerplate for hiding the universal
quantifier but then we just need to implement this function which
is easy we need to return X we have the two functions P to X and Q
to X and we have a P so how do we return X we'll just call this function
on the P so in this way we implement the left we'll also implement
the right in this way we can create values of this type now quite
easily so suppose that this this this G is a value of this type how
can we implement a case expression well we can just call the run method
on two functions like this and that would be actually the case expression
so the result would be of type X because that\textsf{'}s the result of the
run so in this way we program with disjunctions in the church including
and note that this would work in any programming language that has
nameless functions it does not the programming language does not need
to have disjunction types built-in so all we need to do is we need
to create this construction which does not have any disjunctions inside
now this does so this I would not be able to implement in a programming
language that doesn't have disjunctions but this I can implement in
such a programming language and so actually I have heard that people
have used this trick the church encoding for implementing disjunctions
in JavaScript the GU language also comes to mind as a very primitive
type system and I'm not sure how but with generics it would certainly
be able to implement disjunction types Java could do this too so general
recipe for church encoding is that you need to hide your universal
quantifier so you create a trait with method which adi will always
call run in this tutorial this method has an argument which is this
continuation like function or this function maybe several of them
may be a product of them if you have a disjunction and then you can
also think about making it more convenient so if you have a lot of
things here and not just one function but a lot of parts of the disjunction
this could be cumbersome so you could split it into products product
of functions and then you could say this is a value of some type so
you could even do a trait or a case class and parameterize by X containing
just this argument of the Church encoding just for convenience and
this is specifically very convenient with disjunctions because you
could just define like this instead of defining a run method with
this type signature define it as a function from exo X to X and so
this is actually much easier to use with languages such as Java or
JavaScript where you have objects with methods but you do not have
disjunctions now notice that case expression which replaces pattern
matching for these junctions is actually consisting of running this
function so the church encoding of the type is a function and calling
that function means running so just like in the free type constructions
when you interpret the free value or DSL or your interpreter runs
you get some final value that\textsf{'}s in the Church in Korean means you
call this function and get your final result the church encoding in
some sense encodes your DSL or your operations or your program your
declarative program encodes in terms of pieces of the interpreter
that are necessary to run it and so pattern matching is impossible
on functions you cannot determine whether this function uses its argument
or not for example by any kind of pattern matching on this function
value you cannot do that the only thing you can do is to run this
function so one deficiency of church encoded types is that they have
to be run in order to a pattern match they cannot pattern match say
on disjunction without actually having some kind of result type some
kind of target X and putting that X in there putting the extractors
in there and running this function now certainly you could be clever
and your ex could be another Church encoded something else so you
or non Church encoded something else you could very easily convert
this back into the ordinary disjunction type and then you could pattern
match on that but in order to convert this to anything you have to
run it so Church encoding has certain advantages it is easier to work
with if you have many targets and we will see other advantages of
the church and queen it does have also disadvantages and I will talk
about them but one disadvantage we see right away is that pattern
matching is impossible until you run or unless you actually run your
church encoded value so let us see how the church encoding works so
why is this type equivalent to the type a so let\textsf{'}s just consider this
very simple church encoding of a fixed type a which will be implemented
like this so in order to show equivalence between the church encoding
and the type a we need to present isomorphism between the types which
is a pair of functions from a to the church encoding and from the
church encoding vector a and we need to show that these functions
are inverses of each other so that a composition of these two functions
in every order is identity so if we have a value of a how do we get
the value of church encoded a well if we have a value of a then in
order to produce this we take this argument which is a function of
a and apply that function to the value of a that we have the result
will be a value of x which we return so that is the code I just applied
this given function or the continuation argument if you will to the
given value of a so that is in one direction in the other direction
in order to extract a out of this we can call well the only thing
we can do obviously on this value which is a function is the call
that function on which argument and with which type X that is our
choice so we call this function by calling run with type X equal to
a so like this and in an argument which is identity function from
a to a the result would be some a so that\textsf{'}s our second converter c28
Church included two direct type so it remains to show that these functions
are inverses of each other so how do we do that let\textsf{'}s think about
how could it be that we have a value of this type for any X given
this function we're able to produce a value of x now if I I'm able
to produce a value of an arbitrary type X and I don't know anything
about that type the only way I can do that is by using this function
somehow and this function needs to be called to produce an X on some
value of a so unless I have a value away I can't possibly have this
so this is the intuition that explains why this type is equivalent
to a the only way of having a value of this type is to have some value
of a now this value what if I have two different values of a well
the problem is I could only use one of these two values because I'm
supposed to produce this which has a universally quantified X and
I'm not supposed to look at X so this is supposed to be generic in
X so I could not for example check whether X is integer then I use
one value of a if X is not integer then I use another value of a that
is not allowed by by this type this type is fully generic in X and
so I am not allowed to use any specific information about what the
type X might be I could not write code like that I mean I can write
code like this and scholar of course but that is not what this type
is this type says this is a fully generic function which is a natural
transformation from this function to this functor I'm not allowed
to look at the code of X at the type of X I'm not allowed to use reflection
for instance or any other information about the type of X or or the
value of anything I'm supposed to be completely generic so if I had
many values of a at my disposal I be forced to choose one of them
for all X and use that one value of a in order to create this thing
for all X in other words the only way to have a value of this type
is to have a fixed value of a and then this is how I'm forced to implement
a value of this type so that\textsf{'}s intuition now I would like to be more
formal and show that for any Church encoded value CH if I first convert
it to a using this converter and then I converted back to CH then
I have the same stage as I started with but what does it mean I have
the same CHCH as a function so this function must be equal to that
function now equality of functions means if I substitute some argument
into that function I get the same value as a result by applying this
side and this side so let\textsf{'}s apply both sides to some function f of
type a 2x and then we can simplify this so what does the CH run of
f is on the left hand side and the right right hand side is this run
of F now this run of F we can see what that is it is a continuation
of a which means it is an F because the continuation is going to be
F the argument of run is going to be f so f of this now substitute
the definition of c2a it is this and F of that so see H dot run of
a to a now we cannot really simplify this anymore because we don't
know what CH that run does it is a arbitrary given value of this type
so we don't really know what it does when we call it on a to it but
if we look carefully at this equation so we are now required to prove
that this is equal to that looking careful in this equation we find
that this is the condition of naturality of the function G H run as
a transformation between the reader factor and the identity function
applied at type X this is a natural allottee condition here is how
I can illustrate this using a type diagram naturality condition means
that if we do an F map so we have one factor on the left another factor
on the right we have a natural transformation between them if we now
F map with some function on the left and we F map with the same function
on the right diagram should commute and this is precisely the equation
what we have written here run over F is precisely that F sorry I'm
I'm confused it is this direction first the left hand side is this
direction this is the run of F and the right hand side is this direction
first Iran of identity and then you apply F to that so the left-hand
side corresponds to this direction on the diagram and the right-hand
side responds to that direction on the diagram commutativity of the
diagram is therefore exactly the same as this equation so in other
words we have shown that this function will be equal to that function
as long as we demand that this is a natural transformation so this
code must be fully generic should not use any type information about
X and the counter example would be looking at the type of X and using
different values of a to create a to see here so calling this on different
values of a depending on what X is so that we could write this code
in Scala but this would not be an actual transformation the other
direction is easy very fun if we just substitute the code C to a of
a to C of a C to a is this and then a to C away as a run function
and then you have identity applied to a and that\textsf{'}s 8 so in this way
we can show more formally that this type the church encoded a is actually
equivalent to the type a as long as we understand that this must be
fully generic code and in other words a natural transformation that
means these two parameters and another property of the church encoding
is that since it is built up from parts of the run method of some
typeclass usually it will automatically satisfy the laws of that typeclass
now this example as well as this example were not examples of typeclasses
that are and what I was going to church in code this example was a
typeclass the tie church encoded the free semi group and the property
of the church encoding is that it will automatically satisfy the laws
and the reason is we know that laws will be satisfied after you run
the typeclass a free time class instance this we already saw and therefore
since our church encoding is basically functions that run and the
only way you can use them is to call these functions then Church including
will satisfy laws automatically in the same ways this function is
equal to that function which we verify by calling these functions
applying them to specific arbitrary argument a war for a typeclass
means that you need to run the church encoding and then compare the
results so since we know that the run method for free typeclasses
satisfies the laws it follows that the church enrolling over free
typeclass will automatically satisfy the laws of the type course so
this is a very nice property of the church encoding let us look at
the code of church encoding a free similar here we define the extraction
as a typeclass and then in order to define the free semi group we
have very low to work left to do unlike previous implementations where
we have to first define case classes and so on we don't define any
case classes here the Reb constructor is like this and then we are
ready after this we have defined the extraction typeclass we are ready
to start working with seven group values don't need any anymore preparation
so here is x and y these are already values of the three seven groups
so here\textsf{'}s a computation we wrap one wrap to wrap three add them that\textsf{'}s
it we have now defined x and y these are three similar values no more
ceremony so this is another good thing about the church including
perhaps in order to interpret we don't need to define interpreters
these are already interpreters let\textsf{'}s see how that works we will interpret
this threesome in two string which would have a standard seven group
instance so let\textsf{'}s define are those standard semi group instance for
string now in order to extract into string we need to have an extractor
so let\textsf{'}s make it available so now string has a typeclass instance
of the extractor typeclass and we can run that\textsf{'}s it that\textsf{'}s how we
run we do need to specify the type parameter but that\textsf{'}s it so we don't
say or run this with that extractor all of that is in place and so
we have a lot of computations in our DSL those computations are going
to be more concise here is the code for implementing disjunction with
some testing here is for example how we have a case expression so
X is a disjunction which is left of ABC and here we want to match
on X and we have the two possible cases and that\textsf{'}s how it works so
now we have seen the encoding coatings of three typeclasses let\textsf{'}s
now look at examples and have a more have more intuition about how
these including actually work and what are the trade-offs in each
of these in committees the simplest typeclass that has type constructors
is factor now until now we are looking at the semi group or Minh mono
it now these are typeclasses for types functor is a typeclass for
type constructors and for type constructors things are a little more
difficult and there will be more syntax and more type notations however
they are quite similar to non-constructive typeclasses in very important
ways they are very similar so keep in mind that free semigroup Freeman
or your free filter are basically applications of the same construction
to different typeclasses in order to construct a free functor the
first question we need to ask is what methods is typeclass requires
so there is one method let\textsf{'}s look at this method so the tree encoding
of a free factor would have directly encoded this as a case class
let\textsf{'}s call it f map and it will also have a case class for wrapping
a type constructor that we base that we generate from so to remind
the free functor typeclass needs to be generated by a type constructor
so we don't just have a free semi group we have a seat free semi group
generated by type Z so we don't have a free functor we have a free
functor generated by a type constructor if we need to start with some
type constructor which doesn't have to be a functor it can be but
it doesn't have to be so we I call this free funder over F now I introduce
this notation this bullet in order to emphasize that F is a type constructor
it has a type argument here which I'm not writing I could write F
a but a is not known is an argument so it\textsf{'}s a type function really
so I'm trying to find notation for type function so in Scala it'll
be like this and I don't like this notation so much but it\textsf{'}s okay
but in my short notation I right now found this to be a little better
more visual so this is a type constructor F that waits to be given
a type arguments so just like this in Scala and so this is the tree
encoding of a free factor so I call this a tree encoding because this
encodes an expression tree unevaluated expression tree for a functor
valley now what did I do in order to write this code are basically
the wrapping now a trait must be there this is a scala syntax for
disjunction so I need a disjunction so one case class raps a value
of F of N and the other case class raps this so it\textsf{'}s it\textsf{'}s going to
denote the result of applying F map to a free constructor note that
this F map has an extra type parameter because we extend the F of
a so I have chosen the name Z here the result of F map is F of a so
we extend f of a but the arguments of this case class or the parts
of the case class have a parameter Z it\textsf{'}s an arbitrary FZ which is
going to be this free functor of Z which we map with a function of
Z to it and the result is a free factor of a so this type parameter
Z is hidden inside the type constructor we extend F of F F F F a naught
of Z so the Z is not visible outside so we outside we will think this
is a value of this type but actually inside it has a Z now this is
a very interesting situation that we have a case class permit rise
by an extra type parameter which is hidden from the outside type and
let us look a little in more detail about what it means to have such
a type parameter let\textsf{'}s consider a simpler example simpler than all
this and write this code so I declare a sealed trait with a type parameter
a and inside it I have a case class that is permit rised by another
type parameter Z and it has values but depend on Z but it extends
key of it so it hides the Z from the outside type let\textsf{'}s look at how
this works what if I wanted to construct a value of type K of F how
would I do that well here\textsf{'}s here\textsf{'}s how there\textsf{'}s only this case class
so I have to use this case class and I have to specify some other
type for Z let\textsf{'}s specify string and then I would have a value which
has visible type Q int but actually inside it\textsf{'}s hiding a string type
and it knows that it\textsf{'}s hiding experiment right so it could have been
another type so when we have a value Q of this type we know that it
is integer in this parameter but we don't know what is this other
parameter Z we know that it exists inside Q hidden inside Q so it
is called the existential quantified type so this is a tie Plantation
that I would use to denote this this definition this definition is
a type constructor with parameter a witch inside hides a type Z which
must exists also to build a value this type we need to find some type
or select some type Z put it in put a value of this type in there
but we hide it so other outside we don't see that Z it\textsf{'}s exists inside
so this is a notation and this is called the existential quantifier
so this existential quantifier basically says that this I constructor
it has this type so the function qz construct s-{}- a value of key
of a so it hides zi some very interesting thing so the syntax says
that qz is parameterize by both NZ but rho is very different for a
and precede the role for Z is existentially quantified because it\textsf{'}s
hidden from the outside role of a is a type parameter visible from
outside and the functor ends in a so this is always a factor in a
it is not universally quantified so even though it\textsf{'}s a type parameter
here it\textsf{'}s not universally quantified with respect to Z and this is
so because when you build up a value of this type you must use a specific
Z it will not work for another see later it would have that specific
Z baked in the value Q once you construct it so that\textsf{'}s why it is an
existential quantifier and not a universal quantifier but the code
does not show this explicitly the code is a bit confusing we have
just seen a universal quantifier in the code here and here and the
way to implement this universal quantifier was to have a method insider
threat a trait and the method was paralyzed by this X the way to have
an existential quantifier is to have a case class inside the trait
and the case class experiment rised by the Z the method inside the
trade hides the X because the X is not a parameter here the case class
inside the trade hides the Z because the Z is not a parameter here
so until now it\textsf{'}s very similar but case class is not method quite
rate so this is the crucial difference so if it\textsf{'}s a method of a trait
then this would be a universal quantifier a method that has an extra
parameter hidden from the outside a case class with an extra parameter
hidden from the outside that represents the existence of quantifier
so we have to keep track of this ourselves the syntax of Scala does
not help so much to keep track of this but this is a very significant
difference between the types 
\end{comment}

\begin{comment}
so we need to keep in mind that the encoding of the three-factor uses
here Z as the existence of quantified title to get a little more intuition
about how the existence of modified type works let us consider a simple
example similar to this one where you have existential quantified
type Z with a function mapping it to something and another piece of
data containing that type so consider this type expression just temporarily
I denoted this by P a and we will now show that P a is actually equivalent
to the type a a scholar implementation of PA would look like this
we would have a sealed trait and a single case class that hides the
type Z now imagine we would like to construct a value of P a where
a would be some fixed type say integer in order to construct it it
would have to use the case class easy and we would have to give some
value of the type Z and the function from Z to a so imagine that we
have the type Z equal to a well it\textsf{'}s our choice we can choose that
we give a value of type a and here instead of this function will give
identity we can always do that for any type a and so this means we
can always build a value of this type if we have a value of type a
so that gives us a function that converts from a value of type a to
a value of this type just inserting identity function here and inserting
the value a here and setting Z equal to a so we are free to choose
what Z is when we construct the value of this type so this gives us
the equivalence function in one direction from a to P now how about
extracting a from P if we have a value of this type we actually cannot
extract Z out of it so a value of this type contains Z as part of
it but we don't know what the type of Z is and because the type Z
is hidden we cannot extract it out of the function PA we cannot have
a function whose type is unknown whose whose type signature contains
an unknown type however what we can do is we can extract a out of
PA in order to do that we need to apply this function to this value
this is the code and we don't need to know what the type disease this
would be some unknown type the function f has the right type signature
so that we can apply it to that Valley so this is a well defined value
and so in this way we can extract a value V out of PA no actually
we cannot transform PA into anything else other than into a value
of type a because this data only allows us to get a Z or to get this
function or to apply this function to this now we cannot get a Z out
because we don't know the type of Z we cannot get this out because
we don't know the type of this function so we cannot write code that
says take a pee and output some unknown type that doesn't work in
Scala the result type of the function must be given must be fixed
before you can write the code of the function so this means this value
is observable only via this function so the only way of doing any
computations with this PA is to apply is extracting function and to
get an A out of it and so if you wanted for example to compare two
different values of type PA then you cannot directly do that because
you don't know what what Z is you cannot look into it it\textsf{'}s hidden
so the only thing you have to you are then forced to do is to extract
an a out of this and compare the resulting values of type a and so
for this reason the functions a to P and P to a are inverse to each
other when we use P to a in order to come compare any values of type
P a so this can be shown relatively easily thank you for example take
a composition of a to P and P to a in one or another direction and
you can substitute the code in one direction this will be identity
of Z so that\textsf{'}s clearly going to be identity in the other direction
you have this and this should be equal to the results on so this a
equal to a PTA of sum P and that should be equal to that P in order
to show the isomorphism in the opposite direction so that requires
us to compare two different values of type P of a and we have to do
that by applying P to a to both sides and that\textsf{'}s what will again give
us identity so I skipped this calculation but this is very similar
to what we did for proving the identity of types and a couple of slides
before when we used the universally quantified type so this proves
this equivalence and actually there is a stronger version of the equivalence
which is this if you have a functor if so this is not a free construction
this is just a given factor then this is equivalent to that factor
and this is proved in a very similar way the only way to observe a
value of QA in other words to compute anything out of it is to extract
an FA out of it you can extract an FA by taking FZ and doing F map
with this function and you can't extract anything else cannot extract
an FZ out of it because you don't know Z you can't extract this function
out of it you don't know what this function is what would the type
of this function is so the only thing you can get out of this QA is
some value of type of a so that\textsf{'}s the transform transformed q2 f f2
q is similar to this one you take an affiliate take identity function
and very similarly we can show that these two are observational inverse
is now they are not directly inverses in a sense because you cannot
directly compare values of this type because that contains some unknown
type Z inside and what if this type is different however this type
Z is not observable even if it\textsf{'}s different so you have some value
of Q with one Z and another value of Q with another Z you cannot see
that this type z are different in these two values you have to first
extract the observable value out of this which is a value of this
type once you have extracted it you compare those so this is what
I mean by a traditional equality and so you can show that these two
functions are inverse of each other when the Equality is understood
as observational equality so whenever you compare values of this type
instead you extract FA by using this function and compare the resulting
values so this is how the existing shop type works now in the free
functor construction we use the extensional type and we can rewrite
a construction using this type expression so I just taken this code
I have rewritten it using the type notation that I'm using so that
is the definition of the free function so this is a recursive definition
because we're reusing the type FF itself as we are doing here so if
F is reused as part of one of the case classes so this is the tree
encoding in other words this encodes the young unevaluated expression
tree of an expression obtained from with a free factor of values and
operations so there are operations which are insert an FA into the
free function and apply and a map to free frontier so using these
operations in any order we gets arbitrary values of the free functor
so let us derive reduced in cooking to derive the reduced important
we start from the tree including we try to see how it could simplify
values of the tree encoded type using the laws of the typeclass so
the furniture typeclass has two laws there are the identity and the
composition law and composition is also associative so that\textsf{'}s another
property so we need to see if we can simplify values of this type
so let\textsf{'}s consider values of this type any value of this type you must
be by construction either wrapping of this or it will be a previously
constructed value of this type multiplied by a function like this
so essentially we have to start with some wrapping and then we multiply
a few times every time we multiply so we use a map function every
time we do that we add another existing type parameter so then we
have all these existential type parameters then we have the first
wrapped value of this type constructor F which is not necessarily
itself a functor and we have a bunch of functions of different types
now all these functions must be composed associatively in other words
the law of composition is that the result of mapping with this function
and then later mapping with another function and then later again
mapping with another function must be the same as a result of a single
mapping with the composition of all these functions and the composition
is associative so in other words we should be able to simplify this
value into a product of this and the single function here which is
composed out of all of these and the result of the composition doesn't
depend on on the order in which we evaluate the composition because
of associativity so therefore by using these laws we can simplify
this expression into this expression where there is only one quantified
type all of these other types are not visible anymore because we're
not using them and there\textsf{'}s only one function here or also there is
a possibility that we just have this no functions and this possibility
should be equivalent to having this value mapped with an identity
function because of the identity law for function so therefore we
can say let\textsf{'}s just always have this type and if necessary put identity
function here and we always have some value of type constructive F
and we always have a single function but we no longer have disjunction
because we can represent this case by putting an identity function
in here due to the identity law of the factor so this concludes the
derivation of the reduced encoding so the result is this formula which
means we have successfully simplified this expression we got rid of
a disjunction and we got rid of the recursion this is non recursive
we don't use the recursive instance anymore we just found that it\textsf{'}s
equivalent to have just type constructor F and that\textsf{'}s the reduced
encoding of the free factor so the only important remark here is that
it requires a proof that actually this is a reduced in Korean so by
definition a reduced encoding is such that it respects the laws so
if you apply for example map to a value of this type with identity
the result must be equal to this it must so it is not true for the
tree encoding the result will have an extra function here an extra
existential type and so on and that\textsf{'}s kind of not good enough for
reduced encoding it must not be there so the reduced income must satisfy
the laws and that\textsf{'}s what it does so it requires nevertheless some
ingenuity we have to derive it doesn't follow automatically what it
should be and the proof that it is equivalent to the tree in holding
and satisfies a lot another good result from reduced encoding is that
we can see what happens when the type constructor from which we generate
the free function is already itself a functor so if we are taking
a free factor of a tied over a type constructor that is already a
factor then as I already already said this expression which is that
is equivalent to the factor itself so so this type is going to be
equivalent which means that while there\textsf{'}s no harm done including this
free function except maybe performance will suffer you have some extra
stuff will have some identity function here\textsf{'}s a mother function basically
you are just postponing the map there might be some advantages in
doing that which I will show because you can make this stack safe
but this will certainly be a performance hit so don't do this if the
type constructor is already a function if you can avoid it but there\textsf{'}s
no harm done it\textsf{'}s the same equivalent type so you won't have more
information so proud so this is an interesting property because usually
what happens with free constructions is that they wrap you're generating
type in some stuff and so they add information to it so the resulting
type is usually not equivalent to the type constructor that your racket
but in this case a physical one so for functors functors are special
and free functor all over a functor is equivalent to that function
so that\textsf{'}s a special property finally let\textsf{'}s look at the church and
according now this is a more challenging task because we are dealing
with the type constructor so we let\textsf{'}s start with this and what\textsf{'}s children
coldness now church encoding means we need to add a universal quantifier
but since our result is a type constructor the universal quantifier
must be for a type constructor so the church encoding that I have
shown before was for a ordinary type or a free semigroup or something
like that for a free semi group the type is not a type constructor
for a free factor it is a type constructor so therefore the church
encoding must have a universally quantified type constructor in it
and things are just going to be more complicated because here\textsf{'}s the
structure of the type expression in the church encoding of a type
constructor we have a universally quantified different type constructor
then you have a function from your type to that type constructor and
again from that to your type constructor so that\textsf{'}s the general structure
of the church encoding but because the insides are type constructors
then this must be natural transformation so this must have another
Universal quantified type inside so I use this squiggly arrow to indicate
universally quantified functions such as natural transformations just
it\textsf{'}s the same error it\textsf{'}s just suggestive so that like keep track of
where I have universally quantified where I don't so if you follow
this structure then this is going to be the entire expression for
the church encoded free function now this is starting from the tree
encoding we have a choice what do we charge encode which version code
this or do we charge encode this and they're going to be two different
Church encoders so starting from the tree encoding that\textsf{'}s what we
need to do now there\textsf{'}s one interesting side of the church including
that I'm going to explore in more detail now which is that the recursive
use of the type is not seen in the church including in instead he
replaced that with this universally quantified type constructor that
is present so to speak so instead of the recursive use of free factor
here I have this universally quantified P that is a very important
part how church including works with recursive types and just before
we go through that I want to remark that in this expression the quantifiers
cannot be moved and you cannot move this quantifier to the outside
it is really inside these parentheses that the C is dis quantified
so to all see this function is given so for all C this function is
given and that function is the argument of the outside function so
this is important for the church included so you have several layers
where types are 25 this type quantifier is specific to the free functor
this wouldn't appear if we had no type quantifier here so this is
specific but this would be always true for any Church including of
a type constructor have a type quantifier inside that cannot be moved
to the outside and of course also you cannot move this existential
quantifier to the outside so for this reason when we write code we
have to take care to hide these quantified types at the right place
inside the data structure so let\textsf{'}s look at in more detail on at how
church encoding deals with recursive types and with type constructors
so let\textsf{'}s consider an example here\textsf{'}s a recursive type not a type constructor
it\textsf{'}s just a type with fixed type Z it\textsf{'}s a tree with leaves carrying
values of type C the church encoding of this type looks like this
so I'm looking directly at our encoding of the fee-free mono which
was very similar and this was the encoding the church including of
the free memory so we know this is correct now let\textsf{'}s look at how it
works we take this expression which uses the type P recursively twice
and we write it here but instead of the recursive type P we replace
that with X where X is the universal quantified type given outside
so in this way the church encoding replaces the inductive use or recursive
use of P by using this parameter X so the result is a non recursive
type expression or at least it doesn't look recursive it does not
use itself somehow to define it it\textsf{'}s type but it is equivalent to
this recursive type so it\textsf{'}s very interesting that just by using a
type quantifier you can remove type recursion well at least on the
surface you don't of course actually remove it because the type is
equivalent it\textsf{'}s still encodes a tree with devalued leaves so it\textsf{'}s
still a recursive type or your recursive data structure but it\textsf{'}s encoding
does not show recursion so that\textsf{'}s that\textsf{'}s interesting so how shall
we understand the way it works this is a run method of a declarative
way encoded DSL and so this method tells us that in order to extract
a value what you need is to be able to extract value from this and
here you have again these values how would you ever get the value
X in practice in practice it would have to call this function on a
Z several times to get some X\textsf{'}s and then you would put these X\textsf{'}s in
here call this function again to get some more X\textsf{'}s and so on so in
practice it is a recursive process it can encode recursion but all
of this is already encoded in this function so the type does not show
recursion so in other words how can we produce a value of type X and
we don't know what that type is it\textsf{'}s we're required to write code
that produces an value of type X whatever the type might be well the
only ways to use this function somehow and this function requires
us to give this as an argument so how can we give this as an argument
either we give a value of Z as an argument and then we have our X
we can return it or we give two excess as arguments and then we have
a new value of x and we can return it but how where do we get the
two x\textsf{'}s well we still have this function so again either we give some
Z to this function or we give a two-axis to this function so this
is where the recursion comes in in order to produce a value of this
type we need to have a tree with Z valued leaves and once we have
that tree we can write this function so these functions are equivalent
to trees with Z value leaves in this way now we can generalize this
construction to a recursive type defined arbitrarily like this now
here s is an arbitrary function that is fixed and this functor determines
the structure of the step of recursion so for example here this functor
would be as P equals Z plus P times P so this factor I call this induction
factor because it describes one step of the induction when we derived
values of the type so what we have seen right now suggests that the
church encoding of this recursive type looks like this so this is
a general way of encoding recursive types by church encoding and it\textsf{'}s
not recursive at least on the surface and I will show an example of
church encoding of lists of integers {[}Music{]} so here\textsf{'}s an example
of church encoding of list of integers first let\textsf{'}s do the recursive
encoding just for reference it would have a be a shield trait with
two case classes one representing the end of the list or an empty
list and another representing non empty link in other words a value
of integer type and and next value now Scala does not allow us to
do this this would be the short type notation but this cannot be done
in Scala because Scala does not allow you to do universal quantifiers
while is explicitly so instead we denote first this as some helper
case class CP just to make it easier for us and well we could actually
probably define this as a type rather than as a case class but let\textsf{'}s
keep it like this for clarity so the CP of a is just a helper case
class that represents this type it represents a product because we
can simplify this function as a product of two functions one to a
and this to and then we can simplify further 1/2 is just a and this
is like that just for convenience later now it\textsf{'}s very easy to encode
the church encoding of the rest of it just a function from C POA to
it now if you look at what that type signature is it\textsf{'}s very similar
to the type signature we'll fold it\textsf{'}s a function from a and this function
which looks like an updated updated function for fall gives you an
A and a is arbitrary so here a needs to be hidden inside the trade
as a universal quantifier so as I said before that\textsf{'}s how we need to
keep in mind that this is universal quantifier and therefore we do
a method in a trade so we don't do a case class parameterize by a
hidden parameter that would be an existential qualifier we do a method
in a trade because it means that this method can be called with any
parameter unknown at the time of defining this method and that\textsf{'}s what
the universal quantifier does so ok we are done we define this type
let\textsf{'}s define values of this type so to create an empty list we need
to write this boilerplate now how do we implement an empty list well
we need to implement a function that takes this and returns that you
know this has two functions inside we need to think about what these
functions mean in order to be able to implement anything here so what
do they mean all these functions mean what to do we'll look at this
for example what to do when the list is empty how to run the list
how to fold the list what is the result value when the list is empty
and this function tells you what is the result value when the list
is not empty it has a head value act some type integer and it has
some additional arrest values which have been already evaluated or
folded that your value a is given so what do you do then how do you
update your fold down now an empty list would never get into this
case it will always just give you the eighth so therefore this function
for an empty list ignores the link function and just returns in whatever
the end is the empty list when folded always gives you gives you that
justice this value which is denoted by hint in the fold signature
this is denoted by in it but we're trying to imagine the list being
created so there\textsf{'}s a empty list or end of the list that\textsf{'}s just the
name of the variable so for this reason that\textsf{'}s the implementation
of an empty list in the church encoding now let\textsf{'}s do them list with
one element how do we do that so we need to fold and in order to fold
with a list with one element we need to use this updater function
on this element and on the rest of the list which is empty which is
going to always evaluate to the end value so that\textsf{'}s there for the
implementation of a one element list so this is now more suggestive
but we are having an and one element list linking X to end so this
could be this class like this in your case class in coin but you know
this word we don't have any case classes here representing lists all
the lists are our functions the CP is just a convenience type where
pattern matching here just for convenience we don't need to do that
if we for example encoded this just as a tuple of two values then
we would not need the case expression we would just take this under
square one on your store two and so on but it will be less readable
so that\textsf{'}s why I I write it like this let\textsf{'}s implement appending so
we have an element X and a previous list we want to add this to the
list what we need to implement is how to run the resulting list or
running a list means folding it we are given the initial value of
length function now we need to use the link function on the X and
on the rest of the list but the rest of the list is this so we need
to run this using the same fold information so the CP case class encapsulate
all the fold information we need in order to run the list so when
you run it with the same old information we get a value and then we
update with the X so this is how we append now folding is just the
same as run so we can implement the fold function with this type signature
and it\textsf{'}s just calling run with these arguments notice that fold is
non recursive the fold function is non recursive actually none of
these functions are recursive we can implement convert into ordinary
lists just as a fold with a list constructor we can implement math
again this is going to be non recursive because we're just going to
pass some modified food so the lists are how do we run how do we fold
a list after mapping we just fold it with modified function so instead
of X\textsf{'}s we substitute f of X that\textsf{'}s all this is not recursive so the
map is non recursive on these lists the fold is non recursive in these
lists all the recursion has hidden inside these functions that they
run functions those run functions will call other run functions and
critically what we don't see that our our code here is not you closer
here\textsf{'}s how do we-{}-how implement has option we run it on an especially
crafted folder folding information and {[}Music{]} that actually is
an interesting observation that I would like to make is that pattern
matching such as head and tail is not directly available on this data
structure this is a function now it is not a bunch of case classes
we cannot directly pattern mention it and determine if it\textsf{'}s empty
or not for example we have to run this function on some arguments
and this run could take a while so for example tail cannot be implemented
efficiently as a Big O of one operation it has to run lowest to the
end and build the tails as a second list so that\textsf{'}s a deficiency of
the church encoding but if you need pattern matching operations you
need to run the structure or the entire function which might take
a while so let\textsf{'}s run some tests here implement just some function
so here\textsf{'}s how we create it\textsf{'}s just a folding with the Sun here\textsf{'}s how
we create some lists in the church encoding so it\textsf{'}s a pure of ten
which is one element list we append five to this we get a two element
lists with five and ten in it so then we check the sum of these elements
is correct and converting it to list gives you what you expect in
the map gives you what you expect now the map operation here is perhaps
stock safe we can check that some is stack safe so our fold implementation
is stack safe creating a list of any elements is stack safe when implemented
in this way so what we need to do is we need to compose many links
together but this needs to be done in a stack safe way which is why
we do it by hand here we don't just do link compose link composing
writing this would actually not be stack safe you'll see that later
in more detail also appending many elements is not stack safe we obtained
a large number of elements then trying to run that list do anything
with it would be a stack overflow so you see the sum the sum function
itself is a stack safe as long as you can run the list inside it but
it\textsf{'}s the list itself that needs to be stack safe now the function
that constructs the list is a function that builds other functions
and that function needs to be stack safe I should for example avoid
composing many functions but you can't avoid that if you do attending
one by one so you need some more clever implementation which is possible
but I will not discuss it right here let us see that the church encoding
of a type constructor so I'm using this notation with a bullet to
denote type functions so the scows index for that will be this so
the church encoding let\textsf{'}s begin with the church encoding of a type
function P just the type constructor P so what is the church encoding
of that this is the church encoding of the type constructor P you
have to have two quantified types and one of them is a new type construction
which is quantified in other words this is a function others parameterize
by an arbitrary type constructor F and it\textsf{'}s argument is a function
that\textsf{'}s parameterize by an arbitrary X which has this type signature
so this function world alternatively can denote it like that with
the squiggly arrow that I'm using just it\textsf{'}s the same I just want to
have a different notation for this it resembles a natural transformation
however these P and F are not necessarily filters so we don't necessarily
have a naturality law it\textsf{'}s just a generic function parameterize by
a very mature X with fully generic code but if these are not factors
then there are no materiality laws imposed on us so this is not a
natural transformation but a type signature is exactly the same so
this is somewhat complicated and for this reason I'm going to show
you an example of how to encode the option type yeah the option type
constructor in the church encoding so that you see how all this is
translated into code so the direct encoding option would be a polynomial
data type like this and with these classes that you could call like
this so we're going to implement this type expression now where this
is going to be the first type parameter and this is going to be a
second type parameter which is inside this argument so let\textsf{'}s first
encode this argument has a separate type for convenience so this argument
is a function that extracts a P from an option so it\textsf{'}s again looks
like a natural transformation from option to P except P is not necessarily
a function so let\textsf{'}s denote this X option which is this extractor from
option now this X option just for convenience we define this type
separately parameterize by P but it is not parameterize by X because
X is the universal quantifier type which needs to be hidden inside
this X option so therefore we have methods in the X option what are
characterized by X now I could have just had one method here such
as apply with parameter X and then I would have this function as the
type of that method but it is actually more convenient especially
in Scala to have separated methods so if this is a typical pattern
of a function from a disjunction to something is equivalent to product
of functions from each part of the disjunction to that something so
then the equivalent type is less and we can just denote each of these
as a separate method in the trait so that\textsf{'}s just convenience we haven't
done anything really we just equivalently transformed this type for
convenience it\textsf{'}s a little easier to read and we can give these trade
methods suggestive names so having defined this type it\textsf{'}s now easy
to define the church encoding on the option which is parameterize
by a notice listen thing has only one type parameter which is a that
is visible outside the type parameters P and X should not be visible
outside they're hidden inside his type expression so therefore we
put the type parameter a outside and the run method I just call this
run for convenience to suggest what the church encoding does is that
if it runs a DSL program with an interpreter so this is an interpreter
for the the operations of the DSL and this entire thing is the runner
of the DSL program into an arbitrary target type so that\textsf{'}s why I always
call these methods run but this is just been named doesn't do anything
by itself it is the type that do all the word no types so the run
method needs to be permit rised by the parameter P which is itself
a type constructor and this is the type of the run so that\textsf{'}s it we
have finished implementing the church encoding as a type now we need
some helper functions so that we can easily create values of the Church
encoded option so how do we implement for instance constructors the
Sun and none now these are not these trade methods these are our so
these are our methods mean we could you could make these methods private
if we wanted to this entire type could be made private the users should
not have access to it so to define some we need to put an X of type
a into the auction so how do we do that we define this church and
call it option with around method and we need to implement this so
how do we run a non empty option well clearly we use the sum method
on the x value that we have to get a P of X so that\textsf{'}s what we do here
how do we run an empty option we use the non method which has no arguments
and gives us a P of X that\textsf{'}s it a lot of boilerplate as you can notice
all of this is boilerplate all this is boilerplate this is the actual
code implementing the Constructors for direction there are some libraries
that make it easier to use but it doesn't matter enough so we can
also show that option the ordinary option is equivalent to the church
encoded option to do that we do a wrap and unwrap methods let\textsf{'}s say
so first we take an ordinary option and we implement the church encoded
option that\textsf{'}s very easy we just do one of these two constructors unwrapping
from a see option into an ordinary option requires running let\textsf{'}s see
option again we have the same {[}Music{]} same phenomenon but if you
want to pattern match for instance you want to detect whether this
option is empty or not you have to run it there is nothing we can
pattern match directly on this value because this values a function
you cannot pattern match on code of functions so how do we do that
so we need to run it but to run it on what we need to provide an interpreter
so the interpreter will take our church encoded option and produce
an ordinary option so that\textsf{'}s what we need to prove produce and these
are just the standard methods of the standard Scala option and that\textsf{'}s
that\textsf{'}s it so here\textsf{'}s how we can use it so we can create some values
of option type now pattern matching does not work cannot directly
implement that imagine so which if we try it there\textsf{'}s a type of problem
so for example we wanted to pattern match directly like this by running
the option on something but I can't really do that because we need
to provide an interpreter that interprets arbitrary type X under the
option but we only have a specific types here type a so if we write
this code which will be kind of what we want we gathered a pair so
the only way of doing a case expression would be first to run this
like this to unwrap it convert it to an actual option with case buttons
and then we can pattern match on those on the other hand natural transformations
work fine they don't require running on some first on on a real option
you can just run on a constructed interpreter and interpret this into
another function so that\textsf{'}s that works fine and here\textsf{'}s the test code
so now finally let\textsf{'}s look at how the church encoding works for a recursively
defined type constructor so this is very similar to how it works for
a recursive type in that all the recursive usages of the type constructor
are replaced by this type that is universally quantified and since
now we are dealing with a type constructor we need to adjust our notation
so that we define first of all the reclusive type constructor like
this where s is now a factor that describes at the induction principle
but it\textsf{'}s now paralyzed by this type constructor so this notation that
I'm using for a higher-order type function in other words it\textsf{'}s a it\textsf{'}s
a functional of types that are themselves function of types and Escalus
index won't be like this so an example of that would be a list cursor
we define like this and if we define s like this then you see the
P parameter P denotes the recursive use of the type constructor in
its recursive definition so this is how we could denote this construction
and then the church encoding of this looks like that so there is similar
to a church including for cursor types and it\textsf{'}s non-recursive it\textsf{'}s
a type expression that does not require recursion so let\textsf{'}s see how
the list constructor is defined in the church encoding this is the
type expression for the church encoding of the list because this is
the structure or induction factor for a list we just saw and I'm just
adding all the type quantifiers explicitly I have a B which works
inside these parentheses only it\textsf{'}s hidden I'm gonna have a tree which
gives me this is this it\textsf{'}s also hidden from the outside I can equivalently
transform this type signature into this where I {[}Music{]} again
replace a function from disjunction to B or B by a function from just
part of the disjunction to P of B and then from this part of the disjunction
to P of B which I simplify to just beyond P so that is how I would
seem to fight now I will deliberately write code similarly to an on
parameterize list that I did first so the end needs to be paralyzed
by this B now I used X instead of B here and now finally I search
encode the list of a just as a function from this to P of a very similar
code that I had before in order to define empty list a list of one
element and appending there was a difference that link and the run
I'm getting them as methods of a trait whereas before I was getting
them as parts of a case class I could have done a trait before as
well because really it\textsf{'}s just a convenience but here I could not do
case class because I need this type parameter oh I didn't know that
this be in English used for consistency this type parameter being
what I have here needs to be hidden inside the type CL which is this
type which is the argument of this function and case classes will
not do this frame so I need a little trade with methods in Scala other
than that the code is very similar fold is non recursive in order
to implement fold I need to have a bit of typecasting because the
only way to get anything out of the list is to run but I need to run
on an interpreter if I'm folding are not interpreting into another
type constructor I am interpreting into a single type so however need
to pretend I'm interpreting into a type constructor because that\textsf{'}s
the type signature of the church encoding it\textsf{'}s run into an arbitrary
type constructor so I can choose that type constructor to be the identity
factor and in this way I can get ordinary types out so I define or
constant factor be another possibility so I define a constant factor
and then I run into that so I give that C is a type parameter and
then I encode the running just like I did in the fold implementation
above in this hold implementation here except that now I need to specify
this as methods over trait rather than as parts of the case class
other than that it\textsf{'}s very similar and here I typecast X X has type
X but I know this will only be called on values of type a so I know
that even though I'm supposed to provide {[}Music{]} this CL of C
with arbitrary X actually this will only be called on values of type
a so I can cast this safe way to satisfy the type checker now this
is a little ugly but that\textsf{'}s what I found to be necessary with the
constant factor being used so using this I define a sum I define two
lists and I run exactly the same tests as I ran before network of
the lists so now I would like to generalize the constructions we have
seen two arbitrary typeclasses so this is something that the church
encoding makes it particularly easy to understand but it does not
have anything to do with the church encoding so let\textsf{'}s look at first
of the church encoding of a three-cylinder looked like this now here
X is an arbitrary type but this is a signature of the semi group method
which is combined so if X were constrained to the semi group typeclass
and this would be given already as an implicit argument let\textsf{'}s omit
that argument and I would denote it like this so here the typeclass
constraint is denoted here like this so now it is an arbitrary type
X which must be of this typeclass and then I have this so it\textsf{'}s a much
simpler presentation and notice that the induction factor for semi
group over Z is this so basically what happens is that a church encoding
of a cylinder which is this one which we can generally write down
as the semi group functor or induction functor as I call it before
but actually this is always going to be of the form Z plus something
when we do a free side quest inspection because we have to wrap the
Z pipe and then we have these methods this tells us how to generalize
the country construction to arbitrary typeclasses so first of all
we define a functor that describes the operations of the typeclass
so for example for the semi group we have a single operation and writing
it in this form means that CX is just a pair of XX but in more general
typeclasses ships would be more more general and so that would be
what I call the method factor this type is in a category theory called
an algebra or sea algebra so if C is a functor when this type is called
a sea algebra which is a type parameterize by X but I just mentioned
this because the fact that it is called sea algebra in category theory
it doesn't really help us so much it is suggestive typeclass has some
operations these operations maybe have some laws some algebraic laws
and so for this reason it is suggestive to call this an algebra but
it\textsf{'}s perhaps more confusing than suggested so let\textsf{'}s just not use that
terminology instead let\textsf{'}s concentrate on what these things actually
do so this I would call the method factor of the typeclass C I would
call the typeclass C inductive if such a functor exists why because
it appears that we are defining values of x by induction so if this
factor is given so this is some kind of container of some shape containing
X then we can derive new values of X using these operations so the
operations the value of this type that tells us how we can derive
new values of x given some previous values and how we're supposed
to have the previous values is described by the shape of the method
functor so for instance this method FUNKER could have a disjunction
of several parts and each part would have zero one or more X\textsf{'}s in
it and so that would correspond to operations with zero one or more
arguments in the operations of the typeclass so for the semigroup
the C is just a pair for others it will be more complicated but given
this C we can write down a general formula for the free typeclass
C over a type Z so the three encoding would be like this so the free
c generated by z or free c over z is a recursive type defined like
this the church encoding would be like this because we replace the
recursive use of the type through the type parameter X now quite equivalently
we could say the church encoding is like this it\textsf{'}s for every X of
the typeclass C in other words for which we have this value we have
this it is then obvious that also the laws of the typeclass will be
automatically satisfied by the church encoding after running and this
value and the reason is X must be of typeclass C and so after you
run this you would have a value of typeclass C so whatever operations
you apply to this are actually implemented in the typeclass C and
they therefore already satisfied law type constructors used in the
same way here I have shown what to do with new type constructors with
ordinary types it\textsf{'}s just that there\textsf{'}s more notation and more parameters
so for example the freetypeclass C over a type constructor F in the
church encoding looks like this where you have an arbitrary P from
typeclass C and then you have this generic transformation or natural
transformation which might be mapped into PA now it\textsf{'}s very important
to notice where the tag trailers are here so this a is the outside
a this is the only outside type parameter that is visible and this
type rather is hidden and also this is a hidden type parameter inside
so we have generalized from our examples to an arbitrary typeclass
let us remind ourselves what we have done first we start with some
arbitrary type z and we enriched it to a monoid which was a free monoid
we have started with an arbitrary that constructor and we enriched
it to a unit which is DSL that was motivated by the interpreter pattern
but this was actually a free monad so this enrichment was done in
the tree encoding by adding case classes that simply represented the
operations but there are also other encoded in cuttings that are more
sophisticated and so this works for any type Zi and any type constructor
and the result is a free type construction and this type construction
performs no computations it just accumulates all the data and it needs
to be run in order to actually perform computations and so intuitively
the free Mona and mono it over the type Zi adds some wrapping to Z
just enough to make it look like a monoid to satisfy the type signatures
of the moon your head doesn't actually perform computations inside
it just adds some stuff so that the result looks like a mono it similarly
the free functor it wraps a type constructor and just enough stuff
to make it look like a functor and we can interpret these free values
into non free values into specific concrete functors monomers and
so on by running please notice so we have seen several coatings and
running is done differently for these inquiries but all of these including
do the same thing they provide you a free type construction which
performs no computations it delays all the computations records all
the data that you to perform these computations later and later happens
when you run so you create a DSL program you can combine different
programs very easily and you can then run so what are the questions
that are but remain to us so what are the five classes we can construct
in this way so can we construct for a given typeclass C can we construct
a free instance on the typeclass over and given say FA the answer
is in turns out to be yes with some typeclasses no with others so
I will show examples I really started with functor I will show examples
of these typeclasses and I will show why you cannot sometimes have
a free typeclass which encoding is to use this is an important question
for reference some recordings perform better than others these encoders
are not the only ones available but I don't want to go too far into
other possible encodings and if you're interested look up church encoding
and you would immediately see other related components such as course
encoding every go encoding and some other info base and another set
of questions related to each other are about the laws so what are
the properties of this free instance can we define the free instance
by its properties formulated in some way in the turns out there are
four main properties that are important first of all if we have a
free instance of a typeclass over a type construct if it means that
we need to be able to wrap a value of F into a value of this free
type lasso this free C is this free instance of a typeclass so we
should have a function with this type signature now for second property
is that for all specific instances of this typeclass we should be
able to run our type free instance into that specific instance given
this function so this function the extractor as I was used calling
it before this extractor only shows how to map the generating element
or to generating type the F into m and once we know how to do that
we should be able to wrap the entire tree instance into him so in
other words is generating type the Z here and the F here has been
wrapped into some stuff to make it look like typeclass C and we should
be able to unwrap it into a specific M only knowing how to transform
to generating type into him so this extra stuff should be transferable
automatically into the correct typeclass the laws of the typeclass
must hold after running into that ami and the last property is interesting
is that if we transform the generating type into another type then
we should be able to automatically transform the free instance as
well so in other words the free instance should be so to speak a factor
in F except of course F is a type constructor so we need to generalize
the notion of laughter it should be covariant in the type parameter
F and so we should have some kind of map function that map\textsf{'}s atlandis
indeed if we look at this definition we had right here it satisfies
all these properties so for example this is covariant in F because
F is behind two arrows this is covariant in Z obviously so these are
the properties that we will show that how we already know that some
of these properties hold but we will show that more more formally
so what is the recipe for encoding a freetypeclass the recipe is this
first the typeclass needs to be understood as having methods that
is functions with some type signatures like this and all these Q\textsf{'}s
must be covariant complete there are some functors or some type constructors
that must be covariant in the parameter P and that is required that
all these methods should have a type signature of this form in other
words the final return type must be the type constructor not here
that were given if that is so we can put all of these Q\textsf{'}s together
in a disjunction like this call it s and then this generic function
will be a single value that represents all the methods of the typeclass
at once and then we call s the methods factor so once we do that we
define the tree encoding which would look like this it will be recursive
because these queues will have FC inside them perhaps but that that\textsf{'}s
fine now the queues might contain existential type primer so if if
these methods contain more type parameters on the left hand side it\textsf{'}s
fine they will become type parameters here and as we have seen type
parameters in case class inside a trait that are hidden from the trait
become exist tential type parameters and so those are fine those might
be present and then finally we can implement the run method for this
there are easier so if we are in the wrap case which is this part
of the disjunction then we just map it to him and we're done and for
all other parts these methods are run recursively so we run recursively
all the keys that are inside the queues and then we just use the method
of the typeclass M which will have the same signature except that
instead of peas will have specific values already of type M and so
we can just use those methods and that\textsf{'}s how the run function works
so this is very easy to encode the tree with coding it\textsf{'}s very straightforward
almost mechanical so you have a definition of a typeclass you can
mechanically generate this and it\textsf{'}s run method there\textsf{'}s no problem
at all to generate instance of the typeclass and the run method mechanical
in order to get a reduced encoding however you need to perform reasoning
about what are the possible values of this free typeclass instance
and what are the laws of a typeclass and how you can simplify if possible
values you would start with the tree encoding which is going to give
you some nested case classes and then you try to simplify them and
that is non trivial you don't have a generic procedure for doing that
so that has to be done separately in each case or factor for contra
contrary and so on so the factor we have done this but we will do
that for all the other typeclasses finally the church encoding can
be defined either using the tree encoding which again is completely
mechanical so we just do this you do the S and then you have SP TP
all in parentheses going to P put a type quantifier and P and you're
done or you can do a church encoding of the reduced encoding so that\textsf{'}s
a choice and there might be different performance in all these occurrences
so this in other words well we will show the more formally if this
is all true but if you have an inductive typeclass which is characterized
by a methods fantasy and so it\textsf{'}s methods are this algebra the C algebra
then you have a free instance always it has all the properties and
we have further properties for instance if P and Q are instances of
this class then the product of P and Q and the function from z2 p
where Z is a fixed type are also instances of pi plus C not necessarily
these sum or a disjunction and the product with a constant type are
not necessary parts of it last class but those are and this is relatively
easy to prove for instance if you have this and this means you have
a P is an instance of C and you have a Q as an instance of C and you
can derive this easily just project this to this project out the Q
C is a factor so you can do that project out the P to get sick you
get your P get your Q get their product so that\textsf{'}s very easy and it\textsf{'}s
similar will you come to this but you cannot implement the disjunction
for example because you would need to decide which part of the disjunction
you have but you can decide that because we have a C of P plus Q and
it\textsf{'}s not necessarily that you can decide which part of the disjunction
it must be so that function cannot be implemented without losing information
so that won't satisfy lowest similarly you cannot get Z P because
if we need to create values of type Z but you don't have them necessarily
plus Z so it\textsf{'}s also an instance of the same of course and indeed we
have seen looking at all the previous typeclasses that we analyzed
factored contra functor applicative Minard and so on they all have
this property the product of two typeclass instances and this construction
always again if you have a new type cross sixties so that is one because
they are inducted all inductive typeclasses have this property and
type constructor typeclasses have the same property just that the
methods function needs to be in coded language what type lasses cannot
be trained included and they're not inductive well one typeclass that\textsf{'}s
not inductive is reversible and indeed this is not true for traversable
this construction does not work for traversable if P is favorable
than a function from some types need P is not reversible in general
any typeclass that has a method that\textsf{'}s not returning a value of that
type that\textsf{'}s not inductive the reason is methods must be of this sort
so if you have methods not of the sort that did not return values
of this type then it\textsf{'}s not an inductive typeclass so here\textsf{'}s an example
imagine a typeclass for a type constructor PA it has two methods point
which inserts a value of a into P and extract which extracts a value
of a out of P now this would be of this form because it returns the
type construction but this is not it returns just bear type a and
so this typeclass that has both of these methods is not inductive
it does not have a representation of methods through a methods function
like this or like this and therefore we cannot do a free construction
of it using trees and we don't know how to encode free instances of
this class traversable functor is another example of non-inductive
now just to mention that if all methods of the typeclass have the
opposite form that it consumes a value of this type constructor and
then gives you something like this but if all methods are on this
for not just some so this is still not non good enough there\textsf{'}s some
methods did not consume values over this high class of this type constructor
but if all methods are of this form they consume PA and return something
then there is another way of doing a free instance which is called
Co free and these typeclasses are called Co inductive I'm not going
to describe them in this tutorial but perhaps in another chapter so
if we're going to free control function let me go to the code over
free factor which I have not yet shown but actually here\textsf{'}s the code
what I was just talking about I can define free instance of any inductive
typeclass I can write code for this generically so it\textsf{'}s a free instance
of an arbitrary inductive typeclass now this is not for type constructors
for simplicity this is just for ordinary types this before semigroup
monoid and such typeclasses and here goes the rap and the operation
so the operations contains the sea of free so this is the definition
but I just showed of the free instructor so that is the hopes and
basically that\textsf{'}s it we can show that it has methods of the typeclass
and we can run we can write the run method so you see the run method
is for a generic oh it means to assume is that C is a functor C not
not everything I see is this methods function and and I'm done so
the P method C is the evidence that the type P into which I am running
is an instance of typeclass C so this is a value that encapsulates
all the required methods so that\textsf{'}s why I called P methods C so P has
all the methods of C and this is a very easy code that just checks
whether it\textsf{'}s wrapping then it runs the extractor or if it\textsf{'}s the operation
then it runs the methods of T on the result of running under map so
I'm required to run under map because I'm under the sea and coming
here I need to run this first into a value of P under map of C so
then I get C of P and then I can use methods to convert that to pee
that\textsf{'}s how it works and there\textsf{'}s an example I use this for a generic
construction to define some free semigroup so these are this is the
methods functor for the semigroup I'll show it as a factor this is
a free semi-group that\textsf{'}s it generate it by screen now this is just
to be clear this is my own definition here it\textsf{'}s not the cats library
definition or any other or scalzi definition I believe in those libraries
what is called free is actually the free Mona it\textsf{'}s a free Mona not
just freaking structure any type cons so in my definition here it\textsf{'}s
of generic free instance of a given typeclass for inductive typeclasses
and here\textsf{'}s code that creates some values and runs them so I create
ABC XYZ wrap them then I use operations to add them and I run this
into a string and I'm done and I can do the same with the church encoding
it\textsf{'}s slightly more type definitions but it\textsf{'}s exactly similar the church
encoding is this type equivalently it is this type and so I just define
the trait for the argument and then I have this and then I can show
that it\textsf{'}s a five class now the showing that it is a typeclass is actually
non-trivial this church encoding must have methods of the typeclass
C in other words it must have a function of this type C of the charging
: must be mapped into the church encoding itself and the types here
are different with an X inside here and all Y inside here because
are different so this actually is not very trivial to derive you just
need to be very careful and following the types and here\textsf{'}s how this
works so how can we get this value now we would get this value we
have Z or we don't have a Z obviously all we have is this we have
C of something so it looks like our only hope is to get this C of
Y and then we would have a function from C of Y to Y and we can call
on that C of one and that give us the result now we are given this
so we are required to be able to work with an arbitrary given Y so
imagine we are given someone but then we have this function which
has an arbitrary X inside that we can set so this function accepts
arbitrary axis so let\textsf{'}s set this X equal to Y in that function and
then we would have a value of C with Y in here Z plus C of Y going
to 1 but we have AZ plus C of Y going to 1 we are given that value
so we can substitute that value in here mapping undersea so that we
can get a sea of why as a result so then we get a sea of why we can
put it in here and get the white house so this is a little convoluted
but that\textsf{'}s the code we map under sea given a type train with your
Y in here to run the free instance and then we use the ops and the
resulting sea wide so this is this gives us a CL what we run the ops
on it we get away and that\textsf{'}s what we returned so if you want to understand
exactly how this code works you would have to write it yourself it\textsf{'}s
a lot of manipulation with types all these types are permit rised
so this is kind of technical and not so easy to see looking at the
code but this is the only way to implement the required type signature
which is this and now we implement the rap which is straightforward
and the Run which is straightforward by using these methods so this
again we run the semigroup example is exactly the same code up to
some syntax changes give us exactly the same results so let us now
look at the functor so I already showed how the functor here the free
functor is implemented and I derived the tree encoding and the reduced
income and then I started to talk about the church encoding and that
was so complicated that we have to go through much slower and through
all the parts that are required so let\textsf{'}s now look at the code for
the free functor so the free functor actually starts from a given
type constructor so it\textsf{'}s always a free funder generated by a given
type constructor or a free funder over a card constructor and that
that constructor doesn't have to be a function and actually in many
applications it is a node is not a factor and it cannot be possibly
a functor because it has index types with specific type parameters
and it tries types with non-free specific sign type parameters like
this so I call these things unfocus it\textsf{'}s a funny term that I think
is appropriate here because this is it is like a factor because it\textsf{'}s
characterized by a type but it couldn't possibly be a furniture because
of the way it\textsf{'}s defined so this unfactored could be seen as describing
two operations in some business logic where you add the name to some
database say and you get an ID back don't you get named by ID and
this name may may not exist in a database and so the result is an
option of string now we would like to transform this unfilter into
a factor run some program with it and then transform that into an
ordinary option of some result so say sometimes you would have an
option of strange sometimes not so let\textsf{'}s be safe and run this into
an option so in order to do this we need to define an extractor or
interpreter for this and type constructor into options so this is
this type which is natural transformation but actually doesn't have
to be natural transformation it\textsf{'}s just a generic transformation from
one type constructor to another I'm using the cats library type it\textsf{'}s
defined there so how do I transform other two cases if it\textsf{'}s alone
then I just transform it into a one and if it\textsf{'}s an option string then
I transform it into none so doesn't matter it\textsf{'}s just an interpreter
of some kind it doesn't all it does is gives me an empty option or
non empty option it doesn't really do a lot of good so that\textsf{'}s what
I'm going to be using so I'm going to right now a free factor based
on this free function over this on Fronter I'm going to write some
maps on it add some transformations and then run into an option that\textsf{'}s
going to be the example so here\textsf{'}s where the code starts this is the
three encoding of the three factor and have the wrap case class I
have the map case class map case class has an existential type B I
define the function instance for the typeclass functor and the map
method does nothing just creates a new wrapping with map typeclass
case classes then I have my function here which creates a free program
300 programs all it does it applies map to some given value many times
so this number of iterations is given so that many times I apply map
with the same function to that value so this is just a test I'm going
to start with some value wrap it and then map many times the runner
I'm trying to make it stack safe and that\textsf{'}s a little bit of a problem
actually and here is why I will have a lot of nested case classes
I'll have to and go through all of them so the unfold function and
I'm defining here is going to call itself and so one thing I could
have done is just applied in the map we see that F of Z is a free
functor value I could just have run it through the same function and
then apply the map with F to it but that would have been not like
safe so I did another thing so I didn't take a recursive unfold where
I first accumulate so what I did here actually is I did and then George
that was my first implementation every time I have a map I have a
new function so the result is this accumulator that I have in the
unfold and so I just accumulate all the functions inside the map and
I run them only at the end so I I run this only at the end so that\textsf{'}s
the idea so that is tail recursive and then I hope to be stack safe
but I'm not stuck safe this will actually give me a stack overflow
and the reason is that and then is problematic in Scala and that was
quite surprising to me because it\textsf{'}s not so in Haskell and I didn't
expect it but and then is actually not stack safe in this car here\textsf{'}s
why here\textsf{'}s my sample test code that shows why this is so let\textsf{'}s compose
a large number of functions and call the resulting function so here\textsf{'}s
a code it does this let\textsf{'}s just compose a lot of functions all these
functions are just adding one to their argument and so that\textsf{'}s very
simple but if we do do this with a large number of functions we'll
have a stack overflow so whatever we do we'll have a stack work for
we we can compose these functions or we can directly compute still
we have a stack overflow so the reason is that composition of functions
introduces another stack frame and that\textsf{'}s unfortunate and it cannot
be removed apparently in job in JVM for technical reasons so you could
not have a compiler that automatically removes this extra stack frame
so what do we do well cats library includes this and then structure
which you can use and if you use that so if you start with this and
then you compose with more functions then this is stack safe how does
it work it doesn't actually compose these functions until much later
until you need to run this function and then it actually accumulates
all the functions you give it in the list and then it runs that so
I implemented the same kind of thing which I call safe compose using
a data structure called chain which is from the cat\textsf{'}s library which
is a very high-performance list and so here\textsf{'}s what I implemented based
on some of these suggestions actually Michael Gilchrist suggested
this so I just did good massaging so now the idea is that instead
of composing you wrap the function into this chain F data structure
and then composing this with others things doesn't actually compose
functions it adds to the to the chain of functions of these functions
are all stored in lists and only after you run them so the apply function
is called then you fold over the chain and apply these functions so
that\textsf{'}s how it works and I made it so that you can compose on the left
or on the right with the chain and you get a chain again so this what
I did and the result is good so it\textsf{'}s actually faster then using cats
library and attend so that\textsf{'}s what I had to do introduced here I have
to use before before is my replacement of anything which is easier
to use than cats library and it is faster so this is what I would
do if I didn't have this I would accumulate results functions in the
list one at the end I would fold over that list so this is kind of
uglier and it\textsf{'}s better to put this code into a library and here\textsf{'}s
a benchmark free functor in the reduced encoding it has fewer at least
classes but it has a more complicated map because now it needs to
do this in the map notice that in the tree encoding the map didn't
do anything it just wrapped the data into a nucleus class but in the
reduced encoding the map method of the factor actually performs a
computation it already composes the functions although were revealing
this smart composition but that\textsf{'}s what we do before and after are
the smart methods of I implemented here in place and then compose
in the sky and then I do the same testing and it\textsf{'}s slightly slower
than three encoding 
\end{comment}

\begin{comment}
now let us consider the church including of the three functor the
church including is our equivalent as types but they have different
performance characteristics and they are more complicated to implement
the three including of the three factor is like this and in order
to implement it we would have to first implement the trait that hides
this inside type parameter you will have to implement the trait that
hides this type parameter and the outside parameter as well so that\textsf{'}s
why there is quite a lot of boilerplate involved so first I define
this auxiliary type and then i encode the free factor using a trick
that if if I look at the type expression here then this is the same
as the magnitude of the function so I can transform this type expression
into this which is an equivalent type and this is the same as the
magnitude of the factor and so a shorter way of implementing a free
typeclass in the church tree encoding is to impose a type constraint
typeclass constraint on G and to declare this as an argument so that\textsf{'}s
why I'm saving a lot of typing if I do that but it\textsf{'}s not necessary
it\textsf{'}s equivalent to doing it in a straightforward way now the result
is that in life refactor looks like this it has a single method trade
parameterize by an arbitrary type constructor which needs to have
a functor constraint and the type of the method is this now we know
that the three-factor has a punctured typeclass instance and in the
tree encoding it was trivial to define it but in the church including
it is much less trivial because of the complicated type signatures
of these functions so these are functions whose arguments or functions
and type parameters are hidden inside so here is the definition of
the factor instance for this type I need to define a map function
that takes a previous ffs away in function a to be and return the
new F F of B where F is kept as a type parameter throughout now in
order to return a new fffb the only thing i can do is to create a
new anonymous instance of the trait and overwrite the run method so
now I'm here in the run method I'm supposed to do this so let me write
a function so now I have the following data I have this church encoded
fffe I have a function A to B by heaven FF C which is simply a natural
transformation F to G or if you wish generic transformation after
Jesus if F is not necessarily a function so given this data I need
to produce G of B how do I do that well the only way to produce any
kind of G is to call this run method from the previous F of a which
will give me a G of some X where X is up to this F of a so is going
to give me G of a out of here there\textsf{'}s no other way I can get any G
here I need to run therefore this method but I'm free to specify a
type parameter for this run method so I specify the G which is given
to me here at that type parameter and then I apply that to an F FC
which I have so that gives me a G of a now I need to write this syntax
and not just run away for see because run has an implicit argument
and it will be confused if I do that this will not work so having
gotten G of a I just map it through the function f into a G of B since
G has a functor instance so I do it like this just very explicitly
so that\textsf{'}s my implementation now in order to use this I need a helper
function that lifts values of F of a into the free functor so that
is like that we need to implement the run method so the only way to
create a value of the free founder is to do this too to have a new
FF with the run method so then I have an FF C I can apply this to
FA and I get G of a out of it since F FC is directly a transformation
from F to G so that\textsf{'}s very easy and another helper function is to
interpret free factor into a given specific function G so that is
also very easy just to run the function the run function itself is
already the interpreter that is a defining characteristic of the church
encoding it is encoding which is assembled out of pieces of the run
function so the value of a church included type itself is already
its own interpreter now performing tests performance tests given some
reasonable results however some paper claims that church and coatings
are always slower it\textsf{'}s not necessarily always the case you need to
benchmark your code if you want to be sure now the problem with this
code is that there there\textsf{'}s a stack overflow because this run method
is actually not stack safe again as before I already said stack safety
in the Trojan Queen it is up to the implementation of the run method
if the run method calls functions too many times then it\textsf{'}s not going
to I'm not going to be able to make it stack safe in the other parts
of my implementation and can't really made stock safe the reason being
that I have to do so the map function needs to do this I have to apply
to this FFC and you have to run in the map function so since map function
has to run there\textsf{'}s no way to guarantee stack safety every time if
you have a million maps when I would have a million nested calls here
so that\textsf{'}s a stack overflow now let\textsf{'}s consider the church encoding
of the reduced encoding of the free function {[}Music{]} reduced in
Korean is slightly simpler for the free function and so let\textsf{'}s search
encode that we can search encode anything any any type can be Church
encode the question it doesn't bring us any advantage it turns out
it does because the church encoding of the reduced encoding of the
free factor can be made stack safe and here is how so first of all
we cannot do the same trick as before with the typeclasses we have
to encode directly this type expression so that\textsf{'}s encoded directly
so first we called the exists tential type so we named a straight
and it will have a single case class representing this value and here
instead of B and is a Z so that\textsf{'}s the implementation of an existential
type expression then I implement this function for all a from that
to G of a so that\textsf{'}s the straight with apply method parameterize by
a and finally I'll code the type by having another universal quantifier
outside which is paralyzed here so in this way I have encoded this
type expression so this is the boilerplate in Scala that is required
in order to encode this type expression now to define the function
instance I'm going to be more careful in order to make its taxi so
I'm going to pull things out of the run method they have to be if
they don't have to be reevaluated and so one thing I can pull outside
is to reevaluate the run it can be done once so it can be done outside
of this room if I do that and I actually can achieve stage stack safety
another way but I use the before method which is my own implementation
my IntelliJ is a bit confused right now but before it\textsf{'}s my own implementation
of a function composition which is tag safe so how do i implement
this well it\textsf{'}s kind of cumbersome because of all these boilerplate
and types I have a very complicated type expression it is still a
factor the church encoding doesn't change the properties of the type
that will church encoding it just adds a lot of functions and have
a choice types and quantified types but it doesn't change the properties
of the type it\textsf{'}s just a different encoding of the same type so clearly
we should be able to define a furniture instance if we are able to
define a factor instance before church including but defining the
file that would just be more work but this has work done only once
so here\textsf{'}s what we need to do we need to define a lab method and that
method needs to return a new FF of FB so we return that and overwrite
the run method in it run method takes an FF C and now we have the
situation at work that we have this data and we need to produce G
OD now the only way of getting G of B anywhere is to use this run
to run this but running this will give us a value of death commit
which will produce us G of B so where do we get that value we need
to get that value out of our church included free function that we
have we have before so now let\textsf{'}s remember that the church encoding
is equivalent to the type that is being encoded so you can extract
that type outer that encoded value so since the church encoding of
the reduced encoding of the free factor is basically encoding of this
we can retrieve this back from a church encoded type no need to do
this is where it is done so basically we get this free F of fa out
of C F of a which is basically running it with identity so random
with identity is the way to retrieve the underlying type out of a
church and call it that so that\textsf{'}s what we do in these two lines and
we put these lines outside of the run because this needs to be done
it doesn't depend on these arguments needs to be done outside a memory
also achieve star safety when we economize on the stack doing this
one side of the run function so haven't gotten this value we imagine
it or we imagine it just because we need to extract the parts the
F Z and Z to be parts of this 3 F 3 F is just the case one side you
find right here with this map C so I'm going to extract those things
in it to match and this is a key part of the implementation I'm composing
the functions inside the map case class I'm not actually running the
map anywhere yet I'm only going to be running it here so this together
with putting this outside achieves tag safety if I remove this replace
Ness with and then or if I put this inside into the run function I
will have a stack waterfall everything else in this encoding is very
similar to what we had before the wrapping the run is trivial the
interpreter is stack safe it just runs them up and we guarantee that
run is stuck safe so performance test shows us that this is actually
significantly slower then especially creating this method and all
these things that come with creating nested Maps method is significantly
slower than other in puddings but as we will see later Church encoding
has certain advantages so if performance is not a great concern but
flexibility of design is a great concern as well in charge encoding
has significant advantages so this concludes our implementation of
the free function let us look at other three type questions how they
are implemented the next typeclass is the free culture hunter in order
to implement it let us follow the general procedure first be right
down the methods of the typeclass it has only one method which has
this type signature we realize that it\textsf{'}s inductive because this method
returns again the value of the type we're constraining and also we
realize that it has an existential type inside because it\textsf{'}s parameterize
with this be there for the three encoding looks like this it\textsf{'}s again
we are just following the general recipe what tree encoding is a recursive
type what is made out of a disjunction the first is the wrapping of
the generating type constructor F and the second part of the disjunction
is the method the method factor now in this case this is what we need
to do this is the accuracy of instance of that type now reduced encoding
quite similarly to deriving the reduced including for the free filter
we derived for the free control enter a value of a free country func
you type in the tree encoding will always be of the form that either
we have a NFB or we apply several times map to FB which will add here
I forgot the direct product sign we add a few terms of this kind with
products of functions and existence or quantifiers the difference
between this and a fee factor is the opposite directions of the function
arrows so this starts with Z 1 and then we have a function Z - 2 Z
1 and so on the N to the N minus 1 B to Z and the result is a contra
factor parameterize by B however the property of contra funky are
still such that we need to compose these functions associatively and
we can compose them before doing map or other contra motive or we
can compose them after doing Countryman that\textsf{'}s a composition law there
for the reduced encoding can simply compose all these functions and
put them inside a single function of this type and so the equivalent
type is just this with all these other and residential types simply
dropped since they are not used so that\textsf{'}s how we derive the reduced
encoding we need to figure out what are the possible expressions and
how they can be simplified using the laws of the typeclass there\textsf{'}s
some simpler type expression notice that the reduced encoding is non
recursive just as it is for the free functor and I'm going to show
code now this free country function might be a little difficult to
understand or to see where it is to be used but it is just a general
scan you know I don't take any type constructor and wrap it into some
stuff can make it into a pet typeclass instance of an arbitrary typeclass
so for instance I can take a function such as this one you know identity
factor and I can wrap it into a freaking tree function so then this
will become a contractor after wrapping and I can create a control
factor program by replying confirm I have a few times to this then
I can interpret the results interspecific control function such as
this one and the interpreter the only thing the interpreter needs
is a function from here to here this function example the something
like this where we take a value and return a contractor and contractors
are usually consumers of values so imagine you're logging something
that can see so the logger is a typical consumer of values I'm just
going to simplify this very much and consider this function as a contractor
and then this would be a transformation from identity factor to this
control factor which is prepending prefix to the log message and that\textsf{'}s
I'm going to show the code in a few minutes that\textsf{'}s how we would use
a free contractor anything that another important property is that
if the type constructor F is already a contractor then this wrapping
does not produce a new in equivalent type it\textsf{'}s the result is equivalent
the free country function of over F is equivalent to F you just like
it is the case for the pre factor or the look at example code so here\textsf{'}s
how I encode the free country function tree encoding I encode the
wrapping case - and then code the culture map case using an existing
show a quantified type when I create a helper function to wrap things
it\textsf{'}s just putting it into the wrap is constantly the country funky
turquoise instance which does nothing but wrap into the typeclass
sorry into the in our case cost so there is no complete computation
done here other than memory allocations finally I write an interpreter
which is trivial you just run you do a controller and I implement
it producing coding reduced encoding is shorter he just has a single
case class with existential 25 type a wrapper for than a reduced encoding
now that wrapper is less trivial because we don't have the wrap case
anymore so wrapping a value of F means we have this reduced case when
we have we put this F here and we supply an identity function in this
place the control factor instance is stuck safe because we reduce
every function we don't apply map and you are we and I don't run anything
we just collect all these functions and we collect them in a stack
safely using this before method which is a stack safe alternative
to and then and here is a rather so we just run by extracting a value
of C out of the value of F and then running a contra map with the
single function that is left so that\textsf{'}s the example I just described
we have a logger with the prefix now the writer factor is going to
be wrapped in two star to make it into a country funky so we have
a free country founder over the writer function so the fact that it
is a factor is just I chosen us to show that I can take anything but
including the furniture that certainly is not a country function and
I can wrap it into this construction 3 CFR and the result is a contractor
so that\textsf{'}s an that\textsf{'}s an interesting property so the result is is a
contractor but if you look at the country factories type signature
it is say this it\textsf{'}s a contractor in being but it is no longer a functor
so even if the constructor that we used was a functor it is no longer
function and indeed so it\textsf{'}s a contractor indeed so we have we if we
do this we take a function like the right here function we wrap it
into American structure and we lose the factor for it\textsf{'}s a little bit
you know it is a country function just to make it clear what\textsf{'}s going
on and here is some example code where and have some prefix logger
and I wrap my writer function which could be computed after something
sound function computation that I wrap it in their country factor
then I do some contour map on it and the result can be used I interpret
that I run this thing and the result is as expected the next example
is a free pointed front kick a pointed funder is a flat class it has
a symbol method other than function so if we say that this is an arbitrary
type construction done that pointer factor pointed functor class has
two methods to the point which is this or it is just the same type
signature as the pure method and moanin an applicative but since this
is not going to be a monitor a negative this method is called point
it just takes a and inject stuff into p8 and map so this is familiar
so what\textsf{'}s the tree encoding of this well it\textsf{'}s just a so we follow
the recipe we have the wrapping yes we have the first method which
takes a few turns PA I have a second method which takes this in turns
so that\textsf{'}s how we encode so we have a disjunction with three parts
always going to be like this one part is going to be the wrapping
and the other parts correspond each to a metal in inductive typeclasses
are all going to be minus three encoded to derive the reduced encoding
we're going to have a bit more work need to do a bit more work we
see what kind of expressions can be found by using this definition
so we took we take the tree encode it and reason about it so either
we take an A and apply a bunch of maps to it so we first apply points
to some value you get an a value type a and then we apply some map
state so that would be one possibility another possibility that would
take some F a wrap it and then apply some maps to it so therefore
we only have two cases one is like this a general value of this type
will be either like this or like this well it also could be a single
affair or a single a but none of those so if we do have those things
we can compose all of them and just as we did before so we just have
one function one function is sufficient now consider the second case
we have a value and then a function we can just apply this function
to a value and we just have a single pure value so we can encode the
single pure value therefore and we can encode a function x sorry a
functor wrapped x a single function and if if we just have this we
put identity function in there as we did before there for the reduced
encoding has only two cases one is a pure value and the second is
this wrapped constructor times the function and it\textsf{'}s not recursive
so that\textsf{'}s very nice note that this is exactly the same as a free function
over F Z so basically this is what we have if the type constructor
F is already a functor then this is equivalent to F itself therefore
a three-pointed function over a functor is just this it is a very
simple expression so just adding the type a to a factor makes it into
a three-pointed so that becomes appointed and it\textsf{'}s actually free pointed
and of course if it is already pointed factor we should not use this
construction because then this would be not the same as a factor itself
so unlike other cases if we just saw I should not use a free construction
if a factor already has the pointed method only it functor and contra
fun to have the property that applying the free construction doesn't
change them all other typeclasses will change usually when you do
free type construction so for example free wound at over a moment
is not the same moment free pointed over a point that is not the same
function only factors and country functions pure factors pure country
funky typeclasses do not change under applying the free construction
let\textsf{'}s look at the code it\textsf{'}s very easy to implement this we need three
case classes that encapsulate these three parts and to implement this
we only need two his courses and in implementing the factor is very
similar except now we have a point case so in a point case we need
to implement the function by him so applying a map to the value of
this type will just need to apply that function to that type so consider
a pretty filterable now the filterable typeclass was explained in
chapter 6 it is not a class that is widely known so look at chapter
6 for more details it has two methods map and map ok so these are
the methods of of inductive kind or inductive type signature when
they return the type of know actually it\textsf{'}s sufficient to keep just
map upped because we can restore map from it so let\textsf{'}s not overdo things
and let\textsf{'}s just implement one method in the free construction since
we can easily get this out of this in other words if we have this
function and we can implement this function by substituting a going
to zero plus B yeah so the tree encoding has two cases very similar
to tree encoding on a three-factor you start here we have this type
signature if the F type constructor is already a function we can simplify
the tree encoding by using the identity the basic identity of existential
types and then we just obtained this recursive definition so we'll
get rid of the essential type and this recursive definition can be
visualized as an infinite disjunction like this so it\textsf{'}s F a F 1 plus
a F 1 plus 1 plus a and so on so clearly applying filter function
to this will give us this applying filter to this will give us this
so on so it\textsf{'}s this in this way it\textsf{'}s implementing the free filterable
in the green color now this is not the most economical encoding and
it reduced including actually is like this it is non recursive and
you can size in order to derive it we do the same procedure as we
did before these are we stay this is this should be essential like
25 not universal level correctly since lights now an arbitrary value
of this type in the tree encoding would be FA to which a bunch of
map opt have been applied so that will give you a product like this
now using the laws remember that these are composed using the class
like composition because these are of type a to option B so these
can be composed since option of the moment so that composition needs
to be done and it gives us a single function so that can be done and
if we just have a single affair with no function that will encoded
like this so we can still encode it so that\textsf{'}s going to be reduced
encoding and the most interesting simplification is when F is already
itself a factor then we'll use basic identity and we get F of 1 plus
a so the free filterable over F factor is just this you can just implement
a filter for any factor applied to an option so for any function f
f co-option of a is filterable and that\textsf{'}s a free filterable over a
functor and this is a free filterable over an arbitrary type constructor
so we see again that free filterable over f is not the same as f in
a very similar way we can construct filterable contra factors free
filter whole country hunters will not go into details about free filter
will control factors because that is completely analogous here\textsf{'}s the
code for the free filter will factor I'm just sure this is nothing
new in terms of how to implement existential types and recursive types
in three encoding introduced encode consider now Freeman and the moolaade
has two methods pure and flat map the map method can be recovered
and in this way we formulate inductive teleclass now just a comment
and we have seen in previous chapters that typeclasses can be formulated
in different ways you can for example cumulative monad as having methods
pure and flat map or you can do flatten instead of flat map but flatten
does not have the same power as pure and flat map because you cannot
restore a flat map from flatten so you would have to have map here
as a third method if you wanted to if you wanted to do a free one
over an arbitrary type constructor that is not itself already a factor
for the filterable there could be different ways of doing the definition
as well and for the implicit if there\textsf{'}s the different ways but what
we need is a set of methods that return the type that we are constraining
type itself and not something else and we need a set of methods that
are sufficient so without assuming that the function instance is already
given for example so that\textsf{'}s why would she was pure and flat map here
and we can recover map from that so now the tree encoding is very
similar so what we have before except now it has two places in which
we use the same type recursively free m and freedom so the reduced
encoding needs to be derived let\textsf{'}s derive it so first of all let\textsf{'}s
see what happens come on we use the tree encoding and create some
values of the free monotype first we can take this cut type constructor
and apply a few flat maps to it second we can take this constructor
which will appear when the playa few flatmap start but these are the
two possibilities if we take a pure value and apply a flat map to
it that can be simplified due to the laws of the minute so if you
take something else and apply two flat maps they also can be simplified
to a single flat map with a more complicated function here again this
is what social tivity load of the Bonett so therefore it is not necessary
to have many flat maps here they can all be collapsed to a single
flat map maybe with a more complicated function inside so so so then
clearly the first element in the product does not have to be a pure
that can also always be replaced so the first element in the product
is going to be F a or F C for some for some Z and then we have a single
flat map so we don't need more than one flat map however this does
not let us encode the pure value in without any flat maps applied
to it so that means we cannot just have one part of a disjunction
we need to we still need to keep this part of the disjunction that
we have here but we can eliminate a fee and we can eliminate one of
the recursive usages but not the second one so the reduced in chlorine
is still recursive it is somewhat shorter but it\textsf{'}s still recursive
now one comment is that recently the so-called final tagless style
of programming has become more known in a scale community has become
also known and has gotten into a few years before in my terminology
what is called final Tablas style is nothing more than the church
encoding of a free moment so you can do Church encoding of any type
and you can do free going out without a church encoding and if you
want you can do Georgian going over three mooner and you have a choice
you can charge encode this or you can Church encode this and that
could have different performance implications however just keep in
mind I'm not going to talk about final tagless because it\textsf{'}s not really
something specific or or special to jamuna\textsf{'}s or put the portal DSL
it\textsf{'}s just the church encoding of a free movement and you can choose
it for certain reasons or anything not choose it for other it is stack
safety is important I have just found that the church encoding of
a free factor is not stack safe and unless you use reduced encoding
first so you first reduce the improvement using the frontier laws
and the nutrition code the results and that can be made stack safe
most likely it\textsf{'}s similar with monads and because the three encoding
is twice recursive use of the type so that was probably going to prevent
you from being stuck safe this is difficult enough to make a stack
safe but may be possible certainly I would if I were to make a library
I would use reduced encoding and Church encode that as an option but
also provide non-church encoded reduced encoding of the free moment
as an option there\textsf{'}s almost never advantages in using a non reduced
encoding but there might be an advantage in a church encoding so again
let us consider what happens if you do a free Mon and over a functor
so you can actually save yourself a lot of trouble because if F is
a factor then we can use the identity which says that this expression
is equal to F of this which is this so now we get recursive definition
which is much simple which is a free monad over a factor so I would
also provide this as an option in the library because it\textsf{'}s so much
simpler and more efficient perhaps definition and also it shows you
that a free monad is different from the mana of itself if you just
substitute it into here warranty here so the free mode of Ramon odd
is not equivalent to that normal so don't do it as an exercise we
can ask what is a 3-1 out over a pointed functor so again all we need
to do is we need to start with 3 encoding and try to reduce it so
how do we reduce it well first we start with this clearly the pointed
factor doesn't mean this part of the disjunction and clearly we can
start with this encoding collapsing all those flat map functions into
one and the result is going to be this and that\textsf{'}s it we cannot really
simplify this because we don't have a pure encoded so we cannot say
oh let\textsf{'}s only have this case because we cannot encode a fade so we
don't have a permitted for free we have a pure method for F a itself
but not for free we have eliminated that so we cannot encode a failure
we cannot save us as part of the disjunction therefore this is the
reduced encoding we use again the identity for the existential type
to get F of this so therefore the reduced encoding is FA plus F of
this still record so going to be recursive free if free M of F is
FA plus this so that\textsf{'}s reduced encoding here is a code for the free
moment so you spend a lot of time on this let\textsf{'}s consider the free
plug ative which is an interesting tie class it has two methods we
choose pure and app because the other choice would be for example
wrapped unit and zip they do not return the type that we're constraining
so wrapped unit returns F of one not F of a and zip returns F of pair
a B but we cannot have that as a return targetnode type must be the
simple F a with no changes if it is not that and our typeclass is
not inductive so if the typeclass allows us to have a formulation
equivalent to the previous formulation of the typeclass such that
the new formulation contains only methods of inductive type signatures
that is methods that return the typeclass the instructor constraint
then it\textsf{'}s an inductive type cons so as before we think about which
methods to choose and which is pure and half because map can be recovered
from these so the tree encoding is straightforward and in order you
can have two usages of the recursive type let\textsf{'}s derive the reduced
encoding that\textsf{'}s going to be this so how do we derive that so we reason
about what structure of the values we will have either we take F a
and we apply a bunch of apps to it or we take a and apply bunch of
apps to it so we can encode if we have an a to which we apply we can
encode that as something like like this so we can do an app with a
pure here with a different type signature because that\textsf{'}s basically
it\textsf{'}s going basically going to be a Mac due to the laws of the zip
so it\textsf{'}s going to be equivalent to if free app on the Left just the
one that is on the right we'll put it on the left and on the right
we put some other thing so that means if the first one does not have
to be a pure well the first value in this product it does not have
to be a pure value it can always be wrapped F so but then we cannot
encode the pure value so we still need in that case so therefore we
need only two cases the pure value and the wrapped constructor with
a free app so that\textsf{'}s there for the reduced encoding a free applicative
over a factor is taken from here we use this representation and what
we find is that we cannot really reduce this using the identity for
the existential type because this is not of the form exists Z and
then F Z and Z goes to something it is not Z goes to something it
is a type constructor so therefore free applicative over a factor
it looks like this we can still reduce this but we do need to have
a rap constructor but the a is outside of the recursion so the only
game that we have is that if the type constructor F is already a functor
then the pure value is outside the recursion and other than that it\textsf{'}s
a very similar construction so first we construct the recursive case
which is which can be seen as a reduced encoding of freezy bubble
that is a type coins were only the ab method is given the no pure
so this is a freezie bubble and then we do any three pointed out of
that it\textsf{'}s a free pointed over a freezie bubble over a functor if and
we see that again free applicative over applicative is not the same
as that functor so here\textsf{'}s the code of the free applicative in the
trie encoding and introduced including so having gone through all
these examples let us generalize what our laws of the freetypeclass
constructions so we will consider a general inductive typeclass and
for simplicity we will not consider type constructors here only ordinary
types so the typeclass will have methods of this type signature but
you see all the examples we have seen have been inductive so it\textsf{'}s
going to be equivalent for them except is going to be much more syntax
for all these types of constructors and type parameters so I'm not
going to go through laws for type construction typeclasses they're
going to be my analogous up to a much more complicated syntax I'm
going to consider in inductive typeclasses that have just ordinary
types as elements of the or instances of that class so a typeclass
with a method functor c has these methods and this is the definition
of the three instance of c over c over a fixed type z so that\textsf{'}s we
have seen so there are several general properties that this construction
has i'm not going to consider church encoding because the church encoding
is equivalent to this it has exactly the same properties but it\textsf{'}s
much more complicated to reason about it\textsf{'}s just a much more complicated
type I'm going to use a recursive algebraic or polynomial definition
of the three type instance the first property is that this type is
actually an instance of typeclass C so in other words we can implement
these methods all the methods are summarized in a single value of
this type and so once we show that we can implement a value of this
type we're done we have implemented methods another property is that
it is a function in Z so it has an F map which works by changing the
generating type another property is that if we have a specific type
of that see we can implement these functions around and wrap so the
wrap will lift a value of Z into the freetypeclass instance and the
run will take a free typeclass instance it will also take this extractor
function which translates Z into P and then it can translate the entire
free instance entity these functions have certain laws the first law
is that run of the rap is identity so what does it mean um if we wrap
a value Z and then you run it then it\textsf{'}s the same as if you did not
wrap so he transforms e to the same P if you first just take Z to
P or you first wrap it and then you run it you get the same P so that\textsf{'}s
this law the second law is the natural allottee of run so the run
was this z type argument and in this type argument it is natural so
the naturality law as usual it is a lot of how to put F map outside
or inside of your function so this is typically an equation of this
sort you left map either the right hand side has no F mat board has
an F map on the other side so in this case it has no worth map here
is a type diagram so you start with a crease free instance of C over
Y you can transform it into a free C over Z using the F not function
f map of F f is an arbitrary transformation Y to Z and then you can
run this into P or you can run this into P and that shouldn't be different
so you can first run directly with the combine function or you can
run first by transforming into Z and then you can run from Z and it
should be exactly the same so that\textsf{'}s what this law specifies another
important property is the so called Universal property and this property
says that the Runner is universal you only have one runner so if you
have for example to run into two different types and the same runner
works for them in a way that is compatible so suppose you have two
types a and Q and you want to run into P and run into Q and there
is a function that transforms from P to Q well this function preserves
the typeclass so it\textsf{'}s not just an arbitrary transformation from P
to Q it\textsf{'}s a transformation that preserves the time class the property
of preserving the typeclass is this diagram which is that here is
the methods frontier of the typeclass and here\textsf{'}s the method for P
and here are the methods for Q and if you map P the Q and the methyls
are also mapped to each other so in other words for instance if the
class is a monoid then the function f must transform the unit element
of the mono would P into the unit element of the monomyth Q and it
must transform product in the P monoid into the product in the QM
owner so that\textsf{'}s automatically guaranteed by this diagram because the
ops value is already all the methods but all the metals put together
into a single so if the function f from P to Q satisfies this commutativity
condition then what I say it preserves the typeclass and for these
functions f you can see this diagram that you can run first into P
and then you transform into Q or you directly transform into Q and
that\textsf{'}s the same function run does it so that is another kind of property
that is it is quite important so let\textsf{'}s see how these properties can
be proved so first I will repeat the code for the universal construction
of a tree encoded typeclass now you noticed I have been using a tree
encoding here again this is the simplest encoding it is mechanically
produced does not require any reasoning in order to be implemented
whereas the reduced encoding requires some reasoning improves to show
that it is actually reduced and adequate for encoding all possible
values and so it\textsf{'}s much more difficult to reason about although it
can give you advantages in performance so that\textsf{'}s why I'm reasoning
about the tree in going here so I implemented the function ops that
basically says that the free typeclass has the methods that are required
for that typeclass C so the opposite of function from C all free to
free so that\textsf{'}s this function and that that\textsf{'}s the first one that I
need and put in this the second is that I can wrap that is trivial
I just put the wrap constructor then of that I can interpret interpreter
it\textsf{'}s just the general interpreter which we have seen I sure that it
is a functor well this is a simple exercise in making a functor instance
for a recursive type where I use the recursively the map function
in the hopes because obviously the recursive part of the type so the
first law is that um if we run on wrap let\textsf{'}s our identity on both
sides from the first law are functions of this type so therefore we
need to apply both functions on arbitrary value of this type so let\textsf{'}s
call this value free seasonally and also instead of this because we're
working in this type the runner needs an even argument of this obstacle
need to have the hopes for the free type constructor so that\textsf{'}s our
hopes you find above so if we do that and we substitute the code then
this is what we get now if we look at this this function must be identity
which means that it\textsf{'}s a free CZ match something in this match should
be just identity cases cases like this indeed they are identity the
rap case is just rap which is defined like this that\textsf{'}s the definition
of herbs and wrap so oops requires us to execute a recursive call
to the run and so we can use the induction assumption but run of ramp
is identity and that assumption can be applied to recursive calls
of the function that we are proving more for so therefore this is
identity so that\textsf{'}s a map on identity well that\textsf{'}s just observe C F
which is equal to that so that is again identity the second law is
a little more involved it\textsf{'}s a natural T now I could say well much
reality is obvious because our code doesn't look at an edit type but
we can prove this informally so again we look at two sides of this
equation the functions of this type so we apply both sides to an arbitrary
value of that type when we just substitute and compute the left-hand
side which is going to be this and run of that is going to be that
then we compute the right-hand side so we already see that the wrap
case is the same and water is what remains is to demonstrate that
the ops case is the same you know there is a slight difference between
these two expressions and the difference can be resolved because we
can use the induction assumption for this so we are proving the law
of this kind and we can use this law for the recursive call here so
if we do that we can assume this is true and then that\textsf{'}s exactly what
remains to be demonstrated that we can do the map so this is a functor
whose map for United we're using so we can use a composition law for
the function and that\textsf{'}s exactly the expression that we have here what
remains not equal that\textsf{'}s the composition of two maps so we simplify
that we get this so the universal property is slightly more involved
yet but it is proved in a similar way so both sides are functions
of this type so we apply both sides to an arbitrary value of type
faces E or compute the left hand side will contain the right hand
side and we use the typeclass preserving property which is this equation
or it will only written in a scholar corner to space equation so when
we have F of ops P we replace that with upscale of something so oops
P and obscure are assumed to be available now these are typeclass
evidence for P and Q and simplifying the code we put the code until
identical shape so that leaves us home proof from the laws now what
she would call that I have here that code is for the next slide so
another general thing we can do the free typeclass is that we can
combine different generating instructors so far we have been only
looking at a free instance of a typeclass C generated by a single
type Z but we can also consider several constructors at the same time
several generating types of constructors and this would correspond
in a monadic DSL that we have different sets of operations that are
defined separately we would like to combine them and recall that monads
did not compose in general so it is in general not easy to compose
different sets of operations but it is actually easy in the free typeclass
because all you need to do is to take a disjunction since the definition
of the free typeclass is this if you have several generating types
all you need to do is to have several parts of the disjunction here
Z 1 plus Z 2 plus Z 3 and so on which means that the free instance
of C over several constructor is the same as the free instance of
C over the disjunction of these constructors so it is sufficient to
take the disjunction and generate the free type cause using a disjunction
now the only inconvenience is that you would need to inject parts
into the disjunction that it can become cumbersome I will show called
in a minute and the church encoding actually makes it easier to manage
this situation so the reason is that the church encoding for an inductive
typeclass it looks like yes if you have several constructors and it
will be like this you can take the junction and transform it into
this sort of expression now you can do the trick of type questions
so you can encode each of these as extractor typeclass and then the
church encoding would look like this and you can even simplify it
further by saying that even this is a typeclass constraint on X which
means that X must be of type C and so the church encoding would look
like this so in this in this form it is an easier code to maintain
at the same time we find that this definition actually works for any
number of generators and for any typeclass C it\textsf{'}s a general formula
for Church encoded free instance of class typeclass C and generated
by any number of given types so in this very concise form it\textsf{'}s very
easy to implement as well let\textsf{'}s see how this works in order to test
this I have three type constructors that are not functions in other
words unfactored and they describe different kinds of operations in
some kind of imaginary business project the first one factor adds
a name care database and returns a database ID and it gets named by
second and funky logs a message returns unit a third on factor creates
a new ID so these are just for example and I defined generic transformations
from each of these unfactored to the option factor these are just
defined in arbitrary ways for testing purposes only this is not useful
for any kind of application this kind of transformation which are
none a lot nicer just testin I testing that all the types fit together
so the first way of combining the three operation constructors I'm
going to put them into a three factor and as we have seen all I need
to do is I need to take a disjunction of all these constructors so
let me define this unfold as a disjunction of the three type constructors
now I also need to define a generic transformation from the new function
to option let me put the syntax a little easier like this now notice
that I need to write this column in this code this code is pure boilerplate
but it depends on how I defined my unfunny here if I add another one
then this entire core don't have to be reversed and this is kinda
this is a bit of a burden now defining a free function in the reduced
encoding is straightforward in order to use it I need to lift values
from each of the unfactored into the free function so I define these
lifting functions and again I have boilerplate that depends on how
the order of disjunction is chosen now this is an example computation
where I require this type annotation in order to lift I could have
called these functions directly : over keys I could have called them
directly where I can do this but I have to do it so let\textsf{'}s see how
the same works in the church encoding so first I define an extractor
typeclasses and then I define the church encoding this is the entire
church including it has a type parameter G and then there are three
type constraints for each of the unfactored extractors and then a
function type constraint and I've done this is the entire encoding
the furniture instance is trivial but it is not stock safe unfortunately
because we know that the church including of the three encoding over
three frontier is not stack safe now the boilerplate for lifting does
not depend on the order of the heart functions there\textsf{'}s no notion of
order anywhere if I need the first one I can just add it here here
here and here there\textsf{'}s no possibility of making a mistake there and
finally I run the computation the extractors are need to declare and
see there is the run is very simple I don't need an extra brother
I have less code {[}Music{]} another important thing that we can do
is combining different trade type process so suppose you have two
different hypotheses C 1 and C 2 and you want to combine them several
ways of doing that and one is to use factor composition so for example
I can do 3 C 1 over a 3 C 2 over Z I can do that there are disadvantages
in doing this one big disadvantage is that the order of composition
actually matters in terms of what semantics I get if these type assets
return effects and the effects are combined and nested in this order
and not in the opposite order so I would not be able to encode this
order of nesting I must encode always miss order of nesting and of
course all the operations that I want to execute in situ need to be
lifted through the factor C 1 I can do it because it\textsf{'}s a factor as
we have seen and this only works for inductive typeclasses of course
well that is not a big limitation perhaps since most of our typeclasses
are inductive not all for example traversable is not inductive so
there is no free traversable that can be encoded in this way but these
are significant disadvantages most importantly we are not free to
encode arbitrary nesting of effects the second option is to use the
disjunction of method factors and then you build the free typeclass
instance using this C in other words you make a new typeclass that
has all the methods of the previous hypothesis disjunction of method
functors is equivalent to conjunction of the f-typeclass evidence
families because type costs evidence values are of type function CX
to X and so this disjunction is equivalent to taking a conjunction
of those functions so that\textsf{'}s the same as building one big type ones
with all the methods put together now this is of course not ideal
because you would have to change the code if you wanted to combine
different typeclasses but church encoding can give you this combination
for free because all you need to do is to write this kind of type
and then obviously this was just a product of c1 c2 so you have this
formula where you can put different typeclasses here and different
in your use here and so the church encoding automatically gives you
a way to have a way of having a free typeclass instance for any combination
of typeclasses and any combination of generators it\textsf{'}s a very powerful
mechanism let\textsf{'}s consider just two examples one is for curiosity what
if we combine the filter in the control function we would have a typeclass
that is at once a function and the control factor and that\textsf{'}s possible
we can do it the question is what do you do with this class because
this class is going to be free encoding so you need to interpret it
into some specific class typeclass so you could probably interpret
it in a pro factor although I don't know what is the use case for
this a better example is to combine munna and applicative this is
actually useful in practice because ma not an applicative encode slightly
different kind of effects monad encodes sequential effects look at
them encodes effects that are partially parallel so not necessarily
completely independent but the effect parts can be run in Kerala so
computation with applicative factor can be paralyzed very easily but
computations with monads cannot be paralyzed because they are sequentially
the next step depends on the value of the previous step and the effect
also depends on the value of the previous step so you cannot start
running the effect before you know the value but with a quick edit
of you can now ordinarily a monad also has an applicative instance
however in Sun walnuts in other words you can implement zip if you
have flat map but in some walnuts there is a non-standard implementation
of zip that has specific advantages in other words an implementation
of zip that is not equal to that which you get out of a flat map and
you do that for specific reasons either for performance so it could
it could give you the same results but it will run effects differently
and will have different performance for example imagine that you have
a future monad and the zip can be implemented as parallel execution
of futures and flatmap is implemented as sequential execution of futures
so if you combined monad and duplicative in the freetypeclass and
interpreted that pi plus into a future such that the monadic methods
the flat map are converted into flat map in the future but applicative
methods are converted into parallel execution of futures using a special
code then you get an advantage because each zip or create fellow branches
in each flat mark sequential branches so let\textsf{'}s see how that works
in some example code so here\textsf{'}s the encoding of the free monad and
applicative at the same time so I put them into one typeclass for
simplicity I could have done it differently you could have done it
using the church including the real is right before but this is more
interesting because you can see how you would run a combined frame
on a duplicative over a type constructor G that has both applicative
and one on instances the way you would do that is that all you would
translate of course wrapping to wrap here into pure flatmap you would
translate like this you would run and then you run this you so you
run the flat map in the target unit but the applicative you know that
you translate like this you run in parallel and then you combine them
using an applicative method in the model so you see this run is not
in peril because this is inside the function which is this function
which will be called only inside the flat map after the first effect
is finished but these two effects are going to be run in parallel
so if I implement the interpreter like this and I will automatically
translate all the applicative operations into parallel executions
potentially parallel executions let\textsf{'}s see for example for future I
just translate the same into futures and this is actually going to
be pair execution of futures because we know what\textsf{'}s calendars once
you have a future it already is scheduled and run I give it an execution
context and it\textsf{'}s already run so in this way I can have so I don't
have the typeclass instances for functor monad it\textsf{'}s more or less boilerplate
I just do a little bit of simplification it\textsf{'}s not important most so
let me just skip this and then here is my DSL I have some operations
I make a free monad out of it which is at the same time a free applicative
and then I run it through the future so I can run my code melodically
so this is nomadic code the lift is a just method that I defined to
make it quicker to lift things it\textsf{'}s a wrapper so basically I generate
an ID when I generate three new IDs and I validate them in parallel
and I wait until all of this validation is done and I close the session
so this is a combination of melodic and wicked methods at the same
time the interpreter is just some translating these into specific
business logic that I imagined and this is all for a less boilerplate
so basically when I run this computations computations of course just
a pure value doesn't do anything it\textsf{'}s a pure data structure that describes
what needs to be done but when I run this computation and automatically
all these zipped parts become executed in parallel but all the mimetic
parts are executed sequentially and I can I don't need to worry about
the order of these things I can nest them in any way want for example
I could define first validate using monadic the line I combine different
validates using applicative and I again put the results into a monadic
context it\textsf{'}s fine it\textsf{'}s all working it all works in arbitrary order
this is what I was indicating here and this is an advantage over this
method the frankly composition where I would have to choose whether
I have moon add outside applicative inside or more not inside applicative
outside and whatever I choose I can only then encode one of those
combinations so this concludes this chapter and here are some exercises
for making your dream code introduced in coding and working with inductive
typeclasses implement an idea cells implementing the church encoding
simplifying quantified types and deriving a reduced encoding color
of a tree encoding for different cases this concludes chapter tune 
\end{comment}

